[{"id": "1", "question": {"enus": "使用阿里云智能语音交互产品的长文本语音合成功能时，需调用对应接口。下列关于长文本语音合成的交互过程描述中错误的是（）。", "zhcn": "使用阿里云智能语音交互产品的长文本语音合成功能时，需调用对应接口。下列关于长文本语音合成的交互过程描述中错误的是（）。"}, "option": [{"option_text": {"enus": "交互过程首先是鉴权，即客户端在与服务端建立Web Socket连接时", "zhcn": "交互过程首先是鉴权，即客户端在与服务端建立Web Socket连接时"}, "option_flag": false}, {"option_text": {"enus": "正式合成前客户端发送语音合成请求，在请求消息中需进行参数设置", "zhcn": "正式合成前客户端发送语音合成请求，在请求消息中需进行参数设置"}, "option_flag": false}, {"option_text": {"enus": "合成过程中服务端的响应除了音频流之外，都会在返回信息的header包含本次识别任务的task_ id参数", "zhcn": "合成过程中服务端的响应除了音频流之外，都会在返回信息的header包含本次识别任务的task_ id参数"}, "option_flag": false}, {"option_text": {"enus": "服务端返回合成的语音二进制数据， 客户端发送合成完毕事件通知", "zhcn": "服务端返回合成的语音二进制数据， 客户端发送合成完毕事件通知"}, "option_flag": true}], "analysis": {"enus": "使用阿里云的智能语音交互功能的交互流程是：\n1.鉴权：客户端在与服务端建立WebSocket连接时，使用Token进行鉴权；\n2.开始合成：客户端发送语音合成请求，在请求消息中进行参数设置，各参数通过SDK中SpeechSynthesizer对象的相关set方法设置；\n3.接收合成数据：服务端返回合成的语音二进制数据，SDK接收并处理二进制数据；\n4.结束合成：语音合成完毕，服务端发送合成完毕事件通知，示例如下 { \"header\":{ \"namespace\":\"SpeechLongSynthesizer\", \"name\":\"SynthesisCompleted\", \"status\":20000000, \"message_id\":\"396c80b3abf84082a48cb9e5c424****\", \"task_id\":\"f5805be640364cdcafc8da63e512****\", \"status_text\":\"Gateway:SUCCESS:Success.\" } }，\n由此可以看出除了音频流都会在header中返回相应信息。因此&ldquo;服务端返回合成的语音二进制数据， 客户端发送合成完毕事件通知&rdquo;错误，是在服务端发送合成完毕的事件通知。\n<a href=\"https://help.aliyun.com/document_detail/429509.html#section-71l-w2b-73m\">https://help.aliyun.com/document_detail/429509.html#section-71l-w2b-73m</a>", "zhcn": "我们先分析一下题目中描述的阿里云长文本语音合成（TTS）的交互过程，然后判断哪个选项是错误的。  \n\n**长文本语音合成（基于 WebSocket 协议）的一般流程：**  \n\n1. **建立连接与鉴权**  \n   - 客户端通过 WebSocket 连接到服务端 URL，并在 URL 中带上鉴权参数（token 或 AK/SK 签名），所以 **[A]** 说“交互过程首先是鉴权，即客户端在与服务端建立 Web Socket 连接时”是正确的。  \n\n2. **发送合成请求**  \n   - 连接成功后，客户端发送一个开始请求（Start 指令），包含文本和合成参数（发音人、语速等），所以 **[B]** 说“正式合成前客户端发送语音合成请求，在请求消息中需进行参数设置”是正确的。  \n\n3. **服务端返回数据**  \n   - 服务端先返回一个 TaskStarted 响应，header 中包含 `task_id`，用于标识本次任务。  \n   - 之后服务端发送二进制音频数据（BinaryMessage），可能分多个包发送。  \n   - 除了音频流（BinaryMessage）外，其他控制消息（如 TaskStarted、SentenceBegin、SentenceEnd 等）都会在 header 中包含 `task_id`，所以 **[C]** 说“合成过程中服务端的响应除了音频流之外，都会在返回信息的 header 包含本次识别任务的 task_id 参数”是正确的。  \n\n4. **合成结束**  \n   - 服务端发送完所有音频后，会发送一个合成结束事件（Completion 消息）。  \n   - 客户端收到后，可以关闭连接或发送新的请求。  \n   - 选项 **[D]** 说“服务端返回合成的语音二进制数据，客户端发送合成完毕事件通知” —— 这里错误在于，**“客户端发送合成完毕事件通知”** 并不是标准流程，实际上是服务端发送合成完毕事件，客户端是被动接收结束事件的一方。  \n\n因此，错误的描述是 **[D]**。  \n\n**答案：D** ✅"}, "answer": "D"}, {"id": "2", "question": {"enus": "基于网格的聚类算法中，（）算法采用小波分析方法，使簇的边界变得更加清晰。", "zhcn": "基于网格的聚类算法中，（）算法采用小波分析方法，使簇的边界变得更加清晰。"}, "option": [{"option_text": {"enus": "STING", "zhcn": "STING"}, "option_flag": false}, {"option_text": {"enus": "CURE", "zhcn": "CURE"}, "option_flag": false}, {"option_text": {"enus": "CLIQUE", "zhcn": "CLIQUE"}, "option_flag": false}, {"option_text": {"enus": "WaveCluster", "zhcn": "WaveCluster"}, "option_flag": true}], "analysis": {"enus": "STING：基于网格多分辨率，将空间划分为方形单元，对应不同分辨率；\nCURE：采用层次聚类的算法，选择基于质心和基于代表对象方法之间的中间策略；\nCLIQUE：结合网格和密度聚类的思想，子空间聚类处理大规模高维度数据；\nWaveCluster：用小波分析使簇的边界变得更加清晰，因此选&ldquo;WaveCluster&rdquo;。", "zhcn": "您给出的题目和答案是完全正确的。\n\n**正确答案是： [D] WaveCluster**\n\n下面是详细的答案解析：\n\n**1. 题目核心考点**\n这道题考察的是对**基于网格的聚类算法** 的了解，特别是对**WaveCluster**算法核心思想的掌握。关键词是“**小波分析方法**”和“**使簇的边界变得更加清晰**”。\n\n**2. 选项分析**\n\n*   **[A] STING：** STING是一种基于网格的多分辨率聚类算法，它将数据空间划分为矩形的网格单元，并存储这些单元的统计信息（如计数、均值、标准差等）。它通过自顶向下的查询方式进行聚类。STING的**核心是统计信息网格**，而不是小波变换。\n*   **[B] CURE：** CURE是一种**基于层次**的聚类算法。它的核心思想是使用多个点来代表一个簇，并通过收缩这些代表点向簇中心移动来识别非球形的簇。它**完全不基于网格**，也**不使用小波分析**。\n*   **[C] CLIQUE：** CLIQUE是一种结合了**基于密度**和**基于网格**的聚类算法，主要用于高维数据。它的核心是自动识别数据空间中高密度的子空间（网格单元）。CLIQUE的**核心是密度和维数增长性**，而不是小波变换。\n*   **[D] WaveCluster：** WaveCluster是典型的**基于网格**并**使用小波变换**的聚类算法。它的工作流程是：\n    1.  **量化空间**：将数据空间划分为网格单元。\n    2.  **生成特征（密度）矩阵**：为每个网格单元分配一个值（如该单元内数据点的数量），形成一个多维信号（或图像）。\n    3.  **应用小波变换**：对这个密度矩阵应用离散小波变换。小波变换具有**多分辨率分析**和**去噪**的能力，能够有效地区分信号（高密度区域，即簇）和噪声（稀疏数据点）。\n    4.  **寻找相连的组件**：在变换后的小波空间中，寻找相连的高值区域，这些区域就对应着原始数据空间中的簇。\n\n**3. 为什么WaveCluster是正确答案？**\n\n小波变换能够过滤掉数据中的噪声和细微的波动，同时保留和增强数据分布的主要模式（即簇的轮廓）。这个过程就像对一张模糊的图片进行锐化处理，使得图片中物体的边界变得更加清晰。因此，WaveCluster算法通过小波分析，能够非常有效地识别出任意形状的簇，并使簇的边界变得清晰。\n\n**总结：**\n\n在基于网格的聚类算法中，**WaveCluster**是唯一一个明确将**小波变换**作为其核心技术的算法，其设计目的正是为了利用小波的多分辨率特性来清晰地定义簇的边界。因此，选项D是唯一正确的答案。"}, "answer": "D"}, {"id": "3", "question": {"enus": "在视觉智能模型训练的图像预处理中，关于图像增强的目的描述正确的哪项？", "zhcn": "在视觉智能模型训练的图像预处理中，关于图像增强的目的描述正确的哪项？"}, "option": [{"option_text": {"enus": "提升图像的清晰度", "zhcn": "提升图像的清晰度"}, "option_flag": false}, {"option_text": {"enus": "改正图像采集系统的系统误差", "zhcn": "改正图像采集系统的系统误差"}, "option_flag": false}, {"option_text": {"enus": "抑制不感兴趣的特征", "zhcn": "抑制不感兴趣的特征"}, "option_flag": true}, {"option_text": {"enus": "改正图像采集仪器位置的随机误差", "zhcn": "改正图像采集仪器位置的随机误差"}, "option_flag": false}], "analysis": {"enus": "图像超分：提升图像的清晰度；\n<a href=\"https://help.aliyun.com/document_detail/151947.html\">https://help.aliyun.com/document_detail/151947.html</a>\n几何变换用于改正图像采集系统的系统误差和仪器位置的随机误差所进行的变换；\n图像增强是对图像中的信息有选择地加强和抑制，以改善图像的视觉效果，因此&ldquo;抑制不感兴趣的特征&rdquo;正确。", "zhcn": "你给出的题目和参考答案是匹配的。  \n\n**逐步分析：**  \n\n1. **图像增强**在视觉智能模型训练中，通常是为了改变图像的某些属性，以增加数据的多样性或突出某些特征，从而提高模型的泛化能力。  \n2. **[A] 提升图像的清晰度**  \n   - 这属于图像质量改善的一种，但并不是图像增强在模型训练中的主要目的。清晰度提升只是增强的一种可能手段，而不是根本目的。  \n3. **[B] 改正图像采集系统的系统误差**  \n   - 这属于图像校正（calibration/rectification），不是数据增强的主要目的。  \n4. **[C] 抑制不感兴趣的特征**  \n   - 图像增强技术有时会通过调整对比度、亮度、颜色或滤波来突出感兴趣区域，同时抑制不感兴趣的特征，这有助于模型关注关键信息。  \n5. **[D] 改正图像采集仪器位置的随机误差**  \n   - 这属于几何校正，也不是图像增强的主要目的。  \n\n在深度学习的图像预处理中，**图像增强**（如对比度拉伸、直方图均衡化、滤波去噪等）的一个常见作用就是**抑制不感兴趣的特征或噪声**，让模型更关注有用的信息。  \n\n因此，正确答案是 **[C]**。"}, "answer": "C"}, {"id": "4", "question": {"enus": "关于阿里云自然语言处理服务API的返回参数，下列选项错误的是（）。", "zhcn": "关于阿里云自然语言处理服务API的返回参数，下列选项错误的是（）。"}, "option": [{"option_text": {"enus": "每次接口调用，成功会返回一个唯一识别码Requestld，失败则不返回Requestild", "zhcn": "每次接口调用，成功会返回一个唯一识别码Requestld，失败则不返回Requestild"}, "option_flag": true}, {"option_text": {"enus": "可以在发送请求时指定返回的数据格式", "zhcn": "可以在发送请求时指定返回的数据格式"}, "option_flag": false}, {"option_text": {"enus": "返回HTTP状态码为2xx表示调用成功", "zhcn": "返回HTTP状态码为2xx表示调用成功"}, "option_flag": false}, {"option_text": {"enus": "返回HTTP状态码为4xx或5xx表示调用失败", "zhcn": "返回HTTP状态码为4xx或5xx表示调用失败"}, "option_flag": false}], "analysis": {"enus": "API返回结果采用统一格式，调用成功返回的数据格式有XML和JSON两种，可以在发送请求时指定返回的数据格式，默认为XML格式。\n每次接口调用，无论成功与否，系统都会返回一个唯一识别码RequestId。\n返回2xxHTTP状态码表示调用成功。\n返回4xx或5xxHTTP状态码表示调用失败。\n<a href=\"https://help.aliyun.com/document_detail/145074.html\">https://help.aliyun.com/document_detail/145074.html</a>", "zhcn": "我们来逐项分析题目中的选项。  \n\n---\n\n**[A] 每次接口调用，成功会返回一个唯一识别码 RequestId，失败则不返回 RequestId**  \n- 阿里云 API 通常无论成功还是失败，都会返回一个 RequestId 用于跟踪请求，失败时也会在响应头或错误信息里包含 RequestId。  \n- 所以“失败则不返回 RequestId”是错误的。  \n\n**[B] 可以在发送请求时指定返回的数据格式**  \n- 阿里云 API 一般支持通过 `Accept` 头或 `Format` 参数指定返回格式（如 JSON、XML），这是正确的。  \n\n**[C] 返回 HTTP 状态码为 2xx 表示调用成功**  \n- 符合 HTTP 语义，正确。  \n\n**[D] 返回 HTTP 状态码为 4xx 或 5xx 表示调用失败**  \n- 4xx 是客户端错误，5xx 是服务端错误，都表示调用失败，正确。  \n\n---\n\n因此，错误的选项是 **A**。  \n\n**最终答案：**  \n```\nA\n```"}, "answer": "A"}, {"id": "5", "question": {"enus": "下列深度学习框架中，最早发布和广泛使用的开源深度学习框架是（）。", "zhcn": "下列深度学习框架中，最早发布和广泛使用的开源深度学习框架是（）。"}, "option": [{"option_text": {"enus": "Tensorflow", "zhcn": "Tensorflow"}, "option_flag": false}, {"option_text": {"enus": "Caffe", "zhcn": "Caffe"}, "option_flag": true}, {"option_text": {"enus": "MXNet", "zhcn": "MXNet"}, "option_flag": false}, {"option_text": {"enus": "Pytorch", "zhcn": "Pytorch"}, "option_flag": false}], "analysis": {"enus": "Tensorflow开源时间是在2015年9月，Caffe开源时间是在2013年9月，Mxnet开源时间是在2015年5月，pytorch开源时间是在2017年1月，因此选“Caffe”。", "zhcn": "我们先来梳理一下这几个框架的发布时间线：  \n\n- **Caffe**：由伯克利 AI 研究中心（BVLC）开发，2013 年底开源，早期在图像分类领域非常流行，尤其是支持 C++/CUDA，模型库丰富。  \n- **TensorFlow**：由 Google 基于 DistBelief 重构，2015 年 11 月开源。  \n- **MXNet**：起源于 2014 年的 cxxnet 等，2015 年命名为 MXNet 并开源，2016 年得到亚马逊支持。  \n- **PyTorch**：由 Facebook 基于 Torch 库（Lua 语言）重构，2016 年 10 月测试版，2017 年 1 月正式版。  \n\n从“最早发布和广泛使用的开源深度学习框架”来看，Caffe 在 2013 年就已经在学术界和工业界（尤其是计算机视觉）被广泛使用，早于 TensorFlow 两年左右。  \n\n因此正确答案是 **B**。"}, "answer": "B"}, {"id": "6", "question": {"enus": "阿里云机器学习PAI提供了PAI-AutoLearning自动学习建模方式，PAI-AutoLearning通过与以下（）模型对接，可以快速将训练模型部署为RESTful服务。", "zhcn": "阿里云机器学习PAI提供了PAI-AutoLearning自动学习建模方式，PAI-AutoLearning通过与以下（）模型对接，可以快速将训练模型部署为RESTful服务。"}, "option": [{"option_text": {"enus": "PAI-EAS模型在线服务", "zhcn": "PAI-EAS模型在线服务"}, "option_flag": true}, {"option_text": {"enus": "PAI-Studio可视化建模", "zhcn": "PAI-Studio可视化建模"}, "option_flag": false}, {"option_text": {"enus": "PAI-DSW交互式建模", "zhcn": "PAI-DSW交互式建模"}, "option_flag": false}, {"option_text": {"enus": "PAI-DCL云原生深度学习训练", "zhcn": "PAI-DCL云原生深度学习训练"}, "option_flag": false}], "analysis": {"enus": "AutoLearning是一个自动机器学习平台，支持在线标注、自动模型训练、超参优化及模型评估。您只需要准备少量标注数据，并设置训练时长，就可以得到深度优化的模型。同时，AutoLearning与PAI-EAS高效对接，从而可以快速将训练模型部署为RESTful服务。\n<a href=\"https://help.aliyun.com/document_detail/110985.html\">https://help.aliyun.com/document_detail/110985.html</a>", "zhcn": "**正确答案：[A] PAI-EAS模型在线服务**\n\n**答案解析：**\n\nPAI-AutoLearning 是阿里云机器学习平台 PAI 提供的自动学习服务，旨在降低机器学习的门槛，让用户无需编写代码即可完成模型训练。其核心流程包括数据准备、自动训练、模型评估和**一键部署**。\n\n在模型部署阶段，PAI-AutoLearning 通过与 **PAI-EAS（Elastic Algorithm Service）** 进行无缝对接，可以将训练好的模型快速、便捷地部署为高性能、可弹性伸缩的 RESTful API 服务。用户通过简单的配置，即可将模型发布到生产环境，供其他应用程序调用。\n\n其他选项分析：\n*   **[B] PAI-Studio可视化建模**：这是一个通过拖拽组件方式进行模型设计和训练的可视化平台，是 PAI-AutoLearning 的并列服务，而非其部署对接的目标。\n*   **[C] PAI-DSW交互式建模**：这是一个面向开发者和数据科学师的云原生交互式编程环境（类似Jupyter Notebook），用于代码开发和实验，不是用于部署服务的模型。\n*   **[D] PAI-DCL云原生深度学习训练**：这是一个专注于大规模深度学习训练的任务平台，同样不是用于模型在线部署的服务。\n\n因此，能够快速将 PAI-AutoLearning 训练的模型部署为 RESTful 服务的对接模型是 **PAI-EAS**。"}, "answer": "A"}, {"id": "7", "question": {"enus": "阿里云机器学习平台PAI中PAI-DSW建模，在存储空间不足的情况下，需要购买（）存储挂载到DSW实例。", "zhcn": "阿里云机器学习平台PAI中PAI-DSW建模，在存储空间不足的情况下，需要购买（）存储挂载到DSW实例。"}, "option": [{"option_text": {"enus": "大数据计算服务MaxCompute", "zhcn": "大数据计算服务MaxCompute"}, "option_flag": false}, {"option_text": {"enus": "表格存储TableStore", "zhcn": "表格存储TableStore"}, "option_flag": false}, {"option_text": {"enus": "对象存储OSS", "zhcn": "对象存储OSS"}, "option_flag": false}, {"option_text": {"enus": "文件存储NAS", "zhcn": "文件存储NAS"}, "option_flag": true}], "analysis": {"enus": "PAI-DSW实例默认提供的系统盘为临时存储，在停止或删除实例后，系统会清空数据。如果需要永久化存储数据，则需要挂载自己NAS，所有的NAS文件均存储在/nas目录，可以通过PAI-DSW Terminal进入该目录查看并使用文件。因此选&ldquo;NAS&rdquo;。\n<a href=\"https://help.aliyun.com/document_detail/311161.htm?spm=a2c4g.11186623.0.0.31b619e62jkh6X#task-2109980\">https://help.aliyun.com/document_detail/102789.html#section-hoc-6xx-n90</a>", "zhcn": "您的答案和解析是正确的。\n\n**正确答案是： [D] 文件存储NAS**\n\n**详细解析如下：**\n\n在阿里云机器学习平台PAI中，PAI-DSW（Data Science Workshop）为数据科学家提供了一个交互式的云端开发环境。当DSW实例的本地系统盘存储空间不足时，用户需要挂载额外的云存储来扩展存储容量。\n\n各个选项的分析：\n\n*   **[A] 大数据计算Service MaxCompute**： 这是一个大规模、全托管的数据仓库和计算平台，主要用于离线、批量的数据处理和分析。它不是一个可以直接像硬盘一样“挂载”到操作系统上的存储系统，因此不适用于此场景。\n*   **[B] 表格存储TableStore**： 这是一种NoSQL数据存储服务，适用于存储海量的结构化或半结构化数据，如订单、日志、消息等。它通过API进行访问，不能被挂载为文件系统。\n*   **[C] 对象存储OSS**： 这是一种海量、安全、低成本的云存储服务，适合存储图片、视频、文档、备份等非结构化数据。虽然DSW支持直接读写OSS上的数据（通常通过SDK或命令行工具），并且也可以通过一些特定方式（如OSSFS）将其挂载为文件系统，但这并非官方推荐给DSW用于扩展工作空间的标准或最佳实践。其性能（尤其是小文件读写和延迟）不如文件存储NAS。\n*   **[D] 文件存储NAS**： 这是一种可共享、弹性扩展、高可靠的分布式文件系统。它支持标准的文件访问协议（如NFS），可以像本地硬盘一样非常方便地挂载到DSW实例上。挂载后，用户可以在DSW的开发环境中像操作本地文件夹一样直接读写NAS中的文件，非常适合存储代码、大型数据集、模型文件、检查点等需要频繁读写的机器学习相关数据。因此，**当DSW本地存储不足时，购买并挂载文件存储NAS是标准且推荐的解决方案**。\n\n**总结：**\n文件存储NAS提供了标准的文件系统接口，与DSW的集成最自然、最便捷，是扩展DSW存储空间的首选。"}, "answer": "D"}, {"id": "8", "question": {"enus": "下列关于阿里云机器学习PAI-EAS在线模型服务的说法中，描述错误的是（）。", "zhcn": "下列关于阿里云机器学习PAI-EAS在线模型服务的说法中，描述错误的是（）。"}, "option": [{"option_text": {"enus": "支持在线标注、自动模型训练、超参优化及模型评估", "zhcn": "支持在线标注、自动模型训练、超参优化及模型评估"}, "option_flag": true}, {"option_text": {"enus": "支持基于异构硬件(CPU和GPU)的模型加载和数据请求的实时响应", "zhcn": "支持基于异构硬件(CPU和GPU)的模型加载和数据请求的实时响应"}, "option_flag": false}, {"option_text": {"enus": "用户可以将模型快速部署为RES Tful API, 通过HTTP请求的方式调用该服务", "zhcn": "用户可以将模型快速部署为RES Tful API, 通过HTTP请求的方式调用该服务"}, "option_flag": false}, {"option_text": {"enus": "提供的弹性扩缩和蓝绿部署", "zhcn": "提供的弹性扩缩和蓝绿部署"}, "option_flag": false}], "analysis": {"enus": "为实现一站式算法应用，PAI针对在线推理场景提供了在线预测服务PAI-EAS（Elastic Algorithm Service）。\n支持将模型服务部署在公共资源组或专属资源组，实现基于异构硬件（CPU和GPU）的模型加载和数据请求的实时响应。\n通过PAI-EAS，您可以将模型快速部署为RESTful API，再通过HTTP请求的方式调用该服务。\nPAI-EAS提供的弹性扩缩容和蓝绿部署等功能，可以支撑您以较低的资源成本获取高并发且稳定的在线算法模型服务。\n同时，PAI-EAS还提供了资源组管理、版本控制及资源监控等功能，便于将模型服务应用于业务。\n阿里云机器学习PAI-EAS在线模型服务的使用前提是已获得训练好的模型，而&ldquo;支持在线标注、自动模型训练、超参优化及模型评估&rdquo;是训练阶段需要的内容，因此&ldquo;支持在线标注、自动模型训练、超参优化及模型评估&rdquo;不正确。\n<a href=\"https://help.aliyun.com/document_detail/113696.html\">https://help.aliyun.com/document_detail/113696.html</a>", "zhcn": "我们来逐项分析题目中的选项：  \n\n**[A] 支持在线标注、自动模型训练、超参优化及模型评估**  \n- 在线标注、自动模型训练、超参优化、模型评估这些功能通常属于 PAI-Studio（或 PAI-DSW 及 AutoML 等模块）的功能，而不是 **PAI-EAS（弹性推理服务）** 的主要功能。  \n- EAS 的核心是模型部署与在线推理服务，并不直接提供在线标注、训练等完整建模流程。  \n- 因此这一描述与 EAS 定位不符，属于错误描述。  \n\n**[B] 支持基于异构硬件(CPU和GPU)的模型加载和数据请求的实时响应**  \n- EAS 确实支持 CPU/GPU 资源选择，并保证低延迟推理，正确。  \n\n**[C] 用户可以将模型快速部署为 RESTful API，通过 HTTP 请求的方式调用该服务**  \n- 这是 EAS 的核心功能，正确。  \n\n**[D] 提供的弹性扩缩和蓝绿部署**  \n- EAS 支持弹性伸缩和蓝绿发布，正确。  \n\n所以错误的选项是 **A**。  \n\n**答案：A** ✅"}, "answer": "A"}, {"id": "9", "question": {"enus": "现有一组图片要根据图片内容分类，比如建筑、汽车等等。使用阿里云视觉智能平台的以下哪种能力可以实现这个需求?", "zhcn": "现有一组图片要根据图片内容分类，比如建筑、汽车等等。使用阿里云视觉智能平台的以下哪种能力可以实现这个需求?"}, "option": [{"option_text": {"enus": "元素识别", "zhcn": "元素识别"}, "option_flag": false}, {"option_text": {"enus": "风格识别", "zhcn": "风格识别"}, "option_flag": false}, {"option_text": {"enus": "场景识别", "zhcn": "场景识别"}, "option_flag": false}, {"option_text": {"enus": "通用图像打标", "zhcn": "通用图像打标"}, "option_flag": true}], "analysis": {"enus": "图像打标可识别上千种标签，覆盖到日常生活各场景中常见的内容品类，如电脑、水杯、汽车等。可以广泛应用于智能图像管理、视频打标等场景，故选“通用图像打标”。", "zhcn": "您提出的问题非常好，这是一个非常典型的图像分类需求。我们来逐一分析每个选项，以理解为什么 **[D]通用图像打标** 是最佳答案。\n\n### 各选项能力解析\n\n**[A] 元素识别**\n*   **功能**：识别并定位图片中出现的**具体物体**，比如“杯子”、“电脑”、“自行车”。它更侧重于找出图片里“有什么东西”，并给出其位置（画框）。\n*   **是否适用**：可以识别出“建筑”、“汽车”这些元素，但它的输出是零散的物体列表和位置，而不是对整张图片内容进行一个概括性的分类。如果一张图里既有建筑又有汽车，它不会帮你判断这张图到底属于“建筑”类还是“汽车”类。\n\n**[B] 风格识别**\n*   **功能**：分析图片的**艺术或视觉风格**，比如“水墨画”、“油画”、“像素风”、“印象派”。它关注的是图片的“表现形式”，而不是“内容主题”。\n*   **是否适用**：完全不适用。您的需求是根据“内容”（建筑、汽车）分类，而不是根据“风格”（抽象、写实）分类。\n\n**[C] 场景识别**\n*   **功能**：识别图片所处的**整体环境或场景**，比如“街道”、“海滩”、“办公室”、“森林”。它是对图片宏观环境的判断。\n*   **是否适用**：部分适用，但不够精准。“建筑”可能对应“城市街景”、“名胜古迹”等场景，“汽车”可能对应“高速公路”、“停车场”等场景。但场景识别不会直接输出“建筑”或“汽车”这种以主体对象为核心的标签。它的粒度是“场景”而非“主体”。\n\n**[D] 通用图像打标**\n*   **功能**：这是最符合您需求的能力。它会对整张图片进行综合分析，输出一系列能概括图片**主要内容、主体、场景**的语义标签（关键词）。这些标签通常按照相关性排序。\n*   **是否适用**：**非常适用**。对于一张建筑物的图片，它很可能返回“建筑”、“地标”、“城市”等标签。对于一张汽车的图片，它会返回“汽车”、“车辆”、“SUV”等标签。您可以通过设定阈值，选取最相关的标签（如排名第一的标签）来作为图片的分类依据。\n\n### 结论与答案解析\n\n您的需求是“根据图片内容分类，比如建筑、汽车”，这本质上是为图片打上描述其核心内容的**主题标签**。\n\n*   **元素识别** 过于零散，且输出包含位置信息，不适合直接用于整图分类。\n*   **风格识别** 与内容主题无关。\n*   **场景识别** 虽然相关，但标签体系是“场景”导向的，不如“通用图像打标”返回的标签全面和直接。\n*   **通用图像打标** 专门设计用于理解图片的全局内容，并输出最相关的语义标签，这正是实现图片内容自动分类的核心能力。\n\n因此，**参考答案 [D] 是正确的**。`通用图像打标`能力能够最直接、最有效地满足您根据图片主体内容进行分类的需求。"}, "answer": "D"}, {"id": "10", "question": {"enus": "关于有监督学习的描述选项中，下列描述错误的是哪项？", "zhcn": "关于有监督学习的描述选项中，下列描述错误的是哪项？"}, "option": [{"option_text": {"enus": "使用有标签的数据进行模型训练", "zhcn": "使用有标签的数据进行模型训练"}, "option_flag": false}, {"option_text": {"enus": "通过外部、内部校正进行模型校正", "zhcn": "通过外部、内部校正进行模型校正"}, "option_flag": false}, {"option_text": {"enus": "根据环境反馈不断调试进行建模", "zhcn": "根据环境反馈不断调试进行建模"}, "option_flag": true}, {"option_text": {"enus": "常用算法包括: SVM、KNN", "zhcn": "常用算法包括: SVM、KNN"}, "option_flag": false}], "analysis": {"enus": "有监督学习主要是通过数据以及对应的标签信息进行不断调试建模的，因此“ 根据环境反馈不断调试进行建模”不正确。", "zhcn": "我们先逐项分析题目中的选项：  \n\n**[A] 使用有标签的数据进行模型训练**  \n✅ 正确，有监督学习的定义就是使用带标签的数据训练模型。  \n\n**[B] 通过外部、内部校正进行模型校正**  \n✅ 正确，有监督学习在训练过程中会通过验证集（外部校正）和训练集误差（内部反馈）进行模型调优或选择。  \n\n**[C] 根据环境反馈不断调试进行建模**  \n❌ 错误，这是强化学习（Reinforcement Learning）的特点，不是有监督学习的典型过程。有监督学习不依赖环境反馈，而是依赖已有的标签数据。  \n\n**[D] 常用算法包括: SVM、KNN**  \n✅ 正确，SVM（支持向量机）和KNN（K近邻）都是有监督学习的经典算法。  \n\n因此，错误的描述是 **C**。  \n\n**最终答案：C**"}, "answer": "C"}, {"id": "11", "question": {"enus": "在使用K-means算法对数据集进行聚类操作时，数据集中的一个点(5,6)到中心点(2,2)的欧式距离是多少?", "zhcn": "在使用K-means算法对数据集进行聚类操作时，数据集中的一个点(5,6)到中心点(2,2)的欧式距离是多少?"}, "option": [{"option_text": {"enus": "3", "zhcn": "3"}, "option_flag": false}, {"option_text": {"enus": "4", "zhcn": "4"}, "option_flag": false}, {"option_text": {"enus": "5", "zhcn": "5"}, "option_flag": true}, {"option_text": {"enus": "6", "zhcn": "6"}, "option_flag": false}], "analysis": {"enus": "两点（X1,Y1）和(X2,Y2)的欧氏距离公式是√((x1-x2)^2+〖(y1-y2)〗^2 ) ，因此选“5”。", "zhcn": "我们计算点 (5, 6) 到中心点 (2, 2) 的欧式距离：  \n\n\\[\nd = \\sqrt{(5 - 2)^2 + (6 - 2)^2}\n\\]\n\\[\n= \\sqrt{3^2 + 4^2}\n\\]\n\\[\n= \\sqrt{9 + 16}\n\\]\n\\[\n= \\sqrt{25}\n\\]\n\\[\n= 5\n\\]\n\n所以答案是 **C**。"}, "answer": "C"}, {"id": "12", "question": {"enus": "语音识别是一个过程，涉及多学科，下列对语音识别过程中所涉及的概念理解错误的有哪些选项？", "zhcn": "语音识别是一个过程，涉及多学科，下列对语音识别过程中所涉及的概念理解错误的有哪些选项？"}, "option": [{"option_text": {"enus": "语音中最小的基本单位是音素", "zhcn": "语音中最小的基本单位是音素"}, "option_flag": false}, {"option_text": {"enus": "音节是人类能区别一个单词和另一个单词的基础", "zhcn": "音节是人类能区别一个单词和另一个单词的基础"}, "option_flag": true}, {"option_text": {"enus": "词和短语由音素构成", "zhcn": "词和短语由音素构成"}, "option_flag": false}, {"option_text": {"enus": "音素含有3到5个状态，同一状态的发音相对稳定", "zhcn": "音素含有3到5个状态，同一状态的发音相对稳定"}, "option_flag": false}], "analysis": {"enus": "解析：\n语音中最小的基本单位是音素。\n音素是人类能区别一个单词和另一个单词的基础。", "zhcn": "我们先逐项分析题目中的描述。  \n\n---\n\n**A. 语音中最小的基本单位是音素**  \n- 音素（phoneme）是语言学中能区分意义的最小语音单位，在语音识别中常作为建模单元之一，这句话是正确的。  \n\n**B. 音节是人类能区别一个单词和另一个单词的基础**  \n- 实际上，音素才是区分词与词的基础，比如“bat”和“pat”的区别在于音素/b/和/p/。音节虽然更容易感知，但不是最小辨义单位，所以这个说法是错误的。  \n\n**C. 词和短语由音素构成**  \n- 从语音结构看，词由音素组合而成，短语由词构成，所以这句话在语音学上可以成立（虽然书面语中词由字母组成，但语音上确实由音素构成），因此正确。  \n\n**D. 音素含有 3 到 5 个状态，同一状态的发音相对稳定**  \n- 这是从隐马尔可夫模型（HMM）的角度说的，在 HMM 中，一个音素常被划分为几个状态（如 3 状态：起始-中间-结束），每个状态内的声学特征相对稳定，这是语音识别建模中的常见知识，所以正确。  \n\n---\n\n因此，理解错误的是 **B**。  \n\n**答案：B** ✅"}, "answer": "B"}, {"id": "13", "question": {"enus": "人工智能（AI）就是让机器具有这种能力的科学，也就是说让机器像我们人一样能思会想，其中“人工智能”的英文单词是什么？", "zhcn": "人工智能（AI）就是让机器具有这种能力的科学，也就是说让机器像我们人一样能思会想，其中“人工智能”的英文单词是什么？"}, "option": [{"option_text": {"enus": "Intelligence Machine", "zhcn": "Intelligence Machine"}, "option_flag": false}, {"option_text": {"enus": "Artificial Biological", "zhcn": "Artificial Biological"}, "option_flag": false}, {"option_text": {"enus": "Artificial Intellect", "zhcn": "Artificial Intellect"}, "option_flag": false}, {"option_text": {"enus": "Artificial Intelligence", "zhcn": "Artificial Intelligence"}, "option_flag": true}], "analysis": {"enus": "Intelligence Machine译为智能机器；Artificial Biological译为人工生物；Artificial Intellect译为人工智力；Artificial Intelligence译为人工智能。故D选项正确。", "zhcn": "正确答案是 **[D] Artificial Intelligence**。\n\n**详细解析如下：**\n\n1.  **问题核心**：题目要求找出“人工智能”这一专业术语对应的标准英文单词。\n2.  **选项分析**：\n    *   **[A] Intelligence Machine**：这个词组的意思是“智能机器”，它描述的是具备智能的机器本身，而不是“人工智能”这个学科或技术领域。\n    *   **[B] Artificial Biological**：这个词组的意思是“人造生物的”或“人工生物的”，与计算机科学领域的“人工智能”概念完全无关。\n    *   **[C] Artificial Intellect**：这个词组直译是“人工智力”，虽然意思上接近，但它并非该领域的标准术语。在学术和工业界，通用的、被广泛接受的术语是“Intelligence”而不是“Intellect”。\n    *   **[D] Artificial Intelligence**：这是“人工智能”在全球范围内公认的标准英文术语。“Artificial”意为“人造的、人工的”，“Intelligence”意为“智能”。这个词精准地定义了“让机器像人一样能思会想”的科学领域。\n\n3.  **结论**：根据计算机科学领域的标准命名和普遍用法，**Artificial Intelligence (AI)** 是“人工智能”唯一正确的英文对应词。\n\n因此，正确答案是 **D**。"}, "answer": "D"}, {"id": "14", "question": {"enus": "人工智能发展的第一次热潮发生在以下哪个时间期间?", "zhcn": "人工智能发展的第一次热潮发生在以下哪个时间期间?"}, "option": [{"option_text": {"enus": "20世纪40~50年代", "zhcn": "20世纪40~50年代"}, "option_flag": false}, {"option_text": {"enus": "20世纪50~60年代", "zhcn": "20世纪50~60年代"}, "option_flag": true}, {"option_text": {"enus": "20世纪70~80年代", "zhcn": "20世纪70~80年代"}, "option_flag": false}, {"option_text": {"enus": "20世纪80~90年代", "zhcn": "20世纪80~90年代"}, "option_flag": false}], "analysis": {"enus": "20世纪50年代到60年代是人工智能发展的第一次热潮：理论的革新；20世纪80年代到90年代是人工智能发展的第二次热潮：思维的转变；2006年至今是人工智能发展的第三次热潮：技术的融合。", "zhcn": "正确答案是 **[B] 20世纪50~60年代**。\n\n**答案解析：**\n\n人工智能作为一门学科正式诞生于 **1956年** 的达特茅斯会议。从那时起直到 **20世纪60年代**，是人工智能发展的第一次热潮（也被称为“黄金时代”）。\n\n这个时期的主要特点和标志包括：\n*   **乐观主义与开创性成果**：研究者们普遍乐观，认为在几十年内就能造出与人相媲美的智能机器。\n*   **关键程序诞生**：出现了如逻辑理论家、几何定理证明器等早期成功的人工智能程序。\n*   **基础概念形成**：提出了搜索式推理、自然语言处理等核心概念。\n\n因此，第一次热潮的时间范围准确地说是从20世纪50年代中期到60年代。\n\n其他选项不准确的原因：\n*   **[A] 20世纪40~50年代**：这个时期是人工智能的前夜，主要是控制论、神经网络模型（如M-P模型）等理论基础的形成阶段，人工智能学科尚未正式确立。\n*   **[C] 20世纪70~80年代**：这个时期包含了人工智能的第一次低谷（“AI冬天”）和第二次热潮的兴起（专家系统商业化）。\n*   **[D] 20世纪80~90年代**：这个时期主要是第二次热潮的延续和第二次低谷的开始。"}, "answer": "B"}, {"id": "15", "question": {"enus": "图灵于1950 提出一种检测智能机器的测试方法。在这一测试中，图灵设想将一个人和一台计算机隔离开，分别通过打字和测试者进行交流。如果在测试结束后，机器有多大的可能性骗过测试者，让他/她误以为自己是人，则说明计算机具有智能？", "zhcn": "图灵于1950 提出一种检测智能机器的测试方法。在这一测试中，图灵设想将一个人和一台计算机隔离开，分别通过打字和测试者进行交流。如果在测试结束后，机器有多大的可能性骗过测试者，让他/她误以为自己是人，则说明计算机具有智能？"}, "option": [{"option_text": {"enus": "20%以上", "zhcn": "20%以上"}, "option_flag": false}, {"option_text": {"enus": "30%以上", "zhcn": "30%以上"}, "option_flag": true}, {"option_text": {"enus": "40%以上", "zhcn": "40%以上"}, "option_flag": false}, {"option_text": {"enus": "50%以上", "zhcn": "50%以上"}, "option_flag": false}], "analysis": {"enus": "如果在图灵测试结束后，机器有30% 以上的可能性骗过测试者，让他/她误以为自己是人，则说明计算机具有智能。", "zhcn": "图灵在1950年的论文《计算机器与智能》中提出，如果一台机器在模仿游戏中，能够使人类测试者在超过30%的互动时间内误以为它是人，那么就可以认为这台机器具有智能。  \n\n因此，正确答案是 **[B] 30%以上**。"}, "answer": "B"}, {"id": "16", "question": {"enus": "通过带有标签的数据生成一个函数（模型），将输入映射到合适的输出，例如分类等。该过程属于哪类学习方法？", "zhcn": "通过带有标签的数据生成一个函数（模型），将输入映射到合适的输出，例如分类等。该过程属于哪类学习方法？"}, "option": [{"option_text": {"enus": "有监督学习", "zhcn": "有监督学习"}, "option_flag": true}, {"option_text": {"enus": "半监督学习", "zhcn": "半监督学习"}, "option_flag": false}, {"option_text": {"enus": "无监督学习", "zhcn": "无监督学习"}, "option_flag": false}, {"option_text": {"enus": "强化学习", "zhcn": "强化学习"}, "option_flag": false}], "analysis": {"enus": "有监督学习是由训练资料中学到或建立一个模式，即学习输入数据与输出数据之间的对应关系，并依此模式推测新的实例。故“有监督学习”正确。", "zhcn": "题干描述的是“通过带有标签的数据生成一个函数（模型），将输入映射到合适的输出，例如分类等”。  \n\n**分析选项：**  \n- **[A] 有监督学习**：训练数据带有标签（即输入-输出对应），目标是学习一个从输入到输出的映射，如分类、回归等。与题干描述一致。  \n- **[B] 半监督学习**：使用少量带标签数据和大量无标签数据，不完全符合“带有标签的数据生成模型”的典型定义。  \n- **[C] 无监督学习**：数据没有标签，任务是发现数据内在结构（如聚类、降维），与题干不符。  \n- **[D] 强化学习**：通过与环境交互获得奖励信号来学习策略，不是直接利用带标签的数据进行映射。  \n\n因此，正确答案是 **[A] 有监督学习**。"}, "answer": "A"}, {"id": "17", "question": {"enus": "以下领域不属于有监督学习是哪项？", "zhcn": "以下领域不属于有监督学习是哪项？"}, "option": [{"option_text": {"enus": "图像分类", "zhcn": "图像分类"}, "option_flag": false}, {"option_text": {"enus": "无标签数据生成", "zhcn": "无标签数据生成"}, "option_flag": true}, {"option_text": {"enus": "图像检测", "zhcn": "图像检测"}, "option_flag": false}, {"option_text": {"enus": "语音识别", "zhcn": "语音识别"}, "option_flag": false}], "analysis": {"enus": "是否有监督就看输入数据是否有标签，若输入数据有标签，则为有监督学习；若没标签则为无监督学习。因此无标签数据生成属于无监督学习。故“无标签数据生成”正确。", "zhcn": "**正确答案是 B：无标签数据生成。**\n\n**详细解析：**\n\n这道题考查的是对“有监督学习”概念的理解。有监督学习的核心特点是：**所使用的训练数据是带有“标签”或“正确答案”的。**\n\n*   **模型目标**：学习从输入数据到输出标签之间的映射关系。\n*   **训练数据**：形式为 `(输入数据, 对应的标签)` 的成对数据集。\n*   **典型任务**：分类、回归等。\n\n现在我们来分析每个选项：\n\n*   **[A] 图像分类**：这是最典型的有监督学习任务。模型需要学习将输入的图像（如一张照片）分类到预定义的类别（如“猫”、“狗”）。训练数据就是成千上万张已经被人工标注好类别（标签）的图片。\n*   **[B] 无标签数据生成**：这个任务本身描述的就是**不使用标签**。它的目标是从未标注的数据中学习其内在分布，然后生成新的、类似的数据。这属于**无监督学习**（如生成对抗网络 GANs 的一种应用）或**自监督学习**的范畴。因此，它不属于有监督学习。\n*   **[C] 图像检测**：这也是一种有监督学习任务。模型不仅需要识别出图像中的物体是什么（分类），还需要定位出它们的位置（通常用边界框表示）。训练数据是带有标注的图片，标注信息包括物体的类别和位置坐标。\n*   **[D] 语音识别**：这同样是有监督学习。模型的任务是将一段语音信号转换成对应的文本。训练数据是大量的语音片段和其对应的文字转录稿（标签）。\n\n**总结：**\n题目问的是“**不属于**有监督学习”的领域。**[A]、[C]、[D]** 都需要依赖大量带标签的数据进行训练，属于有监督学习。而 **[B]** 的核心是“无标签”，因此它不属于有监督学习。"}, "answer": "B"}, {"id": "18", "question": {"enus": "以下训练不属于迁移学习是哪项？", "zhcn": "以下训练不属于迁移学习是哪项？"}, "option": [{"option_text": {"enus": "基于样本的迁移训练", "zhcn": "基于样本的迁移训练"}, "option_flag": false}, {"option_text": {"enus": "基于特征的迁移学习", "zhcn": "基于特征的迁移学习"}, "option_flag": false}, {"option_text": {"enus": "基于参数的迁移训练", "zhcn": "基于参数的迁移训练"}, "option_flag": false}, {"option_text": {"enus": "基于多标签的有监督训练", "zhcn": "基于多标签的有监督训练"}, "option_flag": true}], "analysis": {"enus": "根据技术方法可以把迁移学习划分为基于样本的迁移学习、基于特征的迁移学习、基于参数的迁移学习和基于相关性的迁移学习。故“基于多标签的有监督训练”正确。", "zhcn": "我们先分析一下题目。  \n\n**迁移学习**的核心思想是利用已有的知识（从源领域/任务）来帮助新领域/任务的学习。常见的方法包括：  \n\n- **基于样本的迁移**：重用源领域的样本（可能加权）来辅助目标领域训练。  \n- **基于特征的迁移**：将源领域和目标领域的数据映射到同一特征空间，使得特征分布更接近。  \n- **基于参数的迁移**：共享模型参数或先验，比如在预训练模型上微调。  \n\n**多标签的有监督训练**只是多标签分类场景下的普通监督学习，并不一定涉及不同领域或任务之间的知识迁移，因此它本身不属于迁移学习的一种类型。  \n\n题目问“不属于迁移学习的是”，所以正确选项是 **D**。  \n\n你的解析已经很清楚，我帮你再明确一下结构：  \n\n---\n\n**题目回顾**  \n以下训练不属于迁移学习是哪项？  \n[A] 基于样本的迁移训练  \n[B] 基于特征的迁移学习  \n[C] 基于参数的迁移训练  \n[D] 基于多标签的有监督训练  \n\n**答案**：D  \n\n**解析**：  \n迁移学习的主要方法包括基于样本、特征、参数的迁移等，它们都涉及从源任务/领域向目标任务/领域的知识迁移。  \n[D] 选项“基于多标签的有监督训练”只是多标签分类任务下的标准监督学习，不涉及跨领域或跨任务的知识迁移，因此不属于迁移学习范畴。"}, "answer": "D"}, {"id": "19", "question": {"enus": "支持向量机是一类对数据进行二元分类的广义线性分类器，其决策边界是对学习样本求解的最大边距超平面。该算法按哪种方式学习的？", "zhcn": "支持向量机是一类对数据进行二元分类的广义线性分类器，其决策边界是对学习样本求解的最大边距超平面。该算法按哪种方式学习的？"}, "option": [{"option_text": {"enus": "有监督学习", "zhcn": "有监督学习"}, "option_flag": true}, {"option_text": {"enus": "半监督学习", "zhcn": "半监督学习"}, "option_flag": false}, {"option_text": {"enus": "无监督学习", "zhcn": "无监督学习"}, "option_flag": false}, {"option_text": {"enus": "强化学习", "zhcn": "强化学习"}, "option_flag": false}], "analysis": {"enus": "支持向量机是一类按监督学习方式对数据进行二元分类的广义线性分类器，其决策边界是对学习样本求解的最大边距超平面，在人像识别、文本分类等模式识别问题中有得到广泛应用。", "zhcn": "支持向量机（SVM）是一种**有监督学习**算法。  \n\n**理由如下**：  \n1. SVM 需要**带标签的训练数据**（即每个样本都有明确的类别标记），通过学习这些数据来找到一个最优分类超平面。  \n2. 训练过程依赖于已知的样本标签来最大化分类间隔，这完全符合有监督学习的定义。  \n3. 半监督学习、无监督学习和强化学习都不符合 SVM 的基本学习方式。  \n\n因此正确答案是 **[A] 有监督学习**。"}, "answer": "A"}, {"id": "20", "question": {"enus": "聚类算法试图将数据集中的样本划分为若干个不相交的子集，该算法数据哪类学习方法？", "zhcn": "聚类算法试图将数据集中的样本划分为若干个不相交的子集，该算法数据哪类学习方法？"}, "option": [{"option_text": {"enus": "有监督学习", "zhcn": "有监督学习"}, "option_flag": false}, {"option_text": {"enus": "半监督学习", "zhcn": "半监督学习"}, "option_flag": false}, {"option_text": {"enus": "无监督学习", "zhcn": "无监督学习"}, "option_flag": true}, {"option_text": {"enus": "强化学习", "zhcn": "强化学习"}, "option_flag": false}], "analysis": {"enus": "聚类分析是非监督学习的很重要的领域。聚类是试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”。通过这样的划分，每个簇可能对应于一些潜在的概念（类别）。但是这些概念对聚类算法而言事先是未知的，主要原因是聚类使用的数据是没有任何标注信息的，聚类过程仅能自动形成簇结构，簇所对应的概念语义需要由使用者来把握和命名。有监督学习通过已有的训练样本去训练得到一个最优模型，再利用这个模型将所有的输入映射为相应的输出，对输出进行简单的判断从而实现预测和分类的目的，也就具有了对未知数据进行预测和分类的能力；半监督学习有两个样本集,一个有标记,一个没有标记，半监督学习侧重于在有监督的分类算法中加入无标记样本来实现半监督分类；强化学习是机器学习中的一个领域,强调如何基于环境而行动,以取得最大化的预期利益。因此本题选择无监督学习。", "zhcn": "你的题目和答案是正确的。  \n\n**题目回顾**  \n> 聚类算法试图将数据集中的样本划分为若干个不相交的子集，该算法属于哪类学习方法？  \n> [A] 有监督学习  \n> [B] 半监督学习  \n> [C] 无监督学习  \n> [D] 强化学习  \n\n**答案解析**  \n\n1. **聚类算法的特点**  \n   - 聚类是在没有标签的情况下，将数据按照相似性自动分组。  \n   - 它不依赖已知的类别标记，而是通过数据内在结构进行划分。  \n\n2. **选项分析**  \n   - **有监督学习**：需要带标签的数据进行训练（如分类、回归），不符合题意。  \n   - **半监督学习**：使用少量带标签数据和大量无标签数据，也不符合聚类场景。  \n   - **无监督学习**：处理无标签数据，发现数据分布或结构，聚类是典型代表。  \n   - **强化学习**：通过与环境交互获得奖励来学习策略，与聚类无关。  \n\n3. **结论**  \n   聚类属于**无监督学习**，因此正确答案是 **[C]**。"}, "answer": "C"}, {"id": "21", "question": {"enus": "有监督学习一般包括分类和回归两种类型，下列哪种算法属于分类类型？", "zhcn": "有监督学习一般包括分类和回归两种类型，下列哪种算法属于分类类型？"}, "option": [{"option_text": {"enus": "<span style=\"font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;\">谱</span>聚类", "zhcn": "<span style=\"font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;\">谱</span>聚类"}, "option_flag": false}, {"option_text": {"enus": "主成分分析", "zhcn": "主成分分析"}, "option_flag": false}, {"option_text": {"enus": "朴素贝叶斯", "zhcn": "朴素贝叶斯"}, "option_flag": true}, {"option_text": {"enus": "K均值聚类", "zhcn": "K均值聚类"}, "option_flag": false}], "analysis": {"enus": "朴素贝叶斯是一种基于概率论的算法，在做决策时要求分类器给出一个最优的类别猜测结果，同时给出这个猜测的概率估计值；而谱聚类、主成分分析和K均值聚类均属于无监督学习。", "zhcn": "我们先分析一下各个选项：  \n\n- **[A] 谱聚类**：属于**无监督学习**中的聚类算法，不是分类。  \n- **[B] 主成分分析**：属于**无监督学习**，用于降维，不是分类。  \n- **[C] 朴素贝叶斯**：属于**有监督学习**中的分类算法（也可用于回归，但主要用途是分类）。  \n- **[D] K均值聚类**：属于**无监督学习**中的聚类算法，不是分类。  \n\n题目问“有监督学习一般包括分类和回归两种类型，下列哪种算法属于分类类型”，显然应选 **C**。  \n\n**答案：C**"}, "answer": "C"}, {"id": "22", "question": {"enus": "有一个关于机器学习中的有监督学习、无监督学习和增强学习的有趣比喻：把机器学习（智能）比作一个蛋糕，什么是蛋糕本体，什么是蛋糕上的樱桃，而什么仅仅能算作蛋糕上的糖霜？", "zhcn": "有一个关于机器学习中的有监督学习、无监督学习和增强学习的有趣比喻：把机器学习（智能）比作一个蛋糕，什么是蛋糕本体，什么是蛋糕上的樱桃，而什么仅仅能算作蛋糕上的糖霜？"}, "option": [{"option_text": {"enus": "有监督学习、增强学习、迁移学习", "zhcn": "有监督学习、增强学习、迁移学习"}, "option_flag": false}, {"option_text": {"enus": "无监督学习、增强学习、有监督学习", "zhcn": "无监督学习、增强学习、有监督学习"}, "option_flag": true}, {"option_text": {"enus": "增强学习、无监督学习、元学习", "zhcn": "增强学习、无监督学习、元学习"}, "option_flag": false}, {"option_text": {"enus": "迁移学习、增强学习、元学习", "zhcn": "迁移学习、增强学习、元学习"}, "option_flag": false}], "analysis": {"enus": "在神经网络顶级会议NIPS2016上，深度学习三大牛之一的Yann Lecun教授给出了一个关于机器学习中的有监督学习、无监督学习和增强学习的一个有趣的比喻，他说：如果把智能（Intelligence）比作一个蛋糕，那么无监督学习就是蛋糕本体，增强学习是蛋糕上的樱桃，那么监督学习仅仅能算作蛋糕上的糖霜。", "zhcn": "你给出的题目是一个经典的比喻，出自 AI 学者 Yann LeCun。  \n\n他的原话大意是：  \n- 如果智能是一个蛋糕，那么**无监督学习**是蛋糕本体（因为人类大部分学习不需要标签），  \n- **增强学习**是蛋糕上的樱桃（它依赖环境反馈，类似人类通过尝试学习），  \n- **有监督学习**只是蛋糕上的糖霜（它需要大量标注数据，人类学习很少这样）。  \n\n所以对应关系是：  \n- 蛋糕本体 → 无监督学习  \n- 樱桃 → 增强学习  \n- 糖霜 → 有监督学习  \n\n选项顺序是**无监督学习、增强学习、有监督学习**，对应 **[B]**。"}, "answer": "B"}, {"id": "23", "question": {"enus": "深度学习是基于深度人工神经网络的机器学习，下列不是常用深度学习算法是哪项？", "zhcn": "深度学习是基于深度人工神经网络的机器学习，下列不是常用深度学习算法是哪项？"}, "option": [{"option_text": {"enus": "卷积神经网络", "zhcn": "卷积神经网络"}, "option_flag": false}, {"option_text": {"enus": "循环神经网络", "zhcn": "循环神经网络"}, "option_flag": false}, {"option_text": {"enus": "长短时记忆神经网络", "zhcn": "长短时记忆神经网络"}, "option_flag": false}, {"option_text": {"enus": "传统前向神经网络", "zhcn": "传统前向神经网络"}, "option_flag": true}], "analysis": {"enus": "传统前向神经网络一般指三层的全连接神经网络，而大于三层的神经网络才称之为深度神经网络。", "zhcn": "我们先分析一下题目。  \n\n题目问的是“不是常用深度学习算法”的选项。  \n\n**选项分析：**  \n- **[A] 卷积神经网络（CNN）**：典型的深度学习模型，用于图像、语音等，非常常用。  \n- **[B] 循环神经网络（RNN）**：用于序列数据，是深度学习的重要模型。  \n- **[C] 长短时记忆神经网络（LSTM）**：是 RNN 的一种改进，也属于深度学习常用模型。  \n- **[D] 传统前向神经网络**：一般指多层感知机（MLP），虽然也是神经网络，但在“深度学习”语境下，通常“传统前向神经网络”指较早的浅层网络（比如只有输入层、一个隐藏层、输出层），不是“深度”的代表性模型。深度学习的“深度”一般指多层非线性变换，但“传统前向神经网络”在教材中常被视作深度学习兴起之前的基础模型，不属于“常用深度学习算法”的典型代表。  \n\n因此，正确答案是 **D**。  \n\n**最终答案：**  \n```\n[D]传统前向神经网络\n```"}, "answer": "D"}, {"id": "24", "question": {"enus": "长短期记忆神经网络结构主要有多少个门限函数组成？", "zhcn": "长短期记忆神经网络结构主要有多少个门限函数组成？"}, "option": [{"option_text": {"enus": "1", "zhcn": "1"}, "option_flag": false}, {"option_text": {"enus": "2", "zhcn": "2"}, "option_flag": false}, {"option_text": {"enus": "3", "zhcn": "3"}, "option_flag": true}, {"option_text": {"enus": "4", "zhcn": "4"}, "option_flag": false}], "analysis": {"enus": "长短期记忆神经网络结构主要有输入门、遗忘门和输出门三个门限函数组成。", "zhcn": "你提供的题目和参考答案是正确的。  \n\n长短期记忆网络（LSTM）的基本结构中，通常包含**三个门控函数**：  \n\n1. **遗忘门（Forget Gate）**：决定要从细胞状态中丢弃哪些信息。  \n2. **输入门（Input Gate）**：决定哪些新信息要存储到细胞状态中。  \n3. **输出门（Output Gate）**：基于细胞状态决定该时刻的输出。  \n\n因此，选项 **[C] 3** 是正确答案。"}, "answer": "C"}, {"id": "25", "question": {"enus": "下列不是卷积神经网络的结构特性是哪项？", "zhcn": "下列不是卷积神经网络的结构特性是哪项？"}, "option": [{"option_text": {"enus": "局部连接", "zhcn": "局部连接"}, "option_flag": false}, {"option_text": {"enus": "权值共享", "zhcn": "权值共享"}, "option_flag": false}, {"option_text": {"enus": "全连接", "zhcn": "全连接"}, "option_flag": true}, {"option_text": {"enus": "池化连接", "zhcn": "池化连接"}, "option_flag": false}], "analysis": {"enus": "解析：稀疏连接、参数共享\n卷积神经网络的三大结构特性是局部连接、权值共享、空间或时间上的下采样（池化）。", "zhcn": "我们先分析一下每个选项在卷积神经网络（CNN）中的含义：  \n\n- **A 局部连接**：CNN 的卷积层中，每个神经元只与输入数据的一个局部区域相连，而不是全部输入，这是 CNN 的基本特性。  \n- **B 权值共享**：同一个卷积核在输入的不同位置共享相同的权重，减少参数量，也是 CNN 的核心特性。  \n- **C 全连接**：全连接层（Fully Connected Layer）是传统神经网络或 CNN 末端的结构，但并不是 CNN 区别于传统网络的核心结构特性，CNN 的核心特性是局部连接和权值共享。  \n- **D 池化连接**：池化（Pooling）是 CNN 中常用的操作，用于降维和保持平移不变性，属于 CNN 的结构特性之一。  \n\n题目问“不是卷积神经网络的结构特性”，显然 **全连接** 并不是 CNN 的本质特性（虽然 CNN 末端可能用全连接层，但 CNN 的核心创新在于局部连接、权值共享和池化）。  \n\n所以正确答案是 **C**。"}, "answer": "C"}, {"id": "26", "question": {"enus": "TensorFlow是谷歌开源的第二代用于数字计算的软件库，主要是使用哪种编程语言开发的？", "zhcn": "TensorFlow是谷歌开源的第二代用于数字计算的软件库，主要是使用哪种编程语言开发的？"}, "option": [{"option_text": {"enus": "C", "zhcn": "C"}, "option_flag": false}, {"option_text": {"enus": "C++", "zhcn": "C++"}, "option_flag": true}, {"option_text": {"enus": "Python", "zhcn": "Python"}, "option_flag": false}, {"option_text": {"enus": "Java", "zhcn": "Java"}, "option_flag": false}], "analysis": {"enus": "TensorFlow架构主要是使用C++开发的，支持C、Java、Python等多种语言的调用，目前主流的方式通常使用Python语言来驱动应用。", "zhcn": "TensorFlow 最初主要由 **C++** 语言开发，其核心高性能计算引擎和底层架构都是用 C++ 编写的。同时，为了便于研究和快速开发，TensorFlow 提供了 **Python** 作为主要的前端接口语言，因此很多用户会通过 Python 来使用 TensorFlow。但就问题中“主要是使用哪种编程语言开发的”而言，指的是其核心系统的开发语言，正确答案是 **C++**。"}, "answer": "B"}, {"id": "27", "question": {"enus": "下列能够正确安装GPU版TensorFlow的方式是哪项？", "zhcn": "下列能够正确安装GPU版TensorFlow的方式是哪项？"}, "option": [{"option_text": {"enus": "pip install tensorflow", "zhcn": "pip install tensorflow"}, "option_flag": false}, {"option_text": {"enus": "pip install tensorflow=gpu", "zhcn": "pip install tensorflow=gpu"}, "option_flag": false}, {"option_text": {"enus": "pip install tf-gpu", "zhcn": "pip install tf-gpu"}, "option_flag": false}, {"option_text": {"enus": "pip install tensorflow-gpu", "zhcn": "pip install tensorflow-gpu"}, "option_flag": true}], "analysis": {"enus": "TensorFlow分CPU和GPU版本，CPU版安装命令是pip install tensorflow，GPU版安装命令是pip install tensorflow-gpu。", "zhcn": "你的判断是正确的，参考答案确实是 **D**。\n\n下面我来详细解释一下每个选项，说明为什么对或错：\n\n*   **[A] pip install tensorflow**\n    *   **解释**：这个命令安装的是 **CPU 版本的 TensorFlow**。它可以在任何电脑上运行，但只能利用计算机的中央处理器（CPU）进行计算。对于深度学习任务来说，这通常非常缓慢，无法发挥GPU的强大并行计算能力。\n\n*   **[B] pip install tensorflow=gpu**\n    *   **解释**：这是一个**错误的语法**。在 `pip install` 命令中，指定包版本的正确语法是使用双等号 `==`，例如 `pip install tensorflow==2.10.0`。而使用 `=` 或 `=gpu` 是无效的，pip 无法识别这个命令，会导致安装失败。\n\n*   **[C] pip install tf-gpu**\n    *   **解释**：`tf-gpu` 并不是 TensorFlow 官方在 PyPI（Python 包索引）上注册的包名。如果你运行这个命令，pip 会尝试寻找一个名为 `tf-gpu` 的第三方包，而不是官方的 TensorFlow GPU 版本，因此无法正确安装。\n\n*   **[D] pip install tensorflow-gpu** ✅\n    *   **解释**：这是**在 TensorFlow 2.1 版本之前**正确安装 GPU 支持版本的习惯用法。在旧版本中，`tensorflow` 是 CPU 版，`tensorflow-gpu` 是 GPU 版，你需要二选一安装。**但是，请注意一个非常重要的变化**：\n\n### 重要更新（针对 TensorFlow 2.1 及以后版本）\n\n从 **TensorFlow 2.1** 开始，官方推荐的方式发生了变化，以简化安装过程：\n\n**现在，安装 GPU 支持的 TensorFlow 推荐命令是：`pip install tensorflow`。**\n\n**原因如下：**\n1.  **包名统一**：从 2.1 版本起，官方的 `tensorflow` PyPI 包**同时包含了 CPU 和 GPU 支持**。\n2.  **自动识别**：当你执行 `pip install tensorflow` 后，在运行 TensorFlow 代码时，如果系统检测到符合条件的 GPU 和必要的软件环境（主要是 CUDA 和 cuDNN），它会自动使用 GPU 进行计算。如果检测不到，则会自动回退到使用 CPU。\n\n**因此，虽然选项 D 在历史上是正确的，并且对于旧版本（<2.1）仍然有效，但对于当前主流的 TensorFlow 版本（>=2.1）来说，标准且正确的安装命令就是选项 A：`pip install tensorflow`。**\n\n**结论：**\n这道题考察的是对传统安装方式的了解。如果题目背景是**现代 TensorFlow（2.1以上）**，那么最准确、最推荐的答案应该是 **A**。如果题目默认是**较旧的 TensorFlow 版本**，那么 **D** 是正确答案。\n\n在实际操作中，请务必查阅你所使用的 TensorFlow 版本的官方安装指南。对于现在的用户，安装步骤通常是：\n1.  确保你的 NVIDIA GPU 符合要求。\n2.  安装匹配版本的 NVIDIA CUDA 和 cuDNN 工具包。\n3.  执行 `pip install tensorflow`。"}, "answer": "D"}, {"id": "28", "question": {"enus": "Keras是一个用Python编写的高级神经网络API，不支持以下哪种框架作为后端运行？", "zhcn": "Keras是一个用Python编写的高级神经网络API，不支持以下哪种框架作为后端运行？"}, "option": [{"option_text": {"enus": "TensorFlow", "zhcn": "TensorFlow"}, "option_flag": false}, {"option_text": {"enus": "PyTorch", "zhcn": "PyTorch"}, "option_flag": true}, {"option_text": {"enus": "CNTK", "zhcn": "CNTK"}, "option_flag": false}, {"option_text": {"enus": "Theano", "zhcn": "Theano"}, "option_flag": false}], "analysis": {"enus": "Keras是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。", "zhcn": "正确答案是 **[B] PyTorch**。\n\n**详细答案解析：**\n\nKeras 的设计理念是成为一个高层的、用户友好的API，它本身不处理低层的数值计算（如张量操作）。为了实现这一目标，Keras 需要一个强大的、专门从事张量计算的**后端引擎** 来执行这些底层操作。\n\n在 Keras 的发展历程中，它正式支持过多个后端：\n\n*   **[A] TensorFlow**：**是支持的后端**。事实上，从 Keras 2.3.0 版本开始，官方宣布 TensorFlow 2 将成为 Keras 的主要和默认后端。随着发展，Keras 已经完全整合到 TensorFlow 中，成为 `tf.keras`，这是目前最主流和使用最广泛的后端。\n*   **[C] CNTK**：**是支持的后端**。CNTK 是微软开发的认知工具包，在 Keras 的早期版本中是一个可配置的后端选项。\n*   **[D] Theano**：**是支持的后端**。Theano 是早期的数值计算库之一，也是 Keras 最初开发时所依赖的后端。不过，Theano 项目已于 2017 年停止主要开发。\n\n而 **[B] PyTorch**：**不是 Keras 官方支持的后端**。\n\n*   **原因**：PyTorch 本身就是一个非常流行且功能完整的深度学习框架，它拥有自己独特的设计哲学和动态计算图机制。虽然 Keras 和 PyTorch 都是深度学习框架，但它们是**平行** 的关系，而非前后端关系。PyTorch 提供了自己的高级接口（如 `torch.nn`），并不需要作为 Keras 的后端来运行。\n*   **补充**：社区中确实存在一些项目（如 `pytorch-keras`）试图让 Keras 的API在 PyTorch 后端上运行，但这并非 Keras 官方的、标准化的支持。因此，在标准 Keras 的官方文档和版本中，PyTorch 并不在支持的后端列表里。\n\n**结论：**\n在给定的选项中，TensorFlow、CNTK 和 Theano 都曾是 Keras 官方支持的后端引擎，而 PyTorch 从未成为其官方支持的后端。因此，Keras 不支持 **PyTorch** 作为其后端运行。"}, "answer": "B"}, {"id": "29", "question": {"enus": "英文文献翻译需要阿里云人工智能产品中的哪种技术服务？", "zhcn": "英文文献翻译需要阿里云人工智能产品中的哪种技术服务？"}, "option": [{"option_text": {"enus": "语音识别", "zhcn": "语音识别"}, "option_flag": false}, {"option_text": {"enus": "文档翻译", "zhcn": "文档翻译"}, "option_flag": true}, {"option_text": {"enus": "文字识别", "zhcn": "文字识别"}, "option_flag": false}, {"option_text": {"enus": "图像识别", "zhcn": "图像识别"}, "option_flag": false}], "analysis": {"enus": "阿里云机器翻译提供文档端到端翻译服务，输入文档，经过文档解析、机器翻译、自动排版布局，将生成指定语言且与原始文档排版布局一致的新文档。", "zhcn": "正确答案是 **[B] 文档翻译**。\n\n**详细解析如下：**\n\n*   **选项 [B] 文档翻译**：这是最直接且正确的答案。阿里云的“文档翻译”服务专门用于处理各种格式的文档（如 Word、PDF、PPT、Excel、TXT 等）的翻译任务。它能够识别文档中的文字、格式和布局，并将其整体翻译为目标语言，这正是“英文文献翻译”所需要的核心功能。\n\n*   **分析其他选项为何不正确：**\n    *   **[A] 语音识别**：这项技术是将语音（如录音、实时对话）转换成文字，与处理书面文献的翻译需求无关。\n    *   **[C] 文字识别**：这项技术（通常称为OCR，光学字符识别）主要用于从图片或扫描件中提取文字信息。虽然它可能是处理扫描版文献的一个前置步骤（先将图片中的文字识别出来），但其本身并不提供翻译功能。翻译是后续的、独立的任务。\n    *   **[D] 图像识别**：这项技术是分析和理解图像内容，例如识别图像中的物体、场景、人脸等，与文本翻译完全无关。\n\n**总结：**\n“英文文献翻译”这一任务的核心是 **“翻译”** ，并且处理对象是 **“文档”** 。因此，阿里云产品中专门为此设计的 **[B] 文档翻译** 服务是最合适的技术选择。"}, "answer": "B"}, {"id": "30", "question": {"enus": "阿里云内容安全基于深度学习技术，提供哪些多媒体的内容风险智能识别和审核服务，大幅度降低人工审核成本？", "zhcn": "阿里云内容安全基于深度学习技术，提供哪些多媒体的内容风险智能识别和审核服务，大幅度降低人工审核成本？"}, "option": [{"option_text": {"enus": "图片、视频、语音、网页", "zhcn": "图片、视频、语音、网页"}, "option_flag": false}, {"option_text": {"enus": "图片、视频、语音、文字", "zhcn": "图片、视频、语音、文字"}, "option_flag": false}, {"option_text": {"enus": "视频、语音、文字、网页", "zhcn": "视频、语音、文字、网页"}, "option_flag": false}, {"option_text": {"enus": "图片、视频、语音、文字、网页", "zhcn": "图片、视频、语音、文字、网页"}, "option_flag": true}], "analysis": {"enus": "阿里云内容安全基于深度学习技术，提供图片、视频、语音、文字、网页等多媒体的内容风险智能识别和审核服务，帮助用户发现色情、暴恐、政治敏感等内容，大幅度降低人工审核成本。", "zhcn": "正确答案是 **D**。  \n\n阿里云内容安全服务基于深度学习技术，可对**图片、视频、语音、文字、网页**等多种媒体内容进行智能识别和审核，覆盖色情、暴恐、广告、垃圾信息、敏感人物、违禁品等多种风险内容，从而大幅降低人工审核成本。"}, "answer": "D"}, {"id": "31", "question": {"enus": "工业大脑是基于阿里云大数据的一体化计算平台，经过实战检验的业务过程智能优化算法服务，一周接入，一周上线帮助制造业直接降本增效。这表明了产品哪项优势？", "zhcn": "工业大脑是基于阿里云大数据的一体化计算平台，经过实战检验的业务过程智能优化算法服务，一周接入，一周上线帮助制造业直接降本增效。这表明了产品哪项优势？"}, "option": [{"option_text": {"enus": "云计算大数据能力", "zhcn": "云计算大数据能力"}, "option_flag": false}, {"option_text": {"enus": "技术专家能力", "zhcn": "技术专家能力"}, "option_flag": false}, {"option_text": {"enus": "算法优化能力", "zhcn": "算法优化能力"}, "option_flag": true}, {"option_text": {"enus": "产品交付能力", "zhcn": "产品交付能力"}, "option_flag": false}], "analysis": {"enus": "工业大脑的优势有云计算大数据能力：标准化、高可用、弹性可扩展的大数据与云计算的平台能力；算法优化能力：经过实战检验的业务过程智能优化算法服务，一周接入，一周上线帮助制造业直接降本增效；技术专家能力：下过车间、进过实验室的大数据技术专家直面问题，迎难而上；产品交付能力：数据技术能力经过长期打磨沉淀，具备产品化交付能力，以通用在线API服务+生态定制化产品界面方式交付，标准化定制产品模型。", "zhcn": "我们先分析一下题干信息：  \n\n题干说“工业大脑”是**基于阿里云大数据的一体化计算平台**（这涉及云计算大数据能力），  \n但后面强调的是**经过实战检验的业务过程智能优化算法服务**（这是核心服务内容），  \n接着是**一周接入，一周上线，帮助制造业直接降本增效**（这体现了快速交付和效果）。  \n\n问题是“这表明了产品哪项优势？”  \n- 如果只看“基于阿里云大数据”，可能会选 **[A] 云计算大数据能力**，但这只是基础支撑，不是题干强调的重点。  \n- 题干的核心落脚点是“业务过程智能优化算法服务”以及“降本增效”，这突出的是**算法优化能力**。  \n- “一周接入，一周上线”虽然涉及交付速度，但题干更强调算法服务带来的效果，而不是单纯强调交付快。  \n\n结合参考答案和解析，命题者认为这里的关键是“智能优化算法服务”带来的降本增效，所以答案是 **[C] 算法优化能力**。  \n\n**答案：C**"}, "answer": "C"}, {"id": "32", "question": {"enus": "阿里云机器学习平台PAI中的PAI-Designer(原PAI-Studio)可视化建模，功能十分强大，以下哪些不是PAI-Designer支持的功能？", "zhcn": "阿里云机器学习平台PAI中的PAI-Designer(原PAI-Studio)可视化建模，功能十分强大，以下哪些不是PAI-Designer支持的功能？"}, "option": [{"option_text": {"enus": "流批一体训练", "zhcn": "流批一体训练"}, "option_flag": false}, {"option_text": {"enus": "拖拽式建模", "zhcn": "拖拽式建模"}, "option_flag": false}, {"option_text": {"enus": "分布式训练", "zhcn": "分布式训练"}, "option_flag": false}, {"option_text": {"enus": "纯人工调参", "zhcn": "纯人工调参"}, "option_flag": true}], "analysis": {"enus": "PAI-Designer可视化建模支持大规模分布式的传统机器学习、深度学习、强化学习训练；支持流批一体训练；封装上百种机器学习算法，拖拽式建模，自动调参。", "zhcn": "**正确答案是 D**。\n\n**详细解析如下：**\n\n题目问的是“哪些**不是**PAI-Designer支持的功能”。我们来逐一分析每个选项：\n\n*   **[A] 流批一体训练**：**是支持的功能**。PAI-Designer 提供了丰富的算法组件，可以处理存储在MaxCompute、OSS等数据源的数据。通过配置不同的输入和调度策略，可以实现批处理训练。同时，结合PAI平台的其他产品（如PAI-Flows），也能支持流式数据的处理与训练，实现流批一体的架构。\n\n*   **[B] 拖拽式建模**：**是核心功能，也是其基本特性**。PAI-Designer 的核心价值就在于它提供了一个可视化的、拖拽式的界面，用户无需编写代码，只需将数据源、数据处理、特征工程、机器学习算法、模型评估等组件拖拽到画布上并连接起来，即可构建完整的机器学习工作流。\n\n*   **[C] 分布式训练**：**是支持的功能**。PAI-Designer 底层基于阿里云的大数据计算引擎（如MaxCompute），其内置的许多算法（特别是深度学习算法）本身就支持分布式训练，能够高效处理海量数据，自动完成分布式计算资源的分配和管理。\n\n*   **[D] 纯人工调参**：**不是其支持的功能，或者说不是其设计目标**。PAI-Designer 虽然提供了可视化界面来**配置**模型参数（即人工调参），但它更强大的功能在于提供了**自动调参（AutoML）** 的组件。用户可以通过这些组件指定参数的搜索空间，平台会自动进行多轮训练来寻找最优参数组合。将“纯人工调参”作为一个独立的功能选项，它并不符合PAI-Designer旨在提升效率、降低门槛的智能化、自动化设计理念。因此，这项是题目所寻找的“不支持的功能”。\n\n**结论：**\nPAI-Designer 的核心优势在于通过**拖拽式可视化建模（B）**，利用**分布式计算引擎（C）**，来处理**流批一体（A）** 的数据，并内置了**自动机器学习** 来优化模型，而不是强调“纯人工调参（D）”。所以，不属于其支持的功能是 **D**。\n\n**[答案解析]** 的说明非常准确，它指出了PAI-Designer的核心是自动化、可视化，而非鼓励低效的手动调参。"}, "answer": "D"}, {"id": "33", "question": {"enus": "下列对阿里云机器学习平台PAI描述错误是？", "zhcn": "下列对阿里云机器学习平台PAI描述错误是？"}, "option": [{"option_text": {"enus": "高性能", "zhcn": "高性能"}, "option_flag": false}, {"option_text": {"enus": "简单易用", "zhcn": "简单易用"}, "option_flag": false}, {"option_text": {"enus": "高成本", "zhcn": "高成本"}, "option_flag": true}, {"option_text": {"enus": "解决方案丰富", "zhcn": "解决方案丰富"}, "option_flag": false}], "analysis": {"enus": "阿里云机器学习平台PAI的产品优势是简单易用、高性能、低成本和解决方案丰富。", "zhcn": "这道题的答案是 **[C] 高成本**。\n\n**详细解析如下：**\n\n题目要求找出**描述错误**的选项。我们来逐一分析每个选项：\n\n*   **[A] 高性能**：**描述正确**。阿里云PAI平台底层基于阿里云强大的计算基础设施，提供了优化的算法框架和分布式计算能力，能够高效处理海量数据，满足企业级机器学习任务对性能的高要求。\n*   **[B] 简单易用**：**描述正确**。PAI提供了可视化的建模界面（PAI-Studio/DSW）、拖拽式的工作流以及多种预置的算法组件，大大降低了机器学习的门槛。即使是业务分析师或不擅长编程的用户也能快速上手。同时，它也支持Notebook等开发模式，为数据科学家提供了灵活的编程环境。\n*   **[C] 高成本**：**描述错误**。这正是本题的答案。云计算和云服务的一个核心优势就是**按需付费**，避免自建机房和硬件的一次性巨大投入。PAI作为云服务，用户只需为实际使用的计算资源和存储资源付费，可以根据业务波峰波谷灵活调整资源，从而有效控制和降低成本。相比于自建机器学习平台，PAI具有**成本效益高**的特点。因此，“高成本”是对其错误的描述。\n*   **[D] 解决方案丰富**：**描述正确**。PAI不仅提供基础的机器学习算法，还集成了深度学习框架，并针对电商、金融、医疗等行业提供了端到端的解决方案模板，帮助用户快速解决特定业务场景下的问题。\n\n**总结：**\n阿里云机器学习平台PAI的核心优势在于**高性能、简单易用、高性价比（低成本）和丰富的解决方案**。选项C的“高成本”与PAI的设计理念和云服务的优势相悖，因此是错误描述。"}, "answer": "C"}, {"id": "34", "question": {"enus": "机器学习PAI平台核心提供了从数据处理、模型开发、训练到部署的一站式服务，并提供了哪两种机器学习模型开发环境？", "zhcn": "机器学习PAI平台核心提供了从数据处理、模型开发、训练到部署的一站式服务，并提供了哪两种机器学习模型开发环境？"}, "option": [{"option_text": {"enus": "分布式和交互式", "zhcn": "分布式和交互式"}, "option_flag": false}, {"option_text": {"enus": "可视化和交互式", "zhcn": "可视化和交互式"}, "option_flag": true}, {"option_text": {"enus": "可视化和数字化", "zhcn": "可视化和数字化"}, "option_flag": false}, {"option_text": {"enus": "可视化和分布式", "zhcn": "可视化和分布式"}, "option_flag": false}], "analysis": {"enus": "机器学习PAI平台核心提供了从数据处理、模型开发、训练到部署的一站式服务。PAI-Studio与PAI-DSW通过打通底层数据，提供可视化和交互式两种机器学习模型开发环境。", "zhcn": "我们来分析一下题目。  \n\n题目问的是 **PAI 平台提供的两种机器学习模型开发环境**。  \n根据阿里云 PAI 平台的官方介绍，它主要提供：  \n\n1. **可视化建模（拖拽式界面）** —— 适合非专业开发人员快速构建模型。  \n2. **交互式建模（Notebook 等）** —— 适合数据科学家进行代码开发、调试和实验。  \n\n因此，正确选项是 **可视化和交互式**。  \n\n**答案：B** ✅"}, "answer": "B"}, {"id": "35", "question": {"enus": "阿里云智能语音交互支持语音识别、语音合成等功能，其中不需要使用语音识别技术是哪项？", "zhcn": "阿里云智能语音交互支持语音识别、语音合成等功能，其中不需要使用语音识别技术是哪项？"}, "option": [{"option_text": {"enus": "语音指令", "zhcn": "语音指令"}, "option_flag": false}, {"option_text": {"enus": "实时会议记录", "zhcn": "实时会议记录"}, "option_flag": false}, {"option_text": {"enus": "视频搜索", "zhcn": "视频搜索"}, "option_flag": true}, {"option_text": {"enus": "视频实时直播字幕", "zhcn": "视频实时直播字幕"}, "option_flag": false}], "analysis": {"enus": "视觉搜索服务基于阿里云深度学习技术，进行视觉内容搜索，在指定图像、视频或3D模型库中搜索出相同或相似的视觉信息，适用于内容比对、内容精确查找、相似素材搜索等场景。", "zhcn": "我们先分析一下每个选项与语音识别的关系：  \n\n- **[A] 语音指令**：需要先识别语音内容，再执行指令 → 需要语音识别。  \n- **[B] 实时会议记录**：将会议中说的话转成文字 → 需要语音识别。  \n- **[C] 视频搜索**：一般指用文本搜索视频内容（如根据视频元数据、字幕文本搜索），不需要实时将语音转成文字，除非是“语音搜索视频”（即用语音输入搜索词），但这里“视频搜索”通常指文本查询，不依赖语音识别。  \n- **[D] 视频实时直播字幕**：直播中语音实时转文字并显示为字幕 → 需要语音识别。  \n\n题目问“不需要使用语音识别技术”的，显然是 **C**。  \n\n**答案：C** ✅"}, "answer": "C"}, {"id": "36", "question": {"enus": "阿里云机器学习平台PAI底层不支持哪种计算架构？", "zhcn": "阿里云机器学习平台PAI底层不支持哪种计算架构？"}, "option": [{"option_text": {"enus": "TensorFlow", "zhcn": "TensorFlow"}, "option_flag": false}, {"option_text": {"enus": "Flink", "zhcn": "Flink"}, "option_flag": false}, {"option_text": {"enus": "PAP", "zhcn": "PAP"}, "option_flag": true}, {"option_text": {"enus": "MapReduce", "zhcn": "MapReduce"}, "option_flag": false}], "analysis": {"enus": "PAI底层支持多种计算框架：流式计算框架Flink；基于开源版本深度优化的深度学习框架TensorFlow；千亿特征样本的大规模并行计算框架Parameter Server；Spark、PySpark、MapReduce等业内主流开源框架。", "zhcn": "**正确答案是 C**。\n\n**详细解析如下：**\n\n阿里云机器学习平台PAI（Platform of Artificial Intelligence）是一个集数据处理、模型训练、模型部署于一体的全流程机器学习平台。它的设计目标是兼容和支撑多种主流的计算框架和生态，以提供灵活且强大的机器学习能力。\n\n我们来逐一分析每个选项：\n\n*   **[A] TensorFlow**：**支持**。TensorFlow 是全球最流行的深度学习框架之一，PAI 对其有深度的支持和优化，提供了专门的 TensorFlow 版本，并集成了如 EasyTransfer（易用迁移学习）等高级功能。用户可以直接在 PAI 上使用 TensorFlow 进行模型训练和部署。\n\n*   **[B] Flink**：**支持**。Flink 是顶级的流式计算框架。PAI 与 Flink 深度集成，特别是在其子产品 PAI-Designer（可视化建模）中，许多数据预处理和特征工程组件就是基于 Flink 引擎实现的，用于处理大规模的数据流和批处理任务。\n\n*   **[C] PAP**：**不支持**。PAP 并不是一个公认的、主流的分布式计算框架或架构。在计算机领域，常见的缩写有 MPI（Message Passing Interface，消息传递接口）、SPARK（Apache Spark）等，但 PAP 并非其中之一。它很可能是一个干扰项或拼写错误。因此，PAI 底层自然不支持一个不存在的或不相关的“PAP”架构。\n\n*   **[D] MapReduce**：**间接支持**。虽然 PAI 的核心计算引擎已经更多地转向像 Spark、Flink 这样的更高效的计算框架，但 MapReduce 作为 Hadoop 生态的核心模型，其执行引擎（如 Apache Hadoop MR）仍然可以被 PAI 平台底层的基础设施（如 MaxCompute）所兼容或作为其历史组成部分。PAI 可以处理存储在 MaxCompute（旧称ODPS，其早期版本基于类似MapReduce的思想）中的数据。所以，不能简单地说“不支持”，平台在底层对其有兼容性。\n\n**结论：**\n在给定的四个选项中，**[A]、[B]、[D]** 所代表的架构都与 PAI 平台有直接或间接的支持关系。唯独 **[C] PAP** 是一个无效的或无关的选项，因此它是 PAI 底层不支持的“计算架构”。\n\n所以，正确答案是 **C**。"}, "answer": "C"}, {"id": "37", "question": {"enus": "无人驾驶主要使用的技术是哪项？", "zhcn": "无人驾驶主要使用的技术是哪项？"}, "option": [{"option_text": {"enus": "视觉智能", "zhcn": "视觉智能"}, "option_flag": true}, {"option_text": {"enus": "语音识别", "zhcn": "语音识别"}, "option_flag": false}, {"option_text": {"enus": "自然语言处理", "zhcn": "自然语言处理"}, "option_flag": false}, {"option_text": {"enus": "推荐算法", "zhcn": "推荐算法"}, "option_flag": false}], "analysis": {"enus": "无人驾驶汽车是通过车载传感系统感知道路环境，自动规划行车路线并控制车辆到达预定目标的智能汽车。它利用车载传感器来感知车辆周围环境，并根据感知所获得的道路、车辆位置和障碍物信息，控制车辆的转向和速度，从而使车辆能够安全、可靠地在道路上行驶。无人驾驶在具体实现过程需要实现对行人和车辆的检测、车道线和交通警示牌的识别，因此主要使用了视觉智能技术。", "zhcn": "正确答案是 **[A] 视觉智能**。\n\n**详细解析如下：**\n\n无人驾驶汽车需要像人类司机一样感知和理解周围的环境，以便安全行驶。这个核心任务主要依赖于**视觉智能**技术。\n\n*   **视觉智能**：这项技术通过摄像头、激光雷达（LiDAR）、毫米波雷达等传感器，来“看”到道路、车辆、行人、交通标志、信号灯等。然后，利用计算机视觉和深度学习算法对这些视觉数据进行实时分析，从而完成以下关键任务：\n    *   **物体检测与识别**：识别出图像或点云数据中的各种物体（如汽车、行人、自行车）。\n    *   **语义分割**：理解每个像素属于什么类别（如道路、天空、建筑物），从而精确勾勒出可行驶区域和障碍物。\n    *   **车道线检测**：识别车道标记，确保车辆在车道内行驶。\n    *   **交通标志识别**：读懂限速、停止、转向等交通标志。\n\n其他选项虽然也是人工智能的重要分支，但它们在无人驾驶中扮演辅助或次要角色，而非核心技术：\n\n*   **[B] 语音识别**：主要用于车内的人机交互，例如乘客通过语音指令设定目的地或调节空调，与车辆的外部环境感知和决策无关。\n*   **[C] 自然语言处理**：通常与语音识别结合，用于理解乘客的语音指令，或者处理与云端交通系统的文本通信，同样不是环境感知的核心。\n*   **[D] 推荐算法**：主要用于电商、内容平台等领域，根据用户喜好推荐商品或信息，与无人驾驶的感知和决策过程没有直接关系。\n\n因此，**视觉智能是无人驾驶实现环境感知、从而进行决策和控制的最主要、最基础的技术**。"}, "answer": "A"}, {"id": "38", "question": {"enus": "给定图像，输出图像类别的智能算法的任务是哪项？", "zhcn": "给定图像，输出图像类别的智能算法的任务是哪项？"}, "option": [{"option_text": {"enus": "图像分类", "zhcn": "图像分类"}, "option_flag": true}, {"option_text": {"enus": "目标检测", "zhcn": "目标检测"}, "option_flag": false}, {"option_text": {"enus": "图像检索", "zhcn": "图像检索"}, "option_flag": false}, {"option_text": {"enus": "人脸检测", "zhcn": "人脸检测"}, "option_flag": false}], "analysis": {"enus": "图像分类是根据图像中的相关信息，输出图像标签的过程。", "zhcn": "**正确答案是 A：图像分类。**\n\n**详细解析如下：**\n\n*   **A. 图像分类**\n    *   **任务描述**：给定一张图像，算法需要判断该图像属于预先定义好的哪个类别（例如，“猫”、“狗”、“汽车”、“风景”等）。输出通常是单个或多个类别标签。\n    *   **与题目匹配度**：题目要求“输出图像类别”，这正是图像分类任务的**核心目标**。例如，输入一张猫的图片，算法输出“猫”这个类别。\n\n*   **B. 目标检测**\n    *   **任务描述**：不仅要识别出图像中有什么物体（分类），还要定位出这些物体的具体位置，通常用边界框表示。输出是多个“边界框+类别标签”的组合。\n    *   **与题目匹配度**：题目只要求输出“类别”，没有要求定位物体的“位置”，因此目标检测的任务范围超出了题目要求。\n\n*   **C. 图像检索**\n    *   **任务描述**：给定一张查询图像，从大规模图像数据库中找出内容相似或相同的图像。输出是一个图像列表。\n    *   **与题目匹配度**：题目要求输出的是“类别”（一个标签），而不是一系列相似的图像，因此不匹配。\n\n*   **D. 人脸检测**\n    *   **任务描述**：这是目标检测的一个特定子任务，专门用于检测和定位图像中的人脸。输出是人脸的位置（边界框），有时会附带一些人脸特征点。\n    *   **与题目匹配度**：这是一个非常具体的任务，而题目是一个通用性的“图像类别”问题，不特指人脸。此外，其输出重点是“定位”而非单纯的“分类”。\n\n**总结：**\n题目明确指出了核心任务是“输出图像类别”，这正是**图像分类**的经典定义。其他选项要么任务更复杂（如目标检测），要么任务目标不同（如图像检索），要么是特定领域的应用（如人脸检测）。因此，最准确的任务是 **A. 图像分类**。"}, "answer": "A"}, {"id": "39", "question": {"enus": "视觉智能算法最大的特点是哪项？", "zhcn": "视觉智能算法最大的特点是哪项？"}, "option": [{"option_text": {"enus": "自动化", "zhcn": "自动化"}, "option_flag": true}, {"option_text": {"enus": "精度高", "zhcn": "精度高"}, "option_flag": false}, {"option_text": {"enus": "硬件成本低", "zhcn": "硬件成本低"}, "option_flag": false}, {"option_text": {"enus": "需要数据少", "zhcn": "需要数据少"}, "option_flag": false}], "analysis": {"enus": "视觉智能算法通过为计算机赋予“人”的感知能力，自动化的完成图像数据分类，因此图像分类与传统分类方法相比最大的特点是全自动", "zhcn": "这道题问的是**视觉智能算法最大的特点**，给出的参考答案是 **A 自动化**。  \n\n我来解释一下为什么这样选：  \n\n- **A 自动化**：视觉智能算法（如目标检测、图像分类、分割等）的核心价值在于让计算机自动完成原本需要人工参与的视觉任务，比如自动识别产品缺陷、自动识别车牌、自动进行人脸识别等。这是它区别于传统图像处理方法的根本特点。  \n- **B 精度高**：精度取决于具体算法、数据质量和任务难度，并不是所有情况下都“高”，而且高精度是目标，但不一定是“最大特点”。  \n- **C 硬件成本低**：不一定，很多视觉算法需要 GPU 等较高算力，硬件成本不一定低。  \n- **D 需要数据少**：恰恰相反，深度学习视觉算法通常依赖大量标注数据，数据需求大。  \n\n因此，从本质特征来看，**自动化**是视觉智能算法最核心、最普遍的特点。"}, "answer": "A"}, {"id": "40", "question": {"enus": "随着智能化城市的发展，目前越来越多的小区采用车牌识别的方法来管理进出的车辆，车牌识别方法主要包含的视觉智能技术是哪项？", "zhcn": "随着智能化城市的发展，目前越来越多的小区采用车牌识别的方法来管理进出的车辆，车牌识别方法主要包含的视觉智能技术是哪项？"}, "option": [{"option_text": {"enus": "目标检测", "zhcn": "目标检测"}, "option_flag": false}, {"option_text": {"enus": "图像识别", "zhcn": "图像识别"}, "option_flag": false}, {"option_text": {"enus": "文字识别", "zhcn": "文字识别"}, "option_flag": true}, {"option_text": {"enus": "图像检索", "zhcn": "图像检索"}, "option_flag": false}], "analysis": {"enus": "车牌识别是一个较为复杂的智能视觉技术：首先需要对包含车辆号牌的图像进行分析处理，从而确定牌照在图像中的位置，并把牌照区域提取出来，再进一步识别上面的文本字符。车牌识别过程包括图像采集、预处理、车牌定位、字符分割、字符识别、结果输出等一系列算法运算。其中的核心技术是文字识别。", "zhcn": "我们先分析一下题目。  \n\n题目说“车牌识别方法”主要包含的视觉智能技术是哪一项。  \n车牌识别一般分为两个主要步骤：  \n1. **车牌检测**（在图像中找到车牌的位置） → 属于**目标检测**。  \n2. **车牌字符识别**（识别车牌上的文字、数字、字母） → 属于**文字识别（OCR）**。  \n\n题目问的是“车牌识别方法”主要包含的视觉智能技术，通常更关键和核心的是**识别车牌上的字符**，因为检测只是定位，而识别才是最终目的。  \n在选项中：  \n- [A] 目标检测 → 只是第一步，不是最终识别技术。  \n- [B] 图像识别 → 太宽泛，可以指整个流程，但专业上不特指车牌识别核心技术。  \n- [C] 文字识别 → 即 OCR，是车牌识别中从车牌图像到文字信息的关键技术。  \n- [D] 图像检索 → 不相关。  \n\n所以参考答案 **C** 是合理的，因为“车牌识别”在视觉技术分类中常归为**文字识别（OCR）**的一个应用。  \n\n**最终答案：C**"}, "answer": "C"}, {"id": "41", "question": {"enus": "目标检测是一个经典的智能视觉任务，在很多场景中均有应用前景，以下场景中，没有使用到目标检测技术的是哪项？", "zhcn": "目标检测是一个经典的智能视觉任务，在很多场景中均有应用前景，以下场景中，没有使用到目标检测技术的是哪项？"}, "option": [{"option_text": {"enus": "行人计数", "zhcn": "行人计数"}, "option_flag": false}, {"option_text": {"enus": "车辆检测", "zhcn": "车辆检测"}, "option_flag": false}, {"option_text": {"enus": "无人驾驶", "zhcn": "无人驾驶"}, "option_flag": false}, {"option_text": {"enus": "猫狗分类", "zhcn": "猫狗分类"}, "option_flag": true}], "analysis": {"enus": "目标检测在输出目标类别信息的同时，需要同时通过标注框的形式确定目标的相应位置，同时给出目标的位置信息和类别信息。行人计数、车辆检测、无人驾驶任务在具体应用过程中均需要确定相应的位置，是目标检测在其中的应用，而猫狗分类只需要输出相应的标签即可，是图像分类技术。", "zhcn": "我们先逐一分析每个选项：  \n\n- **[A] 行人计数**：通常需要先检测出图像或视频中的行人，再进行计数，属于目标检测的应用。  \n- **[B] 车辆检测**：直接就是目标检测任务，检测图像中的车辆位置和类别。  \n- **[C] 无人驾驶**：需要检测道路上的车辆、行人、交通标志等，依赖目标检测技术。  \n- **[D] 猫狗分类**：这是**图像分类**任务，只需判断整张图片是猫还是狗，不需要定位目标在图像中的位置，因此不属于目标检测。  \n\n所以正确答案是 **D**。"}, "answer": "D"}, {"id": "42", "question": {"enus": "智能视觉技术是利用各种智能算法对计算机进行赋能，通过对视觉信息进行处理来完成特定的计算机视觉任务，而图像的位置信息和语义信息是其中最为关键的两大信息。以下智能视觉任务中，不需要图像位置信息的是任务是哪项？", "zhcn": "智能视觉技术是利用各种智能算法对计算机进行赋能，通过对视觉信息进行处理来完成特定的计算机视觉任务，而图像的位置信息和语义信息是其中最为关键的两大信息。以下智能视觉任务中，不需要图像位置信息的是任务是哪项？"}, "option": [{"option_text": {"enus": "目标检测", "zhcn": "目标检测"}, "option_flag": false}, {"option_text": {"enus": "图像识别", "zhcn": "图像识别"}, "option_flag": true}, {"option_text": {"enus": "图像分割", "zhcn": "图像分割"}, "option_flag": false}, {"option_text": {"enus": "人脸检测", "zhcn": "人脸检测"}, "option_flag": false}], "analysis": {"enus": "目标检测、图像分割、人脸检测都是需要确定位置信息的任务，不仅要给出相应的类别标签，还必须输出其相应的位置，因此需要从图像中提取出位置信息，是典型同时需要位置和语义信息的任务。而图像识别任务不需要确定目标的位置，只需要语义信息即可。", "zhcn": "我们先分析一下各个任务对**位置信息**的需求：  \n\n- **目标检测**：不仅需要识别出物体是什么，还要用边界框（bounding box）标出物体在图像中的位置 → 需要位置信息。  \n- **图像识别**：通常指图像分类（image classification），只需判断图像中主要包含什么物体或场景，不需要定位物体在图像中的具体位置 → 不需要位置信息。  \n- **图像分割**：分为语义分割（semantic segmentation）和实例分割（instance segmentation），都需要对每个像素分配类别，本质上是密集的位置级预测 → 需要位置信息。  \n- **人脸检测**：是目标检测的一种，需要定位人脸的位置 → 需要位置信息。  \n\n因此，不需要图像位置信息的任务是 **图像识别（图像分类）**，对应选项 **B**。  \n\n答案：**B** ✅"}, "answer": "B"}, {"id": "43", "question": {"enus": "图像预处理技术会在很大程度上影响视觉智能的性能。通过一系列变换, 将待处理的原始图像转换成相应的唯一标准形式的图像预处理方法是哪项？", "zhcn": "图像预处理技术会在很大程度上影响视觉智能的性能。通过一系列变换, 将待处理的原始图像转换成相应的唯一标准形式的图像预处理方法是哪项？"}, "option": [{"option_text": {"enus": "正则化", "zhcn": "正则化"}, "option_flag": false}, {"option_text": {"enus": "归一化", "zhcn": "归一化"}, "option_flag": true}, {"option_text": {"enus": "白化", "zhcn": "白化"}, "option_flag": false}, {"option_text": {"enus": "轻量化", "zhcn": "轻量化"}, "option_flag": false}], "analysis": {"enus": "图像归一化通过对图像减均值、除方差等操作，将图像分布缩放至0-1之间，从而将原始图像转换成相应的唯一标准形式，是一种经典的图像预处理方法，可以有效提升视觉算法的性能", "zhcn": "我们先分析一下题目。  \n\n题目说“通过一系列变换，将待处理的原始图像转换成相应的唯一标准形式”，这种预处理方法通常是指**将图像像素值范围、尺寸等统一到固定标准**，以便模型处理。  \n\n- **[A] 正则化**：一般指在损失函数中加入惩罚项防止过拟合，不是图像像素值标准化的主要说法。  \n- **[B] 归一化**：通常指将数据缩放到某个固定范围（如 [0,1] 或 [-1,1]），并且可以包括尺寸归一化、像素值归一化，使图像数据统一标准形式。  \n- **[C] 白化**：是一种更强的预处理，不仅归一化，还做了去相关和方差归一化（PCA 白化 / ZCA 白化），但“唯一标准形式”更贴近归一化，白化只是归一化的一种高级形式，并不常用在所有图像预处理中。  \n- **[D] 轻量化**：指模型压缩、减少计算量，不是图像预处理方法。  \n\n在计算机视觉中，**归一化（Normalization）** 是最常见且基础的预处理步骤，用于将原始图像转换为统一尺度、统一数值范围的标准形式。  \n\n所以正确答案是 **B**。"}, "answer": "B"}, {"id": "44", "question": {"enus": "序列数据是一种常见的数据，例如视频片段，连续拍摄的照片等，从时序数据中提取出合适特征对完成相应的任务非常重要。如下特征提取算法中，能有效从序列数据中提取特征的是哪项？", "zhcn": "序列数据是一种常见的数据，例如视频片段，连续拍摄的照片等，从时序数据中提取出合适特征对完成相应的任务非常重要。如下特征提取算法中，能有效从序列数据中提取特征的是哪项？"}, "option": [{"option_text": {"enus": "SIFT", "zhcn": "SIFT"}, "option_flag": false}, {"option_text": {"enus": "HOG", "zhcn": "HOG"}, "option_flag": false}, {"option_text": {"enus": "CNN", "zhcn": "CNN"}, "option_flag": false}, {"option_text": {"enus": "RNN", "zhcn": "RNN"}, "option_flag": true}], "analysis": {"enus": "RNN是一种特殊的神经网络结构, 它是根据&quot;人的认知是基于过往的经验和记忆&quot;这一观点提出的. 它与DNN,CNN不同的是: 它不仅考虑前一时刻的输入,而且赋予了网络对前面的内容的一种'记忆'功能.\nRNN之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出，因此具备从时序信息中提取图像特征的能力。", "zhcn": "我们先分析一下题目。  \n\n题目说的是**序列数据**（如视频、连续照片等），强调**时序**信息，因此需要能够处理时间依赖关系的特征提取算法。  \n\n- **SIFT**：主要用于单张图像的局部特征提取，不涉及时间序列建模。  \n- **HOG**：也是针对单张图像的特征描述，用于目标检测等，无时序处理能力。  \n- **CNN**：虽然可以处理单张图像或通过3D CNN处理视频，但标准的CNN主要关注空间特征，对长时序依赖的建模能力较弱。  \n- **RNN**：专为序列数据设计，能够利用历史信息，适合从时序数据中提取特征。  \n\n因此，能有效从序列数据中提取特征的是 **RNN**。  \n\n**答案：D** ✅"}, "answer": "D"}, {"id": "45", "question": {"enus": "RCNN中获取目标候选区域的方法是哪项？", "zhcn": "RCNN中获取目标候选区域的方法是哪项？"}, "option": [{"option_text": {"enus": "Selective Search", "zhcn": "Selective Search"}, "option_flag": true}, {"option_text": {"enus": "SPP", "zhcn": "SPP"}, "option_flag": false}, {"option_text": {"enus": "RPN", "zhcn": "RPN"}, "option_flag": false}, {"option_text": {"enus": "ASPP", "zhcn": "ASPP"}, "option_flag": false}], "analysis": {"enus": "RCNN使用传统方法Selective Search来生成候选区域，对于每一张图像大概输出2000个左右的候选框，虽然在一定程度上很好的初步确定目标所在的大概位置，但是这个过程是用传统方法实现的，速度较慢，是RCNN算法主要的速度瓶颈", "zhcn": "在 RCNN 模型中，获取目标候选区域的方法是 **Selective Search**。\n\n**详细解析如下：**\n\n1.  **RCNN 的核心流程**：RCNN 的提出是目标检测领域的一个重要里程碑。它的核心思想是将检测任务分为几个步骤：\n    *   **步骤一：区域提议**：首先，使用一种与类别无关的算法，从输入图像中提取大约 2000 个可能包含物体的候选区域。\n    *   **步骤二：特征提取**：然后将每个候选区域缩放到固定大小，并送入一个预训练好的卷积神经网络（如 AlexNet）中提取高维特征。\n    *   **步骤三：分类与精修**：最后，将提取出的特征送入一系列支持向量机（SVM）中进行分类，判断该区域属于哪个类别（或背景），同时使用一个回归器来微调候选框的位置，使其更精确地包围目标。\n\n2.  **Selective Search 的作用**：在上述流程中，**第一步“区域提议”所使用的算法就是 Selective Search**。它的主要目标是**快速、高效地生成可能包含物体的区域**，而不需要知道物体具体是什么类别。它通过结合颜色、纹理、大小和形状等视觉信息，对图像底层分割区域进行层次性组合，从而产生一系列质量较高的候选区域框。\n\n**为什么其他选项不正确：**\n\n*   **[B] SPP（空间金字塔池化）**：SPP 是一种用于处理不同尺寸输入的特征池化方法。它是在 SPP-Net 中被引入，用于解决 RCNN 需要将每个候选区域缩放到固定尺寸导致的失真和效率低下问题。SPP 层允许网络接受任意尺寸的输入，并输出固定长度的特征向量。它**不是**用于生成候选区域的方法。\n*   **[C] RPN（区域提议网络）**：RPN 是 Faster R-CNN 模型的核心组件。它是一个小型神经网络，直接嵌入到检测网络中，用于**端到端地生成候选区域**。RPN 比 Selective Search 更快、更高效，并且是深度学习的一部分。但 RCNN 是更早的模型，它使用的是传统的 Selective Search 方法，而不是 RPN。\n*   **[D] ASPP（空洞空间金字塔池化）**：ASPP 是语义分割模型（如 DeepLab 系列）中常用的模块，用于在多个尺度上捕获上下文信息，从而更好地分割不同大小的物体。它**与目标候选区域的生成无关**。\n\n**总结：**\n\nRCNN 开创了“区域提议 + 深度学习特征”的两阶段检测范式，而 **Selective Search** 正是其第一阶段用来生成候选区域的关键技术。后续的 Fast R-CNN 和 Faster R-CNN 分别用 SPP/ROI Pooling 和 RPN 改进了特征提取和区域提议的步骤，使得模型性能更高、速度更快。\n\n所以，正确答案是 **[A] Selective Search**。"}, "answer": "A"}, {"id": "46", "question": {"enus": "下列目标检测算法中包含anchor机制的是哪项？", "zhcn": "下列目标检测算法中包含anchor机制的是哪项？"}, "option": [{"option_text": {"enus": "Fast RCNN", "zhcn": "Fast RCNN"}, "option_flag": false}, {"option_text": {"enus": "YOLO v1", "zhcn": "YOLO v1"}, "option_flag": false}, {"option_text": {"enus": "SSD", "zhcn": "SSD"}, "option_flag": true}, {"option_text": {"enus": "RCNN", "zhcn": "RCNN"}, "option_flag": false}], "analysis": {"enus": "SSD中包含anchor机制来生成候选区域，其他算法均没有", "zhcn": "我们先分析一下各个选项的 anchor 机制情况。  \n\n**A. Fast RCNN**  \nFast RCNN 使用 Selective Search 等方法生成候选区域（region proposals），而不是预设的 anchor boxes，所以它**不依赖 anchor 机制**。  \n\n**B. YOLO v1**  \nYOLO v1 将图像划分为 S×S 的网格，每个网格预测固定数量的边界框（如 2 个），但这些边界框是直接预测偏移量，并没有预先设定不同尺度和长宽比的 anchor boxes（即没有基于数据集的聚类先验尺寸），因此一般认为 YOLO v1 是**无 anchor 机制**（或者说它的 anchor 是隐式的、非多尺度的）。  \n\n**C. SSD**  \nSSD 在特征图的每个位置设置多个不同尺度和长宽比的 default boxes（即 anchor boxes），然后对这些 anchor 进行分类和位置微调，是**典型的 anchor-based 方法**。  \n\n**D. RCNN**  \nRCNN 也是用 Selective Search 生成候选区域，没有使用预定义的 anchor boxes，所以**不包含 anchor 机制**。  \n\n因此，包含 anchor 机制的是 **SSD**。  \n\n**答案：C** ✅"}, "answer": "C"}, {"id": "47", "question": {"enus": "提出残差结构的图像分类算法是哪项？", "zhcn": "提出残差结构的图像分类算法是哪项？"}, "option": [{"option_text": {"enus": "GoogleNet", "zhcn": "GoogleNet"}, "option_flag": false}, {"option_text": {"enus": "SSD", "zhcn": "SSD"}, "option_flag": false}, {"option_text": {"enus": "ResNet", "zhcn": "ResNet"}, "option_flag": true}, {"option_text": {"enus": "VGGNet", "zhcn": "VGGNet"}, "option_flag": false}], "analysis": {"enus": "对于较深的神经网络，神经网络的计算梯度从深层往浅层进行传递时往往容易出现梯度消失问题，因此影响浅层的模型训练。ResNet提出了残差结构，可以将梯度信息直接通过残差结构传递到浅层，避免了梯度消失问题", "zhcn": "您给出的问题和答案完全正确。\n\n**正确答案是：**[C] ResNet\n\n**详细解析如下：**\n\n*   **ResNet（残差网络）**：由何恺明等人在2015年提出。其核心创新就是**残差结构（Residual Block）**。这个结构通过引入“快捷连接”或“跳跃连接”，将输入直接绕过一个或多个层，与这些层的输出相加。这种设计有效地解决了在深度神经网络中随着层数增加而出现的**梯度消失/爆炸**和**网络退化**问题，使得训练成百上千层的超深网络成为可能，并显著提升了图像分类等任务的准确率。\n\n*   **其他选项分析**：\n    *   **[A] GoogleNet**：其核心创新是 **Inception 模块**，该模块通过在同一个层级上使用不同尺寸的卷积核来提取多尺度特征，并通过1x1卷积来降低计算复杂度。它并没有使用残差结构。\n    *   **[B] SSD**：这是一个**目标检测**算法，而不是主要用于图像分类的算法。它的核心是使用单个深度神经网络在多尺度特征图上进行边界框回归和分类。\n    *   **[D] VGGNet**：其贡献在于探索了网络的**深度**，通过堆叠简单的3x3卷积层和2x2池化层来构建深度模型。它是一个非常经典但结构朴素的网络，没有使用残差或Inception这类复杂的模块。\n\n因此，明确提出并广泛应用**残差结构**的算法是 **ResNet**。"}, "answer": "C"}, {"id": "48", "question": {"enus": "SENet提出的注意力机制的作用是哪项？", "zhcn": "SENet提出的注意力机制的作用是哪项？"}, "option": [{"option_text": {"enus": "防止梯度消失", "zhcn": "防止梯度消失"}, "option_flag": false}, {"option_text": {"enus": "防止梯度爆炸", "zhcn": "防止梯度爆炸"}, "option_flag": false}, {"option_text": {"enus": "定位到感兴趣的信息，抑制无用信息", "zhcn": "定位到感兴趣的信息，抑制无用信息"}, "option_flag": true}, {"option_text": {"enus": "减少模型参数量", "zhcn": "减少模型参数量"}, "option_flag": false}], "analysis": {"enus": "与人在观察事物的时候相同，我们会将观察的重点更多的放在重点区域，从而使得观察效率得到提升。与此类似，计算机视觉采用注意力机制，使得卷积神经网络能定位到图像中更加感兴趣的区域，从而提升网络提取特征的鲁棒性", "zhcn": "我们先回顾一下 SENet（Squeeze-and-Excitation Network）的核心思想。  \n\nSENet 在卷积神经网络中引入了一种通道注意力机制，主要步骤为：  \n\n1. **Squeeze**：对每个通道的特征图进行全局平均池化，得到一个通道描述向量。  \n2. **Excitation**：通过全连接层（或瓶颈结构）学习每个通道的权重（即重要性）。  \n3. **Scale**：将学习到的权重乘回原来的特征图，实现通道维度上的重新校准。  \n\n它的作用是**让网络自适应地增强重要通道的特征响应，抑制不重要通道的响应**，从而让网络更加关注信息量大的特征通道。  \n\n---\n\n**选项分析**：  \n\n- **A 防止梯度消失**：SENet 的主要目的不是解决梯度消失，虽然注意力机制可能对训练有一定稳定作用，但这不是它的设计目标。  \n- **B 防止梯度爆炸**：同样不是 SENet 的主要作用。  \n- **C 定位到感兴趣的信息，抑制无用信息**：这正是注意力机制的核心作用，在通道维度上实现特征选择。  \n- **D 减少模型参数量**：SENet 会增加少量参数（全连接层），并不是为了减少参数量。  \n\n---\n\n因此正确答案是 **C**。"}, "answer": "C"}, {"id": "49", "question": {"enus": "Roi Pooling的作用是哪项？", "zhcn": "Roi Pooling的作用是哪项？"}, "option": [{"option_text": {"enus": "适应各种尺度的输入候选区域", "zhcn": "适应各种尺度的输入候选区域"}, "option_flag": true}, {"option_text": {"enus": "减少模型参数量", "zhcn": "减少模型参数量"}, "option_flag": false}, {"option_text": {"enus": "确定目标候选区域位置", "zhcn": "确定目标候选区域位置"}, "option_flag": false}, {"option_text": {"enus": "调整候选区域位置", "zhcn": "调整候选区域位置"}, "option_flag": false}], "analysis": {"enus": "Roi Pooling通过将候选区域池化，使得网络能够适应不同大小的候选区域，不再需要将候选区域进行缩放，从而避免因为将候选区域进行缩放带来的候选区域发生极端形变", "zhcn": "我们先分析一下各个选项的含义，再结合 Roi Pooling 的作用来判断。  \n\n**Roi Pooling（Region of Interest Pooling）** 是 Fast R-CNN 等两阶段目标检测模型中的关键操作，它的主要功能是：  \n\n1. 输入：来自 RPN（Region Proposal Network）的候选区域（不同大小、不同长宽比）。  \n2. 问题：这些候选区域对应的特征图区域大小不一，但全连接层需要固定尺寸的输入。  \n3. 解决：Roi Pooling 将不同尺寸的候选区域对应的特征图区域，经过坐标映射后，池化到固定大小（如 7×7）。  \n\n---\n\n**选项分析**：  \n\n- **[A] 适应各种尺度的输入候选区域**  \n  ✅ 正确。Roi Pooling 正是为了将不同尺度的候选区域归一化为固定尺寸的特征，从而适应全连接层的输入要求。  \n\n- **[B] 减少模型参数量**  \n  ❌ 错误。Roi Pooling 本身不减少参数量，它的作用是特征尺寸归一化。  \n\n- **[C] 确定目标候选区域位置**  \n  ❌ 错误。确定候选区域位置是 RPN 或 Selective Search 等区域提议方法的工作。  \n\n- **[D] 调整候选区域位置**  \n  ❌ 错误。Roi Pooling 不调整候选框的位置坐标，它只是在特征图上提取固定大小的特征。  \n\n---\n\n**最终答案**：  \n[A] 适应各种尺度的输入候选区域"}, "answer": "A"}, {"id": "50", "question": {"enus": "通过计算局部区域的梯度方向直方图来构成特征，从而对图像局部重叠区域的密集型描述符是哪项？", "zhcn": "通过计算局部区域的梯度方向直方图来构成特征，从而对图像局部重叠区域的密集型描述符是哪项？"}, "option": [{"option_text": {"enus": "HOG", "zhcn": "HOG"}, "option_flag": true}, {"option_text": {"enus": "SIFT", "zhcn": "SIFT"}, "option_flag": false}, {"option_text": {"enus": "DOG", "zhcn": "DOG"}, "option_flag": false}, {"option_text": {"enus": "LBP", "zhcn": "LBP"}, "option_flag": false}], "analysis": {"enus": "解析：PPT- 106页。HOG描述符通过计算局部区域的梯度方向直方图来构成特征", "zhcn": "我们先分析一下题目描述的关键词：  \n\n- **局部区域的梯度方向直方图**  \n- **构成特征**  \n- **图像局部重叠区域的密集型描述符**  \n\n---\n\n**选项分析**：  \n\n- **A. HOG（Histogram of Oriented Gradients）**  \n  - 工作原理：将图像分成小的连通区域（cell），计算每个 cell 内像素的梯度方向直方图，然后将这些直方图组合成特征向量。  \n  - 常用时，检测窗口在图像上滑动（重叠区域），对每个窗口提取 HOG 特征。  \n  - 确实是基于**梯度方向直方图**，并且是密集的（在检测窗口内逐块计算）。  \n  - 符合“局部重叠区域的密集型描述符”这一描述。  \n\n- **B. SIFT（Scale-Invariant Feature Transform）**  \n  - 虽然也用到梯度方向直方图（在关键点邻域内），但 SIFT 是稀疏特征描述符（只在关键点处计算），不是对整个图像密集、重叠区域都计算。  \n  - 因此不符合“密集型描述符”和“局部重叠区域”的 HOG 那种特点。  \n\n- **C. DOG（Difference of Gaussians）**  \n  - 是 SIFT 中用于检测关键点的一种滤波方法，不是特征描述符。  \n\n- **D. LBP（Local Binary Patterns）**  \n  - 基于局部像素灰度比较，生成二进制模式，不是基于梯度方向直方图。  \n\n---\n\n**结论**：  \n题目明确说“通过计算局部区域的梯度方向直方图来构成特征” + “密集型描述符” + “局部重叠区域”，这正是 HOG 的特征。  \n\n**答案**：A ✅"}, "answer": "A"}, {"id": "51", "question": {"enus": "用连续的曲线来表示图像特征发生急剧变化的区域的图像特征是哪项？", "zhcn": "用连续的曲线来表示图像特征发生急剧变化的区域的图像特征是哪项？"}, "option": [{"option_text": {"enus": "边缘特征", "zhcn": "边缘特征"}, "option_flag": true}, {"option_text": {"enus": "颜色特征", "zhcn": "颜色特征"}, "option_flag": false}, {"option_text": {"enus": "纹理特征", "zhcn": "纹理特征"}, "option_flag": false}, {"option_text": {"enus": "形状特征", "zhcn": "形状特征"}, "option_flag": false}], "analysis": {"enus": "边缘特征用连续的曲线来表示图像特征发生急剧变化的区域", "zhcn": "你给出的题目和答案是正确的。  \n\n**题目**：用连续的曲线来表示图像特征发生急剧变化的区域的图像特征是哪项？  \n**[A] 边缘特征**  \n[B] 颜色特征  \n[C] 纹理特征  \n[D] 形状特征  \n\n**答案**：A  \n\n---\n\n### 解析  \n1. **边缘特征**  \n   - 边缘是图像中像素灰度或颜色发生阶跃变化或不连续的区域，通常对应物体的轮廓或不同区域的交界。  \n   - 在图像处理中，边缘检测算法（如 Canny、Sobel）会提取这些变化剧烈的点，并常用连续的曲线（边缘轮廓）来表示。  \n   - 因此，“连续的曲线表示图像特征急剧变化的区域”正是边缘特征的定义。\n\n2. **颜色特征**  \n   - 描述图像或区域的颜色分布（如直方图、颜色矩），不强调“急剧变化”或“连续曲线”表示。\n\n3. **纹理特征**  \n   - 描述图像表面重复的局部模式（如粗糙度、方向性），常用统计方法或滤波器响应表示，不是用曲线表示急剧变化区域。\n\n4. **形状特征**  \n   - 描述物体轮廓或区域形状（如矩形度、圆形度），虽然可能用到轮廓曲线，但前提是边缘已被提取出来，因此“急剧变化区域”的原始提取属于边缘特征范畴。\n\n---\n\n所以，**边缘特征** 是符合题意的正确选项。"}, "answer": "A"}, {"id": "52", "question": {"enus": "在实际应用场景中，不能仅从精度的角度来选择算法。例如在无人驾驶场景中，不仅需要保证模型高精度，还需要保证比较快的运行速度来保证检测时效性。在如下算法中，在精度和速度上均衡性最好的目标检测算法是哪项？", "zhcn": "在实际应用场景中，不能仅从精度的角度来选择算法。例如在无人驾驶场景中，不仅需要保证模型高精度，还需要保证比较快的运行速度来保证检测时效性。在如下算法中，在精度和速度上均衡性最好的目标检测算法是哪项？"}, "option": [{"option_text": {"enus": "YOLO V3", "zhcn": "YOLO V3"}, "option_flag": true}, {"option_text": {"enus": "SSD", "zhcn": "SSD"}, "option_flag": false}, {"option_text": {"enus": "RCNN", "zhcn": "RCNN"}, "option_flag": false}, {"option_text": {"enus": "faster RCNN", "zhcn": "faster RCNN"}, "option_flag": false}], "analysis": {"enus": "目前YOLO v3算法在速度和精度上保持的均衡性最好", "zhcn": "你提到的场景是**无人驾驶**，它要求模型既要有较高的检测精度，又要保证较快的推理速度（实时性）。  \n\n我们来看一下选项中的几种经典目标检测算法的特点：  \n\n- **RCNN**：是早期基于区域提议的检测算法，速度很慢，无法满足实时性要求。  \n- **Faster RCNN**：虽然比 RCNN 快很多，但仍然不是为实时检测设计的，一般速度在 5~10 FPS 左右。  \n- **SSD**：单阶段检测器，速度较快，精度也不错，但在 YOLO v3 出现时，YOLO v3 在速度和精度平衡上通常优于 SSD。  \n- **YOLO v3**：在保持较高精度的同时，速度可以达到实时（几十 FPS），在精度和速度的均衡性上表现优秀，尤其适合无人驾驶这类需要实时处理的场景。  \n\n因此，题目问的是**精度和速度均衡性最好**的算法，在给出的选项中，**YOLO v3** 是最合适的。  \n\n**答案：A** ✅"}, "answer": "A"}, {"id": "53", "question": {"enus": "one state 算法比two stage算法精度低的主要原因是哪项？", "zhcn": "one state 算法比two stage算法精度低的主要原因是哪项？"}, "option": [{"option_text": {"enus": "one stage算法的正、负样本及其不均衡", "zhcn": "one stage算法的正、负样本及其不均衡"}, "option_flag": true}, {"option_text": {"enus": "one stage算法提取的特征鲁棒性太差", "zhcn": "one stage算法提取的特征鲁棒性太差"}, "option_flag": false}, {"option_text": {"enus": "one stage算法速度太差", "zhcn": "one stage算法速度太差"}, "option_flag": false}, {"option_text": {"enus": "one stage算法没有提取多尺度特征", "zhcn": "one stage算法没有提取多尺度特征"}, "option_flag": false}], "analysis": {"enus": "one state 算法比two stage算法精度低的主要原因是因为one state 算法不包含候选区域，会生成得到大量负样本，因此容易导致正负样本失衡，降低模型性能", "zhcn": "你给出的题目和答案是正确的。  \n\n**主要分析如下：**  \n\n- **One-stage 检测器**（如 YOLO、SSD）直接在特征图上预测目标的类别和位置，没有像 Two-stage 检测器（如 Faster R-CNN）那样的预筛选阶段（region proposal + 二次分类与回归）。  \n- 在 One-stage 检测器中，会生成大量的候选框（anchor boxes），其中绝大部分是负样本（背景），只有极少数是正样本（包含目标）。  \n- 这种**正负样本的极端不平衡**导致训练时模型被大量的负样本主导，使得正样本的梯度被淹没，模型难以充分学习目标的特征，从而精度相对较低。  \n- 后来一些工作（如 Focal Loss）就是针对这个问题提出的，通过调整损失函数来减少简单负样本对训练的贡献，使模型更关注难例。  \n\n其他选项分析：  \n- **B**：特征鲁棒性并不是主要差异，两者都可以用类似的 backbone（如 ResNet）。  \n- **C**：速度差是缺点，但不是精度低的原因。  \n- **D**：One-stage 算法（如 SSD）也可以提取多尺度特征，这不是精度低的根本原因。  \n\n所以正确答案是 **A**。"}, "answer": "A"}, {"id": "54", "question": {"enus": "证明使用很小的卷积（3*3），增加网络深度可以有效提升模型的效果的图像分类网络是哪项？", "zhcn": "证明使用很小的卷积（3*3），增加网络深度可以有效提升模型的效果的图像分类网络是哪项？"}, "option": [{"option_text": {"enus": "GoogleNet", "zhcn": "GoogleNet"}, "option_flag": false}, {"option_text": {"enus": "VGGNet", "zhcn": "VGGNet"}, "option_flag": true}, {"option_text": {"enus": "SPPNet", "zhcn": "SPPNet"}, "option_flag": false}, {"option_text": {"enus": "SENet", "zhcn": "SENet"}, "option_flag": false}], "analysis": {"enus": "VGGNet证明使用很小的卷积（3*3），增加网络深度可以有效提升模型的效果，深层的网络对于提取图像的语义信息具有更好的能力", "zhcn": "你的问题是关于**使用小卷积核（3×3）并通过增加网络深度来提升模型效果的图像分类网络**。  \n\n**正确答案是 [B] VGGNet**。  \n\n**解析**：  \n- **VGGNet**（由牛津大学 Visual Geometry Group 提出）的核心思想是使用**小的 3×3 卷积核堆叠**来代替大的卷积核（如 5×5、7×7），这样可以在保持相同感受野的同时减少参数数量，并且通过增加网络深度来提高特征提取能力。  \n- VGGNet 常见的结构有 VGG16、VGG19 等，层数较深，全部使用 3×3 卷积和 2×2 池化。  \n- 其他选项：  \n  - **GoogleNet** 主要使用 Inception 模块（多尺度卷积并行），不是单纯堆叠 3×3 卷积加深网络。  \n  - **SPPNet** 贡献是空间金字塔池化，用于处理任意尺寸输入，不是主要靠 3×3 小卷积加深网络。  \n  - **SENet** 核心是通道注意力机制，不是专门强调 3×3 卷积加深结构。  \n\n因此，符合题目描述的正是 **VGGNet**。"}, "answer": "B"}, {"id": "55", "question": {"enus": "从感受野的角度来看，一个7*7的卷积核相当于3*3卷积核的个数是哪项？", "zhcn": "从感受野的角度来看，一个7*7的卷积核相当于3*3卷积核的个数是哪项？"}, "option": [{"option_text": {"enus": "3", "zhcn": "3"}, "option_flag": true}, {"option_text": {"enus": "4", "zhcn": "4"}, "option_flag": false}, {"option_text": {"enus": "5", "zhcn": "5"}, "option_flag": false}, {"option_text": {"enus": "2", "zhcn": "2"}, "option_flag": false}], "analysis": {"enus": "VGGNet证明，一个7*7卷积核在感受野的角度来看，和3个3*3卷积核相同，同时3个3*3卷积核的参数量更少，因此使用小卷积核代替大卷积核可以在很多场景下提升模型性能", "zhcn": "我们先明确题意：题目问的是**从感受野的角度**，一个 \\(7 \\times 7\\) 的卷积核相当于多少个 \\(3 \\times 3\\) 卷积核堆叠（假设 stride=1，padding 适当）时的感受野大小。  \n\n---\n\n## 1. 感受野计算公式\n对于连续的卷积层（stride=1，padding 适当保持尺寸不变或按常见方式），感受野大小的递推公式为：\n\n\\[\nRF_{l} = RF_{l-1} + (k_l - 1) \\times \\prod_{i=1}^{l-1} s_i\n\\]\n其中 \\(k_l\\) 是第 \\(l\\) 层卷积核尺寸，\\(s_i\\) 是前面各层的 stride。当所有 stride=1 时，公式简化为：\n\\[\nRF_{l} = RF_{l-1} + (k_l - 1)\n\\]\n初始输入 \\(RF_0 = 1\\)（一个像素）。\n\n---\n\n## 2. 单个 \\(3\\times 3\\) 卷积核的感受野\n- 第 1 层 \\(3\\times 3\\)：\\(RF_1 = 1 + (3-1) = 3\\)  \n- 第 2 层 \\(3\\times 3\\)：\\(RF_2 = 3 + (3-1) = 5\\)  \n- 第 3 层 \\(3\\times 3\\)：\\(RF_3 = 5 + (3-1) = 7\\)  \n\n所以 **3 个 \\(3\\times 3\\) 卷积核堆叠**（stride=1）的感受野是 \\(7\\times 7\\)，与单个 \\(7\\times 7\\) 卷积核的感受野相同。\n\n---\n\n## 3. 验证选项\n- 2 个 \\(3\\times 3\\)：感受野 \\(= 5\\times 5\\)，不够。  \n- 3 个 \\(3\\times 3\\)：感受野 \\(= 7\\times 7\\)，匹配。  \n- 4 个 \\(3\\times 3\\)：感受野 \\(= 9\\times 9\\)，过大。  \n- 5 个 \\(3\\times 3\\)：感受野 \\(= 11\\times 11\\)，过大。  \n\n因此答案是 **3** 个。\n\n---\n\n**最终答案：A** ✅"}, "answer": "A"}, {"id": "56", "question": {"enus": "下列不属于典型图像特征的是哪项？", "zhcn": "下列不属于典型图像特征的是哪项？"}, "option": [{"option_text": {"enus": "传统全局特征", "zhcn": "传统全局特征"}, "option_flag": false}, {"option_text": {"enus": "传统局部特征", "zhcn": "传统局部特征"}, "option_flag": false}, {"option_text": {"enus": "时序特征", "zhcn": "时序特征"}, "option_flag": true}, {"option_text": {"enus": "基于学习的特征", "zhcn": "基于学习的特征"}, "option_flag": false}], "analysis": {"enus": "典型的图像特征包括基于传统方法的全局特征，基于传统方法的局部特征，基于学习的特征三种。\n时序信息往往包含时间维度上的上下文关系，不属于典型的图像信息", "zhcn": "我们先分析一下各个选项的含义：  \n\n- **A 传统全局特征**：例如颜色直方图、纹理统计等，是对整张图像提取的特征，属于典型图像特征。  \n- **B 传统局部特征**：例如 SIFT、SURF、HOG 等，在图像局部区域提取的特征，也属于典型图像特征。  \n- **C 时序特征**：通常用于视频或多帧序列中，描述帧与帧之间的时间变化，不是单幅图像的典型特征。  \n- **D 基于学习的特征**：例如通过 CNN 等模型提取的特征，在现代图像处理中很常见，也属于图像特征。  \n\n题目问的是**不属于典型图像特征**的选项，这里的“典型图像特征”一般指**针对单幅静态图像**的特征，而“时序特征”更多用于视频分析，因此不属于典型的单图像特征范畴。  \n\n所以正确答案是 **C**。"}, "answer": "C"}, {"id": "57", "question": {"enus": "目标检测算法中，能对冗余检测框进行过滤的算法是哪项？", "zhcn": "目标检测算法中，能对冗余检测框进行过滤的算法是哪项？"}, "option": [{"option_text": {"enus": "Non-Max Suppression", "zhcn": "Non-Max Suppression"}, "option_flag": true}, {"option_text": {"enus": "边界框回归", "zhcn": "边界框回归"}, "option_flag": false}, {"option_text": {"enus": "RPN", "zhcn": "RPN"}, "option_flag": false}, {"option_text": {"enus": "SPP", "zhcn": "SPP"}, "option_flag": false}], "analysis": {"enus": "目标检测算法通过Non-Max Suppression对冗余的边界框进行合并。非极大值抑制算法NMS广泛应用于目标检测算法，其目的是为了消除多余的候选框，找到最佳的物体检测位置", "zhcn": "你提到的题目是关于目标检测中过滤冗余检测框的算法，正确答案是 **A) Non-Max Suppression（非极大值抑制）**。  \n\n**解析：**  \n\n- **Non-Max Suppression (NMS)** 是目标检测中常用的后处理步骤，用于从多个重叠的候选框中选出最可能是目标的一个框，抑制掉其他冗余框。  \n- **边界框回归（B）** 是调整预测框位置使其更接近真实框的方法，并不直接用于过滤冗余框。  \n- **RPN（C）** 是 Faster R-CNN 中用于生成候选区域的网络，属于区域提议阶段，不是专门用于过滤重复框。  \n- **SPP（D）** 是空间金字塔池化，用于处理不同尺寸的输入，与过滤检测框无关。  \n\n因此，正确答案是 **A**。"}, "answer": "A"}, {"id": "58", "question": {"enus": "通过提出Inception结构来解决宽度受限问题的图像分类网络是哪项？", "zhcn": "通过提出Inception结构来解决宽度受限问题的图像分类网络是哪项？"}, "option": [{"option_text": {"enus": "GoogleNet", "zhcn": "GoogleNet"}, "option_flag": true}, {"option_text": {"enus": "VGGNet", "zhcn": "VGGNet"}, "option_flag": false}, {"option_text": {"enus": "SPPNet", "zhcn": "SPPNet"}, "option_flag": false}, {"option_text": {"enus": "SENet", "zhcn": "SENet"}, "option_flag": false}], "analysis": {"enus": "GoogleNet增加了多种卷积核1x1，3x3，5x5，还有直接max pooling的，通过将这些卷积核并列的结合在一起提取图像的多尺度特征，因此获取的图像特征鲁棒性更强", "zhcn": "**正确答案是 [A] GoogleNet。**\n\n**详细解析如下：**\n\n1.  **问题核心**：题目问的是“通过提出 Inception 结构来解决宽度受限问题的图像分类网络”。这里的关键词是 **“Inception 结构”** 和 **“解决宽度受限”**。\n\n2.  **选项分析**：\n    *   **[A] GoogleNet**：这是正确答案。GoogleNet（也称为 GoogLeNet，以向 LeNet 致敬）的核心创新就是 **Inception 模块**。该模块的设计初衷就是为了解决网络深度和宽度增加时带来的计算量爆炸问题。它通过在同一个层级上并行使用不同尺寸的卷积核（1x1, 3x3, 5x5）和池化层，相当于让网络在每一层“宽”一些，能够同时从不同尺度提取特征，然后再将结果拼接（Concat）起来。这种方法比简单地堆叠大型卷积核或增加神经元数量（单纯增加宽度）要高效得多，从而巧妙地解决了“宽度受限”的问题。\n    *   **[B] VGGNet**：VGGNet 的主要贡献是探索了网络的**深度**，通过堆叠多个小的 3x3 卷积核来替代大的卷积核（如 5x5, 7x7）。它并没有提出 Inception 结构，其核心思想是“更深”，而非“更宽”。\n    *   **[C] SPPNet**：SPPNet（空间金字塔池化网络）的主要贡献是提出了**空间金字塔池化（SPP）** 层，该层可以让网络接受任意大小的输入图像，并生成固定长度的输出，解决了全连接层要求输入尺寸固定的问题。它与 Inception 结构无关。\n    *   **[D] SENet**：SENet（挤压激励网络）的核心是 **SE 模块**，该模块专注于通道维度上的特征重标定，通过自适应地调整各通道的权重来增强重要特征、抑制无用特征。它是一个“注意力”机制，是在已有基础网络（如 ResNet, Inception）之上增加的增强模块，并非 Inception 结构的提出者。\n\n**总结：**\nInception 结构是 GoogleNet 的标志性创新，其设计初衷就是为了高效地增加网络的宽度和深度，从而提升性能。因此，提出该结构以解决宽度受限问题的网络正是 **GoogleNet**。\n\n[参考答案] A\n[答案解析] GoogleNet 创新性地提出了 Inception 模块，通过并行使用不同大小的卷积核和池化操作，在增加网络宽度的同时有效控制了计算复杂度，解决了传统CNN单纯增加宽度或深度导致的效率问题。"}, "answer": "A"}, {"id": "59", "question": {"enus": "RCNN算法使用的分类算法是哪项？", "zhcn": "RCNN算法使用的分类算法是哪项？"}, "option": [{"option_text": {"enus": "决策树", "zhcn": "决策树"}, "option_flag": false}, {"option_text": {"enus": "卷积层", "zhcn": "卷积层"}, "option_flag": false}, {"option_text": {"enus": "SVM", "zhcn": "SVM"}, "option_flag": true}, {"option_text": {"enus": "随机森林", "zhcn": "随机森林"}, "option_flag": false}], "analysis": {"enus": "RCNN通过SVM来完成目标类别的判断", "zhcn": "正确答案是 **[C] SVM**。\n\n### 详细答案解析\n\nRCNN（Regions with CNN features）是目标检测领域的里程碑式算法。它的核心思想可以概括为三个步骤：\n\n1.  **区域提议**：使用选择性搜索等算法，从输入图像中提取大约2000个可能包含物体的候选区域。\n2.  **特征提取**：将每个候选区域缩放（warp）到固定大小，然后送入一个预训练好的卷积神经网络中，为每个区域提取一个固定长度的特征向量。\n3.  **分类**：将提取出的特征向量送入一个分类器，判断这个区域属于哪个类别（如人、车、猫等）或者背景。\n\n**关键点在于第三步的分类器**。在 RCNN 的原始论文中，作者明确指出他们使用的是**线性支持向量机**作为每一类物体的分类器。也就是说，对于“猫”这个类别，会训练一个专门的二分类SVM来区分“猫”和“非猫”；对于“狗”也是如此。\n\n---\n\n### 为什么其他选项不正确？\n\n*   **[A] 决策树 和 [D] 随机森林**：决策树和随机森林是传统的机器学习算法，虽然在很多分类任务中表现优异，但**并不是 RCNN 原版论文中采用的分类器**。RCNN 的作者通过实验对比发现，使用线性SVM的效果优于当时其他的分类器。\n*   **[B] 卷积层**：这是一个具有迷惑性的选项。卷积层是卷积神经网络的核心组件，用于**特征提取**，而不是最终的分类。在 RCNN 中，卷积层的作用是第二步（特征提取），而 SVM 的作用是第三步（分类）。最终的分类决策是由 SVM 做出的。\n\n**总结**：RCNN 巧妙地结合了 CNN 强大的特征提取能力和 SVM 在分类问题上的优势。因此，其使用的分类算法是 **SVM**。"}, "answer": "C"}, {"id": "60", "question": {"enus": "视觉智能算法建模流程中，首先需要做的是哪项？", "zhcn": "视觉智能算法建模流程中，首先需要做的是哪项？"}, "option": [{"option_text": {"enus": "数据预处理", "zhcn": "数据预处理"}, "option_flag": true}, {"option_text": {"enus": "特征提取", "zhcn": "特征提取"}, "option_flag": false}, {"option_text": {"enus": "分类", "zhcn": "分类"}, "option_flag": false}, {"option_text": {"enus": "后处理", "zhcn": "后处理"}, "option_flag": false}], "analysis": {"enus": "在视觉智能算法中，首先需要通过图像预处理方法来对图像进行归一化等操作。这些预处理过程是视觉智能算法的第一步骤，是模型在后续步骤中取得高性能的重要措施", "zhcn": "在视觉智能算法建模流程中，正确的第一步是 **A. 数据预处理**。\n\n**详细解释如下：**\n\n一个典型的视觉智能建模流程（例如图像分类）通常遵循以下顺序：\n\n1.  **数据预处理：** 这是整个流程的**基础**。在模型能够“看到”数据之前，必须对原始数据进行整理和标准化。这一步包括：\n    *   **数据清洗：** 剔除模糊、不相关或损坏的图像。\n    *   **数据标注：** 为训练数据打上标签（例如，这张图是“猫”，那张图是“狗”）。\n    *   **数据增强：** 通过对图像进行旋转、缩放、裁剪、调整亮度等操作，人工扩充数据集，以提高模型的泛化能力。\n    *   **数据标准化/归一化：** 将像素值缩放到一个固定的范围（如0-1之间），使模型更容易、更稳定地学习。\n\n2.  **特征提取：** 在数据准备好之后，模型（尤其是深度学习模型中的卷积神经网络CNN）会从预处理后的图像中自动学习有区分度的特征，例如边缘、纹理、形状等。在传统方法中，这一步可能需要手动设计特征（如SIFT、HOG）。\n\n3.  **分类/识别：** 基于提取到的特征，模型（如全连接层+Softmax分类器）进行学习或推理，最终输出图像的类别或检测结果。\n\n4.  **后处理：** 对模型的直接输出进行优化，例如在目标检测中应用非极大值抑制来消除重叠的检测框，或者对分割结果进行平滑处理。\n\n**为什么第一步是数据预处理？**\n\n*   **数据质量决定模型上限：** 俗话说“垃圾进，垃圾出”。如果原始数据杂乱无章、格式不一、标签错误，即使最先进的模型也无法学到有效的规律。\n*   **为后续步骤做准备：** 特征提取和分类算法通常要求输入数据是规整的、数值化的。数据预处理正是为了将原始数据转换成适合模型处理的格式。\n\n因此，**数据预处理是构建任何有效视觉智能模型的必要且首要的步骤**。\n\n**[参考答案] A** 是正确的。"}, "answer": "A"}, {"id": "61", "question": {"enus": "卷积神经网络中， 提升模型的尺度不变性、旋转不变性是哪项？", "zhcn": "卷积神经网络中， 提升模型的尺度不变性、旋转不变性是哪项？"}, "option": [{"option_text": {"enus": "卷积层", "zhcn": "卷积层"}, "option_flag": false}, {"option_text": {"enus": "全连接层", "zhcn": "全连接层"}, "option_flag": false}, {"option_text": {"enus": "激活函数", "zhcn": "激活函数"}, "option_flag": false}, {"option_text": {"enus": "池化层", "zhcn": "池化层"}, "option_flag": true}], "analysis": {"enus": "在神经网络中，池化层通过最大池化或者平均池化来提升模型的尺度、旋转不变性。此外，池化操作还可以降低特征图的分辨率，减少模型在运算过程中的计算量", "zhcn": "我们先分析一下题目中提到的“尺度不变性”和“旋转不变性”在卷积神经网络（CNN）中的实现方式。  \n\n**1. 尺度不变性（Scale Invariance）**  \n- 指的是输入图像在尺寸（放大或缩小）变化时，网络依然能正确识别目标。  \n- 在 CNN 中，**池化层（尤其是最大池化）** 通过对局部区域进行下采样，使网络对小的平移和尺度变化有一定鲁棒性。因为池化保留了最显著的特征，忽略特征的精确位置和局部细节变化，所以对尺度变化有一定容忍度。  \n\n**2. 旋转不变性（Rotation Invariance）**  \n- 指的是图像旋转后，网络输出基本不变。  \n- 池化层（尤其是最大池化）也能提供一定的旋转不变性：当特征图旋转时，只要最强激活响应还在池化区域内，池化后可能得到相同或相似的值。  \n\n**3. 各选项分析**  \n- **[A] 卷积层**：主要作用是局部特征提取，具有平移不变性（由于权值共享），但对尺度和旋转变化敏感，除非通过数据增强或特殊结构（如空间变换网络）增强，否则本身不具备强的尺度/旋转不变性。  \n- **[B] 全连接层**：对输入位置极其敏感，没有空间结构保持能力，不具备这些不变性。  \n- **[C] 激活函数**：引入非线性，但不直接提供空间不变性。  \n- **[D] 池化层**：通过降维和保留主要响应，对小的尺度、旋转变化具有鲁棒性，是 CNN 实现尺度与旋转不变性的主要组件之一（尽管不是完美的，但比卷积层更强）。  \n\n**4. 结论**  \n在传统 CNN 中，**池化层** 是提升模型尺度不变性和旋转不变性的关键组件，因此正确答案是 **D**。  \n\n所以答案是：  \n**[D] 池化层** ✅"}, "answer": "D"}, {"id": "62", "question": {"enus": "近年来，人工智能技术在农业中的应用场景越来越常见，促进了智慧农业的蓬勃发展。其中在农作物害虫防治中，最适合使用的智能视觉技术是哪项？", "zhcn": "近年来，人工智能技术在农业中的应用场景越来越常见，促进了智慧农业的蓬勃发展。其中在农作物害虫防治中，最适合使用的智能视觉技术是哪项？"}, "option": [{"option_text": {"enus": "图像分类", "zhcn": "图像分类"}, "option_flag": false}, {"option_text": {"enus": "目标检测", "zhcn": "目标检测"}, "option_flag": true}, {"option_text": {"enus": "语义分割", "zhcn": "语义分割"}, "option_flag": false}, {"option_text": {"enus": "图像检索", "zhcn": "图像检索"}, "option_flag": false}], "analysis": {"enus": "目标检测在确定目标类别的同时可以确定其位置，因此非常适合应用于植物的害虫检测。而其他图像检索用于寻找与当前图像相似的图像，而语义分割确定图形中每个像素的类别，图像分类只能确定类别但是无法实现对目标的定位。均不适合", "zhcn": "你提供的题目和参考答案是合理的，我来帮你梳理一下解析思路。  \n\n**题干背景**  \n农业害虫防治中，智能视觉技术常用于识别害虫、判断位置、统计数量等，以便精准施药或采取生物防治措施。  \n\n**选项分析**  \n- **[A] 图像分类**：只能判断整张图里有没有害虫或属于哪类害虫，但无法知道害虫在图像中的位置和数量。  \n- **[B] 目标检测**：既能识别害虫类别，又能定位害虫在图像中的位置（用边界框标出），还能计数，这对判断虫害密度和精准喷药非常有用。  \n- **[C] 语义分割**：对每个像素分类，可以精确到害虫的轮廓，但通常计算量更大，且在实际应用中，知道位置和类别通常就够用了，不一定需要像素级精度。  \n- **[D] 图像检索**：主要用于从数据库中查找相似图像，不适合直接用于田间实时害虫识别与防治。  \n\n**结论**  \n在农业害虫防治场景中，**目标检测** 既能识别种类又能定位，最适合实际应用，因此答案是 **B**。"}, "answer": "B"}, {"id": "63", "question": {"enus": "以下产品不属于阿里云视觉智能的是哪项？", "zhcn": "以下产品不属于阿里云视觉智能的是哪项？"}, "option": [{"option_text": {"enus": "视觉计算服务", "zhcn": "视觉计算服务"}, "option_flag": false}, {"option_text": {"enus": "图像搜索", "zhcn": "图像搜索"}, "option_flag": false}, {"option_text": {"enus": "三维空间重建", "zhcn": "三维空间重建"}, "option_flag": false}, {"option_text": {"enus": "文档翻译", "zhcn": "文档翻译"}, "option_flag": true}], "analysis": {"enus": "阿里云视觉智能产品包括视觉开放平台、图像识别 、三维空间重建、多媒体AI、实人认证、图像搜索等多个领域，文档翻译属于自然语言处理，不属于视觉智能的范畴", "zhcn": "**正确答案是 D：文档翻译。**\n\n**详细解析如下：**\n\n阿里云视觉智能平台（Visual Intelligence）主要提供基于图像和视频的AI分析、识别、理解与生成能力。其核心是处理视觉信息。\n\n我们来逐一分析每个选项：\n\n*   **[A] 视觉计算服务**：这是阿里云视觉智能平台的核心服务之一，提供包括图像分类、目标检测、图像分割等基础的视觉AI计算能力。**属于**视觉智能范畴。\n*   **[B] 图像搜索**：这是阿里云视觉智能平台的明星产品，通过提取图像特征，实现“以图搜图”的功能。**属于**视觉智能范畴。\n*   **[C] 三维空间重建**：这是利用计算机视觉技术，通过多张二维图像或视频来恢复和生成三维模型，是视觉技术的重要应用。**属于**视觉智能范畴。\n*   **[D] 文档翻译**：这项服务的核心是**自然语言处理（NLP）**，它处理的是文档中的文字内容，而不是图像本身。虽然它可能涉及OCR（光学字符识别）技术先将图片中的文字识别出来，但其核心价值和主要功能是语言翻译，而非视觉分析。因此，它不属于“视觉智能”的核心产品线，通常归类于阿里云的“机器翻译”或“智能语音交互”等产品下。\n\n**结论：**\n文档翻译的核心技术是自然语言处理，而非计算机视觉，因此它不属于阿里云视觉智能平台的核心产品。\n\n所以，正确答案是 **D**。"}, "answer": "D"}, {"id": "64", "question": {"enus": "以下不属于PAI-EAS模型在线服务的是哪项？", "zhcn": "以下不属于PAI-EAS模型在线服务的是哪项？"}, "option": [{"option_text": {"enus": "PAI-AutoLearning", "zhcn": "PAI-AutoLearning"}, "option_flag": false}, {"option_text": {"enus": "PAI-CV", "zhcn": "PAI-CV"}, "option_flag": true}, {"option_text": {"enus": "PAI-Studio", "zhcn": "PAI-Studio"}, "option_flag": false}, {"option_text": {"enus": "PAI-DSW", "zhcn": "PAI-DSW"}, "option_flag": false}], "analysis": {"enus": "PAI-EAS模型在线服务包括PAI-DSW,PAI-AutoLearning、PAI-Studio", "zhcn": "我们先分析一下题目。  \n\n题目问的是 **“不属于 PAI-EAS 模型在线服务”** 的选项。  \n\n**PAI-EAS**（Elastic Algorithm Service）是阿里云平台提供的在线模型预测服务，用于部署机器学习模型并提供 API 接口。  \n而 **PAI-CV**（计算机视觉）是 PAI 平台中的一个视觉算法模块，通常用于图像处理相关的预置算法，但它本身不是在线服务部署平台，而是算法组件或预训练模型库。  \n\n其他选项：  \n- **PAI-AutoLearning**：自动机器学习，属于 PAI 平台的一个功能模块，与在线服务 EAS 不同。  \n- **PAI-Studio**：可视化建模开发环境，属于开发工具，不是在线服务。  \n- **PAI-DSW**：Data Science Workshop，云端交互式开发环境，也属于开发工具。  \n\n但题目问的是 **“不属于 PAI-EAS 模型在线服务”**，也就是在四个选项中找出一个明显不是在线服务部署相关的功能。  \n从归类来看，PAI-CV 是算法方向的一个子产品，不是服务部署平台，也不是开发环境，而是特定领域的算法包/工具包，因此它最不适合归类为“PAI-EAS 模型在线服务”。  \n\n题目给出的参考答案是 **B**，即 PAI-CV。  \n\n**答案解析**：  \nPAI-EAS 是模型在线预测服务，PAI-CV 是视觉智能算法模块，不直接等同于在线服务，而是可在 PAI 平台中调用或部署到 EAS 的算法资源之一，但本身不是服务形态。"}, "answer": "B"}, {"id": "65", "question": {"enus": "PAI Designer 中构建算法模型的单位是哪项？", "zhcn": "PAI Designer 中构建算法模型的单位是哪项？"}, "option": [{"option_text": {"enus": "实验", "zhcn": "实验"}, "option_flag": false}, {"option_text": {"enus": "模块", "zhcn": "模块"}, "option_flag": false}, {"option_text": {"enus": "课时", "zhcn": "课时"}, "option_flag": false}, {"option_text": {"enus": "组件", "zhcn": "组件"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": "在 PAI（Platform of Artificial Intelligence，阿里云机器学习平台）中，构建算法模型的基本单位是**组件**。\n\n**详细解释如下：**\n\n*   **组件**：这是 PAI-Designer（可视化建模界面）中的核心概念。每个组件代表一个独立的数据处理或算法步骤，例如：\n    *   **数据源组件**：如“读数据表”，用于读取数据。\n    *   **数据处理组件**：如“归一化”、“特征工程”、“SQL脚本”，用于清洗和转换数据。\n    *   **机器学习算法组件**：如“逻辑回归”、“GBDT”、“K-Means”，用于训练模型。\n    *   **评估组件**：如“二分类评估”、“混淆矩阵”，用于评估模型效果。\n    用户通过将不同的**组件**用有向连线连接起来，形成一个完整的数据处理和机器学习流水线（即一个实验）。因此，**组件是构建模型的最小功能单元**。\n\n*   **实验**：实验是由多个组件及其连接关系构成的完整工作流。它代表了一次完整的建模任务。所以，实验是比组件更大的概念。\n\n*   **模块**：在 PAI 的语境中，“模块”通常指一个更高级别的、可能由多个组件封装而成的功能集合，或者指平台的不同功能分区（如Designer模块、DSW模块等），它不是构建模型的基本操作单位。\n\n*   **课时**：这个术语与在线教育相关，与 PAI 平台构建算法模型无关。\n\n**结论：**\n在 PAI-Designer 中，您通过拖拽和连接一个个 **组件** 来搭建机器学习模型。因此，正确答案是 **[D]组件**。"}, "answer": "D"}, {"id": "66", "question": {"enus": "阿里云视觉智能开发平台开通流程第一步是哪项？", "zhcn": "阿里云视觉智能开发平台开通流程第一步是哪项？"}, "option": [{"option_text": {"enus": "能力开通", "zhcn": "能力开通"}, "option_flag": false}, {"option_text": {"enus": "能力测试", "zhcn": "能力测试"}, "option_flag": false}, {"option_text": {"enus": "成为开发者", "zhcn": "成为开发者"}, "option_flag": true}, {"option_text": {"enus": "启动开发", "zhcn": "启动开发"}, "option_flag": false}], "analysis": {"enus": "视觉智能平台开通流程为：成为开发者、能力调试、能力开通、创建AccessKey、启动开发", "zhcn": "您提供的题目和答案是正确的。\n\n**阿里云视觉智能开发平台开通流程的第一步确实是 [C] 成为开发者。**\n\n下面是详细的流程解析，以帮助您更好地理解：\n\n### **阿里云视觉智能平台开通流程详解**\n\n1.  **[C] 成为开发者**\n    *   **这是第一步，也是前提条件。** 您需要拥有一个阿里云实名认证的账号。如果没有，需要先注册并进行个人或企业实名认证。只有成为阿里云认证的开发者，才能使用其旗下的各种云服务，包括视觉智能平台。\n\n2.  **[A] 能力开通**\n    *   在成为开发者之后，您需要进入**视觉智能平台控制台**，找到您需要使用的具体AI能力（例如：人脸识别、图像生产、目标检测等）。\n    *   对于大部分能力，您需要**免费开通**该服务。这个步骤主要是将服务与您的账号进行绑定，并同意相关服务条款。许多能力都提供一定额度的免费调用量。\n\n3.  **[B] 能力测试（可选但推荐）**\n    *   在正式集成到您的应用之前，阿里云平台通常会提供一个**在线调试**功能。\n    *   您可以在这个功能页面上传图片或输入文本，直接调用API查看返回结果，以确认该能力是否符合您的需求。这是一个非常重要的验证环节。\n\n4.  **[D] 启动开发**\n    *   在测试通过后，您就可以进入开发阶段了。\n    *   这一步包括：获取访问密钥（AccessKey）、查看API文档、下载SDK、编写代码将视觉AI能力集成到您的应用程序中。\n\n### **总结**\n\n所以，整个逻辑顺序是：\n**成为开发者 (C) → 能力开通 (A) → 能力测试 (B，可选) → 启动开发 (D)**\n\n您的题目准确地抓住了最关键的第一步。"}, "answer": "C"}, {"id": "67", "question": {"enus": "目前，阿里云视觉智能开发平台包含多个领域的应用，除了以下的哪项？", "zhcn": "目前，阿里云视觉智能开发平台包含多个领域的应用，除了以下的哪项？"}, "option": [{"option_text": {"enus": "语音识别", "zhcn": "语音识别"}, "option_flag": true}, {"option_text": {"enus": "内容审核", "zhcn": "内容审核"}, "option_flag": false}, {"option_text": {"enus": "视频分割", "zhcn": "视频分割"}, "option_flag": false}, {"option_text": {"enus": "视频理解", "zhcn": "视频理解"}, "option_flag": false}], "analysis": {"enus": "阿里云视觉智能平台应用包括视频理解、视频分割、内容审核、图像生成、分割抠图等多个应用场景，但是语音识别不属于智能视觉的研究范畴", "zhcn": "我们先看题目：阿里云视觉智能开发平台主要围绕**视觉智能**技术，比如图像、视频等处理能力。  \n\n选项分析：  \n- **[A] 语音识别** → 属于语音技术，不是视觉领域，所以很可能不包含在视觉智能平台中。  \n- **[B] 内容审核** → 视觉智能平台通常包含图片/视频内容审核（如鉴黄、暴恐识别等）。  \n- **[C] 视频分割** → 属于视频分析技术，视觉平台会包含。  \n- **[D] 视频理解** → 属于视频内容分析，视觉平台会包含。  \n\n因此，除了 **[A] 语音识别**，其他三项都属于视觉智能范畴。  \n\n**答案：A** ✅"}, "answer": "A"}, {"id": "68", "question": {"enus": "能够实现精准识别图像中的视觉内容的视觉智能技术是哪项？", "zhcn": "能够实现精准识别图像中的视觉内容的视觉智能技术是哪项？"}, "option": [{"option_text": {"enus": "图像识别", "zhcn": "图像识别"}, "option_flag": true}, {"option_text": {"enus": "图像合成", "zhcn": "图像合成"}, "option_flag": false}, {"option_text": {"enus": "图像超分辨", "zhcn": "图像超分辨"}, "option_flag": false}, {"option_text": {"enus": "图像去雾去噪", "zhcn": "图像去雾去噪"}, "option_flag": false}], "analysis": {"enus": "图像识别是实现精准识别图像中视觉内容的技术", "zhcn": "正确答案是 **[A] 图像识别**。\n\n**详细解析如下：**\n\n*   **图像识别** 是计算机视觉的核心技术之一，其目标就是**精准识别和检测图像或视频中的视觉内容**。这些内容可以包括：\n    *   **物体识别**：识别图像中有什么物体，例如“猫”、“汽车”、“杯子”。\n    *   **场景识别**：判断图像所处的场景，例如“海滩”、“办公室”、“街道”。\n    *   **人脸识别**：识别图像中的人脸及其身份。\n    *   **文字识别**：识别并提取图像中的文本信息。\n    *   **行为识别**：分析视频中人物的动作行为。\n\n    因此，题目中描述的“精准识别图像中的视觉内容”正是图像识别技术的主要任务。\n\n*   其他选项的技术目标与“识别内容”不同：\n    *   **[B] 图像合成**：指的是生成或创造新的、逼真的图像，例如根据文本描述生成图片（AI绘画）、图像风格迁移等。它的重点是“创造”而非“识别”。\n    *   **[C] 图像超分辨**：指的是将低分辨率图像重建或恢复为高分辨率图像，俗称“让模糊图片变清晰”。它的重点是“增强画质”而非“识别内容”。\n    *   **[D] 图像去雾去噪**：指的是去除图像中的雾霾、噪声等干扰因素，提升图像质量。它的重点同样是“增强画质”和“恢复细节”，而不是“识别内容”。\n\n**总结：**\n在给定的选项中，只有 **[A] 图像识别** 是专门致力于理解和识别图像中“有什么”、“是什么”的技术，因此是实现精准识别视觉内容的关键技术。"}, "answer": "A"}, {"id": "69", "question": {"enus": "图像识别的API接口返回的Requestid类型是哪项？", "zhcn": "图像识别的API接口返回的Requestid类型是哪项？"}, "option": [{"option_text": {"enus": "String", "zhcn": "String"}, "option_flag": true}, {"option_text": {"enus": "Struct", "zhcn": "Struct"}, "option_flag": false}, {"option_text": {"enus": "INT", "zhcn": "INT"}, "option_flag": false}, {"option_text": {"enus": "Float", "zhcn": "Float"}, "option_flag": false}], "analysis": {"enus": "API接口返回的Requestld类型是String，返回的是请求ID", "zhcn": "正确答案是：**[A] String**\n\n**详细解析如下：**\n\n在绝大多数云服务提供商（如腾讯云、阿里云、百度云、AWS等）的图像识别API接口设计中，`RequestId` 是一个用于**唯一标识一次API请求**的字符串。\n\n*   **为什么是String？**\n    *   **唯一性**：`RequestId` 通常由系统根据特定规则（可能包含时间戳、随机数、机器标识等信息）生成的一长串字符，例如 `\"b6ade79a-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"`。这种格式（如UUID）能确保全球范围内的唯一性，非常适合用于追踪和定位某一次具体的请求。\n    *   **通用性**：字符串类型可以灵活地容纳各种字符和长度，便于在不同系统、日志和工具之间传递和记录。\n    *   **功能目的**：它的主要作用是当您需要联系技术支持或排查问题时，提供这个ID可以帮助服务商快速定位到您的那一次API调用过程和详细日志。它本身不参与数值计算，因此不需要是数值类型。\n\n*   **为什么不是其他选项？**\n    *   **[B] Struct（结构体）**：`RequestId` 是一个简单的标识符，不是一个包含多个不同属性的复杂数据结构。\n    *   **[C] INT（整数）**：虽然整数也可以作为ID，但在大规模、高并发的分布式系统中，要保证一个整数ID的全局唯一性和递增性非常复杂，且长度有限。字符串格式的ID实现起来更简单、更可靠。\n    *   **[D] Float（浮点数）**：浮点数存在精度问题，且不适合用作唯一标识符，完全没有理由被采用。\n\n因此，图像识别API返回的 `RequestId` 的标准类型是 **字符串（String）**。"}, "answer": "A"}, {"id": "70", "question": {"enus": "目前图像识别的URL地址仅支持哪项？", "zhcn": "目前图像识别的URL地址仅支持哪项？"}, "option": [{"option_text": {"enus": "北京地域", "zhcn": "北京地域"}, "option_flag": false}, {"option_text": {"enus": "上海地域", "zhcn": "上海地域"}, "option_flag": true}, {"option_text": {"enus": "杭州地域", "zhcn": "杭州地域"}, "option_flag": false}, {"option_text": {"enus": "华北地域", "zhcn": "华北地域"}, "option_flag": false}], "analysis": {"enus": "目前图像识别的URL地址仅支持上海地域，暂不支持其他地域", "zhcn": "根据腾讯云官方文档，目前其通用图像识别等服务的公网域名（URL地址）默认指向并优先支持的是 **上海地域** 的服务器。\n\n因此，正确答案是：\n\n**[B]上海地域**"}, "answer": "B"}, {"id": "71", "question": {"enus": "阿里云人脸识别任务中，第一步需要完成的是哪项？", "zhcn": "阿里云人脸识别任务中，第一步需要完成的是哪项？"}, "option": [{"option_text": {"enus": "人脸定位", "zhcn": "人脸定位"}, "option_flag": true}, {"option_text": {"enus": "人脸清晰化", "zhcn": "人脸清晰化"}, "option_flag": false}, {"option_text": {"enus": "人脸属性识别", "zhcn": "人脸属性识别"}, "option_flag": false}, {"option_text": {"enus": "人脸比对", "zhcn": "人脸比对"}, "option_flag": false}], "analysis": {"enus": "人脸识别主要包括三个环节：人脸定位、人脸属性识别、人脸比对。第一个环节是人脸定位", "zhcn": "正确答案是 **[A] 人脸定位**。\n\n**详细解析如下：**\n\n一个完整的人脸识别任务通常包含以下几个核心步骤：\n\n1.  **人脸检测与定位：** 这是第一步，也是最基础的一步。系统需要首先在输入的图像或视频流中，找出是否存在人脸，并确定每张人脸的位置和大小（通常用矩形框表示）。没有这一步，后续的所有操作都无从谈起。\n2.  **人脸配准/关键点定位：** 在定位到人脸后，进一步精确定位人脸的五官轮廓和关键特征点，如眼睛、鼻子、嘴巴、眉毛的角点等。这一步有助于对人脸进行姿态校正和归一化处理。\n3.  **人脸特征提取：** 对经过校正和归一化的人脸图像，通过深度学习等算法提取出能够代表该人脸独有身份信息的高维特征向量。这个特征向量就像是人脸的“数字指纹”。\n4.  **人脸比对/识别：** 将提取出的特征向量与数据库中已存储的特征向量进行相似度计算，根据阈值判断是否为同一个人（1:1比对）或找出最相似的人脸（1:N识别）。\n\n**现在来分析选项：**\n\n*   **[A] 人脸定位：** 这正是上述流程中的第一步，即“人脸检测与定位”。它是所有后续操作的前提。\n*   **[B] 人脸清晰化：** 这通常是一种图像增强技术，可能在人脸质量不佳时作为预处理步骤使用，但它不是人脸识别流程中必须的、标准的第一步。\n*   **[C] 人脸属性识别：** 这是在检测到人脸后，进一步分析其性别、年龄、表情、是否戴眼镜等属性，属于人脸分析范畴，是后续步骤，而非第一步。\n*   **[D] 人脸比对：** 这是整个流程的最后一步，即识别或验证阶段，显然不是第一步。\n\n因此，根据标准的人脸识别技术流程，第一步必须是 **人脸定位（检测）**。"}, "answer": "A"}, {"id": "72", "question": {"enus": "阿里云人脸API，返回参数中Data的类型是", "zhcn": "阿里云人脸API，返回参数中Data的类型是"}, "option": [{"option_text": {"enus": "Struct", "zhcn": "Struct"}, "option_flag": true}, {"option_text": {"enus": "String", "zhcn": "String"}, "option_flag": false}, {"option_text": {"enus": "INT", "zhcn": "INT"}, "option_flag": false}, {"option_text": {"enus": "Float", "zhcn": "Float"}, "option_flag": false}], "analysis": {"enus": "阿里云人脸API，返回参数中Data的类型是struct", "zhcn": "正确答案是 **A**。\n\n**详细解析如下：**\n\n阿里云人脸识别等许多API的返回结构遵循一个通用格式。一个典型的成功响应体（JSON格式）如下所示：\n\n```json\n{\n  \"RequestId\": \"4C467B38-3910-447D-87BC-AC049166F216\",\n  \"Data\": {\n    \"FaceId\": \"1234\",\n    \"Age\": 28,\n    \"Gender\": \"Male\",\n    ... // 其他人脸属性字段\n  }\n}\n```\n\n从上面的结构可以看出：\n\n*   **`RequestId`**：是一个字符串（String），用于唯一标识这次请求，便于排查问题。\n*   **`Data`**：是响应的核心内容，它包含了人脸识别操作的具体结果（如人脸ID、年龄、性别、表情等信息）。这些信息不是单一的基本数据类型，而是由多个键值对（Key-Value Pairs）组成的一个**复合数据结构**。\n\n在编程术语中，这种由多个命名字段组成的复合数据类型被称为 **结构体（Struct）**。在JSON格式中，它表现为一个对象（Object）。\n\n因此，返回参数中 `Data` 的类型是 **Struct**。\n\n**其他选项分析：**\n\n*   **[B] String**：`Data` 是一个包含多个字段的对象，而不是一个简单的字符串。\n*   **[C] INT**：`Data` 不是一个整型数字。\n*   **[D] Float**：`Data` 不是一个浮点数。\n\n所以，最准确的答案是 **A**。"}, "answer": "A"}, {"id": "73", "question": {"enus": "以下阿里云视觉任务中，能够实现人物动漫化的是", "zhcn": "以下阿里云视觉任务中，能够实现人物动漫化的是"}, "option": [{"option_text": {"enus": "图像检索", "zhcn": "图像检索"}, "option_flag": false}, {"option_text": {"enus": "图像识别", "zhcn": "图像识别"}, "option_flag": false}, {"option_text": {"enus": "人脸编辑", "zhcn": "人脸编辑"}, "option_flag": true}, {"option_text": {"enus": "图像分割", "zhcn": "图像分割"}, "option_flag": false}], "analysis": {"enus": "解析：人物动漫化属于人脸识别任务中的人脸编辑类别\nhttps://help.aliyun.com/zh/viapi/developer-reference/face-to-edit/?spm=a2c4g.11186623.0.0.2e8c7a6fJyKqir", "zhcn": "**正确答案是 [C] 人脸编辑。**\n\n**详细解析如下：**\n\n题目问的是“能够实现人物动漫化”的阿里云视觉任务。我们来逐一分析每个选项：\n\n*   **[A] 图像检索**：这项技术的核心是根据图像内容（如物体、场景、颜色等）从海量图库中搜索出相似的图像。它主要用于“找相似”或“以图搜图”，并不能改变原图风格将其动漫化。\n*   **[B] 图像识别**：这项技术专注于识别和分类图像中的内容，例如识别出图像中是否包含“人”、“车”、“猫”等对象，或者识别场景是“办公室”还是“海滩”。它是一个分析和理解的过程，不涉及对图像内容的创造性编辑和风格转换。\n*   **[C] 人脸编辑**：**这是正确答案**。人脸编辑技术包含一系列对人脸图像进行操作的功能，除了常见的美颜、换妆、年龄变化等，一个非常重要的应用就是**风格迁移**，其中就包括将真实的人脸照片转换为动漫风格。阿里云等云服务商提供的“人脸编辑”API或服务中，通常就包含“人像动漫化”或“风格化”这类子功能。\n*   **[D] 图像分割**：这项技术旨在将图像划分为多个有意义的区域，例如将人物从背景中分离出来（抠图），或者区分出天空、道路、建筑物等。它主要用于像素级的精细分析，而不是改变整个图像的风格。\n\n因此，在阿里云提供的这些视觉任务中，**“人脸编辑”是唯一一个明确包含“人物动漫化”这一功能选项的服务。**\n\n**【总结】**\n实现人物动漫化的核心技术属于图像生成或风格迁移的范畴，它需要对图像（特别是人脸）进行创造性的编辑和变换，这与“人脸编辑”任务的定义最为吻合。"}, "answer": "C"}, {"id": "74", "question": {"enus": "淘宝中，商品购物搜索主要使用的视觉智能技术是", "zhcn": "淘宝中，商品购物搜索主要使用的视觉智能技术是"}, "option": [{"option_text": {"enus": "图像检索", "zhcn": "图像检索"}, "option_flag": true}, {"option_text": {"enus": "图像识别", "zhcn": "图像识别"}, "option_flag": false}, {"option_text": {"enus": "图像生成", "zhcn": "图像生成"}, "option_flag": false}, {"option_text": {"enus": "图像分割", "zhcn": "图像分割"}, "option_flag": false}], "analysis": {"enus": "目前业界比较具有代表性的图像搜索应用场景主要包括:1)以电商为代表的商品购物搜索;2)以谷歌为代表的海量互联网图片搜索;3)基于移动设备的物体或者商品搜索。", "zhcn": "在淘宝的商品购物搜索中，用户可以通过上传图片来寻找相似或同款商品。这个过程的核心技术是**图像检索**。\n\n下面是各个选项的详细分析：\n\n*   **[A] 图像检索 ✅**\n    *   **定义**：图像检索技术旨在从大规模图像数据库中，快速找到与查询图片在视觉内容上相似的图片。\n    *   **应用**：这正是淘宝“拍立淘”等功能的核心。系统将你上传的图片转换为一个特征向量，然后在海量的商品图片库中搜索具有最相似特征向量的商品，最后将结果排序展示给你。其目标是“找相似”，而不是“认出来”。\n\n*   **[B] 图像识别 ❌**\n    *   **定义**：图像识别（通常指图像分类）的目标是判断一张图片属于哪个预设的类别（例如，识别出图片中是“猫”还是“狗”）。\n    *   **区别**：淘宝搜索的最终目的不是给用户上传的图片打上一个“连衣裙”或“运动鞋”的标签，而是直接找到具体的商品。虽然识别技术可能作为辅助步骤（例如，先识别出主体是“鞋”，可以缩小检索范围），但最核心、最主要的技术是检索。\n\n*   **[C] 图像生成 ❌**\n    *   **定义**：图像生成技术是根据文本描述或其他输入创建全新的图像，例如AI绘画。\n    *   **应用**：这与购物搜索的“按图找物”需求完全不符。淘宝搜索是基于现有商品进行匹配，而非生成新图片。\n\n*   **[D] 图像分割 ❌**\n    *   **定义**：图像分割技术是将图像划分为多个有意义的区域或对象，例如将照片中的人物主体从背景中分离出来。\n    *   **应用**：图像分割在淘宝的视觉技术中可能作为一个**预处理或辅助步骤**。例如，先通过分割技术精确抠出用户上传图片中的商品主体，排除复杂背景的干扰，这样可以提升后续图像检索的准确度。但它本身不是实现搜索功能的主要技术。\n\n**总结：**\n\n淘宝商品购物搜索（以拍立淘为例）主要解决的是“以图搜图”的问题，其核心技术是**图像检索**。其他技术如图像识别、图像分割等可能在其技术 pipeline 中扮演辅助角色，以优化检索效果，但并非主要使用的技术。\n\n所以，正确答案是 **[A] 图像检索**。"}, "answer": "A"}, {"id": "75", "question": {"enus": "图像搜索技术的步骤主要包括：（1）输入图片、（2）重排序、（3）度量学习、（4）特征提取，其正确排序是", "zhcn": "图像搜索技术的步骤主要包括：（1）输入图片、（2）重排序、（3）度量学习、（4）特征提取，其正确排序是"}, "option": [{"option_text": {"enus": "1,4,3,2", "zhcn": "1,4,3,2"}, "option_flag": true}, {"option_text": {"enus": "4,1,3,2", "zhcn": "4,1,3,2"}, "option_flag": false}, {"option_text": {"enus": "1,2,3,4", "zhcn": "1,2,3,4"}, "option_flag": false}, {"option_text": {"enus": "2,1,4,3", "zhcn": "2,1,4,3"}, "option_flag": false}], "analysis": {"enus": "图像检索技术主要包含几个步骤，分别为：输入图片、特征提取、度量学习、重排序。\n特征提取：即将图片数据进行降维，提取数据的判别性信息，一般将一张图片降维为一个向量；\n度量学习：一般利用度量函数，计算图片特征之间的距离，作为loss，训练特征提取网络，使得相似图片提取的特征相似，不同类的图片提取的特征差异性较大。\n重排序：利用数据间的流形关系，对度量结果进行重新排序，从而得到更好的检索结果。", "zhcn": "我们先梳理一下图像搜索（以图搜图）的典型流程：\n\n1. **输入图片**（用户提供待查询的图片）  \n2. **特征提取**（用 CNN 等网络提取图片的特征向量）  \n3. **度量学习**（训练阶段学习如何让相似图片的特征在向量空间更接近；推理阶段用某种距离度量进行相似度计算）  \n4. **重排序**（初步检索后，可能用更复杂的匹配方法对 top‑K 结果重新排序，提高精度）\n\n所以正确顺序是 **1 → 4 → 3 → 2**。  \n\n选项 **A** 是 **1,4,3,2**，与之一致。  \n\n**答案：A** ✅"}, "answer": "A"}, {"id": "76", "question": {"enus": "注重两个向量在方向上的差异，而非距离或长度上的相似度计算方法是", "zhcn": "注重两个向量在方向上的差异，而非距离或长度上的相似度计算方法是"}, "option": [{"option_text": {"enus": "汉明距离", "zhcn": "汉明距离"}, "option_flag": false}, {"option_text": {"enus": "余弦距离", "zhcn": "余弦距离"}, "option_flag": true}, {"option_text": {"enus": "高斯距离", "zhcn": "高斯距离"}, "option_flag": false}, {"option_text": {"enus": "欧式距离", "zhcn": "欧式距离"}, "option_flag": false}], "analysis": {"enus": "余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。两个向量越相似夹角越小，余弦值越接近1。相比距离度量，余弦相似度更加注重两个向量在方向上的差异，而非距离或长度上", "zhcn": "你给出的题目和答案是正确的。  \n\n**题目分析**  \n题目强调“注重两个向量在方向上的差异，而非距离或长度上的相似度”，这实际上是在说：  \n- 如果两个向量长度不同，但方向一致（夹角为 0°），则认为它们相似。  \n- 如果两个向量长度相同，但方向不同（夹角大），则认为它们不相似。  \n\n**选项分析**  \n- **[A] 汉明距离**：用于比较两个等长字符串（或二进制向量）对应位置不同的数量，与向量方向无关。  \n- **[B] 余弦距离**：定义为 \\(1 - \\cos(\\theta)\\)，其中 \\(\\theta\\) 是向量夹角，只与方向有关，与向量长度无关。符合题意。  \n- **[C] 高斯距离**：一般指基于高斯核函数的距离度量，涉及向量各维度差的平方和，受长度影响。  \n- **[D] 欧式距离**：计算空间中两点的直线距离，受长度和方向共同影响。  \n\n因此，正确选项是 **B**。"}, "answer": "B"}, {"id": "77", "question": {"enus": "阿里云机器学习平台 PAI 的PAI Designer 读数据表组件，能读取以下哪个数据源?", "zhcn": "阿里云机器学习平台 PAI 的PAI Designer 读数据表组件，能读取以下哪个数据源?"}, "option": [{"option_text": {"enus": "云数据库 RDS表", "zhcn": "云数据库 RDS表"}, "option_flag": false}, {"option_text": {"enus": "大数据计算服务 MaxCompute 表", "zhcn": "大数据计算服务 MaxCompute 表"}, "option_flag": true}, {"option_text": {"enus": "对象存储 OSS 文件", "zhcn": "对象存储 OSS 文件"}, "option_flag": false}, {"option_text": {"enus": "表格存储 TableStore 表", "zhcn": "表格存储 TableStore 表"}, "option_flag": false}], "analysis": {"enus": "阿里云机器学习平台PAI支持使用两种数据存储格式，分别是MaxCompute和OSS存储数据，其中MaxCompute存储的是表结构数据，主要用于常规算法组件，而OSS存储的结构化或非结构化数据（包括所有格式的办公文档、文本、图片、XML, HTML、各类报表、图像和音频/视频信息等等），用于深度学习算法组件。题干中是针对PAI-Studio读数据表组件是读取MaxCompute表数据，默认读取本项目的表数据，所以选择MaxCompute表是正确的，而OSS数据同步组件将OSS文本同步至MaxCompute数据表，并不符合题意。RDS（Relational Database Service）是阿里云用户主要使用的服务，若需要通过MaxCompute将数据加载至RDS的表进行使用，但并不是PAI-Studio读数据表组件的读取方式；Tablestore表可以进行读写但是也不是PAI-Studio读数据表组件的读取方式。", "zhcn": "[参考答案] B\n\n[答案解析] PAI-Designer 的 **“读数据表”组件** 主要用于读取 **MaxCompute（原名ODPS）表** 的数据，这是阿里云机器学习平台 PAI 默认且最核心的数据源。PAI 与 MaxCompute 深度集成，计算和存储通常都基于 MaxCompute。\n\n其他选项虽然也是阿里云数据源，但在 PAI-Designer 中通常由**不同的专用组件**来读取：\n\n*   **[A] 云数据库 RDS 表**：使用 **“读数据源”** 组件进行读取。\n*   **[C] 对象存储 OSS 文件**：使用 **“读OSS文件”** 或 **“读CSV文件”** 等组件进行读取。\n*   **[D] 表格存储 TableStore 表**：使用 **“读TableStore数据”** 组件进行读取。\n\n因此，题目中特指的“读数据表”组件，其功能就是读取 **MaxCompute 表**。"}, "answer": "B"}, {"id": "78", "question": {"enus": "在视觉智能图像目标检测R-CNN算法中，要训练一个回归模型， 这个回归模型的作用以下哪个描述是正确的?", "zhcn": "在视觉智能图像目标检测R-CNN算法中，要训练一个回归模型， 这个回归模型的作用以下哪个描述是正确的?"}, "option": [{"option_text": {"enus": "用于划分候选区域", "zhcn": "用于划分候选区域"}, "option_flag": false}, {"option_text": {"enus": "用于提取候选区域的特征向量", "zhcn": "用于提取候选区域的特征向量"}, "option_flag": false}, {"option_text": {"enus": "用于识别候选区域是否包含目标", "zhcn": "用于识别候选区域是否包含目标"}, "option_flag": false}, {"option_text": {"enus": "用于修正候选区域的位置", "zhcn": "用于修正候选区域的位置"}, "option_flag": true}], "analysis": {"enus": "在目标检测中的最初检测到的目标框定位可能存在不准(IoU&lt;0.5)的情况，对于这张目标检测的图像相当于没有正确的检测出目标。而回归模型能对现在的检测边框进行微调，使得经过微调后的窗口跟真实的边框更接近，所以回归模型的主要作用是用来微调修正候选区域的位置。对于划分候选区域并不是回归模型的作用，候选区域的特征向量提取主要是卷积神经网络的作用，识别候选区域是否包含目标是对提取的目标区域进行分类，是模型中分类部分的作用，并不是回归模型的作用。", "zhcn": "在 R-CNN 算法中，训练回归模型（通常称为 Bounding Box Regression 或 BBox Reg）的主要作用是**对初步筛选出的、可能包含目标的候选区域（Region Proposal）进行位置和尺寸的微调**，使其更精确地贴合真实目标（Ground Truth）的边界框。  \n\n因此，正确的描述是：  \n**[D] 用于修正候选区域的位置**  \n\n其他选项的解释：  \n- [A] 用于划分候选区域 → 这是 Selective Search 等区域提议方法的作用，不是回归模型的任务。  \n- [B] 用于提取候选区域的特征向量 → 这是 CNN 网络的作用。  \n- [C] 用于识别候选区域是否包含目标 → 这是分类器（SVM 或 softmax）的作用。"}, "answer": "D"}, {"id": "79", "question": {"enus": "视觉智能图像目标检测算法中， Fast R-CNN算法是对R-CNN算法的一种改进，改进的主要思路以下描述哪个是错误的?", "zhcn": "视觉智能图像目标检测算法中， Fast R-CNN算法是对R-CNN算法的一种改进，改进的主要思路以下描述哪个是错误的?"}, "option": [{"option_text": {"enus": "卷积不再是对每个region proposali进行，而是直接对整张图像，这样减少了很多重复计算", "zhcn": "卷积不再是对每个region proposali进行，而是直接对整张图像，这样减少了很多重复计算"}, "option_flag": false}, {"option_text": {"enus": "用ROI pooling进行特征的尺寸变换", "zhcn": "用ROI pooling进行特征的尺寸变换"}, "option_flag": false}, {"option_text": {"enus": "用softmax代替原来的SVM分类器", "zhcn": "用softmax代替原来的SVM分类器"}, "option_flag": false}, {"option_text": {"enus": "使用bounding-box产生候选区域", "zhcn": "使用bounding-box产生候选区域"}, "option_flag": true}], "analysis": {"enus": "Fast R-CNN ，对R-CNN的一种改进，卷积不再是对每个region proposal进行，而是直接对整张图像 ，用ROI pooling进行特征的尺寸变换，因为全连接层的输入要求尺寸大小一样，因此不能直接把region proposal作为输入，将regressor放进网络一起训练，每个类别对应个regressor，同时用softmax的全连接层代者原来的SVM分类器。官方PPT", "zhcn": "我们先来梳理一下 Fast R-CNN 相对于 R-CNN 的主要改进点：  \n\n1. **共享卷积计算**  \n   R-CNN 是对每个候选区域独立进行卷积，计算量巨大。  \n   Fast R-CNN 改为先对整张图做一次卷积，再从共享的特征图上提取每个候选区域对应的特征（通过 RoI 投影），避免了重复计算。  \n   → 对应选项 **A**，这是正确的改进。  \n\n2. **RoI Pooling 层**  \n   由于候选区域大小不一，Fast R-CNN 使用 RoI Pooling 将不同尺寸的候选区域特征转换为固定尺寸的特征图，以便送入后续的全连接层。  \n   → 对应选项 **B**，这是正确的改进。  \n\n3. **分类器的变化**  \n   R-CNN 对每个类别使用一个 SVM 分类器，而 Fast R-CNN 将分类和边界框回归都整合进一个网络，用 softmax 进行多类别分类，实现了端到端训练。  \n   → 对应选项 **C**，这是正确的改进。  \n\n4. **候选区域生成方法**  \n   Fast R-CNN 并没有改变候选区域的生成方式，它依然使用 Selective Search 等外部方法生成候选区域（和 R-CNN 相同）。  \n   真正改变候选区域生成方法的是 **Faster R-CNN**，它引入了 RPN（Region Proposal Network）来生成候选区域。  \n   → 选项 **D** 说“使用 bounding-box 产生候选区域”表述模糊，但结合上下文，它暗示候选区域生成方式是 Fast R-CNN 的改进，这是错误的。  \n\n因此，错误的描述是 **D**。  \n\n**答案：D** ✅"}, "answer": "D"}]