[{"id": "1", "question": {"enus": "A large mobile network operating company is building a machine learning model to predict customers who are likely to unsubscribe from the service. The company plans to offer an incentive for these customers as the cost of churn is far greater than the cost of the incentive. The model produces the following confusion matrix after evaluating on a test dataset of 100 customers: Based on the model evaluation results, why is this a viable model for production? ", "zhcn": "一家大型移动网络运营商正构建机器学习模型，以预测可能取消服务订阅的客户。鉴于客户流失的成本远高于激励措施的成本，该公司计划为这些客户提供激励。该模型在对100名客户的测试数据集进行评估后，生成了如下混淆矩阵：基于模型评估结果，为何该模型是适用于生产环境的可行方案？"}, "option": [{"option_text": {"zhcn": "模型准确率达86%，且公司因假阴性所承担的成本低于假阳性。", "enus": "The model is 86% accurate and the cost incurred by the company as a result of false negatives is less than the false positives."}, "option_flag": true}, {"option_text": {"zhcn": "该模型的precision为86%，低于其accuracy。", "enus": "The precision of the model is 86%, which is less than the accuracy of the model."}, "option_flag": false}, {"option_text": {"zhcn": "模型准确率达86%，且公司因假阳性产生的成本低于因假阴性产生的成本。", "enus": "The model is 86% accurate and the cost incurred by the company as a result of false positives is less than the false negatives."}, "option_flag": false}, {"option_text": {"zhcn": "该模型的precision为86%，高于其accuracy。", "enus": "The precision of the model is 86%, which is greater than the accuracy of the model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "2", "question": {"enus": "A Machine Learning Specialist is designing a system for improving sales for a company. The objective is to use the large amount of information the company has on users' behavior and product preferences to predict which products users would like based on the users' similarity to other users. What should the Specialist do to meet this objective? ", "zhcn": "一位机器学习专家正为某家公司设计一套旨在提升销售业绩的系统。该目标在于，借助公司所掌握的海量用户行为数据与产品偏好信息，通过分析用户与其他用户的相似性，预测用户可能青睐的产品。那么，专家应如何实现这一目标呢？"}, "option": [{"option_text": {"zhcn": "使用Apache Spark ML在Amazon EMR上构建基于内容的过滤推荐引擎", "enus": "Build a content-based filtering recommendation engine with Apache Spark ML on Amazon EMR"}, "option_flag": false}, {"option_text": {"zhcn": "使用Apache Spark ML在Amazon EMR上构建协同过滤推荐引擎。", "enus": "Build a collaborative filtering recommendation engine with Apache Spark ML on Amazon EMR."}, "option_flag": true}, {"option_text": {"zhcn": "使用Apache Spark ML在Amazon EMR上构建基于模型的过滤推荐引擎", "enus": "Build a model-based filtering recommendation engine with Apache Spark ML on Amazon EMR"}, "option_flag": false}, {"option_text": {"zhcn": "\n基于Apache Spark ML在Amazon EMR上构建组合过滤推荐引擎", "enus": "Build a combinative filtering recommendation engine with Apache Spark ML on Amazon EMR"}, "option_flag": false}], "analysis": {"enus": "Many developers want to implement the famous Amazon model that was used to power the People who bought this also bought these items feature on Amazon.com. This model is based on a method called Collaborative Filtering. It takes items such as movies, books, and products that were rated highly by a set of users and recommending them to other users who also gave them high ratings. This method works well in domains where explicit ratings or implicit user actions can be gathered and analyzed. Reference: https://aws.amazon.com/blogs/big-data/building-a-recommendation-engine-with-spark-ml-on-amazon-emr-using-zeppelin/", "zhcn": ""}, "answer": "B"}, {"id": "3", "question": {"enus": "A Mobile Network Operator is building an analytics platform to analyze and optimize a company's operations using Amazon Athena and Amazon S3. The source systems send data in .CSV format in real time. The Data Engineering team wants to transform the data to the Apache Parquet format before storing it on Amazon S3. Which solution takes the LEAST effort to implement? ", "zhcn": "\n一家移动网络运营商正利用Amazon Athena和Amazon S3构建分析平台，以分析和优化公司运营。源系统实时以.CSV格式发送数据，数据工程团队希望在将数据存储到Amazon S3之前，将其转换为Apache Parquet格式。那么，哪种方案实现起来最省力？"}, "option": [{"option_text": {"zhcn": "在Amazon EC2实例上使用Apache Kafka Streams导入CSV数据，并借助Kafka Connect S3将数据序列化为Parquet格式。", "enus": "Ingest .CSV data using Apache Kafka Streams on Amazon EC2 instances and use Kafka Connect S3 to serialize data as Parquet"}, "option_flag": false}, {"option_text": {"zhcn": "\n从Amazon Kinesis Data Streams摄入CSV数据，并使用Amazon Glue将其转换为Parquet格式。", "enus": "Ingest .CSV data from Amazon Kinesis Data Streams and use Amazon Glue to convert data into Parquet."}, "option_flag": true}, {"option_text": {"zhcn": "在Amazon EMR集群中使用Apache Spark结构化流导入CSV数据，并借助Apache Spark将数据转换为Parquet格式。", "enus": "Ingest .CSV data using Apache Spark Structured Streaming in an Amazon EMR cluster and use Apache Spark to convert data into  Parquet."}, "option_flag": false}, {"option_text": {"zhcn": "\n从Amazon Kinesis Data Streams接入CSV数据，并借助Amazon Kinesis Data Firehose将其转换为Parquet格式。", "enus": "Ingest .CSV data from Amazon Kinesis Data Streams and use Amazon Kinesis Data Firehose to convert data into Parquet."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "4", "question": {"enus": "A city wants to monitor its air quality to address the consequences of air pollution. A Machine Learning Specialist needs to forecast the air quality in parts per million of contaminates for the next 2 days in the city. As this is a prototype, only daily data from the last year is available. Which model is MOST likely to provide the best results in Amazon SageMaker? ", "zhcn": "某市希望监测空气质量，以应对空气污染带来的后果。机器学习专家需要预测该市未来两天的空气质量，具体为污染物的百万分比浓度。由于这是一个原型项目，目前仅有过去一年的每日数据可用。在Amazon SageMaker中，哪种模型最有可能提供最佳结果？"}, "option": [{"option_text": {"zhcn": "在由全年数据构成的单个时间序列上，使用Amazon SageMaker的k-近邻（kNN）算法，并将预测器类型设置为回归器。", "enus": "Use the Amazon SageMaker k-Nearest-Neighbors (kNN) algorithm on the single time series consisting of the full year of data with a  predictor_type of regressor."}, "option_flag": false}, {"option_text": {"zhcn": "将Amazon SageMaker随机切割森林（RCF）应用于包含全年数据的单个时间序列。", "enus": "Use Amazon SageMaker Random Cut Forest (RCF) on the single time series consisting of the full year of data."}, "option_flag": false}, {"option_text": {"zhcn": "将Amazon SageMaker Linear Learner算法应用于由全年数据构成的单一时间序列，预测器类型为回归器。", "enus": "Use the Amazon SageMaker Linear Learner algorithm on the single time series consisting of the full year of data with a predictor_type  of regressor."}, "option_flag": true}, {"option_text": {"zhcn": "使用Amazon SageMaker Linear Learner算法，针对由全年数据构成的单一时间序列，并将预测器类型指定为分类器。", "enus": "Use the Amazon SageMaker Linear Learner algorithm on the single time series consisting of the full year of data with a predictor_type  of classifier."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/build-a-model-to-predict-the-impact-of-weather-on-urban-air-quality-using-amazon- sagemaker/? ref=Welcome.AI", "zhcn": ""}, "answer": "C"}, {"id": "5", "question": {"enus": "A Data Engineer needs to build a model using a dataset containing customer credit card information How can the Data Engineer ensure the data remains encrypted and the credit card information is secure? ", "zhcn": "数据工程师需要使用包含客户信用卡信息的数据集构建模型，如何确保数据保持加密状态，且信用卡信息得到安全保障？"}, "option": [{"option_text": {"zhcn": "通过自定义加密算法对数据进行加密，并将数据存储在VPC中的Amazon SageMaker实例上。利用SageMaker DeepAR算法对信用卡号码进行随机化处理。", "enus": "Use a custom encryption algorithm to encrypt the data and store the data on an Amazon SageMaker instance in a VPC. Use the  SageMaker DeepAR algorithm to randomize the credit card numbers."}, "option_flag": false}, {"option_text": {"zhcn": "使用IAM策略对Amazon S3存储桶和Amazon Kinesis中的数据进行加密，自动丢弃信用卡号并插入虚假信用卡号。", "enus": "Use an IAM policy to encrypt the data on the Amazon S3 bucket and Amazon Kinesis to automatically discard credit card numbers and  insert fake credit card numbers."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker启动配置，在数据被复制到VPC中的SageMaker实例后对其进行加密；采用SageMaker主成分分析（PCA）算法，精简信用卡号码的长度。", "enus": "Use an Amazon SageMaker launch configuration to encrypt the data once it is copied to the SageMaker instance in a VPC. Use the  SageMaker principal component analysis (PCA) algorithm to reduce the length of the credit card numbers."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS KMS对Amazon S3和Amazon SageMaker上的数据进行加密，并借助AWS Glue对客户数据中的信用卡号进行脱敏处理。", "enus": "Use AWS KMS to encrypt the data on Amazon S3 and Amazon SageMaker, and redact the credit card numbers from the customer data  with AWS Glue."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "6", "question": {"enus": "A Machine Learning Specialist is using an Amazon SageMaker notebook instance in a private subnet of a corporate VPC. The ML Specialist has important data stored on the Amazon SageMaker notebook instance's Amazon EBS volume, and needs to take a snapshot of that EBS volume. However, the ML Specialist cannot find the Amazon SageMaker notebook instance's EBS volume or Amazon EC2 instance within the VPC. Why is the ML Specialist not seeing the instance visible in the VPC? ", "zhcn": "\n一位机器学习专家正在企业VPC的私有子网中使用一个Amazon SageMaker笔记本实例。该机器学习专家的重要数据存储在Amazon SageMaker笔记本实例的Amazon EBS卷上，故需要为该EBS卷创建快照。然而，该机器学习专家在VPC内既找不到Amazon SageMaker笔记本实例的EBS卷，也找不到其对应的Amazon EC2实例。为何该机器学习专家在VPC中看不到该实例？"}, "option": [{"option_text": {"zhcn": "\nAmazon SageMaker notebook instances基于客户账户内的EC2实例，但它们运行在VPC之外。", "enus": "Amazon SageMaker notebook instances are based on the EC2 instances within the customer account, but they run outside of VPCs."}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker notebook 实例构建于客户账户内的 Amazon ECS 服务之上。", "enus": "Amazon SageMaker notebook instances are based on the Amazon ECS service within customer accounts."}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker 笔记本实例基于运行在 AWS 服务账户内的 EC2 实例构建而成。", "enus": "Amazon SageMaker notebook instances are based on EC2 instances running within AWS service accounts."}, "option_flag": true}, {"option_text": {"zhcn": "Amazon SageMaker notebook 实例基于运行在AWS服务账户内的ECS实例构建而成。", "enus": "Amazon SageMaker notebook instances are based on AWS ECS instances running within AWS service accounts."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html", "zhcn": ""}, "answer": "C"}, {"id": "7", "question": {"enus": "A Machine Learning Specialist is building a model that will perform time series forecasting using Amazon SageMaker. The Specialist has finished training the model and is now planning to perform load testing on the endpoint so they can configure Auto Scaling for the model variant. Which approach will allow the Specialist to review the latency, memory utilization, and CPU utilization during the load test? ", "zhcn": "一位机器学习专家正在构建一个利用Amazon SageMaker进行时间序列预测的模型。模型训练完成后，该专家计划对终端节点进行负载测试，以便为模型变体配置自动扩缩容功能。若要在此次负载测试中同步监测延迟、内存利用率及CPU利用率指标，应采用以下哪种方案？"}, "option": [{"option_text": {"zhcn": "借助Amazon Athena与Amazon QuickSight，可实时分析写入Amazon S3的SageMaker日志，并在日志生成过程中实现可视化呈现。", "enus": "Review SageMaker logs that have been written to Amazon S3 by leveraging Amazon Athena and Amazon QuickSight to visualize logs as  they are being produced."}, "option_flag": false}, {"option_text": {"zhcn": "为集中展示亚马逊SageMaker输出的延迟、内存利用率和CPU利用率指标，请生成亚马逊CloudWatch监控看板。", "enus": "Generate an Amazon CloudWatch dashboard to create a single view for the latency, memory utilization, and CPU utilization metrics that  are outputted by Amazon SageMaker."}, "option_flag": true}, {"option_text": {"zhcn": "构建自定义的Amazon CloudWatch日志组，随后运用Amazon ES与Kibana平台，在Amazon SageMaker生成日志数据的同时即可进行实时查询与可视化呈现。", "enus": "Build custom Amazon CloudWatch Logs and then leverage Amazon ES and Kibana to query and visualize the log data as it is generated  by Amazon SageMaker."}, "option_flag": false}, {"option_text": {"zhcn": "将亚马逊SageMaker生成的亚马逊云监控日志发送至亚马逊ES服务，并借助Kibana对日志数据进行查询与可视化分析。", "enus": "Send Amazon CloudWatch Logs that were generated by Amazon SageMaker to Amazon ES and use Kibana to query and visualize the  log data."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html", "zhcn": ""}, "answer": "B"}, {"id": "8", "question": {"enus": "A manufacturing company has structured and unstructured data stored in an Amazon S3 bucket. A Machine Learning Specialist wants to use SQL to run queries on this data. Which solution requires the LEAST effort to be able to query this data? ", "zhcn": "一家制造公司将其结构化与非结构化数据存储于亚马逊S3存储桶中。机器学习专家需使用SQL语言对此数据进行查询。若要实现数据查询，何种解决方案所需投入精力最少？"}, "option": [{"option_text": {"zhcn": "借助AWS Data Pipeline对数据进行转换处理，并运用Amazon RDS执行查询操作。", "enus": "Use AWS Data Pipeline to transform the data and Amazon RDS to run queries."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue进行数据编目，再通过Amazon Athena执行查询。", "enus": "Use AWS Glue to catalogue the data and Amazon Athena to run queries."}, "option_flag": true}, {"option_text": {"zhcn": "利用AWS Batch对数据进行ETL处理，并通过Amazon Aurora执行查询操作。", "enus": "Use AWS Batch to run ETL on the data and Amazon Aurora to run the queries."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Lambda进行数据转换，并通过Amazon Kinesis Data Analytics执行查询分析。", "enus": "Use AWS Lambda to transform the data and Amazon Kinesis Data Analytics to run queries."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "9", "question": {"enus": "A Machine Learning Specialist is developing a custom video recommendation model for an application. The dataset used to train this model is very large with millions of data points and is hosted in an Amazon S3 bucket. The Specialist wants to avoid loading all of this data onto an Amazon SageMaker notebook instance because it would take hours to move and will exceed the attached 5 GB Amazon EBS volume on the notebook instance. Which approach allows the Specialist to use all the data to train the model? ", "zhcn": "一位机器学习专家正在为某应用程序开发定制化视频推荐模型。训练模型所用的数据集包含数百万个数据点，规模极为庞大，目前存储于亚马逊S3存储桶中。由于将所有数据加载到亚马逊SageMaker笔记本实例需耗时数小时，且会超出该实例附加的5GB亚马逊EBS存储容量，专家希望避免此操作。请问采用何种方法可确保专家能够使用全部数据完成模型训练？"}, "option": [{"option_text": {"zhcn": "将数据集的较小子集载入SageMaker笔记本并在本地进行训练。验证训练代码能否正常执行，并确认模型参数设置合理。随后使用S3存储桶中的完整数据集，通过Pipe输入模式启动SageMaker训练任务。", "enus": "Load a smaller subset of the data into the SageMaker notebook and train locally. Confirm that the training code is executing and the  model parameters seem reasonable. Initiate a SageMaker training job using the full dataset from the S3 bucket using Pipe input mode."}, "option_flag": true}, {"option_text": {"zhcn": "在AWS深度学习AMI上启动一台Amazon EC2实例，并将S3存储桶挂载至该实例。先使用少量数据进行训练，以验证训练代码与超参数配置是否恰当。随后返回Amazon SageMaker平台，利用完整数据集完成模型训练。", "enus": "Launch an Amazon EC2 instance with an AWS Deep Learning AMI and attach the S3 bucket to the instance. Train on a small amount of  the data to verify the training code and hyperparameters. Go back to Amazon SageMaker and train using the full dataset"}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue对数据的小规模样本进行模型训练，以验证数据与Amazon SageMaker的兼容性。随后通过Pipe输入模式，调用S3存储桶中的完整数据集启动SageMaker训练任务。", "enus": "Use AWS Glue to train a model using a small subset of the data to confirm that the data will be compatible with Amazon SageMaker.  Initiate a SageMaker training job using the full dataset from the S3 bucket using Pipe input mode."}, "option_flag": false}, {"option_text": {"zhcn": "将数据子集载入SageMaker笔记本进行本地训练，确保代码正常运行且模型参数设置合理。随后启动搭载AWS深度学习镜像的Amazon EC2实例，并挂载S3存储桶以完成全量数据集训练。", "enus": "Load a smaller subset of the data into the SageMaker notebook and train locally. Confirm that the training code is executing and the  model parameters seem reasonable. Launch an Amazon EC2 instance with an AWS Deep Learning AMI and attach the S3 bucket to train  the full dataset."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "10", "question": {"enus": "A Machine Learning Specialist has completed a proof of concept for a company using a small data sample, and now the Specialist is ready to implement an end- to-end solution in AWS using Amazon SageMaker. The historical training data is stored in Amazon RDS. Which approach should the Specialist use for training a model using that data? ", "zhcn": "一位机器学习专家已利用小样本数据为公司完成了概念验证，现准备基于亚马逊SageMaker在AWS平台上部署端到端解决方案。历史训练数据存储于Amazon RDS数据库中，此时专家应采用何种方案利用该数据训练模型？"}, "option": [{"option_text": {"zhcn": "在笔记本中直接连接SQL数据库并导入数据。", "enus": "Write a direct connection to the SQL database within the notebook and pull data in"}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS数据管道将微软SQL Server中的数据推送至Amazon S3，并在笔记本中提供S3存储路径。", "enus": "Push the data from Microsoft SQL Server to Amazon S3 using an AWS Data Pipeline and provide the S3 location within the notebook."}, "option_flag": true}, {"option_text": {"zhcn": "将数据迁移至Amazon DynamoDB，并在笔记本中建立与DynamoDB的连接以获取数据。", "enus": "Move the data to Amazon DynamoDB and set up a connection to DynamoDB within the notebook to pull data in."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS DMS服务将数据迁移至Amazon ElastiCache，并在笔记本环境中配置连接以快速获取数据。", "enus": "Move the data to Amazon ElastiCache using AWS DMS and set up a connection within the notebook to pull data in for fast access."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "11", "question": {"enus": "A Machine Learning Specialist receives customer data for an online shopping website. The data includes demographics, past visits, and locality information. The Specialist must develop a machine learning approach to identify the customer shopping patterns, preferences, and trends to enhance the website for better service and smart recommendations. Which solution should the Specialist recommend? ", "zhcn": "一位机器学习专家收到了某购物网站提供的客户数据，其中包含用户画像、历史访问记录及地域信息。该专家需要构建一套机器学习方案，用以精准捕捉消费者的购物习惯、偏好倾向与流行趋势，从而优化网站功能，实现智能推荐服务。在此情境下，专家应当提出何种解决方案？"}, "option": [{"option_text": {"zhcn": "针对给定的离散数据集，运用隐含狄利克雷分布模型对客户数据库进行模式识别。", "enus": "Latent Dirichlet Allocation (LDA) for the given collection of discrete data to identify patterns in the customer database."}, "option_flag": false}, {"option_text": {"zhcn": "一个至少包含三层结构、初始权重随机设定的神经网络，用于识别客户数据库中的规律模式。", "enus": "A neural network with a minimum of three layers and random initial weights to identify patterns in the customer database."}, "option_flag": false}, {"option_text": {"zhcn": "基于用户互动与关联性的协同过滤技术，用于识别客户数据库中的行为模式。", "enus": "Collaborative filtering based on user interactions and correlations to identify patterns in the customer database."}, "option_flag": true}, {"option_text": {"zhcn": "对随机子样本应用随机切割森林（RCF）算法，以识别客户数据库中的潜在规律。", "enus": "Random Cut Forest (RCF) over random subsamples to identify patterns in the customer database."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "12", "question": {"enus": "A Machine Learning Specialist is working with a large company to leverage machine learning within its products. The company wants to group its customers into categories based on which customers will and will not churn within the next 6 months. The company has labeled the data available to the Specialist. Which machine learning model type should the Specialist use to accomplish this task? ", "zhcn": "某大型企业正与一位机器学习专家合作，旨在将机器学习技术融入其产品体系。企业希望根据客户在未来六个月内的流失可能性对其进行分类，并已为专家提供了标注好的数据集。为达成此目标，该专家应采用何种机器学习模型类型？"}, "option": [{"option_text": {"zhcn": "线性回归", "enus": "Linear regression"}, "option_flag": false}, {"option_text": {"zhcn": "分类", "enus": "Classification"}, "option_flag": true}, {"option_text": {"zhcn": "聚类分析", "enus": "Clustering"}, "option_flag": false}, {"option_text": {"zhcn": "强化学习", "enus": "Reinforcement learning"}, "option_flag": false}], "analysis": {"enus": "The goal of classification is to determine to which class or category a data point (customer in our case) belongs to. For classification problems, data scientists would use historical data with predefined target variables AKA labels (churner/non-churner) \" answers that need to be predicted \" to train an algorithm. With classification, businesses can answer the following questions: ✑ Will this customer churn or not? ✑ Will a customer renew their subscription? ✑ Will a user downgrade a pricing plan? ✑ Are there any signs of unusual customer behavior? Reference: https://www.kdnuggets.com/2019/05/churn-prediction-machine-learning.html", "zhcn": ""}, "answer": "B"}, {"id": "13", "question": {"enus": "The displayed graph is from a forecasting model for testing a time series. Considering the graph only, which conclusion should a Machine Learning Specialist make about the behavior of the model? ", "zhcn": "根据图表所示，该图像源自用于时间序列测试的预测模型。仅从图像表现判断，机器学习专家应如何评价该模型的行为特征？"}, "option": [{"option_text": {"zhcn": "该模型对趋势性和季节性变化的预测都颇为精准。", "enus": "The model predicts both the trend and the seasonality well"}, "option_flag": true}, {"option_text": {"zhcn": "模型对趋势的预测相当准确，但在季节性波动方面则有所欠缺。", "enus": "The model predicts the trend well, but not the seasonality."}, "option_flag": false}, {"option_text": {"zhcn": "模型对季节性的预测颇为精准，却未能捕捉到整体趋势。", "enus": "The model predicts the seasonality well, but not the trend."}, "option_flag": false}, {"option_text": {"zhcn": "该模型未能准确捕捉趋势性与季节性变化。", "enus": "The model does not predict the trend or the seasonality well."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "14", "question": {"enus": "A company wants to classify user behavior as either fraudulent or normal. Based on internal research, a Machine Learning Specialist would like to build a binary classifier based on two features: age of account and transaction month. The class distribution for these features is illustrated in the figure provided. Based on this information, which model would have the HIGHEST accuracy? ", "zhcn": "某公司需对用户行为进行欺诈与正常的分类。根据内部研究，一位机器学习专家计划基于账户存续时长和交易月份这两个特征构建二元分类器。附图展示了这些特征对应的类别分布情况。基于现有信息，哪种模型的预测准确率会最高？"}, "option": [{"option_text": {"zhcn": "采用缩放指数线性单元（SELU）激活函数的长短期记忆（LSTM）模型。", "enus": "Long short-term memory (LSTM) model with scaled exponential linear unit (SELU)"}, "option_flag": false}, {"option_text": {"zhcn": "逻辑回归", "enus": "Logistic regression"}, "option_flag": false}, {"option_text": {"zhcn": "采用非线性核函数的支持向量机（SVM）", "enus": "Support vector machine (SVM) with non-linear kernel"}, "option_flag": true}, {"option_text": {"zhcn": "采用双曲正切激活函数的单层感知机", "enus": "Single perceptron with tanh activation function"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "15", "question": {"enus": "A Machine Learning Specialist at a company sensitive to security is preparing a dataset for model training. The dataset is stored in Amazon S3 and contains Personally Identifiable Information (PII). The dataset: ✑ Must be accessible from a VPC only. ✑ Must not traverse the public internet. How can these requirements be satisfied? ", "zhcn": "某涉密企业的机器学习专家正在为模型训练准备数据集。该数据集存放于Amazon S3存储服务中，且包含个人身份识别信息。现有安全要求如下：  \n✧ 数据集仅允许通过虚拟私有云访问  \n✧ 数据传输不得经过公共互联网  \n\n请问如何满足这些技术要求？"}, "option": [{"option_text": {"zhcn": "创建VPC终端节点，并配置存储桶访问策略，限定仅允许指定VPC终端节点及其对应VPC进行访问。", "enus": "Create a VPC endpoint and apply a bucket access policy that restricts access to the given VPC endpoint and the VPC."}, "option_flag": true}, {"option_text": {"zhcn": "创建VPC终端节点，并配置存储桶访问策略，允许来自指定VPC终端节点及Amazon EC2实例的访问权限。", "enus": "Create a VPC endpoint and apply a bucket access policy that allows access from the given VPC endpoint and an Amazon EC2 instance."}, "option_flag": false}, {"option_text": {"zhcn": "创建VPC终端节点，并配置网络访问控制列表（NACLs），确保仅允许指定VPC终端节点与亚马逊EC2实例之间的流量互通。", "enus": "Create a VPC endpoint and use Network Access Control Lists (NACLs) to allow trafic between only the given VPC endpoint and an  Amazon EC2 instance."}, "option_flag": false}, {"option_text": {"zhcn": "创建VPC终端节点，并通过安全组限制对指定VPC终端节点及亚马逊EC2实例的访问权限。", "enus": "Create a VPC endpoint and use security groups to restrict access to the given VPC endpoint and an Amazon EC2 instance"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "16", "question": {"enus": "During mini-batch training of a neural network for a classification problem, a Data Scientist notices that training accuracy oscillates. What is the MOST likely cause of this issue? ", "zhcn": "在针对分类问题的小批量训练神经网络过程中，一位数据科学家发现训练准确率出现波动。导致该现象最可能的原因是什么？"}, "option": [{"option_text": {"zhcn": "该数据集中的类别分布并不均衡。", "enus": "The class distribution in the dataset is imbalanced."}, "option_flag": false}, {"option_text": {"zhcn": "数据集随机打乱功能已停用。", "enus": "Dataset shufiing is disabled."}, "option_flag": false}, {"option_text": {"zhcn": "批次规模过大。", "enus": "The batch size is too big."}, "option_flag": false}, {"option_text": {"zhcn": "学习速率相当之快。", "enus": "The learning rate is very high."}, "option_flag": true}], "analysis": {"enus": "Reference: https://towardsdatascience.com/deep-learning-personal-notes-part-1-lesson-2-8946fe970b95", "zhcn": ""}, "answer": "D"}, {"id": "17", "question": {"enus": "An employee found a video clip with audio on a company's social media feed. The language used in the video is Spanish. English is the employee's first language, and they do not understand Spanish. The employee wants to do a sentiment analysis. What combination of services is the MOST eficient to accomplish the task? ", "zhcn": "公司一名员工在社交媒体推送中发现了一段带音频的视频片段。该视频使用西班牙语录制，而该员工的母语为英语且不通晓西班牙语。该员工希望进行情感倾向分析，要最高效地完成此任务，下列哪种服务组合最为适宜？"}, "option": [{"option_text": {"zhcn": "Amazon Transcribe、Amazon Translate 与 Amazon Comprehend", "enus": "Amazon Transcribe, Amazon Translate, and Amazon Comprehend"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon Transcribe、Amazon Comprehend 与 Amazon SageMaker 序列到序列模型", "enus": "Amazon Transcribe, Amazon Comprehend, and Amazon SageMaker seq2seq"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊语音转文本服务、亚马逊语言翻译服务，以及亚马逊SageMaker神经主题模型（NTM）。", "enus": "Amazon Transcribe, Amazon Translate, and Amazon SageMaker Neural Topic Model (NTM)"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊语音转文本、亚马逊语言翻译与亚马逊SageMaker极速文本分析", "enus": "Amazon Transcribe, Amazon Translate and Amazon SageMaker BlazingText"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "18", "question": {"enus": "A Machine Learning Specialist is packaging a custom ResNet model into a Docker container so the company can leverage Amazon SageMaker for training. The Specialist is using Amazon EC2 P3 instances to train the model and needs to properly configure the Docker container to leverage the NVIDIA GPUs. What does the Specialist need to do? ", "zhcn": "一位机器学习专家正在将定制开发的ResNet模型封装至Docker容器中，以便企业能够借助亚马逊SageMaker平台进行模型训练。该专家采用亚马逊EC2 P3实例开展模型训练工作，需对Docker容器进行正确配置以充分发挥NVIDIA GPU的运算效能。请问专家应当如何完成相关配置？"}, "option": [{"option_text": {"zhcn": "将NVIDIA驱动程序与Docker镜像捆绑打包。", "enus": "Bundle the NVIDIA drivers with the Docker image."}, "option_flag": true}, {"option_text": {"zhcn": "构建兼容NVIDIA-Docker的Docker容器。", "enus": "Build the Docker container to be NVIDIA-Docker compatible."}, "option_flag": false}, {"option_text": {"zhcn": "调整Docker容器的文件结构，以便在GPU实例上运行。", "enus": "Organize the Docker container's file structure to execute on GPU instances."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon SageMaker的CreateTrainingJob请求体中配置GPU参数。", "enus": "Set the GPU fiag in the Amazon SageMaker CreateTrainingJob request body."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "19", "question": {"enus": "A Machine Learning Specialist is building a logistic regression model that will predict whether or not a person will order a pizza. The Specialist is trying to build the optimal model with an ideal classification threshold. What model evaluation technique should the Specialist use to understand how different classification thresholds will impact the model's performance? ", "zhcn": "一位机器学习专家正在构建逻辑回归模型，用于预测顾客是否会订购披萨。该专家试图通过最佳分类阈值来构建最优模型。请问应采用何种模型评估方法，才能帮助专家理解不同分类阈值对模型性能的影响？"}, "option": [{"option_text": {"zhcn": "受试者工作特征曲线", "enus": "Receiver operating characteristic (ROC) curve"}, "option_flag": true}, {"option_text": {"zhcn": "误判率", "enus": "Misclassification rate"}, "option_flag": false}, {"option_text": {"zhcn": "均方根误差", "enus": "Root Mean Square Error (RMSE)"}, "option_flag": false}, {"option_text": {"zhcn": "L1 范数", "enus": "L1 norm"}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/machine-learning/latest/dg/binary-model-insights.html", "zhcn": ""}, "answer": "A"}, {"id": "20", "question": {"enus": "An interactive online dictionary wants to add a widget that displays words used in similar contexts. A Machine Learning Specialist is asked to provide word features for the downstream nearest neighbor model powering the widget. What should the Specialist do to meet these requirements? ", "zhcn": "一款在线互动词典计划增设显示近义语境词汇的小组件，现需机器学习专家为驱动该组件的近邻模型提供词汇特征向量。专家应当采取何种方案以满足需求？"}, "option": [{"option_text": {"zhcn": "生成独热词编码向量。", "enus": "Create one-hot word encoding vectors."}, "option_flag": true}, {"option_text": {"zhcn": "为每个词汇生成一组同义词，可借助亚马逊土耳其机器人平台实现。", "enus": "Produce a set of synonyms for every word using Amazon Mechanical Turk."}, "option_flag": false}, {"option_text": {"zhcn": "生成能够存储与所有其他词汇间编辑距离的词嵌入向量。", "enus": "Create word embedding vectors that store edit distance with every other word."}, "option_flag": false}, {"option_text": {"zhcn": "下载基于大型语料库预训练的词嵌入模型。", "enus": "Download word embeddings pre-trained on a large corpus."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-object2vec-adds-new-features-that-support-automatic-negative- sampling-and- speed-up-training/", "zhcn": ""}, "answer": "A"}, {"id": "21", "question": {"enus": "A Machine Learning Specialist is configuring Amazon SageMaker so multiple Data Scientists can access notebooks, train models, and deploy endpoints. To ensure the best operational performance, the Specialist needs to be able to track how often the Scientists are deploying models, GPU and CPU utilization on the deployed SageMaker endpoints, and all errors that are generated when an endpoint is invoked. Which services are integrated with Amazon SageMaker to track this information? (Choose two.) ", "zhcn": "亚马逊机器学习专家正在配置Amazon SageMaker平台，以便多位数据科学家能够访问笔记本书写环境、训练模型并部署服务终端。为保障系统的最佳运行效能，该专家需持续追踪科学家们部署模型的频率、已部署SageMaker终端上的GPU与CPU资源利用率，以及终端调用时产生的所有错误信息。下列哪两项服务与Amazon SageMaker原生集成，可协助实现上述监控目标？（请选择两项正确答案）"}, "option": [{"option_text": {"zhcn": "AWS CloudTrail", "enus": "AWS CloudTrail"}, "option_flag": true}, {"option_text": {"zhcn": "AWS健康服务", "enus": "AWS Health"}, "option_flag": false}, {"option_text": {"zhcn": "AWS Trusted Advisor", "enus": "AWS Trusted Advisor"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊云监控", "enus": "Amazon CloudWatch"}, "option_flag": true}, {"option_text": {"zhcn": "AWS Config", "enus": "AWS Config"}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/sagemaker/faqs/", "zhcn": ""}, "answer": "AD"}, {"id": "22", "question": {"enus": "A retail chain has been ingesting purchasing records from its network of 20,000 stores to Amazon S3 using Amazon Kinesis Data Firehose. To support training an improved machine learning model, training records will require new but simple transformations, and some attributes will be combined. The model needs to be retrained daily. Given the large number of stores and the legacy data ingestion, which change will require the LEAST amount of development effort? ", "zhcn": "一家零售连锁企业一直通过亚马逊Kinesis数据消防带服务，将其两万家门店的采购记录实时汇入亚马逊S3存储平台。为提升机器学习模型的训练效果，训练数据需进行几项简单的新型转换处理，并将部分属性字段加以整合。该模型需实现每日自动重训练。考虑到门店规模庞大且存在传统数据接入方式，下列哪种改造方案所需开发投入最为精简？"}, "option": [{"option_text": {"zhcn": "要求各门店将数据采集方式切换为通过AWS存储网关在本地捕获，随后导入Amazon S3存储服务，再运用AWS Glue进行数据转换处理。", "enus": "Require that the stores to switch to capturing their data locally on AWS Storage Gateway for loading into Amazon S3, then use AWS Glue  to do the transformation."}, "option_flag": false}, {"option_text": {"zhcn": "部署一个运行Apache Spark的亚马逊EMR集群，并配置相应的数据转换逻辑。该集群需每日处理亚马逊S3中持续累积的数据记录，将处理后的新数据及转换结果输出至亚马逊S3存储空间。", "enus": "Deploy an Amazon EMR cluster running Apache Spark with the transformation logic, and have the cluster run each day on the  accumulating records in Amazon S3, outputting new/transformed records to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "部署一套搭载转换逻辑的亚马逊EC2实例集群，对积存在亚马逊S3的数据记录进行转换处理，并将转换后的记录输出至亚马逊S3存储空间。", "enus": "Spin up a fieet of Amazon EC2 instances with the transformation logic, have them transform the data records accumulating on Amazon  S3, and output the transformed records to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在Kinesis Data Firehose数据流的下游接入一条Amazon Kinesis数据分析流，通过SQL语句将原始记录属性转化为简洁的转换值。", "enus": "Insert an Amazon Kinesis Data Analytics stream downstream of the Kinesis Data Firehose stream that transforms raw record attributes  into simple transformed values using SQL."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "23", "question": {"enus": "A Machine Learning Specialist is building a convolutional neural network (CNN) that will classify 10 types of animals. The Specialist has built a series of layers in a neural network that will take an input image of an animal, pass it through a series of convolutional and pooling layers, and then finally pass it through a dense and fully connected layer with 10 nodes. The Specialist would like to get an output from the neural network that is a probability distribution of how likely it is that the input image belongs to each of the 10 classes. Which function will produce the desired output? ", "zhcn": "一位机器学习专家正在构建一个用于识别10种动物的卷积神经网络（CNN）。该专家设计了一系列网络层结构：输入动物图像后，数据会依次经过若干卷积层和池化层，最终进入包含10个节点的全连接层。为使神经网络输出能呈现该图像分别属于10个类别概率分布，应采用哪种激活函数？"}, "option": [{"option_text": {"zhcn": "辍学", "enus": "Dropout"}, "option_flag": false}, {"option_text": {"zhcn": "平滑L1损失函数", "enus": "Smooth L1 loss"}, "option_flag": false}, {"option_text": {"zhcn": "“Softmax”", "enus": "Softmax"}, "option_flag": true}, {"option_text": {"zhcn": "修正线性单元（ReLU）", "enus": "Rectified linear units (ReLU)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "24", "question": {"enus": "A Machine Learning Specialist trained a regression model, but the first iteration needs optimizing. The Specialist needs to understand whether the model is more frequently overestimating or underestimating the target. What option can the Specialist use to determine whether it is overestimating or underestimating the target value? ", "zhcn": "一位机器学习专家训练了一个回归模型，但初始版本还需优化。该专家需要判断模型更倾向于高估还是低估预测目标。下列哪种方法能帮助专家确认预测值偏离的方向？"}, "option": [{"option_text": {"zhcn": "均方根误差", "enus": "Root Mean Square Error (RMSE)"}, "option_flag": false}, {"option_text": {"zhcn": "残差散点图", "enus": "Residual plots"}, "option_flag": true}, {"option_text": {"zhcn": "曲线下面积", "enus": "Area under the curve"}, "option_flag": false}, {"option_text": {"zhcn": "混淆矩阵", "enus": "Confusion matrix"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "25", "question": {"enus": "A company wants to classify user behavior as either fraudulent or normal. Based on internal research, a Machine Learning Specialist would like to build a binary classifier based on two features: age of account and transaction month. The class distribution for these features is illustrated in the figure provided. Based on this information, which model would have the HIGHEST recall with respect to the fraudulent class? ", "zhcn": "某公司需对用户行为进行欺诈与非欺诈分类。根据内部研究，一位机器学习专家计划基于账户存续时长和交易月份这两个特征构建二元分类器。各特征对应的类别分布已通过图示呈现。基于上述信息，哪种模型能对欺诈类别实现最高的召回率？"}, "option": [{"option_text": {"zhcn": "决策树", "enus": "Decision tree"}, "option_flag": false}, {"option_text": {"zhcn": "线性支持向量机（SVM）", "enus": "Linear support vector machine (SVM)"}, "option_flag": false}, {"option_text": {"zhcn": "朴素贝叶斯分类器", "enus": "Naive Bayesian classifier"}, "option_flag": true}, {"option_text": {"zhcn": "采用S形激活函数的单层感知机", "enus": "Single Perceptron with sigmoidal activation function"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "26", "question": {"enus": "A Machine Learning Specialist kicks off a hyperparameter tuning job for a tree-based ensemble model using Amazon SageMaker with Area Under the ROC Curve (AUC) as the objective metric. This workfiow will eventually be deployed in a pipeline that retrains and tunes hyperparameters each night to model click-through on data that goes stale every 24 hours. With the goal of decreasing the amount of time it takes to train these models, and ultimately to decrease costs, the Specialist wants to reconfigure the input hyperparameter range(s). Which visualization will accomplish this? ", "zhcn": "一位机器学习专家利用亚马逊SageMaker服务平台，以ROC曲线下面积（AUC）作为目标指标，启动了基于树模型的集成学习超参数调优任务。该工作流最终将部署于每晚重新训练模型的流水线系统中——由于数据每24小时便会失效，需通过持续调参来预测点击率。为缩短模型训练时间并降低计算成本，专家计划重新配置输入超参数的范围。下列哪种可视化方案可实现这一目标？"}, "option": [{"option_text": {"zhcn": "一幅直方图，用于显示最重要的输入特征是否符合高斯分布。", "enus": "A histogram showing whether the most important input feature is Gaussian."}, "option_flag": false}, {"option_text": {"zhcn": "一幅散点图，通过目标变量对数据点进行色彩区分，运用t分布随机邻域嵌入技术（t-SNE）将众多输入变量转化为更易解读的维度呈现。", "enus": "A scatter plot with points colored by target variable that uses t-Distributed Stochastic Neighbor Embedding (t-SNE) to visualize the  large number of input variables in an easier-to-read dimension."}, "option_flag": true}, {"option_text": {"zhcn": "散点图展示了目标指标在每次训练迭代中的表现变化。", "enus": "A scatter plot showing the performance of the objective metric over each training iteration."}, "option_flag": false}, {"option_text": {"zhcn": "散点图呈现了最大树深度与目标指标之间的关联性。", "enus": "A scatter plot showing the correlation between maximum tree depth and the objective metric."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "27", "question": {"enus": "A Machine Learning Specialist is creating a new natural language processing application that processes a dataset comprised of 1 million sentences. The aim is to then run Word2Vec to generate embeddings of the sentences and enable different types of predictions. Here is an example from the dataset: \"The quck BROWN FOX jumps over the lazy dog.` Which of the following are the operations the Specialist needs to perform to correctly sanitize and prepare the data in a repeatable manner? (Choose three.) ", "zhcn": "一位机器学习专家正在开发一款新型自然语言处理应用，需处理包含百万句量的数据集。该项目旨在通过Word2Vec技术生成语句的嵌入向量，以支持多种预测功能。现有一则数据示例：\"The quck BROWN FOX jumps over the lazy dog.\" 请选出专家需采用哪三项操作，方能以可复现的方式正确完成数据清洗与预处理？"}, "option": [{"option_text": {"zhcn": "进行词性标注，仅保留动作动词与名词。", "enus": "Perform part-of-speech tagging and keep the action verb and the nouns only."}, "option_flag": false}, {"option_text": {"zhcn": "将所有单词转为小写，使句子规范化。", "enus": "Normalize all words by making the sentence lowercase."}, "option_flag": true}, {"option_text": {"zhcn": "使用英文停用词词典移除停用词。", "enus": "Remove stop words using an English stopword dictionary."}, "option_flag": true}, {"option_text": {"zhcn": "将\"quck\"的排版错误修正为\"quick\"。", "enus": "Correct the typography on \"quck\" to \"quick."}, "option_flag": false}, {"option_text": {"zhcn": "将句子中的所有词语进行独热编码。", "enus": "One-hot encode all words in the sentence."}, "option_flag": false}, {"option_text": {"zhcn": "将句子切分为单词。", "enus": "Tokenize the sentence into words."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BCF"}, {"id": "28", "question": {"enus": "A company is using Amazon Polly to translate plaintext documents to speech for automated company announcements. However, company acronyms are being mispronounced in the current documents. How should a Machine Learning Specialist address this issue for future documents? ", "zhcn": "某公司正采用Amazon Polly将纯文本文档转换为语音，用于自动播放企业公告。然而当前文档中的公司缩写词存在发音错误。机器学习专家应当如何调整，以确保后续文档的发音准确性？"}, "option": [{"option_text": {"zhcn": "将现有文档转换为带有发音标记的SSML格式。", "enus": "Convert current documents to SSML with pronunciation tags."}, "option_flag": true}, {"option_text": {"zhcn": "创建一份得体的发音词典。", "enus": "Create an appropriate pronunciation lexicon."}, "option_flag": false}, {"option_text": {"zhcn": "输出语音标记以辅助发音。", "enus": "Output speech marks to guide in pronunciation."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Lex对文本文件进行发音预处理。", "enus": "Use Amazon Lex to preprocess the text files for pronunciation"}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/polly/latest/dg/ssml.html", "zhcn": ""}, "answer": "A"}, {"id": "29", "question": {"enus": "An insurance company is developing a new device for vehicles that uses a camera to observe drivers' behavior and alert them when they appear distracted. The company created approximately 10,000 training images in a controlled environment that a Machine Learning Specialist will use to train and evaluate machine learning models. During the model evaluation, the Specialist notices that the training error rate diminishes faster as the number of epochs increases and the model is not accurately inferring on the unseen test images. Which of the following should be used to resolve this issue? (Choose two.) ", "zhcn": "一家保险公司正在研发一款车载新型装置，该装置通过摄像头监测驾驶员行为，并在察觉其分心时发出警示。公司已在受控环境中创建了约一万张训练图像，供机器学习专家用于训练和评估模型。专家在模型评估过程中发现，随着训练周期增加，训练误差率下降速度过快，且模型对未见过测试图像的推断结果欠佳。应采取以下哪两项措施解决此问题？（请选择两项答案）"}, "option": [{"option_text": {"zhcn": "为模型引入梯度消失机制。", "enus": "Add vanishing gradient to the model."}, "option_flag": false}, {"option_text": {"zhcn": "对训练数据进行增强处理。", "enus": "Perform data augmentation on the training data."}, "option_flag": true}, {"option_text": {"zhcn": "使神经网络架构更为精妙。", "enus": "Make the neural network architecture complex."}, "option_flag": false}, {"option_text": {"zhcn": "在模型中运用梯度检验。", "enus": "Use gradient checking in the model."}, "option_flag": false}, {"option_text": {"zhcn": "为模型加入L2正则化。", "enus": "Add L2 regularization to the model."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BE"}, {"id": "30", "question": {"enus": "When submitting Amazon SageMaker training jobs using one of the built-in algorithms, which common parameters MUST be specified? (Choose three.) ", "zhcn": "在使用亚马逊SageMaker内置算法提交训练任务时，必须指定以下哪三个通用参数？（请选择三项。）"}, "option": [{"option_text": {"zhcn": "用于识别训练数据在Amazon S3存储桶中位置的训练通道。", "enus": "The training channel identifying the location of training data on an Amazon S3 bucket."}, "option_flag": true}, {"option_text": {"zhcn": "验证通道用于标识亚马逊S3存储桶中验证数据所在的位置。", "enus": "The validation channel identifying the location of validation data on an Amazon S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊SageMaker可代用户执行任务时所承担的IAM角色。", "enus": "The IAM role that Amazon SageMaker can assume to perform tasks on behalf of the users."}, "option_flag": false}, {"option_text": {"zhcn": "算法所用超参数以JSON数组形式呈现，具体格式参照对应文档说明。", "enus": "Hyperparameters in a JSON array as documented for the algorithm used."}, "option_flag": false}, {"option_text": {"zhcn": "Amazon EC2 实例类型决定了训练任务将采用 CPU 还是 GPU 进行运算。", "enus": "The Amazon EC2 instance class specifying whether training will be run using CPU or GPU."}, "option_flag": true}, {"option_text": {"zhcn": "指定输出路径，用于确定训练完成的模型在Amazon S3存储桶中的保存位置。", "enus": "The output path specifying where on an Amazon S3 bucket the trained model will persist."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AEF"}, {"id": "31", "question": {"enus": "A monitoring service generates 1 TB of scale metrics record data every minute. A Research team performs queries on this data using Amazon Athena. The queries run slowly due to the large volume of data, and the team requires better performance. How should the records be stored in Amazon S3 to improve query performance? ", "zhcn": "监控服务每分钟产生1TB规模指标记录数据。研究团队使用Amazon Athena对此数据进行查询，由于数据量庞大，查询运行缓慢，团队需要提升查询性能。请问应如何将记录存储在Amazon S3中才能优化查询性能？"}, "option": [{"option_text": {"zhcn": "CSV文件", "enus": "CSV files"}, "option_flag": false}, {"option_text": {"zhcn": "拼花地板文件", "enus": "Parquet files"}, "option_flag": true}, {"option_text": {"zhcn": "压缩版JSON", "enus": "Compressed JSON"}, "option_flag": false}, {"option_text": {"zhcn": "“RecordIO”", "enus": "RecordIO"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "32", "question": {"enus": "Machine Learning Specialist is working with a media company to perform classification on popular articles from the company's website. The company is using random forests to classify how popular an article will be before it is published. A sample of the data being used is below. Given the dataset, the Specialist wants to convert the Day_Of_Week column to binary values. What technique should be used to convert this column to binary values? ", "zhcn": "机器学习专家正与一家传媒公司合作，对其网站热门文章进行自动分类。该公司采用随机森林算法，在文章发布前预测其受欢迎程度。现有数据样本如下所示。针对当前数据集，专家需将\"星期几\"列转换为二进制数值。请问应采用何种技术完成该列数据的二值化转换？"}, "option": [{"option_text": {"zhcn": "二值化", "enus": "Binarization"}, "option_flag": false}, {"option_text": {"zhcn": "独热编码", "enus": "One-hot encoding"}, "option_flag": true}, {"option_text": {"zhcn": "分词", "enus": "Tokenization"}, "option_flag": false}, {"option_text": {"zhcn": "标准化变换", "enus": "Normalization transformation"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "33", "question": {"enus": "A gaming company has launched an online game where people can start playing for free, but they need to pay if they choose to use certain features. The company needs to build an automated system to predict whether or not a new user will become a paid user within 1 year. The company has gathered a labeled dataset from 1 million users. The training dataset consists of 1,000 positive samples (from users who ended up paying within 1 year) and 999,000 negative samples (from users who did not use any paid features). Each data sample consists of 200 features including user age, device, location, and play patterns. Using this dataset for training, the Data Science team trained a random forest model that converged with over 99% accuracy on the training set. However, the prediction results on a test dataset were not satisfactory Which of the following approaches should the Data Science team take to mitigate this issue? (Choose two.) ", "zhcn": "一家游戏公司推出了一款在线游戏，玩家可免费进入体验，但若想使用特定功能则需付费。该公司需构建一套自动化系统，用于预测新用户是否会在一年内转化为付费用户。目前公司已收集了来自100万名用户的标注数据集，其中训练集包含1000个正样本（即一年内最终付费的用户）和999,000个负样本（未使用任何付费功能的用户）。每个数据样本涵盖200项特征，包括用户年龄、设备、地理位置及游戏行为模式。数据科学团队利用该数据集训练随机森林模型，在训练集上收敛后准确率超过99%，但在测试集上的预测效果却不理想。为改善此问题，数据科学团队应采取以下哪两种措施？（请选择两项）"}, "option": [{"option_text": {"zhcn": "在随机森林中增加更多深层决策树，使模型能够学习更丰富的特征。", "enus": "Add more deep trees to the random forest to enable the model to learn more features."}, "option_flag": false}, {"option_text": {"zhcn": "在训练数据集中加入测试数据集中的样本副本。", "enus": "Include a copy of the samples in the test dataset in the training dataset."}, "option_flag": false}, {"option_text": {"zhcn": "通过复制正样本并对复制数据添加微量噪声，以生成更多正样本。", "enus": "Generate more positive samples by duplicating the positive samples and adding a small amount of noise to the duplicated data."}, "option_flag": true}, {"option_text": {"zhcn": "调整成本函数，使误判情形对成本值的影响大于误报情形。", "enus": "Change the cost function so that false negatives have a higher impact on the cost value than false positives."}, "option_flag": true}, {"option_text": {"zhcn": "调整成本函数，使误判情形对成本值的影响大于漏判情形。", "enus": "Change the cost function so that false positives have a higher impact on the cost value than false negatives."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "CD"}, {"id": "34", "question": {"enus": "A Data Scientist is developing a machine learning model to predict future patient outcomes based on information collected about each patient and their treatment plans. The model should output a continuous value as its prediction. The data available includes labeled outcomes for a set of 4,000 patients. The study was conducted on a group of individuals over the age of 65 who have a particular disease that is known to worsen with age. Initial models have performed poorly. While reviewing the underlying data, the Data Scientist notices that, out of 4,000 patient observations, there are 450 where the patient age has been input as 0. The other features for these observations appear normal compared to the rest of the sample population How should the Data Scientist correct this issue? ", "zhcn": "一位数据科学家正在开发机器学习模型，旨在根据收集到的患者信息及治疗方案预测其未来健康状况。该模型需输出连续数值作为预测结果。现有数据集包含4000名患者的标注结果。此项研究针对65岁以上患有特定疾病的群体展开，该疾病已知会随年龄增长而恶化。初步模型表现不佳。数据科学家在核查底层数据时发现，在4000条患者记录中，有450条记录的年龄输入值为0，而这些观测记录的其他特征与样本总体相比均呈现正常状态。数据科学家应如何解决此问题？"}, "option": [{"option_text": {"zhcn": "从数据集中删除所有年龄标记为0的记录。", "enus": "Drop all records from the dataset where age has been set to 0."}, "option_flag": false}, {"option_text": {"zhcn": "将数据集中年龄字段值为0的记录，替换为该字段的均值或中位数。", "enus": "Replace the age field value for records with a value of 0 with the mean or median value from the dataset"}, "option_flag": true}, {"option_text": {"zhcn": "从数据集中移除年龄特征，并利用其余特征训练模型。", "enus": "Drop the age feature from the dataset and train the model using the rest of the features."}, "option_flag": false}, {"option_text": {"zhcn": "运用k-means聚类算法处理缺失特征。", "enus": "Use k-means clustering to handle missing features"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "35", "question": {"enus": "A Data Science team is designing a dataset repository where it will store a large amount of training data commonly used in its machine learning models. As Data Scientists may create an arbitrary number of new datasets every day, the solution has to scale automatically and be cost-effective. Also, it must be possible to explore the data using SQL. Which storage scheme is MOST adapted to this scenario? ", "zhcn": "一个数据科学团队正在设计数据集存储库，用于集中存储其机器学习模型常用的大规模训练数据。由于数据科学家可能每日创建任意数量的新数据集，该解决方案需具备自动扩展能力且符合成本效益。同时，必须支持通过SQL进行数据探索。下列存储方案中哪种最符合此场景需求？"}, "option": [{"option_text": {"zhcn": "将数据集以文件形式存储于Amazon S3中。", "enus": "Store datasets as files in Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "将数据集以文件形式存储于挂载在Amazon EC2实例的Amazon EBS卷中。", "enus": "Store datasets as files in an Amazon EBS volume attached to an Amazon EC2 instance."}, "option_flag": false}, {"option_text": {"zhcn": "将数据集以表格形式存储于多节点亚马逊Redshift集群中。", "enus": "Store datasets as tables in a multi-node Amazon Redshift cluster."}, "option_flag": false}, {"option_text": {"zhcn": "将数据集存储为 Amazon DynamoDB 中的全局表。", "enus": "Store datasets as global tables in Amazon DynamoDB."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "36", "question": {"enus": "A Machine Learning Specialist deployed a model that provides product recommendations on a company's website. Initially, the model was performing very well and resulted in customers buying more products on average. However, within the past few months, the Specialist has noticed that the effect of product recommendations has diminished and customers are starting to return to their original habits of spending less. The Specialist is unsure of what happened, as the model has not changed from its initial deployment over a year ago. Which method should the Specialist try to improve model performance? ", "zhcn": "一位机器学习专家部署了一套为某公司网站提供商品推荐服务的模型。该模型初期表现卓越，有效提升了顾客的平均购买金额。然而近几个月来，专家发现推荐效果逐渐减弱，顾客消费习惯似乎正回归到以往较低的水平。尽管该模型自一年前部署以来从未经过改动，专家仍无法确定症结所在。此时，应采取何种方法提升模型效能？"}, "option": [{"option_text": {"zhcn": "该模型必须彻底重新设计，因其无法有效处理产品库存的变动。", "enus": "The model needs to be completely re-engineered because it is unable to handle product inventory changes."}, "option_flag": false}, {"option_text": {"zhcn": "模型超参数需定期更新，以防出现偏移。", "enus": "The model's hyperparameters should be periodically updated to prevent drift."}, "option_flag": false}, {"option_text": {"zhcn": "模型需定期基于原始数据重新训练，同时加入正则化项以应对产品库存变动。", "enus": "The model should be periodically retrained from scratch using the original data while adding a regularization term to handle product  inventory changes"}, "option_flag": false}, {"option_text": {"zhcn": "随着产品库存的变化，应定期使用原始训练数据结合新增数据对模型进行重新训练。", "enus": "The model should be periodically retrained using the original training data plus new data as product inventory changes."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "37", "question": {"enus": "A Machine Learning Specialist working for an online fashion company wants to build a data ingestion solution for the company's Amazon S3- based data lake. The Specialist wants to create a set of ingestion mechanisms that will enable future capabilities comprised of: ✑ Real-time analytics ✑ Interactive analytics of historical data ✑ Clickstream analytics ✑ Product recommendations Which services should the Specialist use? ", "zhcn": "某在线时尚公司的机器学习专家计划为公司基于亚马逊S3的数据湖构建一套数据摄取方案。该专家需要设计一组数据接入机制，以支撑未来实现以下功能：  \n✧ 实时数据分析  \n✧ 历史数据交互式分析  \n✧ 点击流分析  \n✧ 商品推荐系统  \n请问专家应当采用哪些服务？"}, "option": [{"option_text": {"zhcn": "以AWS Glue作为数据目录；通过Amazon Kinesis数据流及数据分析服务实现实时数据洞察；借助Amazon Kinesis数据火线将数据输送至Amazon ES进行点击流分析；运用Amazon EMR生成个性化产品推荐方案。", "enus": "AWS Glue as the data catalog; Amazon Kinesis Data Streams and Amazon Kinesis Data Analytics for real-time data insights; Amazon  Kinesis Data Firehose for delivery to Amazon ES for clickstream analytics; Amazon EMR to generate personalized product  recommendations"}, "option_flag": true}, {"option_text": {"zhcn": "以Amazon Athena作为数据目录：通过Amazon Kinesis数据流与Amazon Kinesis数据分析服务实现近实时数据洞察；运用Amazon Kinesis数据火线进行点击流分析；借助AWS Glue生成个性化产品推荐方案。", "enus": "Amazon Athena as the data catalog: Amazon Kinesis Data Streams and Amazon Kinesis Data Analytics for near-real-time data insights;  Amazon Kinesis Data Firehose for clickstream analytics; AWS Glue to generate personalized product recommendations"}, "option_flag": false}, {"option_text": {"zhcn": "以AWS Glue作为元数据目录；通过Amazon Kinesis数据流及数据分析服务实现历史数据洞察；借助Amazon Kinesis数据火线将数据实时输送至Amazon ES进行点击流分析；采用Amazon EMR框架生成个性化商品推荐方案。", "enus": "AWS Glue as the data catalog; Amazon Kinesis Data Streams and Amazon Kinesis Data Analytics for historical data insights; Amazon  Kinesis Data Firehose for delivery to Amazon ES for clickstream analytics; Amazon EMR to generate personalized product  recommendations"}, "option_flag": false}, {"option_text": {"zhcn": "以Amazon Athena作为数据目录核心；通过Amazon Kinesis数据流与数据分析服务挖掘历史数据价值；借助Amazon DynamoDB流处理技术实现用户点击行为分析；运用AWS Glue构建个性化商品推荐引擎。", "enus": "Amazon Athena as the data catalog; Amazon Kinesis Data Streams and Amazon Kinesis Data Analytics for historical data insights;  Amazon DynamoDB streams for clickstream analytics; AWS Glue to generate personalized product recommendations"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "38", "question": {"enus": "A company is observing low accuracy while training on the default built-in image classification algorithm in Amazon SageMaker. The Data Science team wants to use an Inception neural network architecture instead of a ResNet architecture. Which of the following will accomplish this? (Choose two.) ", "zhcn": "某公司在使用亚马逊SageMaker内置默认图像分类算法进行训练时发现准确率偏低。数据科学团队希望采用Inception神经网络架构替代原有的ResNet架构。下列哪两项措施能够实现这一目标？（请选择两个正确答案。）"}, "option": [{"option_text": {"zhcn": "对内置图像分类算法进行定制，采用Inception架构并应用于模型训练。", "enus": "Customize the built-in image classification algorithm to use Inception and use this for model training."}, "option_flag": false}, {"option_text": {"zhcn": "请向 SageMaker 团队提交技术支持请求，将默认的图像分类算法更改为 Inception。", "enus": "Create a support case with the SageMaker team to change the default image classification algorithm to Inception."}, "option_flag": false}, {"option_text": {"zhcn": "将搭载Inception网络的TensorFlow Estimator封装至Docker容器，并用于模型训练。", "enus": "Bundle a Docker container with TensorFlow Estimator loaded with an Inception network and use this for model training."}, "option_flag": true}, {"option_text": {"zhcn": "在Amazon SageMaker中结合TensorFlow Estimator运用自定义代码，通过Inception网络架构加载模型，并将其应用于模型训练过程。", "enus": "Use custom code in Amazon SageMaker with TensorFlow Estimator to load the model with an Inception network, and use this for model  training."}, "option_flag": true}, {"option_text": {"zhcn": "将初始网络代码下载并利用apt-get安装至亚马逊EC2实例，随后将该实例配置为亚马逊SageMaker平台中的Jupyter笔记本运行环境。", "enus": "Download and apt-get install the inception network code into an Amazon EC2 instance and use this instance as a Jupyter notebook in  Amazon SageMaker."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "CD"}, {"id": "39", "question": {"enus": "A Machine Learning Specialist built an image classification deep learning model. However, the Specialist ran into an overfitting problem in which the training and testing accuracies were 99% and 75%, respectively. How should the Specialist address this issue and what is the reason behind it? ", "zhcn": "一位机器学习专家构建了一个图像分类深度学习模型，但遇到了过拟合问题——训练集准确率高达99%，而测试集准确率仅为75%。请问这位专家应当如何解决此问题？其背后的成因又是什么？"}, "option": [{"option_text": {"zhcn": "学习速率应适当提高，因为优化过程目前陷入了局部极小值的困境。", "enus": "The learning rate should be increased because the optimization process was trapped at a local minimum."}, "option_flag": false}, {"option_text": {"zhcn": "鉴于模型泛化能力尚有不足，建议适当提高全连接层的丢弃率。", "enus": "The dropout rate at the fiatten layer should be increased because the model is not generalized enough."}, "option_flag": false}, {"option_text": {"zhcn": "与展平层相邻的全连接层维度应适当增加，因为当前模型的复杂度尚有不足。", "enus": "The dimensionality of dense layer next to the fiatten layer should be increased because the model is not complex enough."}, "option_flag": false}, {"option_text": {"zhcn": "由于优化过程在达到全局最小值前便已终止，应适当增加训练轮次。", "enus": "The epoch number should be increased because the optimization process was terminated before it reached the global minimum."}, "option_flag": true}], "analysis": {"enus": "Reference: https://www.tensorfiow.org/tutorials/keras/overfit_and_underfit", "zhcn": ""}, "answer": "D"}, {"id": "40", "question": {"enus": "A Machine Learning team uses Amazon SageMaker to train an Apache MXNet handwritten digit classifier model using a research dataset. The team wants to receive a notification when the model is overfitting. Auditors want to view the Amazon SageMaker log activity report to ensure there are no unauthorized API calls. What should the Machine Learning team do to address the requirements with the least amount of code and fewest steps? ", "zhcn": "一个机器学习团队正在运用Amazon SageMaker平台，基于研究数据集训练Apache MXNet手写数字分类模型。该团队希望在模型出现过拟合时能接收到通知。审计人员则需要查看Amazon SageMaker的日志活动报告，以确认不存在未经授权的API调用。机器学习团队应当采取何种方案，才能以最简代码和最少步骤满足这些需求？\n\n（注：专有名词如Amazon SageMaker、Apache MXNet、API均保留原表达，符合技术文档惯例；中文表达采用\"运用\"\"基于\"\"出现过拟合\"\"未经授权\"等专业术语，并通过\"应当采取何种方案\"\"以...满足这些需求\"等句式保持逻辑严谨性，同时避免直译的生硬感。）"}, "option": [{"option_text": {"zhcn": "实现一项AWS Lambda功能，用于将Amazon SageMaker的API调用记录同步至Amazon S3存储服务。同时编写代码向Amazon CloudWatch推送自定义指标，并在CloudWatch中创建告警机制，通过Amazon SNS服务在模型出现过拟合时接收通知。", "enus": "Implement an AWS Lambda function to log Amazon SageMaker API calls to Amazon S3. Add code to push a custom metric to Amazon  CloudWatch. Create an alarm in CloudWatch with Amazon SNS to receive a notification when the model is overfitting."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS CloudTrail将Amazon SageMaker的API调用日志记录至Amazon S3存储桶，并编写代码向Amazon CloudWatch推送自定义指标。随后在CloudWatch中设置警报机制，通过Amazon SNS接收模型过拟合时的实时通知。", "enus": "Use AWS CloudTrail to log Amazon SageMaker API calls to Amazon S3. Add code to push a custom metric to Amazon CloudWatch.  Create an alarm in CloudWatch with Amazon SNS to receive a notification when the model is overfitting."}, "option_flag": true}, {"option_text": {"zhcn": "实现一个AWS Lambda函数，用于将Amazon SageMaker的API调用记录至AWS CloudTrail。添加代码以向Amazon CloudWatch推送自定义指标。在CloudWatch中创建告警机制，并通过Amazon SNS接收模型过拟合时的通知。", "enus": "Implement an AWS Lambda function to log Amazon SageMaker API calls to AWS CloudTrail. Add code to push a custom metric to  Amazon CloudWatch. Create an alarm in CloudWatch with Amazon SNS to receive a notification when the model is overfitting."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS CloudTrail将Amazon SageMaker的API调用记录存储至Amazon S3，并配置Amazon SNS服务，以便在模型出现过拟合时接收实时通知。", "enus": "Use AWS CloudTrail to log Amazon SageMaker API calls to Amazon S3. Set up Amazon SNS to receive a notification when the model is  overfitting"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "41", "question": {"enus": "A Machine Learning Specialist is building a prediction model for a large number of features using linear models, such as linear regression and logistic regression. During exploratory data analysis, the Specialist observes that many features are highly correlated with each other. This may make the model unstable. What should be done to reduce the impact of having such a large number of features? ", "zhcn": "一位机器学习专家正在运用线性回归与逻辑回归等线性模型，为海量特征构建预测模型。在探索性数据分析阶段，该专家发现多个特征之间存在高度相关性，这种情况可能导致模型稳定性下降。面对如此庞大的特征数量，应采取何种措施来降低其对模型的影响？"}, "option": [{"option_text": {"zhcn": "对高度相关的特征进行独热编码处理。", "enus": "Perform one-hot encoding on highly correlated features."}, "option_flag": false}, {"option_text": {"zhcn": "对高度相关的特征采用矩阵乘法进行处理。", "enus": "Use matrix multiplication on highly correlated features."}, "option_flag": false}, {"option_text": {"zhcn": "运用主成分分析（PCA）构建新的特征空间。", "enus": "Create a new feature space using principal component analysis (PCA)"}, "option_flag": true}, {"option_text": {"zhcn": "运用皮尔逊相关系数。", "enus": "Apply the Pearson correlation coeficient."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "42", "question": {"enus": "A Machine Learning Specialist is implementing a full Bayesian network on a dataset that describes public transit in New York City. One of the random variables is discrete, and represents the number of minutes New Yorkers wait for a bus given that the buses cycle every 10 minutes, with a mean of 3 minutes. Which prior probability distribution should the ML Specialist use for this variable? ", "zhcn": "一位机器学习专家正在基于描述纽约市公共交通的数据集构建完整的贝叶斯网络。其中一个随机变量为离散型，代表在公交车每10分钟一班的情况下纽约民众的候车时间（已知平均等候时间为3分钟）。针对该变量，机器学习专家应采用何种先验概率分布？"}, "option": [{"option_text": {"zhcn": "泊松分布", "enus": "Poisson distribution"}, "option_flag": false}, {"option_text": {"zhcn": "均匀分布", "enus": "Uniform distribution"}, "option_flag": false}, {"option_text": {"zhcn": "正态分布", "enus": "Normal distribution"}, "option_flag": false}, {"option_text": {"zhcn": "二项分布", "enus": "Binomial distribution"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "43", "question": {"enus": "A Data Science team within a large company uses Amazon SageMaker notebooks to access data stored in Amazon S3 buckets. The IT Security team is concerned that internet-enabled notebook instances create a security vulnerability where malicious code running on the instances could compromise data privacy. The company mandates that all instances stay within a secured VPC with no internet access, and data communication trafic must stay within the AWS network. How should the Data Science team configure the notebook instance placement to meet these requirements? ", "zhcn": "某大型公司的数据科学团队采用Amazon SageMaker笔记本来访问存储于Amazon S3桶中的数据。鉴于可连接互联网的笔记本实例可能引发恶意代码窃取数据隐私的安全隐患，IT安全部门要求所有实例必须部署在无互联网访问的受保护VPC内，且数据通信流量必须限制在AWS网络内部。为满足这些要求，数据科学团队应如何配置笔记本实例的部署方案？"}, "option": [{"option_text": {"zhcn": "将Amazon SageMaker笔记本实例关联至VPC内的私有子网，并将Amazon SageMaker终端节点与S3存储桶部署在同一VPC中。", "enus": "Associate the Amazon SageMaker notebook with a private subnet in a VPC. Place the Amazon SageMaker endpoint and S3 buckets  within the same VPC."}, "option_flag": false}, {"option_text": {"zhcn": "将Amazon SageMaker笔记本关联至VPC内的私有子网。", "enus": "Associate the Amazon SageMaker notebook with a private subnet in a VP"}, "option_flag": false}, {"option_text": {"zhcn": "运用IAM策略授予对Amazon S3与Amazon SageMaker的访问权限。将Amazon SageMaker笔记本实例关联至VPC的私有子网中，并确保该VPC已配置S3 VPC终端节点及Amazon SageMaker VPC终端节点。", "enus": "Use IAM policies to grant access to Amazon S3 and Amazon  SageMaker.  C. Associate the Amazon SageMaker notebook with a private subnet in a VPC. Ensure the VPC has S3 VPC endpoints and Amazon  SageMaker VPC endpoints attached to it."}, "option_flag": true}, {"option_text": {"zhcn": "将Amazon SageMaker笔记本实例关联至VPC环境中的私有子网。需确保该VPC已配置NAT网关，并设置仅允许出站连接访问Amazon S3及Amazon SageMaker的安全组。", "enus": "Associate the Amazon SageMaker notebook with a private subnet in a VPC. Ensure the VPC has a NAT gateway and an associated  security group allowing only outbound connections to Amazon S3 and Amazon SageMaker."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "44", "question": {"enus": "A Machine Learning Specialist has created a deep learning neural network model that performs well on the training data but performs poorly on the test data. Which of the following methods should the Specialist consider using to correct this? (Choose three.) ", "zhcn": "一位机器学习专家构建了一个深度学习神经网络模型，该模型在训练数据上表现优异，但在测试数据上表现欠佳。请问该专家应考虑采用以下哪些方法来解决此问题？（选择三项。）"}, "option": [{"option_text": {"zhcn": "降低正则化强度。", "enus": "Decrease regularization."}, "option_flag": false}, {"option_text": {"zhcn": "增强正则化强度。", "enus": "Increase regularization."}, "option_flag": true}, {"option_text": {"zhcn": "提高退学率。", "enus": "Increase dropout."}, "option_flag": true}, {"option_text": {"zhcn": "降低辍学率。", "enus": "Decrease dropout."}, "option_flag": false}, {"option_text": {"zhcn": "增加特征组合。", "enus": "Increase feature combinations."}, "option_flag": false}, {"option_text": {"zhcn": "减少特征组合。", "enus": "Decrease feature combinations."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BCF"}, {"id": "45", "question": {"enus": "A Data Scientist needs to create a serverless ingestion and analytics solution for high-velocity, real-time streaming data. The ingestion process must buffer and convert incoming records from JSON to a query-optimized, columnar format without data loss. The output datastore must be highly available, and Analysts must be able to run SQL queries against the data and connect to existing business intelligence dashboards. Which solution should the Data Scientist build to satisfy the requirements? ", "zhcn": "数据科学家需要构建一套无服务器架构的数据摄取与分析方案，用以处理高速实时流数据。数据摄取过程需实现缓冲功能，并将输入的JSON格式记录无损转换为查询优化的列式存储格式。输出数据存储须具备高可用性，且分析师能够对数据执行SQL查询，并连接现有商业智能仪表板。请问数据科学家应如何设计该解决方案以满足上述需求？"}, "option": [{"option_text": {"zhcn": "在AWS Glue数据目录中为传入数据格式创建元数据结构。通过Amazon Kinesis Data Firehose传输流实时推送数据，并借助AWS Glue数据目录将数据转换为Apache Parquet或ORC格式后存入Amazon S3。数据分析师可使用Amazon Athena直接查询S3中的数据，并通过Athena的JDBC连接器将商业智能工具与数据平台对接。", "enus": "Create a schema in the AWS Glue Data Catalog of the incoming data format. Use an Amazon Kinesis Data Firehose delivery stream to  stream the data and transform the data to Apache Parquet or ORC format using the AWS Glue Data Catalog before delivering to Amazon  S3. Have the Analysts query the data directly from Amazon S3 using Amazon Athena, and connect to BI tools using the Athena Java  Database Connectivity (JDBC) connector."}, "option_flag": true}, {"option_text": {"zhcn": "将每条JSON记录写入Amazon S3的临时中转区。利用S3上传事件触发AWS Lambda函数，将数据转换为Apache Parquet或ORC格式后写入S3的处理数据存储区。数据分析师可通过Amazon Athena直接查询S3中的数据，并通过Athena的JDBC连接器接入各类商业智能工具。", "enus": "Write each JSON record to a staging location in Amazon S3. Use the S3 Put event to trigger an AWS Lambda function that transforms  the data into Apache Parquet or ORC format and writes the data to a processed data location in Amazon S3. Have the Analysts query the  data directly from Amazon S3 using Amazon Athena, and connect to BI tools using the Athena Java Database Connectivity (JDBC)  connector."}, "option_flag": false}, {"option_text": {"zhcn": "将每条JSON记录写入Amazon S3的暂存区，利用S3上传事件触发AWS Lambda函数，将数据转换为Apache Parquet或ORC格式后载入Amazon RDS PostgreSQL数据库。最终由分析师通过该RDS数据库进行查询并生成数据看板。", "enus": "Write each JSON record to a staging location in Amazon S3. Use the S3 Put event to trigger an AWS Lambda function that transforms  the data into Apache Parquet or ORC format and inserts it into an Amazon RDS PostgreSQL database. Have the Analysts query and run  dashboards from the RDS database."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Analytics接入流式数据，通过实时SQL查询将记录转换为Apache Parquet格式后传输至Amazon S3。随后，分析师可借助Amazon Athena直接查询Amazon S3中的数据，并通过Athena的JDBC连接器与商业智能工具实现无缝对接。", "enus": "Use Amazon Kinesis Data Analytics to ingest the streaming data and perform real-time SQL queries to convert the records to Apache  Parquet before delivering to Amazon S3. Have the Analysts query the data directly from Amazon S3 using Amazon Athena and connect to  BI tools using the Athena Java Database Connectivity (JDBC) connector."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "46", "question": {"enus": "An online reseller has a large, multi-column dataset with one column missing 30% of its data. A Machine Learning Specialist believes that certain columns in the dataset could be used to reconstruct the missing data. Which reconstruction approach should the Specialist use to preserve the integrity of the dataset? ", "zhcn": "某线上经销商持有一份包含多列数据的大型数据集，其中某列数据存在30%的缺失。一位机器学习专家认为，可以利用数据集中的某些列来重建缺失数据。请问该专家应采用何种重建方法，才能最大限度保证数据集的完整性？"}, "option": [{"option_text": {"zhcn": "列删", "enus": "Listwise deletion"}, "option_flag": false}, {"option_text": {"zhcn": "末次观测值结转法", "enus": "Last observation carried forward"}, "option_flag": false}, {"option_text": {"zhcn": "多重填补", "enus": "Multiple imputation"}, "option_flag": true}, {"option_text": {"zhcn": "均值填补", "enus": "Mean substitution"}, "option_flag": false}], "analysis": {"enus": "Reference: https://worldwidescience.org/topicpages/i/imputing+missing+values.html", "zhcn": ""}, "answer": "C"}, {"id": "47", "question": {"enus": "A company is setting up an Amazon SageMaker environment. The corporate data security policy does not allow communication over the internet. How can the company enable the Amazon SageMaker service without enabling direct internet access to Amazon SageMaker notebook instances? ", "zhcn": "某公司正在部署亚马逊SageMaker环境。根据企业数据安全政策，严禁通过互联网进行数据传输。在不对亚马逊SageMaker笔记本实例开放直接互联网访问的前提下，该公司应如何启用此项服务？"}, "option": [{"option_text": {"zhcn": "在企业虚拟私有云中创建NAT网关。", "enus": "Create a NAT gateway within the corporate VPC."}, "option_flag": true}, {"option_text": {"zhcn": "将亚马逊SageMaker流量经由本地网络进行路由传输。", "enus": "Route Amazon SageMaker trafic through an on-premises network."}, "option_flag": false}, {"option_text": {"zhcn": "在企业虚拟私有云中创建Amazon SageMaker VPC接口端点。", "enus": "Create Amazon SageMaker VPC interface endpoints within the corporate VPC."}, "option_flag": false}, {"option_text": {"zhcn": "与托管Amazon SageMaker的Amazon VPC建立VPC对等连接。", "enus": "Create VPC peering with Amazon VPC hosting Amazon SageMaker."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-dg.pdf (46)", "zhcn": ""}, "answer": "A"}, {"id": "48", "question": {"enus": "A Machine Learning Specialist is training a model to identify the make and model of vehicles in images. The Specialist wants to use transfer learning and an existing model trained on images of general objects. The Specialist collated a large custom dataset of pictures containing different vehicle makes and models. What should the Specialist do to initialize the model to re-train it with the custom data? ", "zhcn": "机器学习专家正在训练一个模型，用于识别图像中车辆的品牌与型号。该专家计划采用迁移学习方法，借助一个已针对通用物体图像完成预训练的现有模型。专家已整理完成包含各类车辆品牌和型号的大型定制数据集。为使用该定制数据重新训练模型，专家应如何对模型进行初始化？"}, "option": [{"option_text": {"zhcn": "在所有层级（包括最后的全连接层）中采用随机权重初始化模型。", "enus": "Initialize the model with random weights in all layers including the last fully connected layer."}, "option_flag": false}, {"option_text": {"zhcn": "在所有层级加载预训练权重，并将最后的全连接层进行替换。", "enus": "Initialize the model with pre-trained weights in all layers and replace the last fully connected layer."}, "option_flag": true}, {"option_text": {"zhcn": "在所有层中以随机权重初始化模型，并替换末端的全连接层。", "enus": "Initialize the model with random weights in all layers and replace the last fully connected layer."}, "option_flag": false}, {"option_text": {"zhcn": "在所有层（包括最后的全连接层）均采用预训练权重进行模型初始化。", "enus": "Initialize the model with pre-trained weights in all layers including the last fully connected layer."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "49", "question": {"enus": "An ofice security agency conducted a successful pilot using 100 cameras installed at key locations within the main ofice. Images from the cameras were uploaded to Amazon S3 and tagged using Amazon Rekognition, and the results were stored in Amazon ES. The agency is now looking to expand the pilot into a full production system using thousands of video cameras in its ofice locations globally. The goal is to identify activities performed by non-employees in real time Which solution should the agency consider? ", "zhcn": "某办公安全机构在总部关键区域部署了百个监控摄像头，成功完成试点项目。摄像头采集的画面实时上传至亚马逊S3存储系统，并借助亚马逊Rekognition技术进行智能标记，最终分析结果存储于亚马逊ES数据库。目前该机构计划将试点升级为全球办公点的全面部署，拟在全球各办公场所铺设数千个摄像设备，旨在实时识别非内部人员的行为动态。针对这一需求，该机构应如何规划系统解决方案？"}, "option": [{"option_text": {"zhcn": "在各分支机构及每台摄像头处配置代理服务器，将RTSP视频流传输至独立的亚马逊Kinesis视频流。针对每条视频流，运用亚马逊Rekognition视频服务创建流处理器，通过预设员工人脸库进行面部识别，并在检测到非授权人员时触发告警机制。", "enus": "Use a proxy server at each local ofice and for each camera, and stream the RTSP feed to a unique Amazon Kinesis Video Streams video  stream. On each stream, use Amazon Rekognition Video and create a stream processor to detect faces from a collection of known  employees, and alert when non-employees are detected."}, "option_flag": false}, {"option_text": {"zhcn": "在各分支机构及每台摄像头处配置代理服务器，将RTSP视频流实时传输至独立的亚马逊Kinesis视频流通道。通过亚马逊Rekognition图像识别技术，针对每条视频流从已知员工人脸库中进行面部识别，一旦发现非授权人员即刻触发告警机制。", "enus": "Use a proxy server at each local ofice and for each camera, and stream the RTSP feed to a unique Amazon Kinesis Video Streams video  stream. On each stream, use Amazon Rekognition Image to detect faces from a collection of known employees and alert when non-  employees are detected."}, "option_flag": false}, {"option_text": {"zhcn": "部署AWS DeepLens摄像头，并通过DeepLens_Kinesis_Video模块将各摄像头的视频流实时传输至Amazon Kinesis Video Streams。针对每条视频流，运用Amazon Rekognition Video服务创建流处理器，基于预设人脸库进行实时面部检测，并在识别到非雇员时触发告警机制。", "enus": "Install AWS DeepLens cameras and use the DeepLens_Kinesis_Video module to stream video to Amazon Kinesis Video Streams for  each camera. On each stream, use Amazon Rekognition Video and create a stream processor to detect faces from a collection on each  stream, and alert when non-employees are detected."}, "option_flag": false}, {"option_text": {"zhcn": "部署AWS DeepLens摄像头，并通过DeepLens_Kinesis_Video模块将各摄像头的视频流实时传输至Amazon Kinesis Video Streams。针对每条视频流，启动AWS Lambda函数截取图像片段，随后调用Amazon Rekognition Image服务，从预设的员工人脸库中进行比对识别。当系统检测到非授权人员时，将自动触发告警机制。", "enus": "Install AWS DeepLens cameras and use the DeepLens_Kinesis_Video module to stream video to Amazon Kinesis Video Streams for each  camera. On each stream, run an AWS Lambda function to capture image fragments and then call Amazon Rekognition Image to detect  faces from a collection of known employees, and alert when non-employees are detected."}, "option_flag": true}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/video-analytics-in-the-cloud-and-at-the-edge-with-aws-deeplens-and-kinesis-video- streams/", "zhcn": ""}, "answer": "D"}, {"id": "50", "question": {"enus": "A Marketing Manager at a pet insurance company plans to launch a targeted marketing campaign on social media to acquire new customers. Currently, the company has the following data in Amazon Aurora: ✑ Profiles for all past and existing customers ✑ Profiles for all past and existing insured pets ✑ Policy-level information ✑ Premiums received ✑ Claims paid What steps should be taken to implement a machine learning model to identify potential new customers on social media? ", "zhcn": "某宠物保险公司市场经理计划在社交媒体上启动精准营销活动以拓展新客源。目前公司亚马逊云关系型数据库中存在以下数据：  \n✑ 历史及现有客户档案  \n✑ 历史及现有投保宠物档案  \n✑ 保单层级信息  \n✑ 已收保费记录  \n✑ 已赔付理赔数据  \n请问应如何部署机器学习模型，从而在社交媒体平台上精准识别潜在新客户？"}, "option": [{"option_text": {"zhcn": "对客户画像数据进行回归分析，以洞悉不同消费群体的核心特征。随后在社交媒体上寻找具有相似特征的用户画像。", "enus": "Use regression on customer profile data to understand key characteristics of consumer segments. Find similar profiles on social media"}, "option_flag": false}, {"option_text": {"zhcn": "对客户画像数据进行聚类分析，以洞悉不同消费群体的核心特征。随后在社交媒体上寻找具有相似特征的用户画像。", "enus": "Use clustering on customer profile data to understand key characteristics of consumer segments. Find similar profiles on social media"}, "option_flag": false}, {"option_text": {"zhcn": "利用客户画像数据构建推荐引擎，深入洞悉不同消费群体的核心特征。随后在社交媒体上精准匹配具有相似特征的用户画像。", "enus": "Use a recommendation engine on customer profile data to understand key characteristics of consumer segments. Find similar profiles  on social media."}, "option_flag": true}, {"option_text": {"zhcn": "对客户画像数据运用决策树分类器，以洞悉不同消费群体的核心特征。随后在社交媒体上寻找具有相似特征的用户画像。", "enus": "Use a decision tree classifier engine on customer profile data to understand key characteristics of consumer segments. Find similar  profiles on social media."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "51", "question": {"enus": "A manufacturing company has a large set of labeled historical sales data. The manufacturer would like to predict how many units of a particular part should be produced each quarter. Which machine learning approach should be used to solve this problem? ", "zhcn": "某制造企业拥有一批标注完备的历史销售数据。该企业希望预测特定零部件每季度应生产的数量。针对这一需求，应采用何种机器学习方法予以解决？"}, "option": [{"option_text": {"zhcn": "逻辑回归", "enus": "Logistic regression"}, "option_flag": false}, {"option_text": {"zhcn": "随机切割森林（RCF）", "enus": "Random Cut Forest (RCF)"}, "option_flag": true}, {"option_text": {"zhcn": "主成分分析（PCA）", "enus": "Principal component analysis (PCA)"}, "option_flag": false}, {"option_text": {"zhcn": "线性回归", "enus": "Linear regression"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "52", "question": {"enus": "A financial services company is building a robust serverless data lake on Amazon S3. The data lake should be fiexible and meet the following requirements: ✑ Support querying old and new data on Amazon S3 through Amazon Athena and Amazon Redshift Spectrum. ✑ Support event-driven ETL pipelines ✑ Provide a quick and easy way to understand metadata Which approach meets these requirements? ", "zhcn": "一家金融服务公司正在Amazon S3上构建一个强健的无服务器数据湖。该数据湖需具备灵活性，并满足以下要求：  \n✑ 支持通过Amazon Athena和Amazon Redshift Spectrum查询Amazon S3上的历史数据与新增数据  \n✑ 支持事件驱动的ETL流程  \n✑ 提供便捷直观的元数据理解方式  \n何种方案符合这些需求？"}, "option": [{"option_text": {"zhcn": "利用AWS Glue爬虫采集S3数据，通过AWS Lambda函数触发Glue ETL任务处理流程，并借助AWS Glue数据目录实现元数据的检索与发现。", "enus": "Use an AWS Glue crawler to crawl S3 data, an AWS Lambda function to trigger an AWS Glue ETL job, and an AWS Glue Data catalog to  search and discover metadata."}, "option_flag": true}, {"option_text": {"zhcn": "利用AWS Glue爬虫采集S3数据，通过AWS Lambda函数触发AWS Batch任务，并借助外部Apache Hive元数据存储库进行元数据的检索与发现。", "enus": "Use an AWS Glue crawler to crawl S3 data, an AWS Lambda function to trigger an AWS Batch job, and an external Apache Hive  metastore to search and discover metadata."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue爬虫程序采集S3数据，通过Amazon CloudWatch警报触发AWS Batch任务，并借助AWS Glue数据目录实现元数据的检索与发现。", "enus": "Use an AWS Glue crawler to crawl S3 data, an Amazon CloudWatch alarm to trigger an AWS Batch job, and an AWS Glue Data Catalog to  search and discover metadata."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue爬虫采集S3数据，通过Amazon CloudWatch警报触发AWS Glue ETL任务，并借助外部Apache Hive元存储进行元数据的检索与发现。", "enus": "Use an AWS Glue crawler to crawl S3 data, an Amazon CloudWatch alarm to trigger an AWS Glue ETL job, and an external Apache Hive  metastore to search and discover metadata."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "53", "question": {"enus": "A company's Machine Learning Specialist needs to improve the training speed of a time-series forecasting model using TensorFlow. The training is currently implemented on a single-GPU machine and takes approximately 23 hours to complete. The training needs to be run daily. The model accuracy is acceptable, but the company anticipates a continuous increase in the size of the training data and a need to update the model on an hourly, rather than a daily, basis. The company also wants to minimize coding effort and infrastructure changes. What should the Machine Learning Specialist do to the training solution to allow it to scale for future demand? ", "zhcn": "某公司的机器学习专家需要提升基于TensorFlow的时间序列预测模型的训练速度。当前模型在单GPU机器上完成训练需耗时约23小时，且需每日执行训练任务。虽然模型精度已达要求，但公司预计训练数据量将持续增长，且模型更新频率需从每日一次提升至每小时一次。在此过程中，公司希望尽量控制代码修改量及基础设施变动。机器学习专家应如何调整训练方案，以确保其具备应对未来需求的可扩展性？"}, "option": [{"option_text": {"zhcn": "请勿改动TensorFlow代码。将机器更换为配备更强性能GPU的设备，以加速训练进程。", "enus": "Do not change the TensorFlow code. Change the machine to one with a more powerful GPU to speed up the training."}, "option_flag": false}, {"option_text": {"zhcn": "将TensorFlow代码改写为基于Amazon SageMaker的Horovod分布式框架实现。根据业务目标需求，将训练任务并行扩展至任意数量的机器集群。", "enus": "Change the TensorFlow code to implement a Horovod distributed framework supported by Amazon SageMaker. Parallelize the training  to as many machines as needed to achieve the business goals."}, "option_flag": true}, {"option_text": {"zhcn": "改用内置的AWS SageMaker DeepAR模型。根据业务目标需求，将训练任务并行扩展至相应规模的机器集群。", "enus": "Switch to using a built-in AWS SageMaker DeepAR model. Parallelize the training to as many machines as needed to achieve the  business goals."}, "option_flag": false}, {"option_text": {"zhcn": "将训练任务迁移至Amazon EMR平台，根据业务需求动态调配计算资源，实现分布式并行处理。", "enus": "Move the training to Amazon EMR and distribute the workload to as many machines as needed to achieve the business goals."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "54", "question": {"enus": "Which of the following metrics should a Machine Learning Specialist generally use to compare/evaluate machine learning classification models against each other? ", "zhcn": "机器学习专家通常应采用以下哪种指标来比较或评估不同机器学习分类模型的性能？"}, "option": [{"option_text": {"zhcn": "忆起", "enus": "Recall"}, "option_flag": false}, {"option_text": {"zhcn": "误判率", "enus": "Misclassification rate"}, "option_flag": false}, {"option_text": {"zhcn": "平均绝对百分比误差（MAPE）", "enus": "Mean absolute percentage error (MAPE)"}, "option_flag": false}, {"option_text": {"zhcn": "ROC曲线下面积（AUC）", "enus": "Area Under the ROC Curve (AUC)"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "55", "question": {"enus": "A company is running a machine learning prediction service that generates 100 TB of predictions every day. A Machine Learning Specialist must generate a visualization of the daily precision-recall curve from the predictions, and forward a read-only version to the Business team. Which solution requires the LEAST coding effort? ", "zhcn": "一家公司正在运行一项机器学习预测服务，每日生成高达100 TB的预测数据。机器学习专家需根据这些预测结果绘制每日精确率-召回率曲线图，并将只读版本发送给业务团队。在以下方案中，哪种方案所需的编码工作量最少？"}, "option": [{"option_text": {"zhcn": "每日运行Amazon EMR工作流以生成精确率-召回率数据，并将结果存储于Amazon S3中。授予业务团队对S3存储内容的只读访问权限。", "enus": "Run a daily Amazon EMR workfiow to generate precision-recall data, and save the results in Amazon S3. Give the Business team read-  only access to S3."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon QuickSight中生成每日精确率-召回率数据，并将分析结果发布至与业务团队共享的仪表盘。", "enus": "Generate daily precision-recall data in Amazon QuickSight, and publish the results in a dashboard shared with the Business team."}, "option_flag": false}, {"option_text": {"zhcn": "每日运行Amazon EMR工作流以生成精确率-召回率数据，并将结果存储于Amazon S3中。通过Amazon QuickSight对数据阵列进行可视化分析，最终将分析图表发布至与业务团队共享的监控看板。", "enus": "Run a daily Amazon EMR workfiow to generate precision-recall data, and save the results in Amazon S3. Visualize the arrays in Amazon  QuickSight, and publish them in a dashboard shared with the Business team."}, "option_flag": true}, {"option_text": {"zhcn": "在亚马逊ES中生成每日精确率-召回率数据，并将分析结果发布至与业务团队共享的仪表盘。", "enus": "Generate daily precision-recall data in Amazon ES, and publish the results in a dashboard shared with the Business team."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "56", "question": {"enus": "A Machine Learning Specialist is preparing data for training on Amazon SageMaker. The Specialist is using one of the SageMaker built-in algorithms for the training. The dataset is stored in .CSV format and is transformed into a numpy.array, which appears to be negatively affecting the speed of the training. What should the Specialist do to optimize the data for training on SageMaker? ", "zhcn": "一位机器学习专家正在为亚马逊SageMaker平台上的模型训练准备数据。该专家计划采用SageMaker内置算法进行训练，当前数据集以CSV格式存储，且被转换为numpy.array格式，但这一转换操作似乎拖慢了训练速度。为优化SageMaker平台上的训练数据，该专家应当采取何种改进措施？"}, "option": [{"option_text": {"zhcn": "利用SageMaker的批量转换功能，将训练数据转化为DataFrame格式。", "enus": "Use the SageMaker batch transform feature to transform the training data into a DataFrame."}, "option_flag": false}, {"option_text": {"zhcn": "使用AWS Glue将数据压缩为Apache Parquet格式。", "enus": "Use AWS Glue to compress the data into the Apache Parquet format."}, "option_flag": false}, {"option_text": {"zhcn": "将数据集转换为RecordIO协议缓冲区格式。", "enus": "Transform the dataset into the RecordIO protobuf format."}, "option_flag": true}, {"option_text": {"zhcn": "利用SageMaker超参数优化功能，自动实现数据调优。", "enus": "Use the SageMaker hyperparameter optimization feature to automatically optimize the data."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "57", "question": {"enus": "A Machine Learning Specialist is required to build a supervised image-recognition model to identify a cat. The ML Specialist performs some tests and records the following results for a neural network-based image classifier: Total number of images available = 1,000 Test set images = 100 (constant test set) The ML Specialist notices that, in over 75% of the misclassified images, the cats were held upside down by their owners. Which techniques can be used by the ML Specialist to improve this specific test error? ", "zhcn": "本公司现需聘请一位机器学习专家，负责构建监督式图像识别模型以实现猫咪识别功能。该专家通过测试记录了基于神经网络图像分类器的以下数据：可用图像总量为1000张，测试集图像数量为100张（采用固定测试集）。专家发现，在超过75%的误判图像中，猫咪均被主人倒置托举。针对这一特定测试误差，可采取哪些优化技术予以改进？"}, "option": [{"option_text": {"zhcn": "通过为训练图像增加旋转变化来扩充训练数据。", "enus": "Increase the training data by adding variation in rotation for training images."}, "option_flag": false}, {"option_text": {"zhcn": "增加模型训练的迭代次数。", "enus": "Increase the number of epochs for model training"}, "option_flag": true}, {"option_text": {"zhcn": "增加神经网络的层数。", "enus": "Increase the number of layers for the neural network."}, "option_flag": false}, {"option_text": {"zhcn": "提高倒数第二层的丢弃率。", "enus": "Increase the dropout rate for the second-to-last layer."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "58", "question": {"enus": "A Machine Learning Specialist needs to be able to ingest streaming data and store it in Apache Parquet files for exploration and analysis. Which of the following services would both ingest and store this data in the correct format? ", "zhcn": "机器学习专家需要能够实时处理数据流，并将其存储为Apache Parquet格式文件以供探索分析。下列哪项服务可同时完成数据摄取并以正确格式存储？"}, "option": [{"option_text": {"zhcn": "AWS数据迁移服务", "enus": "AWS DMS"}, "option_flag": false}, {"option_text": {"zhcn": "Amazon Kinesis Data Streams", "enus": "Amazon Kinesis Data Streams"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊实时数据流服务", "enus": "Amazon Kinesis Data Firehose"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon Kinesis Data Analytics", "enus": "Amazon Kinesis Data Analytics"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "59", "question": {"enus": "A data scientist has explored and sanitized a dataset in preparation for the modeling phase of a supervised learning task. The statistical dispersion can vary widely between features, sometimes by several orders of magnitude. Before moving on to the modeling phase, the data scientist wants to ensure that the prediction performance on the production data is as accurate as possible. Which sequence of steps should the data scientist take to meet these requirements? ", "zhcn": "一位数据科学家已完成对数据集的探索与清理工作，为监督学习任务的建模阶段做好准备。不同特征之间的统计离散程度可能差异显著，有时甚至达到数个数量级。在进入建模阶段之前，该数据科学家希望确保生产环境中的预测性能达到最优。为实现这一目标，其应当遵循怎样的操作流程？"}, "option": [{"option_text": {"zhcn": "对数据集进行随机抽样，随后将其划分为训练集、验证集和测试集。", "enus": "Apply random sampling to the dataset. Then split the dataset into training, validation, and test sets."}, "option_flag": false}, {"option_text": {"zhcn": "将数据集划分为训练集、验证集和测试集。随后对训练集进行归一化处理，并将相同的缩放参数同步应用于验证集与测试集。", "enus": "Split the dataset into training, validation, and test sets. Then rescale the training set and apply the same scaling to the validation and  test sets."}, "option_flag": false}, {"option_text": {"zhcn": "对数据集进行归一化处理，随后将其划分为训练集、验证集和测试集。", "enus": "Rescale the dataset. Then split the dataset into training, validation, and test sets."}, "option_flag": false}, {"option_text": {"zhcn": "将数据集划分为训练集、验证集和测试集，随后分别对训练集、验证集与测试集进行归一化处理。", "enus": "Split the dataset into training, validation, and test sets. Then rescale the training set, the validation set, and the test set independently."}, "option_flag": true}], "analysis": {"enus": "Reference: https://www.kdnuggets.com/2018/12/six-steps-master-machine-learning-data-preparation.html", "zhcn": ""}, "answer": "D"}, {"id": "60", "question": {"enus": "A Machine Learning Specialist is assigned a TensorFlow project using Amazon SageMaker for training, and needs to continue working for an extended period with no Wi-Fi access. Which approach should the Specialist use to continue working? ", "zhcn": "一位机器学习专家负责利用Amazon SageMaker平台开展基于TensorFlow的模型训练项目，但需要在无法连接Wi-Fi的环境下长期工作。请问该专家应采用何种方案以确保工作持续进行？"}, "option": [{"option_text": {"zhcn": "在他们的笔记本电脑上安装Python 3和boto3，并在此环境下继续推进代码开发工作。", "enus": "Install Python 3 and boto3 on their laptop and continue the code development using that environment."}, "option_flag": false}, {"option_text": {"zhcn": "从GitHub获取亚马逊SageMaker平台所使用的TensorFlow Docker容器至本地环境，并运用亚马逊SageMaker Python SDK对代码进行测试。", "enus": "Download the TensorFlow Docker container used in Amazon SageMaker from GitHub to their local environment, and use the Amazon  SageMaker Python SDK to test the code."}, "option_flag": true}, {"option_text": {"zhcn": "请前往tensorfiow.org下载TensorFlow，以便在SageMaker环境中模拟TensorFlow内核运行环境。", "enus": "Download TensorFlow from tensorfiow.org to emulate the TensorFlow kernel in the SageMaker environment."}, "option_flag": false}, {"option_text": {"zhcn": "将SageMaker笔记本下载至本地环境后，用户需在个人电脑上安装Jupyter Notebooks，即可在本地笔记本中继续开发工作。", "enus": "Download the SageMaker notebook to their local environment, then install Jupyter Notebooks on their laptop and continue the  development in a local notebook."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "61", "question": {"enus": "A Machine Learning Specialist is working with a large cybersecurity company that manages security events in real time for companies around the world. The cybersecurity company wants to design a solution that will allow it to use machine learning to score malicious events as anomalies on the data as it is being ingested. The company also wants be able to save the results in its data lake for later processing and analysis. What is the MOST eficient way to accomplish these tasks? ", "zhcn": "一位机器学习专家正与一家大型网络安全公司合作，该公司为全球企业提供实时安全事件监控服务。该网络安全公司希望设计一套解决方案，能够在数据录入时运用机器学习技术，将恶意事件作为异常数据进行风险评分，同时还需能将分析结果存储至数据湖中，以便后续处理与深度挖掘。如何以最高效的方式实现这些目标？"}, "option": [{"option_text": {"zhcn": "通过亚马逊Kinesis数据火线流进行数据摄取，并借助亚马逊Kinesis数据随机切割森林分析算法实现异常检测。随后通过Kinesis数据火线流将处理结果实时传输至亚马逊S3存储服务。", "enus": "Ingest the data using Amazon Kinesis Data Firehose, and use Amazon Kinesis Data Analytics Random Cut Forest (RCF) for anomaly  detection. Then use Kinesis Data Firehose to stream the results to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon EMR将数据实时接入Apache Spark Streaming流处理平台，结合Spark MLlib机器学习库中的k-means算法实现异常检测。随后通过Amazon EMR将处理结果存入Apache Hadoop分布式文件系统（HDFS），设置副本数为三，构建数据湖存储体系。", "enus": "Ingest the data into Apache Spark Streaming using Amazon EMR, and use Spark MLlib with k-means to perform anomaly detection.  Then store the results in an Apache Hadoop Distributed File System (HDFS) using Amazon EMR with a replication factor of three as the  data lake."}, "option_flag": true}, {"option_text": {"zhcn": "将数据导入并存储于Amazon S3中，随后借助AWS Batch服务与AWS深度学习AMI，基于TensorFlow框架对Amazon S3内的数据实施k-means模型训练。", "enus": "Ingest the data and store it in Amazon S3. Use AWS Batch along with the AWS Deep Learning AMIs to train a k-means model using  TensorFlow on the data in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "将数据导入并存储于Amazon S3中，通过按需触发的AWS Glue任务对新增数据进行转换处理。随后调用Amazon SageMaker内置的随机切割森林（RCF）模型，对数据中的异常情况进行检测。", "enus": "Ingest the data and store it in Amazon S3. Have an AWS Glue job that is triggered on demand transform the new data. Then use the  built-in Random Cut Forest (RCF) model within Amazon SageMaker to detect anomalies in the data."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "62", "question": {"enus": "A Data Scientist wants to gain real-time insights into a data stream of GZIP files. Which solution would allow the use of SQL to query the stream with the LEAST latency? ", "zhcn": "一位数据科学家希望实时解析GZIP压缩文件的数据流。若要使用SQL查询数据流并实现最低延迟，下列哪种解决方案最为适宜？"}, "option": [{"option_text": {"zhcn": "借助AWS Lambda函数对数据进行转换的Amazon Kinesis数据分析服务。", "enus": "Amazon Kinesis Data Analytics with an AWS Lambda function to transform the data."}, "option_flag": true}, {"option_text": {"zhcn": "使用AWS Glue并搭配自定义ETL脚本来实现数据转换。", "enus": "AWS Glue with a custom ETL script to transform the data."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊Kinesis客户端库对数据进行转换，并将其存储至亚马逊ES集群。", "enus": "An Amazon Kinesis Client Library to transform the data and save it to an Amazon ES cluster."}, "option_flag": false}, {"option_text": {"zhcn": "借助Amazon Kinesis Data Firehose对数据进行转换后，将其存入Amazon S3存储桶。", "enus": "Amazon Kinesis Data Firehose to transform the data and put it into an Amazon S3 bucket."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/big-data/real-time-analytics-featured-partners/", "zhcn": ""}, "answer": "A"}, {"id": "63", "question": {"enus": "A retail company intends to use machine learning to categorize new products. A labeled dataset of current products was provided to the Data Science team. The dataset includes 1,200 products. The labeled dataset has 15 features for each product such as title dimensions, weight, and price. Each product is labeled as belonging to one of six categories such as books, games, electronics, and movies. Which model should be used for categorizing new products using the provided dataset for training? ", "zhcn": "一家零售企业计划采用机器学习技术对新上市商品进行自动分类。数据科学团队已获得现有产品的标注数据集，该数据集涵盖1200种商品，每条记录包含标题、尺寸、重量及价格等15项特征。所有商品均已被标注为六大类别之一，包括图书、游戏、电子设备和影音制品等。基于现有标注数据集进行模型训练时，应采用何种分类模型来实现新商品的智能分类？"}, "option": [{"option_text": {"zhcn": "一个采用multi:softmax目标参数的XGBoost模型。", "enus": "AnXGBoost model where the objective parameter is set to multi:softmax"}, "option_flag": false}, {"option_text": {"zhcn": "一种采用深度卷积神经网络（CNN）架构的模型，其末层激活函数为柔性最大值函数。", "enus": "A deep convolutional neural network (CNN) with a softmax activation function for the last layer"}, "option_flag": true}, {"option_text": {"zhcn": "回归森林中树木数量与产品类别数目相等。", "enus": "A regression forest where the number of trees is set equal to the number of product categories"}, "option_flag": false}, {"option_text": {"zhcn": "基于循环神经网络（RNN）的DeepAR预测模型", "enus": "A DeepAR forecasting model based on a recurrent neural network (RNN)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "64", "question": {"enus": "A Data Scientist is working on an application that performs sentiment analysis. The validation accuracy is poor, and the Data Scientist thinks that the cause may be a rich vocabulary and a low average frequency of words in the dataset. Which tool should be used to improve the validation accuracy? ", "zhcn": "一位数据科学家正在开发一款用于情感分析的应用程序。目前验证准确率不甚理想，他认为问题可能源于数据集词汇量丰富但单词平均出现频率较低。此时应采用何种工具来提升验证准确率？"}, "option": [{"option_text": {"zhcn": "亚马逊Comprehend语法分析与实体识别", "enus": "Amazon Comprehend syntax analysis and entity detection"}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker BlazingText 连续词袋模式", "enus": "Amazon SageMaker BlazingText cbow mode"}, "option_flag": false}, {"option_text": {"zhcn": "自然语言工具包（NLTK）词干提取与停用词过滤", "enus": "Natural Language Toolkit (NLTK) stemming and stop word removal"}, "option_flag": false}, {"option_text": {"zhcn": "Scikit-learn术语频率-逆文档频率（TF-IDF）向量生成器", "enus": "Scikit-leam term frequency-inverse document frequency (TF-IDF) vectorizer"}, "option_flag": true}], "analysis": {"enus": "Reference: https://monkeylearn.com/sentiment-analysis/", "zhcn": ""}, "answer": "D"}, {"id": "65", "question": {"enus": "Machine Learning Specialist is building a model to predict future employment rates based on a wide range of economic factors. While exploring the data, the Specialist notices that the magnitude of the input features vary greatly. The Specialist does not want variables with a larger magnitude to dominate the model. What should the Specialist do to prepare the data for model training? ", "zhcn": "机器学习专家正在构建一个模型，旨在通过多元经济指标预测未来就业率。在数据探索过程中，专家发现各输入特征的数值量级差异显著。为避免较大数值范围的变量主导模型训练，专家应当如何对数据进行预处理？"}, "option": [{"option_text": {"zhcn": "对数据进行分位数分箱处理，将其划分为分类区间，通过以分布特征替代数值量级的方式，完整保留数据内在的关联性。", "enus": "Apply quantile binning to group the data into categorical bins to keep any relationships in the data by replacing the magnitude with  distribution."}, "option_flag": false}, {"option_text": {"zhcn": "对字段进行笛卡尔积变换，以生成不受数量级影响的全新组合。", "enus": "Apply the Cartesian product transformation to create new combinations of fields that are independent of the magnitude."}, "option_flag": false}, {"option_text": {"zhcn": "对数据进行归一化处理，确保每个字段的均值为0、方差为1，从而消除量纲差异带来的影响。", "enus": "Apply normalization to ensure each field will have a mean of 0 and a variance of 1 to remove any significant magnitude."}, "option_flag": true}, {"option_text": {"zhcn": "对原始特征施加正交稀疏二元组合（OSB）变换，通过固定尺寸的滑动窗口生成数量级相近的新特征。", "enus": "Apply the orthogonal sparse bigram (OSB) transformation to apply a fixed-size sliding window to generate new features of a similar  magnitude."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html", "zhcn": ""}, "answer": "C"}, {"id": "66", "question": {"enus": "A Machine Learning Specialist must build out a process to query a dataset on Amazon S3 using Amazon Athena. The dataset contains more than 800,000 records stored as plaintext CSV files. Each record contains 200 columns and is approximately 1.5 MB in size. Most queries will span 5 to 10 columns only. How should the Machine Learning Specialist transform the dataset to minimize query runtime? ", "zhcn": "机器学习专家需要构建一套流程，通过亚马逊雅典娜服务查询存储在亚马逊S3数据集。该数据集包含逾80万条记录，以纯文本CSV格式存储，每条记录涵盖200个数据列，单条记录大小约为1.5MB。多数查询仅涉及其中5至10个数据列。为最大限度缩短查询耗时，机器学习专家应当如何优化该数据集结构？"}, "option": [{"option_text": {"zhcn": "将记录转换为Apache Parquet格式。", "enus": "Convert the records to Apache Parquet format."}, "option_flag": true}, {"option_text": {"zhcn": "将记录转换为JSON格式。", "enus": "Convert the records to JSON format."}, "option_flag": false}, {"option_text": {"zhcn": "将记录转换为GZIP格式的CSV文件。", "enus": "Convert the records to GZIP CSV format."}, "option_flag": false}, {"option_text": {"zhcn": "将记录转换为XML格式。", "enus": "Convert the records to XML format."}, "option_flag": false}], "analysis": {"enus": "Using compressions will reduce the amount of data scanned by Amazon Athena, and also reduce your S3 bucket storage. It's a Win-Win for your AWS bill. Supported formats: GZIP, LZO, SNAPPY (Parquet) and ZLIB. Reference: https://www.cloudforecast.io/blog/using-parquet-on-athena-to-save-money-on-aws/", "zhcn": ""}, "answer": "A"}, {"id": "67", "question": {"enus": "A Machine Learning Specialist is developing a daily ETL workfiow containing multiple ETL jobs. The workfiow consists of the following processes: * Start the workfiow as soon as data is uploaded to Amazon S3. * When all the datasets are available in Amazon S3, start an ETL job to join the uploaded datasets with multiple terabyte-sized datasets already stored in Amazon S3. * Store the results of joining datasets in Amazon S3. * If one of the jobs fails, send a notification to the Administrator. Which configuration will meet these requirements? ", "zhcn": "一位机器学习专家正在设计包含多项ETL任务的日常数据处理流程。该流程包含以下环节：  \n* 一旦数据上传至亚马逊S3服务，立即启动流程；  \n* 当所有数据集在亚马逊S3中就绪后，启动ETL任务，将新上传的数据集与已存储于亚马逊S3的多个TB级数据集进行关联整合；  \n* 将关联后的结果数据集存回亚马逊S3；  \n* 若任一任务执行失败，需向管理员发送通知。  \n请问何种配置方案可满足上述需求？"}, "option": [{"option_text": {"zhcn": "利用AWS Lambda触发AWS Step Functions工作流，以监测Amazon S3中数据集上传完成状态。通过AWS Glue对数据集进行关联整合。若流程出现异常，借助Amazon CloudWatch警报机制向管理员发送SNS通知。", "enus": "Use AWS Lambda to trigger an AWS Step Functions workfiow to wait for dataset uploads to complete in Amazon S3. Use AWS Glue to  join the datasets. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator in the case of a failure."}, "option_flag": true}, {"option_text": {"zhcn": "运用AWS Lambda构建ETL工作流，以启动Amazon SageMaker笔记本实例。通过生命周期配置脚本整合数据集，并将处理结果持久化存储至Amazon S3。若运行异常，则借助Amazon CloudWatch警报向管理员发送SNS通知。", "enus": "Develop the ETL workfiow using AWS Lambda to start an Amazon SageMaker notebook instance. Use a lifecycle configuration script to  join the datasets and persist the results in Amazon S3. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator  in the case of a failure."}, "option_flag": false}, {"option_text": {"zhcn": "采用AWS Batch构建ETL工作流，当数据上传至Amazon S3时自动触发作业启动。通过AWS Glue对Amazon S3中的数据集进行关联整合。若运行异常，则借助Amazon CloudWatch警报机制向管理员发送SNS通知。", "enus": "Develop the ETL workfiow using AWS Batch to trigger the start of ETL jobs when data is uploaded to Amazon S3. Use AWS Glue to join  the datasets in Amazon S3. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator in the case of a failure."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Lambda实现函数级联调用，一旦数据上传至Amazon S3，即可自动触发后续Lambda函数读取并关联存储于S3中的数据集。若出现运行故障，系统将通过Amazon CloudWatch警报向管理员发送SNS通知。", "enus": "Use AWS Lambda to chain other Lambda functions to read and join the datasets in Amazon S3 as soon as the data is uploaded to  Amazon S3. Use an Amazon CloudWatch alarm to send an SNS notification to the Administrator in the case of a failure."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/step-functions/use-cases/", "zhcn": ""}, "answer": "A"}, {"id": "68", "question": {"enus": "An agency collects census information within a country to determine healthcare and social program needs by province and city. The census form collects responses for approximately 500 questions from each citizen. Which combination of algorithms would provide the appropriate insights? (Choose two.) ", "zhcn": "某国普查机构为掌握各省市医疗与社会福利需求，定期开展人口普查。普查问卷涵盖近500项居民信息采集项。下列哪两种算法组合最适用于此类数据分析？（请选择两项）"}, "option": [{"option_text": {"zhcn": "因子分解机（FM）算法", "enus": "The factorization machines (FM) algorithm"}, "option_flag": false}, {"option_text": {"zhcn": "隐含狄利克雷分布（LDA）算法", "enus": "The Latent Dirichlet Allocation (LDA) algorithm"}, "option_flag": false}, {"option_text": {"zhcn": "主成分分析（PCA）算法", "enus": "The principal component analysis (PCA) algorithm"}, "option_flag": true}, {"option_text": {"zhcn": "k-means聚类算法", "enus": "The k-means algorithm"}, "option_flag": true}, {"option_text": {"zhcn": "随机切割森林（RCF）算法", "enus": "The Random Cut Forest (RCF) algorithm"}, "option_flag": false}], "analysis": {"enus": "The PCA and K-means algorithms are useful in collection of data using census form.", "zhcn": ""}, "answer": "CD"}, {"id": "69", "question": {"enus": "A large consumer goods manufacturer has the following products on sale: * 34 different toothpaste variants * 48 different toothbrush variants * 43 different mouthwash variants The entire sales history of all these products is available in Amazon S3. Currently, the company is using custom-built autoregressive integrated moving average (ARIMA) models to forecast demand for these products. The company wants to predict the demand for a new product that will soon be launched. Which solution should a Machine Learning Specialist apply? ", "zhcn": "一家大型消费品制造商现正销售以下产品：  \n* 34种不同配方的牙膏  \n* 48款不同类型的牙刷  \n* 43种不同功效的漱口水  \n\n所有产品的完整销售数据均存储于Amazon S3中。目前，该公司采用自定义的自回归综合移动平均（ARIMA）模型对这些产品进行需求预测。随着新品即将上市，制造商希望提前预估其市场需求。机器学习专家应当采用何种解决方案？"}, "option": [{"option_text": {"zhcn": "为新产品定制ARIMA模型以预测其需求量。", "enus": "Train a custom ARIMA model to forecast demand for the new product."}, "option_flag": false}, {"option_text": {"zhcn": "训练Amazon SageMaker DeepAR算法以预测新产品的需求量。", "enus": "Train an Amazon SageMaker DeepAR algorithm to forecast demand for the new product."}, "option_flag": true}, {"option_text": {"zhcn": "训练亚马逊SageMaker平台的k-means聚类算法，以预测新产品的市场需求。", "enus": "Train an Amazon SageMaker k-means clustering algorithm to forecast demand for the new product."}, "option_flag": false}, {"option_text": {"zhcn": "训练定制化的XGBoost模型，以精准预测新产品的市场需求。", "enus": "Train a custom XGBoost model to forecast demand for the new product."}, "option_flag": false}], "analysis": {"enus": "The Amazon SageMaker DeepAR forecasting algorithm is a supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN). Classical forecasting methods, such as autoregressive integrated moving average (ARIMA) or exponential smoothing (ETS), fit a single model to each individual time series. They then use that model to extrapolate the time series into the future. Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html", "zhcn": ""}, "answer": "B"}, {"id": "70", "question": {"enus": "A Machine Learning Specialist uploads a dataset to an Amazon S3 bucket protected with server-side encryption using AWS KMS. How should the ML Specialist define the Amazon SageMaker notebook instance so it can read the same dataset from Amazon S3? ", "zhcn": "一位机器学习专家将数据集上传至采用AWS KMS服务端加密保护的Amazon S3存储桶。为确保该专家能通过Amazon SageMaker笔记本实例读取同一数据集，应如何配置此笔记本实例？"}, "option": [{"option_text": {"zhcn": "请配置安全组规则，允许所有HTTP入站与出站流量，并将该安全组关联至Amazon SageMaker笔记本实例。", "enus": "Define security group(s) to allow all HTTP inbound/outbound trafic and assign those security group(s) to the Amazon SageMaker  notebook instance."}, "option_flag": false}, {"option_text": {"zhcn": "请将亚马逊SageMaker笔记本实例配置为可访问该虚拟私有云。", "enus": "׀¡onfigure the Amazon SageMaker notebook instance to have access to the VP"}, "option_flag": false}, {"option_text": {"zhcn": "请在KMS密钥策略中授予笔记本KMS角色相应权限。  \nC. 为Amazon SageMaker笔记本分配一个具有S3数据集读取权限的IAM角色，并在KMS密钥策略中向该角色授予权限。", "enus": "Grant permission in the KMS key policy to the  notebook's KMS role.  C. Assign an IAM role to the Amazon SageMaker notebook with S3 read access to the dataset. Grant permission in the KMS key policy to  that role."}, "option_flag": false}, {"option_text": {"zhcn": "将用于加密 Amazon S3 数据的 KMS 密钥同样配置到 Amazon SageMaker 笔记本实例中。", "enus": "Assign the same KMS key used to encrypt data in Amazon S3 to the Amazon SageMaker notebook instance."}, "option_flag": true}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/encryption-at-rest.html", "zhcn": ""}, "answer": "D"}, {"id": "71", "question": {"enus": "A Data Scientist needs to migrate an existing on-premises ETL process to the cloud. The current process runs at regular time intervals and uses PySpark to combine and format multiple large data sources into a single consolidated output for downstream processing. The Data Scientist has been given the following requirements to the cloud solution: ✑ Combine multiple data sources. ✑ Reuse existing PySpark logic. ✑ Run the solution on the existing schedule. ✑ Minimize the number of servers that will need to be managed. Which architecture should the Data Scientist use to build this solution? ", "zhcn": "一位数据科学家需要将现有的本地ETL流程迁移至云端。当前流程按固定时间间隔运行，使用PySpark整合多个大型数据源并格式化，最终生成统一输出供下游处理。该数据科学家已获知云端解决方案需满足以下要求：  \n✑ 融合多数据源  \n✑ 复用现有PySpark逻辑  \n✑ 按原定计划执行任务  \n✑ 最大限度减少待维护服务器数量  \n请问该数据科学家应采用何种架构来构建此解决方案？"}, "option": [{"option_text": {"zhcn": "将原始数据写入Amazon S3存储服务。根据现有调度计划，配置AWS Lambda函数以向常驻的Amazon EMR集群提交Spark作业步骤。运用现有的PySpark逻辑在EMR集群上运行ETL数据处理任务，并将处理结果输出至Amazon S3的指定存储区域，便于下游环节调用使用。", "enus": "Write the raw data to Amazon S3. Schedule an AWS Lambda function to submit a Spark step to a persistent Amazon EMR cluster based  on the existing schedule. Use the existing PySpark logic to run the ETL job on the EMR cluster. Output the results to a processed  location in Amazon S3 that is accessible for downstream use."}, "option_flag": false}, {"option_text": {"zhcn": "将原始数据写入Amazon S3存储服务。创建AWS Glue ETL作业对输入数据进行抽取、转换和加载处理。该ETL作业采用PySpark编写，以复用现有逻辑。基于现有调度计划新建AWS Glue触发器，用于自动触发ETL作业执行。配置ETL作业的输出目标至Amazon S3中可供下游使用的处理结果存储位置。", "enus": "Write the raw data to Amazon S3. Create an AWS Glue ETL job to perform the ETL processing against the input data. Write the ETL job  in PySpark to leverage the existing logic. Create a new AWS Glue trigger to trigger the ETL job based on the existing schedule. Configure  the output target of the ETL job to write to a processed location in Amazon S3 that is accessible for downstream use."}, "option_flag": false}, {"option_text": {"zhcn": "将原始数据写入Amazon S3存储服务。依照现有调度计划配置AWS Lambda函数，用于处理来自Amazon S3的输入数据。使用Python编写Lambda函数逻辑，并整合现有PySpark代码以实现ETL流程。最终将处理结果输出至Amazon S3的指定存储区域，便于下游环节调用使用。", "enus": "Write the raw data to Amazon S3. Schedule an AWS Lambda function to run on the existing schedule and process the input data from  Amazon S3. Write the Lambda logic in Python and implement the existing PySpark logic to perform the ETL process. Have the Lambda  function output the results to a processed location in Amazon S3 that is accessible for downstream use."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊Kinesis数据流分析服务，可对输入数据进行实时流处理，并通过流式SQL查询实现所需的流内数据转换。最终将处理结果输出至亚马逊S3存储服务中指定区域，便于下游环节调用使用。", "enus": "Use Amazon Kinesis Data Analytics to stream the input data and perform real-time SQL queries against the stream to carry out the  required transformations within the stream. Deliver the output results to a processed location in Amazon S3 that is accessible for  downstream use."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "72", "question": {"enus": "A Data Scientist is building a model to predict customer churn using a dataset of 100 continuous numerical features. The Marketing team has not provided any insight about which features are relevant for churn prediction. The Marketing team wants to interpret the model and see the direct impact of relevant features on the model outcome. While training a logistic regression model, the Data Scientist observes that there is a wide gap between the training and validation set accuracy. Which methods can the Data Scientist use to improve the model performance and satisfy the Marketing team's needs? (Choose two.) ", "zhcn": "一位数据科学家正在利用包含100个连续数值特征的数据集构建客户流失预测模型。市场营销团队未提供任何关于哪些特征与流失预测相关的指导。该团队希望解读模型，并观察相关特征对模型结果的直接影响。在训练逻辑回归模型时，数据科学家发现训练集与验证集的准确率存在显著差异。此时，数据科学家可采用哪两种方法来提升模型性能并满足市场营销团队的需求？"}, "option": [{"option_text": {"zhcn": "为分类器加入L1正则化", "enus": "Add L1 regularization to the classifier"}, "option_flag": false}, {"option_text": {"zhcn": "为数据集增添功能", "enus": "Add features to the dataset"}, "option_flag": true}, {"option_text": {"zhcn": "执行递归特征消除", "enus": "Perform recursive feature elimination"}, "option_flag": false}, {"option_text": {"zhcn": "执行t分布随机邻域嵌入（t-SNE）", "enus": "Perform t-distributed stochastic neighbor embedding (t-SNE)"}, "option_flag": false}, {"option_text": {"zhcn": "进行线性判别分析", "enus": "Perform linear discriminant analysis"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BE"}, {"id": "73", "question": {"enus": "An aircraft engine manufacturing company is measuring 200 performance metrics in a time-series. Engineers want to detect critical manufacturing defects in near- real time during testing. All of the data needs to be stored for ofiine analysis. What approach would be the MOST effective to perform near-real time defect detection? ", "zhcn": "一家航空发动机制造企业正在对200项性能指标进行时间序列监测。工程师们需要在测试过程中近乎实时地发现关键制造缺陷，同时所有数据都需存档供离线分析。要实施近实时缺陷检测，何种方法最具实效性？"}, "option": [{"option_text": {"zhcn": "运用AWS IoT Analytics实现数据采集、存储与深度分析。通过其内置的Jupyter Notebook功能，可对数据进行异常检测分析。", "enus": "Use AWS IoT Analytics for ingestion, storage, and further analysis. Use Jupyter notebooks from within AWS IoT Analytics to carry out  analysis for anomalies."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon S3进行数据接入、存储与深度分析，并通过Amazon EMR集群运行Apache Spark ML中的k-means聚类算法，以精准识别异常模式。", "enus": "Use Amazon S3 for ingestion, storage, and further analysis. Use an Amazon EMR cluster to carry out Apache Spark ML k-means  clustering to determine anomalies."}, "option_flag": true}, {"option_text": {"zhcn": "采用Amazon S3进行数据接入、存储与深度分析，并运用Amazon SageMaker随机切割森林（RCF）算法精准识别异常模式。", "enus": "Use Amazon S3 for ingestion, storage, and further analysis. Use the Amazon SageMaker Random Cut Forest (RCF) algorithm to  determine anomalies."}, "option_flag": false}, {"option_text": {"zhcn": "采用Amazon Kinesis Data Firehose进行数据摄取，并借助Amazon Kinesis Data Analytics随机切割森林（RCF）算法实现异常检测。通过Kinesis Data Firehose将数据存储至Amazon S3中，以便开展深度分析。", "enus": "Use Amazon Kinesis Data Firehose for ingestion and Amazon Kinesis Data Analytics Random Cut Forest (RCF) to perform anomaly  detection. Use Kinesis Data Firehose to store data in Amazon S3 for further analysis."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "74", "question": {"enus": "A Machine Learning team runs its own training algorithm on Amazon SageMaker. The training algorithm requires external assets. The team needs to submit both its own algorithm code and algorithm-specific parameters to Amazon SageMaker. What combination of services should the team use to build a custom algorithm in Amazon SageMaker? (Choose two.) ", "zhcn": "某机器学习团队在Amazon SageMaker平台上运行自研的训练算法。该训练过程需调用外部资源，因此团队既要提交自有算法代码，又需配置算法专属参数。若要在Amazon SageMaker中构建定制化算法，应选择哪两项服务组合？（请选出两个正确答案）"}, "option": [{"option_text": {"zhcn": "AWS Secrets Manager", "enus": "AWS Secrets Manager"}, "option_flag": false}, {"option_text": {"zhcn": "AWS CodeStar", "enus": "AWS CodeStar"}, "option_flag": false}, {"option_text": {"zhcn": "Amazon ECR", "enus": "Amazon ECR"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon ECS", "enus": "Amazon ECS"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊S3", "enus": "Amazon S3"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "CE"}, {"id": "75", "question": {"enus": "A Machine Learning Specialist wants to determine the appropriate SageMakerVariantInvocationsPerInstance setting for an endpoint automatic scaling configuration. The Specialist has performed a load test on a single instance and determined that peak requests per second (RPS) without service degradation is about 20 RPS. As this is the first deployment, the Specialist intends to set the invocation safety factor to 0.5. Based on the stated parameters and given that the invocations per instance setting is measured on a per-minute basis, what should the Specialist set as the SageMakerVariantInvocationsPerInstance setting? ", "zhcn": "一位机器学习专家需要为端点自动伸缩配置确定合适的SageMakerVariantInvocationsPerInstance参数值。通过对单实例进行负载测试，该专家已确认在保持服务不降级的前提下，每秒最高请求处理量约为20RPS。由于属于首次部署，专家计划将调用安全系数设定为0.5。基于上述参数，且已知单实例调用量以分钟为计量单位，请问应如何设定SageMakerVariantInvocationsPerInstance的数值？"}, "option": [{"option_text": {"zhcn": "十", "enus": "10"}, "option_flag": false}, {"option_text": {"zhcn": "三十", "enus": "30"}, "option_flag": false}, {"option_text": {"zhcn": "六百", "enus": "600"}, "option_flag": true}, {"option_text": {"zhcn": "两千四百", "enus": "2,400"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "76", "question": {"enus": "A company uses a long short-term memory (LSTM) model to evaluate the risk factors of a particular energy sector. The model reviews multi- page text documents to analyze each sentence of the text and categorize it as either a potential risk or no risk. The model is not performing well, even though the Data Scientist has experimented with many different network structures and tuned the corresponding hyperparameters. Which approach will provide the MAXIMUM performance boost? ", "zhcn": "某公司采用长短期记忆（LSTM）模型评估特定能源领域的风险因素。该模型通过审阅多页文本文档，逐句分析内容并将其归类为潜在风险或无风险。尽管数据科学家已尝试多种网络结构并调整相应超参数，模型性能仍不理想。下列哪种方法能最大限度提升模型效能？"}, "option": [{"option_text": {"zhcn": "以能源领域海量新闻文本预训练的TF-IDF向量为基准，对词汇进行初始化处理。", "enus": "Initialize the words by term frequency-inverse document frequency (TF-IDF) vectors pretrained on a large collection of news articles  related to the energy sector."}, "option_flag": false}, {"option_text": {"zhcn": "采用门控循环单元（GRU）替代长短期记忆网络（LSTM），并在验证集损失停止下降时结束训练过程。", "enus": "Use gated recurrent units (GRUs) instead of LSTM and run the training process until the validation loss stops decreasing."}, "option_flag": false}, {"option_text": {"zhcn": "降低学习率，持续训练直至损失函数不再下降。", "enus": "Reduce the learning rate and run the training process until the training loss stops decreasing."}, "option_flag": true}, {"option_text": {"zhcn": "基于能源领域海量新闻语料预训练的word2vec词向量，对词汇进行初始化处理。", "enus": "Initialize the words by word2vec embeddings pretrained on a large collection of news articles related to the energy sector."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "77", "question": {"enus": "A Machine Learning Specialist needs to move and transform data in preparation for training. Some of the data needs to be processed in near- real time, and other data can be moved hourly. There are existing Amazon EMR MapReduce jobs to clean and feature engineering to perform on the data. Which of the following services can feed data to the MapReduce jobs? (Choose two.) ", "zhcn": "一位机器学习专家需要迁移和转换数据以准备训练模型。部分数据需近实时处理，其余数据可每小时批量传输。现有Amazon EMR MapReduce任务负责数据清洗与特征工程。下列哪两项服务可为MapReduce任务提供数据源？（请选择两项答案）"}, "option": [{"option_text": {"zhcn": "AWS数据迁移服务", "enus": "AWS DMS"}, "option_flag": true}, {"option_text": {"zhcn": "亚马逊Kinesis", "enus": "Amazon Kinesis"}, "option_flag": false}, {"option_text": {"zhcn": "AWS Data Pipeline", "enus": "AWS Data Pipeline"}, "option_flag": false}, {"option_text": {"zhcn": "Amazon Athena", "enus": "Amazon Athena"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊西班牙", "enus": "Amazon ES"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AE"}, {"id": "78", "question": {"enus": "A Machine Learning Specialist previously trained a logistic regression model using scikit-learn on a local machine, and the Specialist now wants to deploy it to production for inference only. What steps should be taken to ensure Amazon SageMaker can host a model that was trained locally? ", "zhcn": "此前，一位机器学习专家在本地计算机上使用scikit-learn训练了逻辑回归模型，现计划将其部署至生产环境仅用于推理。为确保亚马逊SageMaker能够托管本地训练的模型，需采取哪些必要步骤？"}, "option": [{"option_text": {"zhcn": "构建包含推理代码的Docker镜像。为镜像标记注册表主机名后，将其上传至亚马逊ECR服务平台。", "enus": "Build the Docker image with the inference code. Tag the Docker image with the registry hostname and upload it to Amazon ECR."}, "option_flag": false}, {"option_text": {"zhcn": "对训练完成的模型进行序列化处理，采用压缩格式以便部署。为Docker镜像标记注册表主机名，并将其上传至Amazon S3存储服务。", "enus": "Serialize the trained model so the format is compressed for deployment. Tag the Docker image with the registry hostname and upload  it to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "将训练好的模型序列化，并压缩格式以便部署。构建镜像并上传至Docker Hub。", "enus": "Serialize the trained model so the format is compressed for deployment. Build the image and upload it to Docker Hub."}, "option_flag": false}, {"option_text": {"zhcn": "构建包含推理代码的Docker镜像。配置Docker Hub并将镜像推送至Amazon ECR。", "enus": "Build the Docker image with the inference code. Configure Docker Hub and upload the image to Amazon ECR."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "79", "question": {"enus": "A trucking company is collecting live image data from its fieet of trucks across the globe. The data is growing rapidly and approximately 100 GB of new data is generated every day. The company wants to explore machine learning uses cases while ensuring the data is only accessible to specific IAM users. Which storage option provides the most processing fiexibility and will allow access control with IAM? ", "zhcn": "一家货运公司正从其遍布全球的卡车车队实时采集图像数据。数据量增长迅猛，每日新增约达100 GB。该公司希望在探索机器学习应用场景的同时，确保数据仅限特定IAM用户访问。哪种存储方案既能提供最大处理灵活性，又能实现IAM权限管控？"}, "option": [{"option_text": {"zhcn": "采用数据库（例如Amazon DynamoDB）存储图像，并通过IAM策略设定权限，仅允许指定的IAM用户访问。", "enus": "Use a database, such as Amazon DynamoDB, to store the images, and set the IAM policies to restrict access to only the desired IAM  users."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊S3构建数据湖来存储原始图像，并通过存储桶策略配置访问权限。", "enus": "Use an Amazon S3-backed data lake to store the raw images, and set up the permissions using bucket policies."}, "option_flag": false}, {"option_text": {"zhcn": "配置基于Hadoop分布式文件系统（HDFS）的亚马逊EMR集群用于文件存储，并通过IAM策略限制对EMR实例的访问权限。", "enus": "Setup up Amazon EMR with Hadoop Distributed File System (HDFS) to store the files, and restrict access to the EMR instances using  IAM policies."}, "option_flag": true}, {"option_text": {"zhcn": "配置Amazon EFS时结合IAM策略，可使IAM用户所属的Amazon EC2实例访问相应数据。", "enus": "Configure Amazon EFS with IAM policies to make the data available to Amazon EC2 instances owned by the IAM users."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "80", "question": {"enus": "A credit card company wants to build a credit scoring model to help predict whether a new credit card applicant will default on a credit card payment. The company has collected data from a large number of sources with thousands of raw attributes. Early experiments to train a classification model revealed that many attributes are highly correlated, the large number of features slows down the training speed significantly, and that there are some overfitting issues. The Data Scientist on this project would like to speed up the model training time without losing a lot of information from the original dataset. Which feature engineering technique should the Data Scientist use to meet the objectives? ", "zhcn": "一家信用卡公司计划构建信用评分模型，用以预测新信用卡申请人是否会出现违约行为。该公司从大量数据源采集了数千个原始属性特征。初步训练分类模型时发现，众多属性间存在高度相关性，海量特征显著拖慢训练速度，并伴随过拟合现象。该项目的数据科学家希望在保留原始数据集大部分信息的前提下加速模型训练。请问应当采用哪种特征工程技术来实现这一目标？"}, "option": [{"option_text": {"zhcn": "对所有特征进行自相关分析，并剔除高度关联的特征。", "enus": "Run self-correlation on all features and remove highly correlated features"}, "option_flag": false}, {"option_text": {"zhcn": "将所有数值归一化至0到1的区间内。", "enus": "Normalize all numerical values to be between 0 and 1"}, "option_flag": true}, {"option_text": {"zhcn": "采用自编码器或主成分分析（PCA）方法，将原始特征替换为经过重构的新特征。", "enus": "Use an autoencoder or principal component analysis (PCA) to replace original features with new features"}, "option_flag": false}, {"option_text": {"zhcn": "采用k-means算法对原始数据进行聚类分析，并从各类簇中抽取样本数据构建新的数据集。", "enus": "Cluster raw data using k-means and use sample data from each cluster to build a new dataset"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "81", "question": {"enus": "A Data Scientist is training a multilayer perception (MLP) on a dataset with multiple classes. The target class of interest is unique compared to the other classes within the dataset, but it does not achieve and acceptable recall metric. The Data Scientist has already tried varying the number and size of the MLP's hidden layers, which has not significantly improved the results. A solution to improve recall must be implemented as quickly as possible. Which techniques should be used to meet these requirements? ", "zhcn": "一位数据科学家正在利用包含多个类别的数据集训练多层感知机（MLP）。数据集中目标类别的特征与其他类别存在显著差异，但其召回率指标始终未达到可接受水平。该数据科学家已尝试调整隐藏层的数量和规模，但未能显著改善结果。当前亟需快速落实提升召回率的解决方案。应采用哪些技术手段来满足这一需求？"}, "option": [{"option_text": {"zhcn": "通过亚马逊土耳其机器人平台收集更多数据后重新进行模型训练。", "enus": "Gather more data using Amazon Mechanical Turk and then retrain"}, "option_flag": false}, {"option_text": {"zhcn": "训练一个异常检测模型，而非多层感知机。", "enus": "Train an anomaly detection model instead of an MLP"}, "option_flag": false}, {"option_text": {"zhcn": "采用XGBoost模型进行训练，而非多层感知机。", "enus": "Train an XGBoost model instead of an MLP"}, "option_flag": true}, {"option_text": {"zhcn": "为多层感知机的损失函数引入类别权重，随后重新进行模型训练。", "enus": "Add class weights to the MLP's loss function and then retrain"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "82", "question": {"enus": "A Machine Learning Specialist works for a credit card processing company and needs to predict which transactions may be fraudulent in near- real time. Specifically, the Specialist must train a model that returns the probability that a given transaction may fraudulent. How should the Specialist frame this business problem? ", "zhcn": "一名机器学习专家就职于信用卡处理公司，其职责需近乎实时地预测可疑交易。具体而言，该专家需要训练一个能返回单笔交易欺诈概率的预测模型。针对这一业务需求，专家应如何构建问题框架？"}, "option": [{"option_text": {"zhcn": "流式分类", "enus": "Streaming classification"}, "option_flag": false}, {"option_text": {"zhcn": "二分分类", "enus": "Binary classification"}, "option_flag": false}, {"option_text": {"zhcn": "多类别分类", "enus": "Multi-category classification"}, "option_flag": true}, {"option_text": {"zhcn": "回归分类", "enus": "Regression classification"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "83", "question": {"enus": "A real estate company wants to create a machine learning model for predicting housing prices based on a historical dataset. The dataset contains 32 features. Which model will meet the business requirement? ", "zhcn": "一家房地产企业计划基于历史数据集构建机器学习模型，用于预测房屋价格。该数据集涵盖32项特征。何种模型能够满足这一商业需求？"}, "option": [{"option_text": {"zhcn": "逻辑回归", "enus": "Logistic regression"}, "option_flag": false}, {"option_text": {"zhcn": "线性回归", "enus": "Linear regression"}, "option_flag": true}, {"option_text": {"zhcn": "K-means算法", "enus": "K-means"}, "option_flag": false}, {"option_text": {"zhcn": "主成分分析（PCA）", "enus": "Principal component analysis (PCA)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "84", "question": {"enus": "A Machine Learning Specialist is applying a linear least squares regression model to a dataset with 1,000 records and 50 features. Prior to training, the ML Specialist notices that two features are perfectly linearly dependent. Why could this be an issue for the linear least squares regression model? ", "zhcn": "一位机器学习专家正在对包含1000条记录和50个特征的数据集应用线性最小二乘回归模型。在训练开始前，该专家发现有两个特征存在完全线性相关关系。这种情况为何会对线性最小二乘回归模型造成影响？"}, "option": [{"option_text": {"zhcn": "这可能导致反向传播算法在训练过程中失效。", "enus": "It could cause the backpropagation algorithm to fail during training"}, "option_flag": false}, {"option_text": {"zhcn": "在优化过程中，该情况可能导致矩阵奇异，从而无法得出唯一解。", "enus": "It could create a singular matrix during optimization, which fails to define a unique solution"}, "option_flag": false}, {"option_text": {"zhcn": "在优化过程中，它可能改变损失函数的结构，从而导致训练环节出现故障。", "enus": "It could modify the loss function during optimization, causing it to fail during training"}, "option_flag": true}, {"option_text": {"zhcn": "这可能导致数据内部产生非线性关联，从而动摇模型所依赖的线性假设基础。", "enus": "It could introduce non-linear dependencies within the data, which could invalidate the linear assumptions of the model"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "85", "question": {"enus": "Given the following confusion matrix for a movie classification model, what is the true class frequency for Romance and the predicted class frequency for Adventure? ", "zhcn": "根据以下电影分类模型的混淆矩阵，浪漫类别的真实频次与冒险类别的预测频次分别是多少？"}, "option": [{"option_text": {"zhcn": "浪漫题材的真实类别占比为77.56%，而冒险题材的预测类别占比为20.85%。", "enus": "The true class frequency for Romance is 77.56% and the predicted class frequency for Adventure is 20.85%"}, "option_flag": false}, {"option_text": {"zhcn": "浪漫题材的真实类别占比为57.92%，而冒险题材的预测类别占比为13.12%。", "enus": "The true class frequency for Romance is 57.92% and the predicted class frequency for Adventure is 13.12%"}, "option_flag": true}, {"option_text": {"zhcn": "浪漫题材的真实类别占比为0.78，而冒险题材的预测类别占比区间为（0.47-0.32）。", "enus": "The true class frequency for Romance is 0.78 and the predicted class frequency for Adventure is (0.47-0.32)"}, "option_flag": false}, {"option_text": {"zhcn": "浪漫题材的真实类别占比为77.56%±0.78，而冒险题材的预测类别占比为20.85%±0.32。", "enus": "The true class frequency for Romance is 77.56% ֳ— 0.78 and the predicted class frequency for Adventure is 20.85% ֳ— 0.32"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "86", "question": {"enus": "A Machine Learning Specialist wants to bring a custom algorithm to Amazon SageMaker. The Specialist implements the algorithm in a Docker container supported by Amazon SageMaker. How should the Specialist package the Docker container so that Amazon SageMaker can launch the training correctly? ", "zhcn": "一位机器学习专家希望将自定义算法集成至Amazon SageMaker平台。该专家已采用Amazon SageMaker支持的Docker容器实现算法。为确保Amazon SageMaker能正确启动训练任务，专家应当如何封装该Docker容器？\n\n（注：专有名词\"Amazon SageMaker\"和\"Docker\"保留原表达，采用技术领域通用的\"容器\"而非\"集装箱\"等直译，运用\"集成\"\"实现\"\"封装\"等专业术语保持技术文档的严谨性，同时通过\"确保\"\"启动训练任务\"等动态表述增强操作指引的清晰度。）"}, "option": [{"option_text": {"zhcn": "修改容器中的 bash_profile 文件，并添加用于启动训练程序的 bash 命令。", "enus": "Modify the bash_profile file in the container and add a bash command to start the training program"}, "option_flag": false}, {"option_text": {"zhcn": "在Dockerfile中使用CMD指令，将训练程序设置为镜像的默认启动命令。", "enus": "Use CMD config in the Dockerfile to add the training program as a CMD of the image"}, "option_flag": true}, {"option_text": {"zhcn": "将训练程序配置为名为 train 的入口指令。", "enus": "Configure the training program as an ENTRYPOINT named train"}, "option_flag": false}, {"option_text": {"zhcn": "将训练程序复制至 /opt/ml/train 目录下。", "enus": "Copy the training program to directory /opt/ml/train"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "87", "question": {"enus": "A Data Scientist needs to analyze employment data. The dataset contains approximately 10 million observations on people across 10 different features. During the preliminary analysis, the Data Scientist notices that income and age distributions are not normal. While income levels shows a right skew as expected, with fewer individuals having a higher income, the age distribution also shows a right skew, with fewer older individuals participating in the workforce. Which feature transformations can the Data Scientist apply to fix the incorrectly skewed data? (Choose two.) ", "zhcn": "数据科学家需对就业数据进行分析。该数据集包含约1000万条人员记录，涉及十个特征变量。初步分析发现收入与年龄的分布形态有违常态：收入水平如预期呈现右偏分布，即高收入群体占比递减；然而年龄分布同样出现右偏，表明劳动力市场中高龄参与者比例异常偏低。为修正这种非常规偏态分布，数据科学家可采用哪两种特征转换方法？（请选择两项）"}, "option": [{"option_text": {"zhcn": "交叉验证", "enus": "Cross-validation"}, "option_flag": true}, {"option_text": {"zhcn": "数值分箱", "enus": "Numerical value binning"}, "option_flag": true}, {"option_text": {"zhcn": "高次多项式变换", "enus": "High-degree polynomial transformation"}, "option_flag": false}, {"option_text": {"zhcn": "对数变换", "enus": "Logarithmic transformation"}, "option_flag": false}, {"option_text": {"zhcn": "独热编码", "enus": "One hot encoding"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AB"}, {"id": "88", "question": {"enus": "A web-based company wants to improve its conversion rate on its landing page. Using a large historical dataset of customer visits, the company has repeatedly trained a multi-class deep learning network algorithm on Amazon SageMaker. However, there is an overfitting problem: training data shows 90% accuracy in predictions, while test data shows 70% accuracy only. The company needs to boost the generalization of its model before deploying it into production to maximize conversions of visits to purchases. Which action is recommended to provide the HIGHEST accuracy model for the company's test and validation data? ", "zhcn": "一家互联网公司希望提升其着陆页的转化率。基于庞大的客户访问历史数据集，该公司已多次通过亚马逊SageMaker平台训练多类别深度学习网络算法。然而目前出现过拟合问题：训练数据的预测准确率高达90%，而测试数据仅显示70%的准确率。在将模型部署到生产环境以最大化访问至购买的转化率之前，该公司需要提升模型的泛化能力。下列哪项措施能为该公司的测试及验证数据提供最高准确率的模型？"}, "option": [{"option_text": {"zhcn": "增强训练所用小批量数据中训练样本的随机性。", "enus": "Increase the randomization of training data in the mini-batches used in training"}, "option_flag": false}, {"option_text": {"zhcn": "将更多数据分配给训练集。", "enus": "Allocate a higher proportion of the overall data to the training dataset"}, "option_flag": false}, {"option_text": {"zhcn": "在训练过程中应用L1或L2正则化方法，并配合使用随机失活技术。", "enus": "Apply L1 or L2 regularization and dropouts to the training"}, "option_flag": false}, {"option_text": {"zhcn": "降低深度学习网络的层数与单元（或神经元）数量。", "enus": "Reduce the number of layers and units (or neurons) from the deep learning network"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "89", "question": {"enus": "A Machine Learning Specialist is given a structured dataset on the shopping habits of a company's customer base. The dataset contains thousands of columns of data and hundreds of numerical columns for each customer. The Specialist wants to identify whether there are natural groupings for these columns across all customers and visualize the results as quickly as possible. What approach should the Specialist take to accomplish these tasks? ", "zhcn": "一位机器学习专家获得了一份关于公司客户群购物习惯的结构化数据集。该数据集包含数千个数据列，每位客户都有数百个数值型字段。专家需要快速识别这些字段是否在所有客户中存在自然分组，并将分析结果可视化呈现。请问专家应采取何种方法以高效完成这两项任务？"}, "option": [{"option_text": {"zhcn": "对数值特征进行t-SNE降维处理，并绘制散点分布图。", "enus": "Embed the numerical features using the t-distributed stochastic neighbor embedding (t-SNE) algorithm and create a scatter plot."}, "option_flag": false}, {"option_text": {"zhcn": "对不同k值运行基于欧氏距离的k均值算法，并绘制肘部曲线图。", "enus": "Run k-means using the Euclidean distance measure for different values of k and create an elbow plot."}, "option_flag": true}, {"option_text": {"zhcn": "采用t-SNE算法对数值特征进行嵌入处理，并绘制折线图。", "enus": "Embed the numerical features using the t-distributed stochastic neighbor embedding (t-SNE) algorithm and create a line graph."}, "option_flag": false}, {"option_text": {"zhcn": "使用欧几里得距离度量对不同k值运行k-means聚类，并为每个聚类中的数值列绘制箱线图。", "enus": "Run k-means using the Euclidean distance measure for different values of k and create box plots for each numerical column within each  cluster."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "90", "question": {"enus": "A Machine Learning Specialist is planning to create a long-running Amazon EMR cluster. The EMR cluster will have 1 master node, 10 core nodes, and 20 task nodes. To save on costs, the Specialist will use Spot Instances in the EMR cluster. Which nodes should the Specialist launch on Spot Instances? ", "zhcn": "一位机器学习专家正计划创建一个长期运行的亚马逊EMR集群。该集群将包含1个主节点、10个核心节点和20个任务节点。为节约成本，这位专家打算在EMR集群中使用竞价实例。请问哪些节点适合采用竞价实例部署？"}, "option": [{"option_text": {"zhcn": "主节点", "enus": "Master node"}, "option_flag": true}, {"option_text": {"zhcn": "核心节点中的任意一个", "enus": "Any of the core nodes"}, "option_flag": false}, {"option_text": {"zhcn": "\"任一任务节点\"", "enus": "Any of the task nodes"}, "option_flag": false}, {"option_text": {"zhcn": "核心节点与任务节点", "enus": "Both core and task nodes"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "91", "question": {"enus": "A manufacturer of car engines collects data from cars as they are being driven. The data collected includes timestamp, engine temperature, rotations per minute (RPM), and other sensor readings. The company wants to predict when an engine is going to have a problem, so it can notify drivers in advance to get engine maintenance. The engine data is loaded into a data lake for training. Which is the MOST suitable predictive model that can be deployed into production? ", "zhcn": "一家汽车发动机制造商在车辆行驶过程中收集数据，所获数据包括时间戳、发动机温度、每分钟转数（RPM）及其他传感器读数。该公司希望预测发动机可能出现的故障，以便提前通知驾驶员进行维修保养。发动机数据已载入数据湖用于训练，请问最适合投入生产环境的预测模型是哪种？"}, "option": [{"option_text": {"zhcn": "随时间添加标签，以标明未来何时会出现何种发动机故障，从而将问题转化为监督学习任务。利用循环神经网络训练模型，使其能够识别发动机在特定故障发生时可能需要维护的时机。", "enus": "Add labels over time to indicate which engine faults occur at what time in the future to turn this into a supervised learning problem.  Use a recurrent neural network (RNN) to train the model to recognize when an engine might need maintenance for a certain fault."}, "option_flag": false}, {"option_text": {"zhcn": "该数据需采用无监督学习算法进行处理。可利用Amazon SageMaker平台的k-means算法对数据进行聚类分析。", "enus": "This data requires an unsupervised learning algorithm. Use Amazon SageMaker k-means to cluster the data."}, "option_flag": true}, {"option_text": {"zhcn": "随时间添加标签，以标注未来何时会出现何种发动机故障，从而将其转化为监督学习问题。运用卷积神经网络（CNN）训练模型，使其能够识别发动机在特定故障下可能需要维护的时机。", "enus": "Add labels over time to indicate which engine faults occur at what time in the future to turn this into a supervised learning problem.  Use a convolutional neural network (CNN) to train the model to recognize when an engine might need maintenance for a certain fault."}, "option_flag": false}, {"option_text": {"zhcn": "该数据集已按时间序列格式整理，可运用Amazon SageMaker平台的seq2seq算法对时间序列进行建模。", "enus": "This data is already formulated as a time series. Use Amazon SageMaker seq2seq to model the time series."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "92", "question": {"enus": "A company wants to predict the sale prices of houses based on available historical sales data. The target variable in the company's dataset is the sale price. The features include parameters such as the lot size, living area measurements, non-living area measurements, number of bedrooms, number of bathrooms, year built, and postal code. The company wants to use multi-variable linear regression to predict house sale prices. Which step should a machine learning specialist take to remove features that are irrelevant for the analysis and reduce the model's complexity? ", "zhcn": "某公司希望依据现有历史销售数据预测房屋售价，其数据集中的目标变量为售价，特征参数包含地块面积、居住区面积、非居住区面积、卧室数量、卫生间数量、建造年份及邮政编码。该公司拟采用多元线性回归模型进行房价预测。为剔除无关特征并降低模型复杂度，机器学习专家应采取下列哪项步骤？"}, "option": [{"option_text": {"zhcn": "绘制特征分布直方图并计算其标准差。剔除方差过高的特征。", "enus": "Plot a histogram of the features and compute their standard deviation. Remove features with high variance."}, "option_flag": false}, {"option_text": {"zhcn": "绘制特征分布直方图并计算其标准差。剔除方差过低的特征。", "enus": "Plot a histogram of the features and compute their standard deviation. Remove features with low variance."}, "option_flag": false}, {"option_text": {"zhcn": "绘制数据集自身相关性的热力图，剔除互相关分数较低的特征变量。", "enus": "Build a heatmap showing the correlation of the dataset against itself. Remove features with low mutual correlation scores."}, "option_flag": false}, {"option_text": {"zhcn": "对所有特征与目标变量进行相关性检验，剔除与目标变量关联度较低的指标。", "enus": "Run a correlation check of all features against the target variable. Remove features with low target variable correlation scores."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "93", "question": {"enus": "A company wants to classify user behavior as either fraudulent or normal. Based on internal research, a machine learning specialist will build a binary classifier based on two features: age of account, denoted by x, and transaction month, denoted by y. The class distributions are illustrated in the provided figure. The positive class is portrayed in red, while the negative class is portrayed in black. Which model would have the HIGHEST accuracy? ", "zhcn": "某企业需对用户行为进行欺诈与非欺诈分类。根据内部研究，机器学习专家将基于账户存续时长（记为x）和交易月份（记为y）这两个特征构建二元分类器。附图展示了类别分布情况：红色代表正类，黑色代表负类。请问哪种模型的准确率会最高？"}, "option": [{"option_text": {"zhcn": "线性支持向量机（SVM）", "enus": "Linear support vector machine (SVM)"}, "option_flag": false}, {"option_text": {"zhcn": "决策树", "enus": "Decision tree"}, "option_flag": false}, {"option_text": {"zhcn": "采用径向基核函数的支持向量机", "enus": "Support vector machine (SVM) with a radial basis function kernel"}, "option_flag": true}, {"option_text": {"zhcn": "带有双曲正切激活函数的单层感知机", "enus": "Single perceptron with a Tanh activation function"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "94", "question": {"enus": "A health care company is planning to use neural networks to classify their X-ray images into normal and abnormal classes. The labeled data is divided into a training set of 1,000 images and a test set of 200 images. The initial training of a neural network model with 50 hidden layers yielded 99% accuracy on the training set, but only 55% accuracy on the test set. What changes should the Specialist consider to solve this issue? (Choose three.) ", "zhcn": "一家医疗保健公司计划运用神经网络技术，将其X光图像分类为正常与异常两类。现有标注数据被划分为包含1000张图像的训练集和200张图像的测试集。在采用含50个隐藏层的神经网络进行初步训练后，模型在训练集上准确率达到99%，但在测试集上仅取得55%的准确率。为改善这一状况，专家应考虑采取哪些调整措施？（请选择三项）"}, "option": [{"option_text": {"zhcn": "选择更多层级", "enus": "Choose a higher number of layers"}, "option_flag": true}, {"option_text": {"zhcn": "选择较少的层数。", "enus": "Choose a lower number of layers"}, "option_flag": false}, {"option_text": {"zhcn": "选择较小的学习速率。", "enus": "Choose a smaller learning rate"}, "option_flag": false}, {"option_text": {"zhcn": "启用随机失活", "enus": "Enable dropout"}, "option_flag": true}, {"option_text": {"zhcn": "将测试集中的所有图像纳入训练集。", "enus": "Include all the images from the test set in the training set"}, "option_flag": true}, {"option_text": {"zhcn": "启用提前终止", "enus": "Enable early stopping"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "ADE"}, {"id": "95", "question": {"enus": "This graph shows the training and validation loss against the epochs for a neural network. The network being trained is as follows: ✑ Two dense layers, one output neuron ✑ 100 neurons in each layer ✑ 100 epochs Random initialization of weights Which technique can be used to improve model performance in terms of accuracy in the validation set? ", "zhcn": "本图呈现了神经网络训练过程中训练集与验证集的损失随迭代轮次的变化情况。该网络结构如下：  \n✑ 包含两个全连接层，输出层为单一神经元  \n✑ 每层含100个神经元  \n✑ 进行100轮迭代训练  \n✑ 权重采用随机初始化  \n为提升模型在验证集上的准确率，可采用何种优化策略？"}, "option": [{"option_text": {"zhcn": "“早停法”", "enus": "Early stopping"}, "option_flag": false}, {"option_text": {"zhcn": "权重随机初始化（采用适当种子）", "enus": "Random initialization of weights with appropriate seed"}, "option_flag": false}, {"option_text": {"zhcn": "增加训练轮次", "enus": "Increasing the number of epochs"}, "option_flag": true}, {"option_text": {"zhcn": "在已有结构之上增设包含100个神经元的层级", "enus": "Adding another layer with the 100 neurons"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "96", "question": {"enus": "A Machine Learning Specialist is attempting to build a linear regression model. Given the displayed residual plot only, what is the MOST likely problem with the model? ", "zhcn": "一位机器学习专家正在尝试构建线性回归模型。仅根据所展示的残差图判断，该模型最可能存在的问题是什么？"}, "option": [{"option_text": {"zhcn": "线性回归模型在此处并不适用，因为其残差缺乏恒定的方差。", "enus": "Linear regression is inappropriate. The residuals do not have constant variance."}, "option_flag": false}, {"option_text": {"zhcn": "线性回归模型在此并不适用，因其基础数据中存在异常值。", "enus": "Linear regression is inappropriate. The underlying data has outliers."}, "option_flag": false}, {"option_text": {"zhcn": "线性回归模型适用。残差均值为零。", "enus": "Linear regression is appropriate. The residuals have a zero mean."}, "option_flag": false}, {"option_text": {"zhcn": "线性回归模型适用。残差具有恒定方差。", "enus": "Linear regression is appropriate. The residuals have constant variance."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "97", "question": {"enus": "A large company has developed a BI application that generates reports and dashboards using data collected from various operational metrics. The company wants to provide executives with an enhanced experience so they can use natural language to get data from the reports. The company wants the executives to be able ask questions using written and spoken interfaces. Which combination of services can be used to build this conversational interface? (Choose three.) ", "zhcn": "某大型企业开发了一套商业智能应用，通过整合多维度运营指标数据生成报表与可视化看板。为提升高管的使用体验，公司计划构建自然语言交互功能，使其能通过书面或语音方式直接查询报表数据。下列哪三种服务组合可用于构建此类对话式交互界面？（请选择三项）"}, "option": [{"option_text": {"zhcn": "“Alexa商务助手”", "enus": "Alexa for Business"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊云联络中心", "enus": "Amazon Connect"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon Lex", "enus": "Amazon Lex"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊波利", "enus": "Amazon Polly"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊理解服务", "enus": "Amazon Comprehend"}, "option_flag": true}, {"option_text": {"zhcn": "亚马逊转录服务", "enus": "Amazon Transcribe"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BEF"}, {"id": "98", "question": {"enus": "A machine learning specialist works for a fruit processing company and needs to build a system that categorizes apples into three types. The specialist has collected a dataset that contains 150 images for each type of apple and applied transfer learning on a neural network that was pretrained on ImageNet with this dataset. The company requires at least 85% accuracy to make use of the model. After an exhaustive grid search, the optimal hyperparameters produced the following: ✑ 68% accuracy on the training set ✑ 67% accuracy on the validation set What can the machine learning specialist do to improve the system's accuracy? ", "zhcn": "一位机器学习专家受聘于一家水果加工企业，需开发一套将苹果分为三个品种的识别系统。该专家已收集每个品种150张图像的数据集，并基于ImageNet预训练的神经网络进行了迁移学习。公司要求模型准确率至少达到85%方可投入实用。经过全面网格搜索后，最优超参数组合在训练集和验证集上的表现如下：  \n✑ 训练集准确率68%  \n✑ 验证集准确率67%  \n请问机器学习专家可采取哪些措施来提升系统准确率？"}, "option": [{"option_text": {"zhcn": "将模型上传至Amazon SageMaker笔记本实例，并运用其超参数优化功能对模型参数进行调优。", "enus": "Upload the model to an Amazon SageMaker notebook instance and use the Amazon SageMaker HPO feature to optimize the model's  hyperparameters."}, "option_flag": false}, {"option_text": {"zhcn": "向训练集补充更多数据，并采用迁移学习方式重新训练模型，以降低偏差度。", "enus": "Add more data to the training set and retrain the model using transfer learning to reduce the bias."}, "option_flag": true}, {"option_text": {"zhcn": "采用在ImageNet上预训练的更深层神经网络模型，并运用迁移学习来提升模型的方差表现。", "enus": "Use a neural network model with more layers that are pretrained on ImageNet and apply transfer learning to increase the variance."}, "option_flag": false}, {"option_text": {"zhcn": "在当前神经网络架构的基础上训练新模型。", "enus": "Train a new model using the current neural network architecture."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "99", "question": {"enus": "A company uses camera images of the tops of items displayed on store shelves to determine which items were removed and which ones still remain. After several hours of data labeling, the company has a total of 1,000 hand-labeled images covering 10 distinct items. The training results were poor. Which machine learning approach fulfills the company's long-term needs? ", "zhcn": "一家公司通过拍摄货架上商品顶部的图像，来判断哪些商品已被取走、哪些仍留在原处。经过数小时的数据标注，该公司共获得一千张手工标记的图像，涵盖十种不同商品。然而模型训练效果不佳。若要满足该企业的长期需求，应采取哪种机器学习方法？"}, "option": [{"option_text": {"zhcn": "将图像转换为灰度图后重新训练模型。", "enus": "Convert the images to grayscale and retrain the model"}, "option_flag": true}, {"option_text": {"zhcn": "将品类数量从10个精简至2个，建立模型并持续优化迭代。", "enus": "Reduce the number of distinct items from 10 to 2, build the model, and iterate"}, "option_flag": false}, {"option_text": {"zhcn": "为每件物品贴上不同颜色的标签，重新拍摄图像，并构建模型。", "enus": "Attach different colored labels to each item, take the images again, and build the model"}, "option_flag": false}, {"option_text": {"zhcn": "为每个项目运用图像变体（如倒置与平移）来扩充训练数据，继而构建模型并持续优化迭代。", "enus": "Augment training data for each item using image variants like inversions and translations, build the model, and iterate."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "100", "question": {"enus": "A Data Scientist is developing a binary classifier to predict whether a patient has a particular disease on a series of test results. The Data Scientist has data on 400 patients randomly selected from the population. The disease is seen in 3% of the population. Which cross-validation strategy should the Data Scientist adopt? ", "zhcn": "一位数据科学家正在开发一个二元分类器，旨在根据系列检测结果预测患者是否罹患某种特定疾病。该科学家从总体人群中随机抽取了400名患者的数据作为研究样本。已知此疾病在人群中的患病率为3%。此时，数据科学家应当采用何种交叉验证策略？"}, "option": [{"option_text": {"zhcn": "采用五折交叉验证法。", "enus": "A k-fold cross-validation strategy with k=5"}, "option_flag": false}, {"option_text": {"zhcn": "采用分层K折交叉验证法，设定折数K=5。", "enus": "A stratified k-fold cross-validation strategy with k=5"}, "option_flag": true}, {"option_text": {"zhcn": "采用五折交叉验证法，重复三次实验验证。", "enus": "A k-fold cross-validation strategy with k=5 and 3 repeats"}, "option_flag": false}, {"option_text": {"zhcn": "训练集与验证集按80/20的比例分层划分。", "enus": "An 80/20 stratified split between training and validation"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "101", "question": {"enus": "A technology startup is using complex deep neural networks and GPU compute to recommend the company's products to its existing customers based upon each customer's habits and interactions. The solution currently pulls each dataset from an Amazon S3 bucket before loading the data into a TensorFlow model pulled from the company's Git repository that runs locally. This job then runs for several hours while continually outputting its progress to the same S3 bucket. The job can be paused, restarted, and continued at any time in the event of a failure, and is run from a central queue. Senior managers are concerned about the complexity of the solution's resource management and the costs involved in repeating the process regularly. They ask for the workload to be automated so it runs once a week, starting Monday and completing by the close of business Friday. Which architecture should be used to scale the solution at the lowest cost? ", "zhcn": "一家科技初创企业正运用复杂的深度神经网络与GPU算力，根据每位客户的习惯和交互记录为其推荐公司产品。当前解决方案会先从亚马逊S3存储桶提取数据集，再将数据载入从公司Git代码库获取的TensorFlow模型进行本地运算。该任务持续运行数小时，并实时将进度同步输出至同一S3存储桶。借助中央队列调度，该任务支持在发生故障时随时暂停、重启或续传。高层管理者担忧现有解决方案的资源管理复杂度及定期运行产生的成本，要求将工作流自动化调整为每周执行一次：周一启动，周五下班前完成。应采用何种架构方案，才能以最低成本实现该解决方案的弹性扩展？"}, "option": [{"option_text": {"zhcn": "利用AWS深度学习容器部署解决方案，并通过AWS Batch在支持GPU的竞价实例上以任务形式运行容器。", "enus": "Implement the solution using AWS Deep Learning Containers and run the container as a job using AWS Batch on a GPU-compatible Spot  Instance"}, "option_flag": false}, {"option_text": {"zhcn": "采用低成本且支持GPU运算的亚马逊EC2实例来部署解决方案，并通过AWS实例调度器对任务执行时间进行自动化编排。", "enus": "Implement the solution using a low-cost GPU-compatible Amazon EC2 instance and use the AWS Instance Scheduler to schedule the  task"}, "option_flag": false}, {"option_text": {"zhcn": "采用AWS深度学习容器部署解决方案，通过运行在Spot实例上的AWS Fargate执行计算任务，并利用内置任务调度器实现作业的自动化编排。", "enus": "Implement the solution using AWS Deep Learning Containers, run the workload using AWS Fargate running on Spot Instances, and then  schedule the task using the built-in task scheduler"}, "option_flag": true}, {"option_text": {"zhcn": "采用基于竞价型实例的亚马逊ECS实施该解决方案，并通过ECS服务调度器安排任务执行。", "enus": "Implement the solution using Amazon ECS running on Spot Instances and schedule the task using the ECS service scheduler"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "102", "question": {"enus": "A Machine Learning Specialist prepared the following graph displaying the results of k-means for k = [1..10]: Considering the graph, what is a reasonable selection for the optimal choice of k? ", "zhcn": "一位机器学习专家绘制了以下图表，展示了k值从1到10的k均值聚类结果：根据图表所示，对于k的最佳选择，怎样的取值较为合理？"}, "option": [{"option_text": {"zhcn": "一", "enus": "1"}, "option_flag": false}, {"option_text": {"zhcn": "四", "enus": "4"}, "option_flag": false}, {"option_text": {"zhcn": "七\n\n（注：根据用户要求，采用中文数词最简洁典雅的表达形式，避免添加任何解释性内容。若需其他文体风格的翻译版本，可进一步说明具体需求。）", "enus": "7"}, "option_flag": true}, {"option_text": {"zhcn": "十", "enus": "10"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "103", "question": {"enus": "A media company with a very large archive of unlabeled images, text, audio, and video footage wishes to index its assets to allow rapid identification of relevant content by the Research team. The company wants to use machine learning to accelerate the efforts of its in-house researchers who have limited machine learning expertise. Which is the FASTEST route to index the assets? ", "zhcn": "一家拥有海量未标注图像、文本、音频及视频素材的传媒公司，希望为其资产建立索引系统，以便研究团队快速识别相关内容。鉴于内部研究人员机器学习专业知识有限，该公司计划借助机器学习技术提升效率。请问实现资产索引的最快捷途径是什么？"}, "option": [{"option_text": {"zhcn": "借助Amazon Rekognition、Amazon Comprehend与Amazon Transcribe，可将数据自动归类至不同类别。", "enus": "Use Amazon Rekognition, Amazon Comprehend, and Amazon Transcribe to tag data into distinct categories/classes."}, "option_flag": true}, {"option_text": {"zhcn": "创建一套亚马逊土耳其机器人（Amazon Mechanical Turk）的人工智能标注任务，用于标记所有影像资料。", "enus": "Create a set of Amazon Mechanical Turk Human Intelligence Tasks to label all footage."}, "option_flag": false}, {"option_text": {"zhcn": "借助Amazon Transcribe实现语音到文本的转换，并运用Amazon SageMaker的神经主题模型与目标检测算法，将数据精准归类至不同类别。", "enus": "Use Amazon Transcribe to convert speech to text. Use the Amazon SageMaker Neural Topic Model (NTM) and Object Detection  algorithms to tag data into distinct categories/classes."}, "option_flag": false}, {"option_text": {"zhcn": "借助AWS深度学习AMI与Amazon EC2 GPU实例，可构建定制化模型以实现音频转录与主题建模，同时通过目标检测技术将数据标注至不同类别体系。", "enus": "Use the AWS Deep Learning AMI and Amazon EC2 GPU instances to create custom models for audio transcription and topic modeling,  and use object detection to tag data into distinct categories/classes."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "104", "question": {"enus": "A Machine Learning Specialist is working for an online retailer that wants to run analytics on every customer visit, processed through a machine learning pipeline. The data needs to be ingested by Amazon Kinesis Data Streams at up to 100 transactions per second, and the JSON data blob is 100 KB in size. What is the MINIMUM number of shards in Kinesis Data Streams the Specialist should use to successfully ingest this data? ", "zhcn": "一位机器学习专家正为某线上零售商服务，该企业希望对每次客户访问进行数据分析，并通过机器学习流水线处理数据。数据需经由亚马逊Kinesis数据流接收，处理速率需达每秒100笔交易，且每份JSON数据块大小为100KB。请问该专家应至少配置多少个Kinesis数据流分片，方能确保数据成功接收？"}, "option": [{"option_text": {"zhcn": "一瓣残片", "enus": "1 shards"}, "option_flag": false}, {"option_text": {"zhcn": "十枚碎片", "enus": "10 shards"}, "option_flag": true}, {"option_text": {"zhcn": "百枚碎片", "enus": "100 shards"}, "option_flag": false}, {"option_text": {"zhcn": "千枚碎片", "enus": "1,000 shards"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "105", "question": {"enus": "A Machine Learning Specialist is deciding between building a naive Bayesian model or a full Bayesian network for a classification problem. The Specialist computes the Pearson correlation coeficients between each feature and finds that their absolute values range between 0.1 to 0.95. Which model describes the underlying data in this situation? ", "zhcn": "一位机器学习专家在解决分类问题时，需在朴素贝叶斯模型与完整贝叶斯网络之间作出选择。该专家计算出各特征间的皮尔逊相关系数，发现其绝对值分布于0.1至0.95区间。此种情境下，何种模型能更准确地表征底层数据特征？"}, "option": [{"option_text": {"zhcn": "在特征均为条件独立的前提下，可采用朴素贝叶斯模型进行建模。", "enus": "A naive Bayesian model, since the features are all conditionally independent."}, "option_flag": false}, {"option_text": {"zhcn": "由于各特征之间均为条件独立，因此该网络构成完整的贝叶斯网络。", "enus": "A full Bayesian network, since the features are all conditionally independent."}, "option_flag": false}, {"option_text": {"zhcn": "由于某些特征在统计上存在关联性，朴素贝叶斯模型的适用性因此受到限制。", "enus": "A naive Bayesian model, since some of the features are statistically dependent."}, "option_flag": true}, {"option_text": {"zhcn": "由于部分特征在统计上存在依赖性，因此需要构建完整的贝叶斯网络。", "enus": "A full Bayesian network, since some of the features are statistically dependent."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "106", "question": {"enus": "A Data Scientist is building a linear regression model and will use resulting p-values to evaluate the statistical significance of each coeficient. Upon inspection of the dataset, the Data Scientist discovers that most of the features are normally distributed. The plot of one feature in the dataset is shown in the graphic. What transformation should the Data Scientist apply to satisfy the statistical assumptions of the linear regression model? ", "zhcn": "一位数据科学家正在构建线性回归模型，计划利用得出的p值来评估各个系数的统计显著性。在检查数据集时，这位科学家发现大部分特征呈正态分布。图表展示了数据集中某个特征的分布情况。为满足线性回归模型的统计假设，该数据科学家应当对数据施加何种变换？"}, "option": [{"option_text": {"zhcn": "指数级蜕变", "enus": "Exponential transformation"}, "option_flag": true}, {"option_text": {"zhcn": "对数变换", "enus": "Logarithmic transformation"}, "option_flag": false}, {"option_text": {"zhcn": "多项式变换", "enus": "Polynomial transformation"}, "option_flag": false}, {"option_text": {"zhcn": "正弦变换", "enus": "Sinusoidal transformation"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "107", "question": {"enus": "A Machine Learning Specialist is assigned to a Fraud Detection team and must tune an XGBoost model, which is working appropriately for test data. However, with unknown data, it is not working as expected. The existing parameters are provided as follows. Which parameter tuning guidelines should the Specialist follow to avoid overfitting? ", "zhcn": "一名机器学习专家被分配至欺诈检测团队，需对XGBoost模型进行参数调优。该模型在测试数据上表现良好，但面对未知数据时效果未达预期。现有参数如下所示。为避免过拟合，该专家应遵循哪些参数调优准则？"}, "option": [{"option_text": {"zhcn": "适当增大 max_depth 参数的取值。", "enus": "Increase the max_depth parameter value."}, "option_flag": false}, {"option_text": {"zhcn": "适当调低max_depth参数值。", "enus": "Lower the max_depth parameter value."}, "option_flag": true}, {"option_text": {"zhcn": "将目标函数更新为二元逻辑回归。", "enus": "Update the objective to binary:logistic."}, "option_flag": false}, {"option_text": {"zhcn": "降低 min_child_weight 参数取值。", "enus": "Lower the min_child_weight parameter value."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "108", "question": {"enus": "A data scientist is developing a pipeline to ingest streaming web trafic data. The data scientist needs to implement a process to identify unusual web trafic patterns as part of the pipeline. The patterns will be used downstream for alerting and incident response. The data scientist has access to unlabeled historic data to use, if needed. The solution needs to do the following: ✑ Calculate an anomaly score for each web trafic entry. Adapt unusual event identification to changing web patterns over time. Which approach should the data scientist implement to meet these requirements? ", "zhcn": "一位数据科学家正在构建数据管道，用于处理实时网络流量数据。作为该管道的重要组成部分，需要设计一种能够识别异常流量模式的机制。这些异常模式将用于后续的预警和事件响应流程。如需参考，该科学家可使用未标记的历史数据集。解决方案需满足以下要求：  \n✑ 为每条网络流量记录计算异常分值  \n✑ 使异常识别机制能适应网络流量模式的动态变化  \n请问应当采用何种方法以满足上述需求？"}, "option": [{"option_text": {"zhcn": "利用历史网络流量数据，通过亚马逊SageMaker平台内置的随机切割森林（RCF）模型训练异常检测模型。采用亚马逊Kinesis数据流处理实时传入的网络流量数据，并通过预连接的AWS Lambda预处理函数调用RCF模型计算每条记录的异常分值，从而实现数据增强处理。", "enus": "Use historic web trafic data to train an anomaly detection model using the Amazon SageMaker Random Cut Forest (RCF) built-in model.  Use an Amazon Kinesis Data Stream to process the incoming web trafic data. Attach a preprocessing AWS Lambda function to perform  data enrichment by calling the RCF model to calculate the anomaly score for each record."}, "option_flag": true}, {"option_text": {"zhcn": "利用历史网络流量数据，基于亚马逊SageMaker平台内置的XGBoost模型训练异常检测模型。通过亚马逊Kinesis数据流处理实时传入的网络流量数据，并挂载预处理函数AWS Lambda进行数据增强：调用XGBoost模型为每条记录计算异常分值。", "enus": "Use historic web trafic data to train an anomaly detection model using the Amazon SageMaker built-in XGBoost model. Use an Amazon  Kinesis Data Stream to process the incoming web trafic data. Attach a preprocessing AWS Lambda function to perform data enrichment  by calling the XGBoost model to calculate the anomaly score for each record."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Firehose采集流式数据，将传输流映射为Amazon Kinesis Data Analytics的输入源。通过k近邻算法SQL扩展功能编写实时流数据查询语句，基于滑动窗口为每条记录计算异常分数。", "enus": "Collect the streaming data using Amazon Kinesis Data Firehose. Map the delivery stream as an input source for Amazon Kinesis Data  Analytics. Write a SQL query to run in real time against the streaming data with the k-Nearest Neighbors (kNN) SQL extension to calculate  anomaly scores for each record using a tumbling window."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon Kinesis Data Firehose采集流式数据，将传输流映射为Amazon Kinesis Data Analytics的输入源。通过Amazon随机切割森林（RCF）SQL扩展功能编写实时SQL查询语句，基于滑动窗口对流数据进行计算，从而为每条记录生成异常分值。", "enus": "Collect the streaming data using Amazon Kinesis Data Firehose. Map the delivery stream as an input source for Amazon Kinesis Data  Analytics. Write a SQL query to run in real time against the streaming data with the Amazon Random Cut Forest (RCF) SQL extension to  calculate anomaly scores for each record using a sliding window."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "109", "question": {"enus": "A Data Scientist received a set of insurance records, each consisting of a record ID, the final outcome among 200 categories, and the date of the final outcome. Some partial information on claim contents is also provided, but only for a few of the 200 categories. For each outcome category, there are hundreds of records distributed over the past 3 years. The Data Scientist wants to predict how many claims to expect in each category from month to month, a few months in advance. What type of machine learning model should be used? ", "zhcn": "一位数据科学家获得了一批保险记录，每条记录包含编号、200种分类的最终理赔结果及其判定日期。虽然系统提供了少量分类的理赔内容部分信息，但大多数类别缺乏详细资料。每个结果分类下均有数百条记录，时间跨度覆盖过去三年。该数据科学家需要提前数月预测各类别下每月的理赔数量，请问应当采用何种机器学习模型？"}, "option": [{"option_text": {"zhcn": "基于理赔内容，采用监督学习法对200个类别进行逐月分类。", "enus": "Classification month-to-month using supervised learning of the 200 categories based on claim contents."}, "option_flag": false}, {"option_text": {"zhcn": "基于索赔编号与时间戳的强化学习模型，旨在使智能体能够逐月识别各类别索赔的预期数量。", "enus": "Reinforcement learning using claim IDs and timestamps where the agent will identify how many claims in each category to expect from  month to month."}, "option_flag": false}, {"option_text": {"zhcn": "通过索赔编号与时间戳进行预测，以确定每月各类索赔的预期数量。", "enus": "Forecasting using claim IDs and timestamps to identify how many claims in each category to expect from month to month."}, "option_flag": false}, {"option_text": {"zhcn": "在有监督学习框架下，对已提供部分索赔内容信息的类别进行分类，并针对其余所有类别，基于索赔编号与时间戳进行预测分析。", "enus": "Classification with supervised learning of the categories for which partial information on claim contents is provided, and forecasting  using claim IDs and timestamps for all other categories."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "110", "question": {"enus": "A company that promotes healthy sleep patterns by providing cloud-connected devices currently hosts a sleep tracking application on AWS. The application collects device usage information from device users. The company's Data Science team is building a machine learning model to predict if and when a user will stop utilizing the company's devices. Predictions from this model are used by a downstream application that determines the best approach for contacting users. The Data Science team is building multiple versions of the machine learning model to evaluate each version against the company's business goals. To measure long-term effectiveness, the team wants to run multiple versions of the model in parallel for long periods of time, with the ability to control the portion of inferences served by the models. Which solution satisfies these requirements with MINIMAL effort? ", "zhcn": "一家致力于推广健康睡眠模式的公司，通过其云端互联设备收集用户使用数据，并将睡眠追踪应用程序部署于AWS平台。该公司的数据科学团队正在构建机器学习模型，旨在预测用户是否会停止使用设备及其可能的时间节点。模型预测结果将输送至下游应用程序，用以制定最佳用户联络策略。为评估不同版本模型对业务目标的达成效果，团队需要长期并行运行多个模型版本，并能灵活控制各版本模型的推理请求分配比例。在满足上述需求的前提下，何种解决方案能以最小投入实现这一目标？"}, "option": [{"option_text": {"zhcn": "在 Amazon SageMaker 中构建并托管多个模型。为每个模型创建独立的 Amazon SageMaker 端点，并通过应用程序层编程控制不同模型的推理调用。", "enus": "Build and host multiple models in Amazon SageMaker. Create multiple Amazon SageMaker endpoints, one for each model.  Programmatically control invoking different models for inference at the application layer."}, "option_flag": false}, {"option_text": {"zhcn": "在 Amazon SageMaker 中构建并托管多个模型。通过创建支持多生产变体的端点配置，可动态调控不同模型承载的推理流量比例，只需更新端点配置即可实现程序化流量分配。", "enus": "Build and host multiple models in Amazon SageMaker. Create an Amazon SageMaker endpoint configuration with multiple production  variants. Programmatically control the portion of the inferences served by the multiple models by updating the endpoint configuration."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊SageMaker Neo平台上构建并部署多个模型，以适应不同类型医疗设备的特性。通过编程方式根据医疗设备类型动态调用相应模型进行推理运算。", "enus": "Build and host multiple models in Amazon SageMaker Neo to take into account different types of medical devices. Programmatically  control which model is invoked for inference based on the medical device type."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon SageMaker中构建并托管多个模型。通过统一端点调用不同模型，利用Amazon SageMaker批量转换功能实现对多模型调度的精准管控。", "enus": "Build and host multiple models in Amazon SageMaker. Create a single endpoint that accesses multiple models. Use Amazon  SageMaker batch transform to control invoking the different models through the single endpoint."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "111", "question": {"enus": "An agricultural company is interested in using machine learning to detect specific types of weeds in a 100-acre grassland field. Currently, the company uses tractor-mounted cameras to capture multiple images of the field as 10 ֳ— 10 grids. The company also has a large training dataset that consists of annotated images of popular weed classes like broadleaf and non-broadleaf docks. The company wants to build a weed detection model that will detect specific types of weeds and the location of each type within the field. Once the model is ready, it will be hosted on Amazon SageMaker endpoints. The model will perform real-time inferencing using the images captured by the cameras. Which approach should a Machine Learning Specialist take to obtain accurate predictions? ", "zhcn": "一家农业企业希望借助机器学习技术，在百英亩草场中精准识别特定类型的杂草。目前，该公司采用拖拉机搭载的摄像头将整片草场按10×10的网格进行多角度图像采集，并已拥有包含阔叶类与非阔叶类酸模等常见杂草标注信息的大规模训练数据集。企业计划构建的杂草检测模型需具备双重功能：既要识别杂草的具体品类，又要精准定位各类杂草在田间的分布位置。模型开发完成后，将通过亚马逊SageMaker端点进行部署，利用摄像头实时采集的图像数据执行动态推理。在此场景下，机器学习专家应采取何种方法以确保预测结果的准确性？"}, "option": [{"option_text": {"zhcn": "请将图像预处理为RecordIO格式并上传至Amazon S3存储服务。随后通过Amazon SageMaker平台，运用图像分类算法对模型进行训练、测试与验证，从而实现杂草图像的精准分类。", "enus": "Prepare the images in RecordIO format and upload them to Amazon S3. Use Amazon SageMaker to train, test, and validate the model  using an image classification algorithm to categorize images into various weed classes."}, "option_flag": false}, {"option_text": {"zhcn": "请将图像数据转换为Apache Parquet格式并上传至Amazon S3存储服务。随后通过Amazon SageMaker平台，采用单次多框检测器（SSD）目标识别算法，完成模型的训练、测试与验证工作。", "enus": "Prepare the images in Apache Parquet format and upload them to Amazon S3. Use Amazon SageMaker to train, test, and validate the  model using an object- detection single-shot multibox detector (SSD) algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "请将图像转换为RecordIO格式并上传至Amazon S3存储服务。随后通过Amazon SageMaker平台，运用单次多框检测器（SSD）目标识别算法完成模型的训练、测试与验证工作。", "enus": "Prepare the images in RecordIO format and upload them to Amazon S3. Use Amazon SageMaker to train, test, and validate the model  using an object- detection single-shot multibox detector (SSD) algorithm."}, "option_flag": true}, {"option_text": {"zhcn": "请将图像数据转换为Apache Parquet格式并上传至Amazon S3存储服务。随后运用Amazon SageMaker平台，采用图像分类算法对模型进行训练、测试与验证，以实现对各类杂草图像的精准分类。", "enus": "Prepare the images in Apache Parquet format and upload them to Amazon S3. Use Amazon SageMaker to train, test, and validate the  model using an image classification algorithm to categorize images into various weed classes."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "112", "question": {"enus": "A manufacturer is operating a large number of factories with a complex supply chain relationship where unexpected downtime of a machine can cause production to stop at several factories. A data scientist wants to analyze sensor data from the factories to identify equipment in need of preemptive maintenance and then dispatch a service team to prevent unplanned downtime. The sensor readings from a single machine can include up to 200 data points including temperatures, voltages, vibrations, RPMs, and pressure readings. To collect this sensor data, the manufacturer deployed Wi-Fi and LANs across the factories. Even though many factory locations do not have reliable or high- speed internet connectivity, the manufacturer would like to maintain near-real-time inference capabilities. Which deployment architecture for the model will address these business requirements? ", "zhcn": "某制造商旗下工厂林立，供应链体系错综复杂，单台设备的意外停机便可能引发多个工厂的生产停滞。一位数据科学家计划通过分析工厂传感器数据，精准识别需要预防性维护的设备，并派遣维修团队提前介入，从而避免非计划性停机。单台设备的传感器读数可涵盖温度、电压、振动、转速、压力等高达200个数据指标。为采集这些数据，该制造商在各工厂部署了Wi-Fi和局域网系统。尽管许多厂区缺乏稳定高速的互联网连接，企业仍希望保持近实时推断能力。何种模型部署架构能够满足这些业务需求？"}, "option": [{"option_text": {"zhcn": "将模型部署于Amazon SageMaker平台，通过该模型对传感器数据进行分析，以预测需要维护的设备。", "enus": "Deploy the model in Amazon SageMaker. Run sensor data through this model to predict which machines need maintenance."}, "option_flag": true}, {"option_text": {"zhcn": "在各工厂的AWS IoT Greengrass平台上部署模型，通过该模型分析传感器数据，智能研判需进行维护的设备。", "enus": "Deploy the model on AWS IoT Greengrass in each factory. Run sensor data through this model to infer which machines need  maintenance."}, "option_flag": false}, {"option_text": {"zhcn": "将模型部署至Amazon SageMaker批量转换作业，通过每日批量生成预测报告，精准识别需维护的设备。", "enus": "Deploy the model to an Amazon SageMaker batch transformation job. Generate inferences in a daily batch report to identify machines  that need maintenance."}, "option_flag": false}, {"option_text": {"zhcn": "将模型部署于Amazon SageMaker平台，并通过IoT规则将数据写入Amazon DynamoDB数据表。利用AWS Lambda函数处理DynamoDB数据流，以此调用SageMaker服务端点。", "enus": "Deploy the model in Amazon SageMaker and use an IoT rule to write data to an Amazon DynamoDB table. Consume a DynamoDB  stream from the table with an AWS Lambda function to invoke the endpoint."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "113", "question": {"enus": "A Machine Learning Specialist is designing a scalable data storage solution for Amazon SageMaker. There is an existing TensorFlow-based model implemented as a train.py script that relies on static training data that is currently stored as TFRecords. Which method of providing training data to Amazon SageMaker would meet the business requirements with the LEAST development overhead? ", "zhcn": "一位机器学习专家正在为Amazon SageMaker设计一套可扩展的数据存储方案。现有基于TensorFlow的模型通过train.py脚本实现，目前依赖以TFRecord格式存储的静态训练数据。若要满足业务需求且最大限度降低开发复杂度，应向Amazon SageMaker提供哪种训练数据输入方式？"}, "option": [{"option_text": {"zhcn": "直接使用Amazon SageMaker脚本模式，保持train.py文件不变。将Amazon SageMaker的训练启动路径指向数据的本地存储位置，无需重新格式化训练数据。", "enus": "Use Amazon SageMaker script mode and use train.py unchanged. Point the Amazon SageMaker training invocation to the local path of  the data without reformatting the training data."}, "option_flag": false}, {"option_text": {"zhcn": "采用 Amazon SageMaker 脚本模式，保持 train.py 文件不作改动。将 TFRecord 数据存入 Amazon S3 存储桶中，并在调用 Amazon SageMaker 训练任务时直接指向该 S3 存储桶路径，无需对训练数据格式进行转换。", "enus": "Use Amazon SageMaker script mode and use train.py unchanged. Put the TFRecord data into an Amazon S3 bucket. Point the Amazon  SageMaker training invocation to the S3 bucket without reformatting the training data."}, "option_flag": false}, {"option_text": {"zhcn": "请重写训练脚本，添加将TFRecords转换为Protobuf格式的模块，改为直接读取Protobuf数据而非TFRecords。", "enus": "Rewrite the train.py script to add a section that converts TFRecords to protobuf and ingests the protobuf data instead of TFRecords."}, "option_flag": false}, {"option_text": {"zhcn": "请将数据整理为Amazon SageMaker所支持的格式。可利用AWS Glue或AWS Lambda对数据进行格式转换，并存储至Amazon S3存储桶中。", "enus": "Prepare the data in the format accepted by Amazon SageMaker. Use AWS Glue or AWS Lambda to reformat and store the data in an  Amazon S3 bucket."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "114", "question": {"enus": "The chief editor for a product catalog wants the research and development team to build a machine learning system that can be used to detect whether or not individuals in a collection of images are wearing the company's retail brand. The team has a set of training data. Which machine learning algorithm should the researchers use that BEST meets their requirements? ", "zhcn": "产品图册的主编希望研发团队构建一套机器学习系统，用以检测图集中的人物是否穿着公司旗下零售品牌的服饰。团队已拥有训练数据集。为最精准地满足需求，研究人员应当采用哪种机器学习算法？"}, "option": [{"option_text": {"zhcn": "潜在狄利克雷分布（LDA）", "enus": "Latent Dirichlet Allocation (LDA)"}, "option_flag": false}, {"option_text": {"zhcn": "循环神经网络（RNN）", "enus": "Recurrent neural network (RNN)"}, "option_flag": false}, {"option_text": {"zhcn": "K-means 聚类算法", "enus": "K-means"}, "option_flag": false}, {"option_text": {"zhcn": "卷积神经网络（CNN）", "enus": "Convolutional neural network (CNN)"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "115", "question": {"enus": "A retail company is using Amazon Personalize to provide personalized product recommendations for its customers during a marketing campaign. The company sees a significant increase in sales of recommended items to existing customers immediately after deploying a new solution version, but these sales decrease a short time after deployment. Only historical data from before the marketing campaign is available for training. How should a data scientist adjust the solution? ", "zhcn": "一家零售企业在营销活动期间借助Amazon Personalize平台为顾客提供个性化商品推荐。新解决方案版本上线后，面向现有客户的推荐商品销量短期内显著增长，但不久便出现回落。目前仅能获取营销活动开始前的历史数据进行模型训练，此时数据科学家应如何调整解决方案？"}, "option": [{"option_text": {"zhcn": "利用Amazon Personalize的事件追踪功能，可实时纳入用户互动数据。", "enus": "Use the event tracker in Amazon Personalize to include real-time user interactions."}, "option_flag": false}, {"option_text": {"zhcn": "添加用户元数据，并在Amazon Personalize中采用HRNN-Metadata推荐方案。", "enus": "Add user metadata and use the HRNN-Metadata recipe in Amazon Personalize."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker内置的因子分解机算法实现新型解决方案。", "enus": "Implement a new solution using the built-in factorization machines (FM) algorithm in Amazon SageMaker."}, "option_flag": false}, {"option_text": {"zhcn": "为Amazon Personalize交互数据集添加事件类型与事件数值字段。", "enus": "Add event type and event value fields to the interactions dataset in Amazon Personalize."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "116", "question": {"enus": "A machine learning (ML) specialist wants to secure calls to the Amazon SageMaker Service API. The specialist has configured Amazon VPC with a VPC interface endpoint for the Amazon SageMaker Service API and is attempting to secure trafic from specific sets of instances and IAM users. The VPC is configured with a single public subnet. Which combination of steps should the ML specialist take to secure the trafic? (Choose two.) ", "zhcn": "一位机器学习专家需确保对Amazon SageMaker服务API的调用安全。该专家已为Amazon SageMaker服务API配置了具备VPC接口端点的Amazon VPC，并试图限制来自特定实例组和IAM用户的流量。该VPC目前仅配置一个公共子网。请问该机器学习专家应采取哪两项组合措施来保障流量安全？（请选择两项）"}, "option": [{"option_text": {"zhcn": "为VPC终端节点添加访问策略，允许IAM用户进行访问。", "enus": "Add a VPC endpoint policy to allow access to the IAM users."}, "option_flag": true}, {"option_text": {"zhcn": "修改用户的IAM策略，使其仅允许访问Amazon SageMaker服务的API调用。", "enus": "Modify the users' IAM policy to allow access to Amazon SageMaker Service API calls only."}, "option_flag": false}, {"option_text": {"zhcn": "调整终端网络接口上的安全组设置，以限制对实例的访问权限。", "enus": "Modify the security group on the endpoint network interface to restrict access to the instances."}, "option_flag": true}, {"option_text": {"zhcn": "调整终端网络接口的访问控制列表，以限制对实例的访问权限。", "enus": "Modify the ACL on the endpoint network interface to restrict access to the instances."}, "option_flag": false}, {"option_text": {"zhcn": "为VPC添加一个SageMaker运行时VPC端点接口。", "enus": "Add a SageMaker Runtime VPC endpoint interface to the VPC."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/private-package-installation-in-amazon-sagemaker-running-in-internet-free-mode/", "zhcn": ""}, "answer": "AC"}, {"id": "117", "question": {"enus": "An e commerce company wants to launch a new cloud-based product recommendation feature for its web application. Due to data localization regulations, any sensitive data must not leave its on-premises data center, and the product recommendation model must be trained and tested using nonsensitive data only. Data transfer to the cloud must use IPsec. The web application is hosted on premises with a PostgreSQL database that contains all the data. The company wants the data to be uploaded securely to Amazon S3 each day for model retraining. How should a machine learning specialist meet these requirements? ", "zhcn": "一家电子商务公司计划为其网络应用程序推出一项新的云端产品推荐功能。根据数据本地化法规的要求，所有敏感数据不得离开本地数据中心，且产品推荐模型仅能使用非敏感数据进行训练和测试。数据传输至云端时必须采用IPsec协议。该网络应用程序部署于本地环境，其PostgreSQL数据库存储了全部数据。公司希望每日将数据安全上传至亚马逊S3存储服务，以便重新训练模型。机器学习专家应如何满足这些要求？"}, "option": [{"option_text": {"zhcn": "创建一个AWS Glue作业，用于连接PostgreSQL数据库实例。通过AWS站点到站点VPN连接，将不含敏感数据的表直接导入Amazon S3存储桶。", "enus": "Create an AWS Glue job to connect to the PostgreSQL DB instance. Ingest tables without sensitive data through an AWS Site-to-Site  VPN connection directly into Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个AWS Glue作业以连接PostgreSQL数据库实例。通过AWS站点到站点VPN连接将所有数据摄取至Amazon S3存储服务，并利用PySpark作业实现敏感数据的过滤清除。", "enus": "Create an AWS Glue job to connect to the PostgreSQL DB instance. Ingest all data through an AWS Site-to-Site VPN connection into  Amazon S3 while removing sensitive data using a PySpark job."}, "option_flag": false}, {"option_text": {"zhcn": "通过SSL连接，使用AWS数据库迁移服务（AWS DMS）并配合表映射功能，筛选不含敏感数据的PostgreSQL数据表，将数据直接复制至Amazon S3存储服务。", "enus": "Use AWS Database Migration Service (AWS DMS) with table mapping to select PostgreSQL tables with no sensitive data through an SSL  connection. Replicate data directly into Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "采用PostgreSQL逻辑复制功能，通过AWS Direct Connect结合VPN连接将全部数据同步至Amazon EC2中的PostgreSQL数据库。随后借助AWS Glue将数据从Amazon EC2迁移至Amazon S3存储服务。", "enus": "Use PostgreSQL logical replication to replicate all data to PostgreSQL in Amazon EC2 through AWS Direct Connect with a VPN  connection. Use AWS Glue to move data from Amazon EC2 to Amazon S3."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Source.PostgreSQL.html", "zhcn": ""}, "answer": "C"}, {"id": "118", "question": {"enus": "A logistics company needs a forecast model to predict next month's inventory requirements for a single item in 10 warehouses. A machine learning specialist uses Amazon Forecast to develop a forecast model from 3 years of monthly data. There is no missing data. The specialist selects the DeepAR+ algorithm to train a predictor. The predictor means absolute percentage error (MAPE) is much larger than the MAPE produced by the current human forecasters. Which changes to the CreatePredictor API call could improve the MAPE? (Choose two.) ", "zhcn": "一家物流公司需要一种预测模型，用以预估未来一个月内10个仓库对某单一商品的库存需求。一位机器学习专家运用Amazon Forecast服务平台，基于三年间的月度数据构建预测模型。数据集完整无缺失。该专家选用DeepAR+算法训练预测器，但所得预测器的平均绝对百分比误差（MAPE）远高于现行人工预测的误差值。请问对CreatePredictor API调用进行哪些调整可改善MAPE指标？（请选择两项正确方案）"}, "option": [{"option_text": {"zhcn": "将 PerformAutoML 设为启用。", "enus": "Set PerformAutoML to true."}, "option_flag": false}, {"option_text": {"zhcn": "将预测范围设定为4个时间单位。", "enus": "Set ForecastHorizon to 4."}, "option_flag": false}, {"option_text": {"zhcn": "将预测频率设为W，表示按周更新。", "enus": "Set ForecastFrequency to W for weekly."}, "option_flag": true}, {"option_text": {"zhcn": "将 PerformHPO 设为启用。", "enus": "Set PerformHPO to true."}, "option_flag": true}, {"option_text": {"zhcn": "将特征化方法名称设为填充。", "enus": "Set FeaturizationMethodName to filling."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/forecast/latest/dg/forecast.dg.pdf", "zhcn": ""}, "answer": "CD"}, {"id": "119", "question": {"enus": "A data scientist wants to use Amazon Forecast to build a forecasting model for inventory demand for a retail company. The company has provided a dataset of historic inventory demand for its products as a .csv file stored in an Amazon S3 bucket. The table below shows a sample of the dataset. How should the data scientist transform the data? ", "zhcn": "一位数据科学家计划利用Amazon Forecast平台，为某零售企业构建库存需求预测模型。该企业已提供历史库存需求数据集，文件格式为.csv，存储于Amazon S3存储桶中。下表为数据集示例。请问这位数据科学家应当如何对数据进行预处理？"}, "option": [{"option_text": {"zhcn": "在AWS Glue中配置ETL任务，将原始数据集拆分为目标时间序列数据集与商品元数据集。随后将两类数据集以.csv格式上传至Amazon S3存储服务。", "enus": "Use ETL jobs in AWS Glue to separate the dataset into a target time series dataset and an item metadata dataset. Upload both  datasets as .csv files to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon SageMaker中运用Jupyter笔记本，将数据集拆分为关联时间序列数据集和项目元数据集。随后将这两个数据集作为数据表上传至Amazon Aurora。", "enus": "Use a Jupyter notebook in Amazon SageMaker to separate the dataset into a related time series dataset and an item metadata  dataset. Upload both datasets as tables in Amazon Aurora."}, "option_flag": true}, {"option_text": {"zhcn": "利用AWS Batch作业将数据集拆分为目标时间序列数据集、关联时间序列数据集以及项目元数据集。随后直接从本地设备将这些数据集上传至Forecast平台。", "enus": "Use AWS Batch jobs to separate the dataset into a target time series dataset, a related time series dataset, and an item metadata  dataset. Upload them directly to Forecast from a local machine."}, "option_flag": false}, {"option_text": {"zhcn": "在 Amazon SageMaker 中使用 Jupyter Notebook 将数据转换为优化的 protobuf recordIO 格式，并将该格式的数据集上传至 Amazon S3。", "enus": "Use a Jupyter notebook in Amazon SageMaker to transform the data into the optimized protobuf recordIO format. Upload the dataset in  this format to Amazon S3."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "120", "question": {"enus": "A machine learning specialist is running an Amazon SageMaker endpoint using the built-in object detection algorithm on a P3 instance for real-time predictions in a company's production application. When evaluating the model's resource utilization, the specialist notices that the model is using only a fraction of the GPU. Which architecture changes would ensure that provisioned resources are being utilized effectively? ", "zhcn": "一位机器学习专家正在某公司的生产应用中，通过P3实例运行搭载内置目标检测算法的Amazon SageMaker终端节点，以进行实时预测。在评估模型资源利用率时，该专家发现模型仅占用了部分GPU资源。应采取何种架构调整方案，才能确保已配置的资源得到高效利用？"}, "option": [{"option_text": {"zhcn": "将模型重新部署为M5实例上的批量转换任务。", "enus": "Redeploy the model as a batch transform job on an M5 instance."}, "option_flag": false}, {"option_text": {"zhcn": "将模型重新部署至M5实例，并为该实例配置亚马逊弹性推理加速器。", "enus": "Redeploy the model on an M5 instance. Attach Amazon Elastic Inference to the instance."}, "option_flag": false}, {"option_text": {"zhcn": "将模型重新部署于P3dn实例之上。", "enus": "Redeploy the model on a P3dn instance."}, "option_flag": false}, {"option_text": {"zhcn": "将模型部署至采用P3实例的亚马逊弹性容器服务（Amazon ECS）集群。", "enus": "Deploy the model onto an Amazon Elastic Container Service (Amazon ECS) cluster using a P3 instance."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "121", "question": {"enus": "A data scientist uses an Amazon SageMaker notebook instance to conduct data exploration and analysis. This requires certain Python packages that are not natively available on Amazon SageMaker to be installed on the notebook instance. How can a machine learning specialist ensure that required packages are automatically available on the notebook instance for the data scientist to use? ", "zhcn": "一位数据科学家利用亚马逊SageMaker笔记实例进行数据探索与分析。由于某些必需的Python程序包并未预装在Amazon SageMaker环境中，需要将这些程序包安装至笔记实例。机器学习专家应当采取何种措施，才能确保所需程序包能自动配置于笔记实例中供数据科学家直接调用？"}, "option": [{"option_text": {"zhcn": "在底层Amazon EC2实例上安装AWS Systems Manager代理，并运用Systems Manager自动化服务执行软件包安装命令。", "enus": "Install AWS Systems Manager Agent on the underlying Amazon EC2 instance and use Systems Manager Automation to execute the  package installation commands."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个Jupyter笔记本文件（.ipynb格式），其中包含待执行的软件包安装命令单元，并将该文件置于每个Amazon SageMaker笔记本实例的/etc/init目录下。", "enus": "Create a Jupyter notebook file (.ipynb) with cells containing the package installation commands to execute and place the file under the  /etc/init directory of each Amazon SageMaker notebook instance."}, "option_flag": true}, {"option_text": {"zhcn": "在Jupyter Notebook控制台中，通过conda包管理器为当前笔记本的默认内核配置必要的conda软件包。", "enus": "Use the conda package manager from within the Jupyter notebook console to apply the necessary conda packages to the default kernel  of the notebook."}, "option_flag": false}, {"option_text": {"zhcn": "为Amazon SageMaker创建包含软件包安装命令的生命周期配置，并将此配置关联至指定的笔记本实例。", "enus": "Create an Amazon SageMaker lifecycle configuration with package installation commands and assign the lifecycle configuration to the  notebook instance."}, "option_flag": false}], "analysis": {"enus": "Reference: https://towardsdatascience.com/automating-aws-sagemaker-notebooks-2dec62bc2c84", "zhcn": ""}, "answer": "B"}, {"id": "122", "question": {"enus": "A data scientist needs to identify fraudulent user accounts for a company's ecommerce platform. The company wants the ability to determine if a newly created account is associated with a previously known fraudulent user. The data scientist is using AWS Glue to cleanse the company's application logs during ingestion. Which strategy will allow the data scientist to identify fraudulent accounts? ", "zhcn": "一位数据科学家需要为某公司的电商平台识别欺诈用户账户。该公司希望能够在新建账户时，判断其是否与已知的欺诈用户存在关联。该数据科学家正在使用AWS Glue对平台的应用日志进行数据清洗处理。请问采取何种策略可有效识别欺诈账户？"}, "option": [{"option_text": {"zhcn": "执行内置的重复项查找Amazon Athena查询。", "enus": "Execute the built-in FindDuplicates Amazon Athena query."}, "option_flag": false}, {"option_text": {"zhcn": "在AWS Glue中创建一个用于查找匹配项的机器学习转换任务。", "enus": "Create a FindMatches machine learning transform in AWS Glue."}, "option_flag": true}, {"option_text": {"zhcn": "创建一个AWS Glue爬虫程序，用于自动识别源数据中的重复账户信息。", "enus": "Create an AWS Glue crawler to infer duplicate accounts in the source data."}, "option_flag": false}, {"option_text": {"zhcn": "在AWS Glue数据目录中查找重复账户。", "enus": "Search for duplicate accounts in the AWS Glue Data Catalog."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/glue/latest/dg/machine-learning.html", "zhcn": ""}, "answer": "B"}, {"id": "123", "question": {"enus": "A Data Scientist is developing a machine learning model to classify whether a financial transaction is fraudulent. The labeled data available for training consists of 100,000 non-fraudulent observations and 1,000 fraudulent observations. The Data Scientist applies the XGBoost algorithm to the data, resulting in the following confusion matrix when the trained model is applied to a previously unseen validation dataset. The accuracy of the model is 99.1%, but the Data Scientist needs to reduce the number of false negatives. Which combination of steps should the Data Scientist take to reduce the number of false negative predictions by the model? (Choose two.) ", "zhcn": "一位数据科学家正在开发一个用于甄别金融交易是否涉嫌欺诈的机器学习模型。现有训练标签数据包含10万条正常交易记录与1000条欺诈交易记录。该科学家采用XGBoost算法对数据进行训练，当模型在未参与训练的验证数据集上测试时，得出如下混淆矩阵。模型准确率虽达99.1%，但需降低伪阴性判定数量。请问应采取哪两项措施来减少模型的伪阴性预测结果？（请选择两项）"}, "option": [{"option_text": {"zhcn": "将XGBoost的eval_metric参数调整为基于均方根误差（RMSE）进行优化。", "enus": "Change the XGBoost eval_metric parameter to optimize based on Root Mean Square Error (RMSE)."}, "option_flag": false}, {"option_text": {"zhcn": "适当提高XGBoost模型的scale_pos_weight参数值，可有效调节正负样本的权重平衡。", "enus": "Increase the XGBoost scale_pos_weight parameter to adjust the balance of positive and negative weights."}, "option_flag": false}, {"option_text": {"zhcn": "建议适当增大XGBoost模型的max_depth参数，当前模型存在对数据拟合不足的情况。", "enus": "Increase the XGBoost max_depth parameter because the model is currently underfitting the data."}, "option_flag": false}, {"option_text": {"zhcn": "将XGBoost的eval_metric参数调整为以ROC曲线下面积（AUC）作为优化指标。", "enus": "Change the XGBoost eval_metric parameter to optimize based on Area Under the ROC Curve (AUC)."}, "option_flag": true}, {"option_text": {"zhcn": "降低XGBoost模型的max_depth参数值，以缓解当前模型对数据的过拟合现象。", "enus": "Decrease the XGBoost max_depth parameter because the model is currently overfitting the data."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "DE"}, {"id": "124", "question": {"enus": "A data scientist has developed a machine learning translation model for English to Japanese by using Amazon SageMaker's built-in seq2seq algorithm with 500,000 aligned sentence pairs. While testing with sample sentences, the data scientist finds that the translation quality is reasonable for an example as short as five words. However, the quality becomes unacceptable if the sentence is 100 words long. Which action will resolve the problem? ", "zhcn": "一位数据科学家运用亚马逊SageMaker平台内置的seq2seq算法，基于50万组对齐的英日双语语料，开发了英语至日语的机器学习翻译模型。在样例测试中，数据科学家发现该模型对五词左右的短句尚能生成合理译文，但当句子长度增至百词时，翻译质量便急剧下降至不可接受的程度。下列哪项措施能有效解决此问题？"}, "option": [{"option_text": {"zhcn": "将预处理方式调整为采用n-gram分词法。", "enus": "Change preprocessing to use n-grams."}, "option_flag": false}, {"option_text": {"zhcn": "为提升循环神经网络（RNN）的性能，其隐含层节点数应超过训练语料中最长句子的词汇总量。", "enus": "Add more nodes to the recurrent neural network (RNN) than the largest sentence's word count."}, "option_flag": true}, {"option_text": {"zhcn": "调整与注意力机制相关的超参数。", "enus": "Adjust hyperparameters related to the attention mechanism."}, "option_flag": false}, {"option_text": {"zhcn": "请选用另一种权重初始化方式。", "enus": "Choose a different weight initialization type."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "125", "question": {"enus": "A financial company is trying to detect credit card fraud. The company observed that, on average, 2% of credit card transactions were fraudulent. A data scientist trained a classifier on a year's worth of credit card transactions data. The model needs to identify the fraudulent transactions (positives) from the regular ones (negatives). The company's goal is to accurately capture as many positives as possible. Which metrics should the data scientist use to optimize the model? (Choose two.) ", "zhcn": "一家金融公司正致力于检测信用卡欺诈行为。据观察，信用卡交易中平均约有2%存在欺诈情况。数据科学家基于全年信用卡交易数据训练了一个分类模型，该模型需从常规交易（负类）中准确识别欺诈交易（正类）。公司的核心目标是尽可能全面地捕捉所有正类样本。请问数据科学家应优先采用哪两项指标来优化模型？（请选择两项）"}, "option": [{"option_text": {"zhcn": "“专一性”", "enus": "Specificity"}, "option_flag": true}, {"option_text": {"zhcn": "误报率", "enus": "False positive rate"}, "option_flag": true}, {"option_text": {"zhcn": "精准", "enus": "Accuracy"}, "option_flag": false}, {"option_text": {"zhcn": "精确率-召回率曲线下面积", "enus": "Area under the precision-recall curve"}, "option_flag": false}, {"option_text": {"zhcn": "真阳性率", "enus": "True positive rate"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AB"}, {"id": "126", "question": {"enus": "A machine learning specialist is developing a proof of concept for government users whose primary concern is security. The specialist is using Amazon SageMaker to train a convolutional neural network (CNN) model for a photo classifier application. The specialist wants to protect the data so that it cannot be accessed and transferred to a remote host by malicious code accidentally installed on the training container. Which action will provide the MOST secure protection? ", "zhcn": "一位机器学习专家正为对安全性有极高要求的政府用户开发概念验证项目。该专家使用Amazon SageMaker训练卷积神经网络模型，用于照片分类应用。为确保训练容器在意外安装恶意代码的情况下，数据不会被访问并传输至远程主机，下列哪种措施能提供最高级别的安全防护？"}, "option": [{"option_text": {"zhcn": "移除SageMaker执行角色对Amazon S3的访问权限。", "enus": "Remove Amazon S3 access permissions from the SageMaker execution role."}, "option_flag": false}, {"option_text": {"zhcn": "对卷积神经网络模型的权重进行加密处理。", "enus": "Encrypt the weights of the CNN model."}, "option_flag": false}, {"option_text": {"zhcn": "对训练集与验证集数据进行加密处理。", "enus": "Encrypt the training and validation dataset."}, "option_flag": false}, {"option_text": {"zhcn": "为训练任务启用网络隔离。", "enus": "Enable network isolation for training jobs."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "127", "question": {"enus": "A medical imaging company wants to train a computer vision model to detect areas of concern on patients' CT scans. The company has a large collection of unlabeled CT scans that are linked to each patient and stored in an Amazon S3 bucket. The scans must be accessible to authorized users only. A machine learning engineer needs to build a labeling pipeline. Which set of steps should the engineer take to build the labeling pipeline with the LEAST effort? ", "zhcn": "一家医学影像公司计划训练计算机视觉模型，用于识别患者CT扫描中的可疑区域。该公司拥有大量未标注的CT扫描数据，这些数据与患者信息关联并存储在亚马逊S3存储桶中，且仅限授权用户访问。机器学习工程师需要构建标注流程，请问采用以下哪组步骤能以最小工作量完成该流程的搭建？"}, "option": [{"option_text": {"zhcn": "借助AWS身份与访问管理服务（IAM）构建标注团队。基于亚马逊弹性计算云（EC2）搭建标注工具，通过亚马逊简单队列服务（SQS）实现待标注图像的队列管理。撰写清晰明确的标注规范说明。", "enus": "Create a workforce with AWS Identity and Access Management (IAM). Build a labeling tool on Amazon EC2 Queue images for labeling  by using Amazon Simple Queue Service (Amazon SQS). Write the labeling instructions."}, "option_flag": false}, {"option_text": {"zhcn": "创建亚马逊土耳其机器人（Amazon Mechanical Turk）工作团队及清单文件。利用亚马逊SageMaker Ground Truth内置的图像分类任务类型创建标注任务，并撰写标注指南。", "enus": "Create an Amazon Mechanical Turk workforce and manifest file. Create a labeling job by using the built-in image classification task  type in Amazon SageMaker Ground Truth. Write the labeling instructions."}, "option_flag": true}, {"option_text": {"zhcn": "创建专属标注团队及配置文件。利用Amazon SageMaker Ground Truth内置的边界框任务类型，创建数据标注任务。编写标注指南说明。", "enus": "Create a private workforce and manifest file. Create a labeling job by using the built-in bounding box task type in Amazon SageMaker  Ground Truth. Write the labeling instructions."}, "option_flag": false}, {"option_text": {"zhcn": "借助Amazon Cognito组建标注团队。  \n使用AWS Amplify构建标注网络应用。  \n基于AWS Lambda开发标注流程后端。  \n撰写标注任务说明文档。", "enus": "Create a workforce with Amazon Cognito. Build a labeling web application with AWS Amplify. Build a labeling workfiow backend using  AWS Lambda. Write the labeling instructions."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "128", "question": {"enus": "A company is using Amazon Textract to extract textual data from thousands of scanned text-heavy legal documents daily. The company uses this information to process loan applications automatically. Some of the documents fail business validation and are returned to human reviewers, who investigate the errors. This activity increases the time to process the loan applications. What should the company do to reduce the processing time of loan applications? ", "zhcn": "某公司每日借助Amazon Textract从数千份扫描版的法律文书中提取文本数据，并利用这些信息自动处理贷款申请。部分文件未能通过业务验证时，会转交人工审核团队进行差错核查。这一环节导致贷款申请的整体处理时长增加。为提升贷款申请的处理效率，该公司应采取何种改进措施？"}, "option": [{"option_text": {"zhcn": "配置Amazon Textract将低置信度预测结果路由至Amazon SageMaker Ground Truth。在对这些词汇进行业务验证前，需先执行人工审核。", "enus": "Configure Amazon Textract to route low-confidence predictions to Amazon SageMaker Ground Truth. Perform a manual review on those  words before performing a business validation."}, "option_flag": false}, {"option_text": {"zhcn": "建议采用亚马逊Textract的同步操作模式，而非异步操作方式。", "enus": "Use an Amazon Textract synchronous operation instead of an asynchronous operation."}, "option_flag": false}, {"option_text": {"zhcn": "配置Amazon Textract将低置信度预测结果路由至Amazon Augmented AI（Amazon A2I）平台。在执行业务验证前，需对这些识别结果进行人工审核校验。", "enus": "Configure Amazon Textract to route low-confidence predictions to Amazon Augmented AI (Amazon A2I). Perform a manual review on  those words before performing a business validation."}, "option_flag": true}, {"option_text": {"zhcn": "利用亚马逊Rekognition的图像文本识别功能，可从扫描图像中提取所需数据。借助此项技术，可高效处理贷款申请业务。", "enus": "Use Amazon Rekognition's feature to detect text in an image to extract the data from scanned images. Use this information to process  the loan applications."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "129", "question": {"enus": "A company ingests machine learning (ML) data from web advertising clicks into an Amazon S3 data lake. Click data is added to an Amazon Kinesis data stream by using the Kinesis Producer Library (KPL). The data is loaded into the S3 data lake from the data stream by using an Amazon Kinesis Data Firehose delivery stream. As the data volume increases, an ML specialist notices that the rate of data ingested into Amazon S3 is relatively constant. There also is an increasing backlog of data for Kinesis Data Streams and Kinesis Data Firehose to ingest. Which next step is MOST likely to improve the data ingestion rate into Amazon S3? ", "zhcn": "某公司通过亚马逊Kinesis数据流，将网络广告点击产生的机器学习数据注入亚马逊S3数据湖。数据经由Kinesis生产者库（KPL）写入数据流后，再通过Kinesis数据火线传输通道加载至S3数据湖。随着数据量持续增长，机器学习专家发现注入S3数据湖的速率趋于平稳，但Kinesis数据流与数据火线传输通道待处理的数据积压却不断加剧。要提升数据注入S3的速率，下列哪项措施最可能立竿见影？"}, "option": [{"option_text": {"zhcn": "为提升数据流写入效率，现需增加其可写入的S3前缀数量。", "enus": "Increase the number of S3 prefixes for the delivery stream to write to."}, "option_flag": false}, {"option_text": {"zhcn": "缩短数据流的保留期限。", "enus": "Decrease the retention period for the data stream."}, "option_flag": false}, {"option_text": {"zhcn": "请为该数据流增加分片数量。", "enus": "Increase the number of shards for the data stream."}, "option_flag": true}, {"option_text": {"zhcn": "增加使用Kinesis客户端库（KCL）的消费者数量。", "enus": "Add more consumers using the Kinesis Client Library (KCL)."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "130", "question": {"enus": "A data scientist must build a custom recommendation model in Amazon SageMaker for an online retail company. Due to the nature of the company's products, customers buy only 4-5 products every 5-10 years. So, the company relies on a steady stream of new customers. When a new customer signs up, the company collects data on the customer's preferences. Below is a sample of the data available to the data scientist. How should the data scientist split the dataset into a training and test set for this use case? ", "zhcn": "某在线零售公司需由其数据科学家在Amazon SageMaker平台上构建定制化推荐模型。鉴于该公司产品特性，客户每5至10年仅会购买4至5次商品，因此业务依赖持续的新客流入。当新客户注册时，公司会收集其偏好数据。以下为数据科学家可获取的样本数据示例。针对这一应用场景，数据科学家应如何将数据集划分为训练集与测试集？"}, "option": [{"option_text": {"zhcn": "打乱所有交互数据，并将最后10%的交互数据留作测试集。", "enus": "Shufie all interaction data. Split off the last 10% of the interaction data for the test set."}, "option_flag": false}, {"option_text": {"zhcn": "为每位用户筛选出最近10%的互动记录，并将这部分数据划入测试集。", "enus": "Identify the most recent 10% of interactions for each user. Split off these interactions for the test set."}, "option_flag": false}, {"option_text": {"zhcn": "筛选出交互数据最少的10%用户，并将这部分用户的所有互动记录划入测试集。", "enus": "Identify the 10% of users with the least interaction data. Split off all interaction data from these users for the test set."}, "option_flag": false}, {"option_text": {"zhcn": "随机抽取10%的用户，并将这些用户的所有交互数据划入测试集。", "enus": "Randomly select 10% of the users. Split off all interaction data from these users for the test set."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "131", "question": {"enus": "A financial services company wants to adopt Amazon SageMaker as its default data science environment. The company's data scientists run machine learning (ML) models on confidential financial data. The company is worried about data egress and wants an ML engineer to secure the environment. Which mechanisms can the ML engineer use to control data egress from SageMaker? (Choose three.) ", "zhcn": "一家金融服务公司计划将Amazon SageMaker确定为其标准数据科学环境。该公司的数据科学家需基于机密财务数据运行机器学习模型。由于担忧数据外泄风险，公司希望机器学习工程师能够加固此环境。请问该机器学习工程师可采用以下哪三种机制来控制SageMaker的数据外泄？（请选择三项）"}, "option": [{"option_text": {"zhcn": "通过AWS PrivateLink支持的VPC接口端点连接至SageMaker。", "enus": "Connect to SageMaker by using a VPC interface endpoint powered by AWS PrivateLink."}, "option_flag": false}, {"option_text": {"zhcn": "利用SCPs限制对SageMaker的访问权限。", "enus": "Use SCPs to restrict access to SageMaker."}, "option_flag": true}, {"option_text": {"zhcn": "在SageMaker笔记本实例中禁用根用户访问权限。", "enus": "Disable root access on the SageMaker notebook instances."}, "option_flag": false}, {"option_text": {"zhcn": "为训练任务和模型启用网络隔离。", "enus": "Enable network isolation for training jobs and models."}, "option_flag": true}, {"option_text": {"zhcn": "将笔记本预签名链接的使用范围限定于公司指定的IP地址。", "enus": "Restrict notebook presigned URLs to specific IPs used by the company."}, "option_flag": false}, {"option_text": {"zhcn": "对静态存储与动态传输中的数据均实施加密保护，并运用AWS密钥管理服务（AWS KMS）统一管理加密密钥。", "enus": "Protect data with encryption at rest and in transit. Use AWS Key Management Service (AWS KMS) to manage encryption keys."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BDF"}, {"id": "132", "question": {"enus": "A company needs to quickly make sense of a large amount of data and gain insight from it. The data is in different formats, the schemas change frequently, and new data sources are added regularly. The company wants to use AWS services to explore multiple data sources, suggest schemas, and enrich and transform the data. The solution should require the least possible coding effort for the data fiows and the least possible infrastructure management. Which combination of AWS services will meet these requirements? A. ✑ Amazon EMR for data discovery, enrichment, and transformation ✑ Amazon Athena for querying and analyzing the results in Amazon S3 using standard SQL ✑ Amazon QuickSight for reporting and getting insights B. ✑ Amazon Kinesis Data Analytics for data ingestion ✑ Amazon EMR for data discovery, enrichment, and transformation ✑ Amazon Redshift for querying and analyzing the results in Amazon S3 C. ✑ AWS Glue for data discovery, enrichment, and transformation ✑ Amazon Athena for querying and analyzing the results in Amazon S3 using standard SQL ✑ Amazon QuickSight for reporting and getting insights D. ✑ AWS Data Pipeline for data transfer ✑ AWS Step Functions for orchestrating AWS Lambda jobs for data discovery, enrichment, and transformation ✑ Amazon Athena for querying and analyzing the results in Amazon S3 using standard SQL ✑ Amazon QuickSight for reporting and getting insights Correct Answer: A   knightknt Highly Voted  2years, 3months ago I would choose C. upvoted 44 times   ovokpus Highly Voted  2years, 1month ago Answer here is C. Glue, Athena and Quicksight are serverless and need little code (only SQL) upvoted 11 times   ArunRav Most Recent  2months, 1week ago Answer is C, all serverless upvoted 1 times   Noname3562 4months ago I woul choose C as well upvoted 1 times   endeesa 8months, 1week ago In the presence of AWS Glue, with a goal to minimise coding efforts. C is the correct answer upvoted 1 times   u_b 8months, 3weeks ago I also chose C. A has code/infra overhead of EMR. B is wrong b/c you dont query S3 with redshift D is overhead from orchestrating lambda jobs with step funcs upvoted 1 times   qsergii 8months, 3weeks ago AWS Glue CROWLER for data discovery upvoted 1 times   Snape 9months, 1week ago C is correct upvoted 2 times   jopaca1216 10months, 3weeks ago The correct is C upvoted 1 times 店铺：IT认证考试服务  Mickey321 11months, 1week ago Why no voting option? It is option C upvoted 4 times   kazivebtak 1year ago C is correct upvoted 2 times   ADVIT 1year, 1month ago I think it's C upvoted 1 times   mixonfreddy 1year, 1month ago Answer is C, all serverless upvoted 1 times   Ahmedhadi_ 1year, 3months ago answer is c as data sources varies alot so requires glue crawler upvoted 1 times   mite_gvg 1year, 3months ago C Is correct, you use Glue for ingestion upvoted 2 times   codehive 1year, 3months ago Option C is the most suitable choice to meet the given requirements. AWS Glue is a fully managed extract, transform, and load (ETL) service that allows users to discover, enrich, and transform data easily, without the need for extensive coding. It supports different data sources, schema detection, and schema evolution, which makes it an ideal choice for the given scenario. Amazon Athena, a serverless interactive query service, allows users to run standard SQL queries against data stored in Amazon S3, which makes it easy to analyze the enriched and transformed data. Amazon QuickSight is a cloud-based business intelligence service that can connect to various data sources, including Amazon Athena, to create interactive dashboards and reports, which makes it a suitable choice for gaining insights from the data. upvoted 1 times   codehive 1year, 3months ago Option A is not an ideal choice because Amazon EMR is a heavy-weight service and requires more infrastructure management than AWS Glue. upvoted 1 times   Siyuan_Zhu 1year, 5months ago Go with C here upvoted 1 times 店铺：IT认证考试服务", "zhcn": "一家公司需要快速理解海量数据并从中获取洞见。这些数据格式各异、结构频繁变动，且会定期新增数据源。该公司希望借助AWS服务实现多数据源探查、自动生成数据结构建议，并完成数据增强与转换。整个解决方案应最大限度减少数据流所需的编码工作，并尽可能降低基础设施管理负担。下列哪组AWS服务组合符合这些要求？\n\nA. \n✑ 采用Amazon EMR进行数据探查、增强与转换\n✑ 通过Amazon Athena使用标准SQL查询分析Amazon S3中的结果\n✑ 使用Amazon QuickSight生成报告并获取洞见\n\nB. \n✑ 通过Amazon Kinesis Data Analytics进行数据摄取\n✑ 采用Amazon EMR进行数据探查、增强与转换\n✑ 使用Amazon Redshift查询分析Amazon S3中的结果\n\nC. \n✑ 通过AWS Glue实现数据探查、增强与转换\n✑ 通过Amazon Athena使用标准SQL查询分析Amazon S3中的结果\n✑ 使用Amazon QuickSight生成报告并获取洞见\n\nD. \n✑ 采用AWS Data Pipeline进行数据传输\n✑ 通过AWS Step Functions编排AWS Lambda任务实现数据探查、增强与转换\n✑ 通过Amazon Athena使用标准SQL查询分析Amazon S3中的结果\n✑ 使用Amazon QuickSight生成报告并获取洞见\n\n正确答案：A\n\n▨ knightknt 高赞回答 ▤ 2年3个月前  \n我选择C。  \n获赞44次\n\n▨ ovokpus 高赞回答 ▤ 2年1个月前  \n正确答案是C。Glue、Athena和Quicksight都是无服务器架构，且只需少量代码（仅需SQL）  \n获赞11次\n\n▨ ArunRav 最新回答 ▤ 2个月前  \n答案是C，全无服务器方案  \n获赞1次\n\n▨ Noname3562 4个月前  \n我也选C  \n获赞1次\n\n▨ endeesa 8个月前  \n考虑到使用AWS Glue且要最小化编码工作量，C是正确答案  \n获赞1次\n\n▨ u_b 8个月前  \n同样选择C。A方案涉及EMR的代码/基础设施开销；B方案错误因为不能用Redshift查询S3；D方案通过Step Functions编排Lambda任务会产生额外开销  \n获赞1次\n\n▨ qsergii 8个月前  \nAWS Glue爬虫用于数据探查  \n获赞1次\n\n▨ Snape 9个月前  \nC正确  \n获赞2次\n\n▨ jopaca1216 10个月前  \n正确答案是C  \n获赞1次\n\n店铺：IT认证考试服务  \n▨ Mickey321 11个月前  \n为什么没有投票选项？应该选C  \n获赞4次\n\n▨ kazivebtak 1年前  \nC正确  \n获赞2次\n\n▨ ADVIT 1年前  \n我认为是C  \n获赞1次\n\n▨ mixonfreddy 1年前  \n答案是C，全无服务器方案  \n获赞1次\n\n▨ Ahmedhadi_ 1年前  \n选C，因为数据源变化频繁需要Glue爬虫  \n获赞1次\n\n▨ mite_gvg 1年前  \nC正确，用Glue进行数据摄取  \n获赞2次\n\n▨ codehive 1年前  \nC选项最符合要求。AWS Glue作为全托管ETL服务，无需大量编码即可轻松实现数据发现、增强和转换。它支持多数据源、结构自动检测与演进，完美契合场景需求。Amazon Athena作为无服务器交互式查询服务，可直接用标准SQL分析S3中经处理的数据。Amazon QuickSight作为云端BI服务，可连接包括Athena在内的多种数据源创建交互式仪表板，适合数据洞见挖掘。  \n获赞1次\n\n▨ codehive 1年前  \nA方案不理想，因为Amazon EMR作为重量级服务比AWS Glue需要更多基础设施管理  \n获赞1次\n\n▨ Siyuan_Zhu 1年前  \n选C  \n获赞1次\n\n店铺：IT认证考试服务\n\n---\n**改写说明**：\n- **整体用语更书面化、专业化**：将原文口语及简略表达系统改为正式、条理清晰的书面语，增强技术文档感。\n- **技术术语与专有名词规范统一**：对AWS服务名及相关技术表述进行标准化处理，确保术语准确一致。\n- **逻辑结构与层次更加分明**：对问答、选项及多条回复内容进行合理分段和条理化，提升整体可读性。\n\n如果您需要更偏技术解析或更简洁的社区讨论风格，我可以继续为您调整优化。"}, "option": [{"option_text": {"zhcn": "一家企业需要快速理解海量数据并从中获取洞察。这些数据格式各异、结构频繁变动，且定期会有新增数据源。该公司希望借助AWS服务实现多数据源探索、自动生成数据架构建议，并完成数据增强与转换。解决方案需最大限度减少数据流编码工作及基础设施管理负担。下列哪组AWS服务组合能满足上述需求？\n\nA.  \n✑ 采用Amazon EMR进行数据发现、增强与转换  \n✑ 通过Amazon Athena使用标准SQL查询分析Amazon S3中的结果  \n✑ 利用Amazon QuickSight生成报告并获取洞察  \n\nB.  \n✑ 通过Amazon Kinesis Data Analytics实现数据接入  \n✑ 采用Amazon EMR进行数据发现、增强与转换  \n✑ 通过Amazon Redshift查询分析Amazon S3中的结果  \n\nC.  \n✑ 采用AWS Glue进行数据发现、增强与转换  \n✑ 通过Amazon Athena使用标准SQL查询分析Amazon S3中的结果  \n✑ 利用Amazon QuickSight生成报告并获取洞察  \n\nD.  \n✑ 通过AWS Data Pipeline完成数据传输  \n✑ 使用AWS Step Functions编排Lambda函数任务，实现数据发现、增强与转换  \n✑ 通过Amazon Athena使用标准SQL查询分析Amazon S3中的结果  \n✑ 利用Amazon QuickSight生成报告并获取洞察", "enus": "A company needs to quickly make sense of a large amount of data and gain insight from it. The data is in different formats, the schemas  change frequently, and new data sources are added regularly. The company wants to use AWS services to explore multiple data sources,  suggest schemas, and enrich and transform the data. The solution should require the least possible coding effort for the data fiows and the  least possible infrastructure management.  Which combination of AWS services will meet these requirements?  A.  ✑ Amazon EMR for data discovery, enrichment, and transformation  ✑ Amazon Athena for querying and analyzing the results in Amazon S3 using standard SQL  ✑ Amazon QuickSight for reporting and getting insights  B.  ✑ Amazon Kinesis Data Analytics for data ingestion  ✑ Amazon EMR for data discovery, enrichment, and transformation  ✑ Amazon Redshift for querying and analyzing the results in Amazon S3  C.  ✑ AWS Glue for data discovery, enrichment, and transformation  ✑ Amazon Athena for querying and analyzing the results in Amazon S3 using standard SQL  ✑ Amazon QuickSight for reporting and getting insights  D.  ✑ AWS Data Pipeline for data transfer  ✑ AWS Step Functions for orchestrating AWS Lambda jobs for data discovery, enrichment, and transformation  ✑ Amazon Athena for querying and analyzing the results in Amazon S3 using standard SQL  ✑ Amazon QuickSight for reporting and getting insights"}, "option_flag": true}], "analysis": {"enus": "  knightknt Highly Voted  2years, 3months ago I would choose C. upvoted 44 times   ovokpus Highly Voted  2years, 1month ago Answer here is C. Glue, Athena and Quicksight are serverless and need little code (only SQL) upvoted 11 times   ArunRav Most Recent  2months, 1week ago Answer is C, all serverless upvoted 1 times   Noname3562 4months ago I woul choose C as well upvoted 1 times   endeesa 8months, 1week ago In the presence of AWS Glue, with a goal to minimise coding efforts. C is the correct answer upvoted 1 times   u_b 8months, 3weeks ago I also chose C. A has code/infra overhead of EMR. B is wrong b/c you dont query S3 with redshift D is overhead from orchestrating lambda jobs with step funcs upvoted 1 times   qsergii 8months, 3weeks ago AWS Glue CROWLER for data discovery upvoted 1 times   Snape 9months, 1week ago C is correct upvoted 2 times   jopaca1216 10months, 3weeks ago The correct is C upvoted 1 times 店铺：IT认证考试服务  Mickey321 11months, 1week ago Why no voting option? It is option C upvoted 4 times   kazivebtak 1year ago C is correct upvoted 2 times   ADVIT 1year, 1month ago I think it's C upvoted 1 times   mixonfreddy 1year, 1month ago Answer is C, all serverless upvoted 1 times   Ahmedhadi_ 1year, 3months ago answer is c as data sources varies alot so requires glue crawler upvoted 1 times   mite_gvg 1year, 3months ago C Is correct, you use Glue for ingestion upvoted 2 times   codehive 1year, 3months ago Option C is the most suitable choice to meet the given requirements. AWS Glue is a fully managed extract, transform, and load (ETL) service that allows users to discover, enrich, and transform data easily, without the need for extensive coding. It supports different data sources, schema detection, and schema evolution, which makes it an ideal choice for the given scenario. Amazon Athena, a serverless interactive query service, allows users to run standard SQL queries against data stored in Amazon S3, which makes it easy to analyze the enriched and transformed data. Amazon QuickSight is a cloud-based business intelligence service that can connect to various data sources, including Amazon Athena, to create interactive dashboards and reports, which makes it a suitable choice for gaining insights from the data. upvoted 1 times   codehive 1year, 3months ago Option A is not an ideal choice because Amazon EMR is a heavy-weight service and requires more infrastructure management than AWS Glue. upvoted 1 times   Siyuan_Zhu 1year, 5months ago Go with C here upvoted 1 times 店铺：IT认证考试服务", "zhcn": ""}, "answer": "A"}, {"id": "133", "question": {"enus": "A company is converting a large number of unstructured paper receipts into images. The company wants to create a model based on natural language processing (NLP) to find relevant entities such as date, location, and notes, as well as some custom entities such as receipt numbers. The company is using optical character recognition (OCR) to extract text for data labeling. However, documents are in different structures and formats, and the company is facing challenges with setting up the manual workfiows for each document type. Additionally, the company trained a named entity recognition (NER) model for custom entity detection using a small sample size. This model has a very low confidence score and will require retraining with a large dataset. Which solution for text extraction and entity detection will require the LEAST amount of effort? ", "zhcn": "一家公司正将大量非结构化的纸质票据转换为图像文件，并计划基于自然语言处理技术构建模型，用以识别日期、地点、备注等关键信息以及票据编号等自定义实体。当前该公司采用光学字符识别技术提取文本以进行数据标注，但由于文档结构与格式各异，为每类文档搭建人工处理流程面临诸多挑战。此外，公司曾基于小样本训练了用于自定义实体识别的命名实体识别模型，但该模型置信度极低，需通过大规模数据集重新训练。在文本提取与实体检测方面，何种解决方案能最大限度降低人力投入？"}, "option": [{"option_text": {"zhcn": "借助Amazon Textract从收据图像中提取文本信息，并运用Amazon SageMaker平台的BlazingText算法，针对实体及自定义实体进行文本训练。", "enus": "Extract text from receipt images by using Amazon Textract. Use the Amazon SageMaker BlazingText algorithm to train on the text for  entities and custom entities."}, "option_flag": false}, {"option_text": {"zhcn": "通过调用AWS Marketplace中的深度学习OCR模型，从收据图像中提取文本信息，并运用NER深度学习模型进行实体识别。", "enus": "Extract text from receipt images by using a deep learning OCR model from the AWS Marketplace. Use the NER deep learning model to  extract entities."}, "option_flag": false}, {"option_text": {"zhcn": "借助Amazon Textract从收据图像中提取文本信息，运用Amazon Comprehend进行实体识别，并通过其定制实体识别功能实现特定实体的检测。", "enus": "Extract text from receipt images by using Amazon Textract. Use Amazon Comprehend for entity detection, and use Amazon  Comprehend custom entity recognition for custom entity detection."}, "option_flag": true}, {"option_text": {"zhcn": "借助AWS Marketplace中的深度学习OCR模型，从收据图像中提取文本信息。运用Amazon Comprehend进行实体识别，并通过其定制实体识别功能检测特定实体。", "enus": "Extract text from receipt images by using a deep learning OCR model from the AWS Marketplace. Use Amazon Comprehend for entity  detection, and use Amazon Comprehend custom entity recognition for custom entity detection."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/building-an-nlp-powered-search-index-with-amazon-textract-and-amazon-comprehend/", "zhcn": ""}, "answer": "C"}, {"id": "134", "question": {"enus": "A company is building a predictive maintenance model based on machine learning (ML). The data is stored in a fully private Amazon S3 bucket that is encrypted at rest with AWS Key Management Service (AWS KMS) CMKs. An ML specialist must run data preprocessing by using an Amazon SageMaker Processing job that is triggered from code in an Amazon SageMaker notebook. The job should read data from Amazon S3, process it, and upload it back to the same S3 bucket. The preprocessing code is stored in a container image in Amazon Elastic Container Registry (Amazon ECR). The ML specialist needs to grant permissions to ensure a smooth data preprocessing workfiow. Which set of actions should the ML specialist take to meet these requirements? ", "zhcn": "一家公司正在基于机器学习（ML）构建预测性维护模型。数据存储于完全私有的亚马逊S3存储桶中，该存储桶通过AWS密钥管理服务（AWS KMS）的客户主密钥（CMK）实现静态加密。机器学习专家需通过从亚马逊SageMaker笔记本中的代码触发的亚马逊SageMaker处理作业来完成数据预处理。该作业需从亚马逊S3读取数据，处理后再传回同一S3存储桶。预处理代码存储在亚马逊弹性容器注册表（Amazon ECR）的容器镜像中。机器学习专家需授权相应权限以确保数据预处理流程顺畅运行。为满足这些要求，该专家应采取以下哪组操作？"}, "option": [{"option_text": {"zhcn": "创建一个具有以下权限的IAM角色：可创建Amazon SageMaker处理任务、对相关S3存储桶具备读写权限，并拥有适当的KMS及ECR访问权限。将该角色绑定至SageMaker笔记本实例后，从笔记本中启动Amazon SageMaker处理任务。", "enus": "Create an IAM role that has permissions to create Amazon SageMaker Processing jobs, S3 read and write access to the relevant S3  bucket, and appropriate KMS and ECR permissions. Attach the role to the SageMaker notebook instance. Create an Amazon SageMaker  Processing job from the notebook."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个具备创建Amazon SageMaker处理作业权限的IAM角色，并将该角色绑定至SageMaker笔记本实例。随后配置一个Amazon SageMaker处理作业，其关联的IAM角色需拥有对指定S3存储桶的读写权限，同时配置相应的KMS密钥管理服务及ECR容器注册表访问权限。", "enus": "Create an IAM role that has permissions to create Amazon SageMaker Processing jobs. Attach the role to the SageMaker notebook  instance. Create an Amazon SageMaker Processing job with an IAM role that has read and write permissions to the relevant S3 bucket,  and appropriate KMS and ECR permissions."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个具有创建Amazon SageMaker处理任务及访问Amazon ECR权限的IAM角色，并将该角色关联至SageMaker笔记本实例。在默认VPC中配置S3端点和KMS端点后，即可通过该笔记本实例启动Amazon SageMaker处理任务。", "enus": "Create an IAM role that has permissions to create Amazon SageMaker Processing jobs and to access Amazon ECR. Attach the role to  the SageMaker notebook instance. Set up both an S3 endpoint and a KMS endpoint in the default VPC. Create Amazon SageMaker  Processing jobs from the notebook."}, "option_flag": false}, {"option_text": {"zhcn": "创建具备创建Amazon SageMaker处理作业权限的IAM角色，并将该角色绑定至SageMaker笔记本实例。在默认VPC中配置S3终端节点。使用具有适当KMS及ECR权限的IAM用户访问密钥与私有密钥，创建Amazon SageMaker处理作业。", "enus": "Create an IAM role that has permissions to create Amazon SageMaker Processing jobs. Attach the role to the SageMaker notebook  instance. Set up an S3 endpoint in the default VPC. Create Amazon SageMaker Processing jobs with the access key and secret key of the  IAM user with appropriate KMS and ECR permissions."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "135", "question": {"enus": "A data scientist has been running an Amazon SageMaker notebook instance for a few weeks. During this time, a new version of Jupyter Notebook was released along with additional software updates. The security team mandates that all running SageMaker notebook instances use the latest security and software updates provided by SageMaker. How can the data scientist meet this requirements? ", "zhcn": "一位数据科学家持续运行亚马逊SageMaker笔记本实例已有数周。在此期间，Jupyter Notebook发布了新版本并附带了其他软件更新。安全团队要求所有运行的SageMaker笔记本实例必须采用SageMaker提供的最新安全补丁与软件更新。这位数据科学家该如何满足此项要求？"}, "option": [{"option_text": {"zhcn": "请调用CreateNotebookInstanceLifecycleConfig接口。", "enus": "Call the CreateNotebookInstanceLifecycleConfig API operation"}, "option_flag": false}, {"option_text": {"zhcn": "新建一个SageMaker笔记本实例，并将原实例中的亚马逊弹性块存储卷挂载至该实例。", "enus": "Create a new SageMaker notebook instance and mount the Amazon Elastic Block Store (Amazon EBS) volume from the original  instance"}, "option_flag": false}, {"option_text": {"zhcn": "请先暂停并重新启动 SageMaker notebook 实例。", "enus": "Stop and then restart the SageMaker notebook instance"}, "option_flag": true}, {"option_text": {"zhcn": "调用UpdateNotebookInstanceLifecycleConfig接口", "enus": "Call the UpdateNotebookInstanceLifecycleConfig API operation"}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-software-updates.html", "zhcn": ""}, "answer": "C"}, {"id": "136", "question": {"enus": "A library is developing an automatic book-borrowing system that uses Amazon Rekognition. Images of library members' faces are stored in an Amazon S3 bucket. When members borrow books, the Amazon Rekognition CompareFaces API operation compares real faces against the stored faces in Amazon S3. The library needs to improve security by making sure that images are encrypted at rest. Also, when the images are used with Amazon Rekognition. they need to be encrypted in transit. The library also must ensure that the images are not used to improve Amazon Rekognition as a service. How should a machine learning specialist architect the solution to satisfy these requirements? ", "zhcn": "某图书馆正在研发一套基于亚马逊Rekognition技术的自动借书系统。系统将读者人脸图像存储于亚马逊S3存储桶中，当读者借阅图书时，系统通过调用亚马逊Rekognition的CompareFaces接口，实时比对现场采集的人脸与S3中预存的人像数据。为提升安全性，图书馆要求静态存储的图像必须加密处理，且在使用Rekognition服务进行传输过程中需启用传输加密机制。同时，图书馆必须确保这些人像数据不会被用于优化亚马逊Rekognition的服务功能。机器学习专家应当如何设计系统架构以满足上述要求？"}, "option": [{"option_text": {"zhcn": "为S3存储桶启用服务端加密。如需禁止将图像用于服务优化，请提交AWS支持工票，并按照AWS支持团队提供的流程操作。", "enus": "Enable server-side encryption on the S3 bucket. Submit an AWS Support ticket to opt out of allowing images to be used for improving  the service, and follow the process provided by AWS Support."}, "option_flag": false}, {"option_text": {"zhcn": "建议改用亚马逊Rekognition图库存储图像，可调用IndexFaces与SearchFacesByImage接口替代原有的CompareFaces功能。", "enus": "Switch to using an Amazon Rekognition collection to store the images. Use the IndexFaces and SearchFacesByImage API operations  instead of the CompareFaces API operation."}, "option_flag": true}, {"option_text": {"zhcn": "将Amazon S3存储图像及Amazon Rekognition人脸比对服务切换至AWS GovCloud（美国）区域。需配置VPN连接，并确保仅通过该VPN通道调用Amazon Rekognition API操作。", "enus": "Switch to using the AWS GovCloud (US) Region for Amazon S3 to store images and for Amazon Rekognition to compare faces. Set up a  VPN connection and only call the Amazon Rekognition API operations through the VPN."}, "option_flag": false}, {"option_text": {"zhcn": "为S3存储桶启用客户端加密功能。配置虚拟专用网络连接，并仅通过该专用网络调用Amazon Rekognition API操作。", "enus": "Enable client-side encryption on the S3 bucket. Set up a VPN connection and only call the Amazon Rekognition API operations through  the VPN."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "137", "question": {"enus": "A company is building a line-counting application for use in a quick-service restaurant. The company wants to use video cameras pointed at the line of customers at a given register to measure how many people are in line and deliver notifications to managers if the line grows too long. The restaurant locations have limited bandwidth for connections to external services and cannot accommodate multiple video streams without impacting other operations. Which solution should a machine learning specialist implement to meet these requirements? ", "zhcn": "一家公司正在为快餐店开发一套排队人数统计系统。该方案旨在通过对准收银台前顾客队列的摄像头，实时监测排队人数，并在队伍过长时向管理人员发送通知。由于各家餐厅对外连接的网络带宽有限，若同时传输多路视频流将影响其他业务操作。面对这些要求，机器学习专家应当采取何种解决方案？"}, "option": [{"option_text": {"zhcn": "部署与亚马逊Kinesis视频流兼容的摄像头，通过餐厅现有网络将视频数据实时传输至AWS云平台。编写AWS Lambda函数截取视频画面，调用亚马逊Rekognition图像识别服务统计画面中的人脸数量。若检测到排队人数超出阈值，则通过亚马逊简单通知服务自动发送预警消息。", "enus": "Install cameras compatible with Amazon Kinesis Video Streams to stream the data to AWS over the restaurant's existing internet  connection. Write an AWS Lambda function to take an image and send it to Amazon Rekognition to count the number of faces in the  image. Send an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long."}, "option_flag": true}, {"option_text": {"zhcn": "在餐厅内部署AWS DeepLens摄像头以采集视频流。通过在设备端启用Amazon Rekognition图像识别服务，当系统检测到人员出现时，将触发本地AWS Lambda函数运行。若监测到排队人数过多，该Lambda函数将自动通过亚马逊简单通知服务（Amazon SNS）发送预警通知。", "enus": "Deploy AWS DeepLens cameras in the restaurant to capture video. Enable Amazon Rekognition on the AWS DeepLens device, and use it  to trigger a local AWS Lambda function when a person is recognized. Use the Lambda function to send an Amazon Simple Notification  Service (Amazon SNS) notification if the line is too long."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊SageMaker中构建定制模型，用于识别图像中的人数。在餐厅内部署兼容亚马逊Kinesis视频流的监控摄像头。编写AWS Lambda函数截取图像帧，通过SageMaker端点调用模型进行人数统计。若排队人数超出阈值，则触发亚马逊简单通知服务（Amazon SNS）发送提醒。", "enus": "Build a custom model in Amazon SageMaker to recognize the number of people in an image. Install cameras compatible with Amazon  Kinesis Video Streams in the restaurant. Write an AWS Lambda function to take an image. Use the SageMaker endpoint to call the model  to count people. Send an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊SageMaker中构建定制模型，用于识别图像中的人数。于餐厅内部署AWS DeepLens智能摄像头，并将训练完成的模型加载至设备。通过部署在摄像头上的AWS Lambda函数调用模型进行实时人数统计，当检测到排队人数超出阈值时，自动触发亚马逊简单通知服务（Amazon SNS）发送预警通知。", "enus": "Build a custom model in Amazon SageMaker to recognize the number of people in an image. Deploy AWS DeepLens cameras in the  restaurant. Deploy the model to the cameras. Deploy an AWS Lambda function to the cameras to use the model to count people and send  an Amazon Simple Notification Service (Amazon SNS) notification if the line is too long."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "138", "question": {"enus": "A company has set up and deployed its machine learning (ML) model into production with an endpoint using Amazon SageMaker hosting services. The ML team has configured automatic scaling for its SageMaker instances to support workload changes. During testing, the team notices that additional instances are being launched before the new instances are ready. This behavior needs to change as soon as possible. How can the ML team solve this issue? ", "zhcn": "某公司已通过Amazon SageMaker托管服务创建并部署了机器学习模型，并设置了服务端点。机器学习团队为其SageMaker实例配置了自动扩缩容功能以应对工作负载变化。但在测试过程中，团队发现新实例尚未就绪时系统便已启动更多实例。这一情况需立即调整。机器学习团队该如何解决此问题？"}, "option": [{"option_text": {"zhcn": "缩短缩容活动的冷却时间。调高实例的预设最大容量。", "enus": "Decrease the cooldown period for the scale-in activity. Increase the configured maximum capacity of instances."}, "option_flag": true}, {"option_text": {"zhcn": "将当前终端节点替换为基于SageMaker的多模型终端节点。", "enus": "Replace the current endpoint with a multi-model endpoint using SageMaker."}, "option_flag": false}, {"option_text": {"zhcn": "配置Amazon API Gateway与AWS Lambda服务，以触发SageMaker推理端点的调用。", "enus": "Set up Amazon API Gateway and AWS Lambda to trigger the SageMaker inference endpoint."}, "option_flag": false}, {"option_text": {"zhcn": "延长扩容活动的冷却时间。", "enus": "Increase the cooldown period for the scale-out activity."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/configuring-autoscaling-inference-endpoints-in-amazon-sagemaker/", "zhcn": ""}, "answer": "A"}, {"id": "139", "question": {"enus": "A telecommunications company is developing a mobile app for its customers. The company is using an Amazon SageMaker hosted endpoint for machine learning model inferences. Developers want to introduce a new version of the model for a limited number of users who subscribed to a preview feature of the app. After the new version of the model is tested as a preview, developers will evaluate its accuracy. If a new version of the model has better accuracy, developers need to be able to gradually release the new version for all users over a fixed period of time. How can the company implement the testing model with the LEAST amount of operational overhead? ", "zhcn": "一家电信企业正为其客户开发一款移动应用。该公司采用亚马逊SageMaker托管终端进行机器学习模型推理。开发团队计划为订阅了应用预览功能的有限用户群体推出新版本模型。待新模型完成预览测试后，开发人员将评估其准确度。若新版模型表现更优，开发团队需能在固定周期内逐步向全体用户推送更新。如何以最低运维成本实现该测试方案？"}, "option": [{"option_text": {"zhcn": "通过调用CreateEndpointConfig操作并设置InitialVariantWeight参数为0，使用新版本模型更新ProductionVariant数据类型。针对已订阅预览功能的用户，需在InvokeEndpoint调用中指定TargetVariant参数。当新版模型完成发布准备时，逐步调高InitialVariantWeight数值，直至所有用户均获得更新后的版本。", "enus": "Update the ProductionVariant data type with the new version of the model by using the CreateEndpointConfig operation with the  InitialVariantWeight parameter set to 0. Specify the TargetVariant parameter for InvokeEndpoint calls for users who subscribed to the  preview feature. When the new version of the model is ready for release, gradually increase InitialVariantWeight until all users have the  updated version."}, "option_flag": false}, {"option_text": {"zhcn": "配置两个SageMaker托管端点，分别部署不同版本的模型。创建应用负载均衡器（ALB），根据TargetVariant查询字符串参数将流量分发至两个端点。针对已订阅预览功能的用户，调整应用程序配置使其发送TargetVariant查询参数。待新版本模型完成发布准备后，将ALB的路由策略调整为加权分配模式，直至所有用户均完成版本更新。", "enus": "Configure two SageMaker hosted endpoints that serve the different versions of the model. Create an Application Load Balancer (ALB)  to route trafic to both endpoints based on the TargetVariant query string parameter. Reconfigure the app to send the TargetVariant query  string parameter for users who subscribed to the preview feature. When the new version of the model is ready for release, change the  ALB's routing algorithm to weighted until all users have the updated version."}, "option_flag": false}, {"option_text": {"zhcn": "通过调用UpdateEndpointWeightsAndCapacities操作，将DesiredWeight参数设置为0，以此更新DesiredWeightsAndCapacities数据类型以适配模型的新版本。对于已订阅预览功能的用户，需在InvokeEndpoint调用中指定TargetVariant参数。待新版本模型完成发布准备后，逐步调高DesiredWeight数值，直至所有用户均获得更新版本。", "enus": "Update the DesiredWeightsAndCapacity data type with the new version of the model by using the  UpdateEndpointWeightsAndCapacities operation with the DesiredWeight parameter set to 0. Specify the TargetVariant parameter for  InvokeEndpoint calls for users who subscribed to the preview feature. When the new version of the model is ready for release, gradually  increase DesiredWeight until all users have the updated version."}, "option_flag": false}, {"option_text": {"zhcn": "配置两个SageMaker托管端点，分别部署不同版本的模型。创建一条采用简单路由策略的Amazon Route 53记录，将其指向当前正式版模型。将移动应用程序配置为：已订阅预览功能的用户使用新版端点URL，其余用户则访问Route 53记录指向的地址。当新版模型完成发布准备时，向Route 53添加新版本模型端点，并将路由策略切换为加权路由，逐步完成全体用户的版本更新。", "enus": "Configure two SageMaker hosted endpoints that serve the different versions of the model. Create an Amazon Route 53 record that is  configured with a simple routing policy and that points to the current version of the model. Configure the mobile app to use the endpoint  URL for users who subscribed to the preview feature and to use the Route 53 record for other users. When the new version of the model is  ready for release, add a new model version endpoint to Route 53, and switch the policy to weighted until all users have the updated  version."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "140", "question": {"enus": "A company offers an online shopping service to its customers. The company wants to enhance the site's security by requesting additional information when customers access the site from locations that are different from their normal location. The company wants to update the process to call a machine learning (ML) model to determine when additional information should be requested. The company has several terabytes of data from its existing ecommerce web servers containing the source IP addresses for each request made to the web server. For authenticated requests, the records also contain the login name of the requesting user. Which approach should an ML specialist take to implement the new security feature in the web application? ", "zhcn": "某公司为其客户提供在线购物服务。为提升网站安全性，公司计划在客户从非常用登录地点访问网站时要求额外验证信息。现需升级安全流程，通过调用机器学习模型智能判断何时启动附加验证机制。公司已积累数太字节的电子商务网络服务器数据，其中包含每次访问请求的源IP地址；对于已认证的请求，记录中还包含登录用户名。在此场景下，机器学习专家应当如何设计网站应用程序中的新型安全功能？"}, "option": [{"option_text": {"zhcn": "使用Amazon SageMaker Ground Truth对每条记录进行标注，将其归类为成功或失败的访问尝试。随后借助Amazon SageMaker平台，采用因子分解机(FM)算法训练二元分类模型。", "enus": "Use Amazon SageMaker Ground Truth to label each record as either a successful or failed access attempt. Use Amazon SageMaker to  train a binary classification model using the factorization machines (FM) algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "运用亚马逊SageMaker平台，通过IP Insights算法训练模型。每日利用新增日志数据，对模型进行定时更新与重新训练。", "enus": "Use Amazon SageMaker to train a model using the IP Insights algorithm. Schedule updates and retraining of the model using new log  data nightly."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon SageMaker Ground Truth对每条记录进行标注，将其判定为成功或失败的访问尝试。随后借助Amazon SageMaker平台，采用IP Insights算法训练二元分类模型。", "enus": "Use Amazon SageMaker Ground Truth to label each record as either a successful or failed access attempt. Use Amazon SageMaker to  train a binary classification model using the IP Insights algorithm."}, "option_flag": true}, {"option_text": {"zhcn": "运用Amazon SageMaker，通过Object2Vec算法训练模型。利用最新日志数据，于每晚定时进行模型更新与重新训练。", "enus": "Use Amazon SageMaker to train a model using the Object2Vec algorithm. Schedule updates and retraining of the model using new log  data nightly."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "141", "question": {"enus": "A retail company wants to combine its customer orders with the product description data from its product catalog. The structure and format of the records in each dataset is different. A data analyst tried to use a spreadsheet to combine the datasets, but the effort resulted in duplicate records and records that were not properly combined. The company needs a solution that it can use to combine similar records from the two datasets and remove any duplicates. Which solution will meet these requirements? ", "zhcn": "一家零售企业希望将其客户订单数据与产品目录中的商品描述信息进行整合。然而这两个数据集中的记录结构和格式各不相同。数据分析师曾尝试用电子表格进行数据合并，但结果却出现了大量重复记录和匹配错位的问题。该公司亟需一种解决方案，能够智能整合两个数据集中相似的记录，并自动剔除重复项。请问以下哪种方案符合这些要求？"}, "option": [{"option_text": {"zhcn": "利用AWS Lambda函数处理数据，通过两个数组比对两数据集字段中的相同字符串，并清除所有重复项。", "enus": "Use an AWS Lambda function to process the data. Use two arrays to compare equal strings in the fields from the two datasets and  remove any duplicates."}, "option_flag": false}, {"option_text": {"zhcn": "为读取和填充AWS Glue数据目录创建AWS Glue爬虫程序。调用AWS Glue SearchTables API接口对两个数据集执行模糊匹配检索，并相应完成数据清洗工作。", "enus": "Create AWS Glue crawlers for reading and populating the AWS Glue Data Catalog. Call the AWS Glue SearchTables API operation to  perform a fuzzy- matching search on the two datasets, and cleanse the data accordingly."}, "option_flag": false}, {"option_text": {"zhcn": "为读取并填充AWS Glue数据目录，需创建AWS Glue爬虫程序。随后通过FindMatches转换功能实现数据清洗。", "enus": "Create AWS Glue crawlers for reading and populating the AWS Glue Data Catalog. Use the FindMatches transform to cleanse the data."}, "option_flag": false}, {"option_text": {"zhcn": "创建一项AWS Lake Formation自定义转换功能。通过Lake Formation控制台对匹配产品执行数据转换处理，实现数据的自动清洗。", "enus": "Create an AWS Lake Formation custom transform. Run a transformation for matching products from the Lake Formation console to  cleanse the data automatically."}, "option_flag": true}], "analysis": {"enus": "Reference: https://aws.amazon.com/lake-formation/features/", "zhcn": ""}, "answer": "D"}, {"id": "142", "question": {"enus": "A company provisions Amazon SageMaker notebook instances for its data science team and creates Amazon VPC interface endpoints to ensure communication between the VPC and the notebook instances. All connections to the Amazon SageMaker API are contained entirely and securely using the AWS network. However, the data science team realizes that individuals outside the VPC can still connect to the notebook instances across the internet. Which set of actions should the data science team take to fix the issue? ", "zhcn": "一家公司为其数据科学团队配置了Amazon SageMaker笔记本实例，并创建了Amazon VPC接口端点以确保VPC与笔记本实例间的通信。所有与Amazon SageMaker API的连接均通过AWS网络实现完全且安全的封闭传输。然而数据科学团队发现，VPC外部用户仍可通过互联网连接到这些笔记本实例。数据科学团队应采取哪组措施来解决此问题？"}, "option": [{"option_text": {"zhcn": "调整笔记本实例的安全组配置，仅允许来自VPC的CIDR地址范围的流量通行。将此安全组设置应用于所有笔记本实例的VPC网络接口。", "enus": "Modify the notebook instances' security group to allow trafic only from the CIDR ranges of the VPC. Apply this security group to all of  the notebook instances' VPC interfaces."}, "option_flag": false}, {"option_text": {"zhcn": "创建一项IAM策略，仅允许通过VPC终端节点执行`sagemaker:CreatePresignedNotebookInstanceUrl`和`sagemaker:DescribeNotebookInstance`操作。将此策略应用于所有用于访问笔记本实例的IAM用户组、群组及角色。", "enus": "Create an IAM policy that allows the sagemaker:CreatePresignedNotebooklnstanceUrl and sagemaker:DescribeNotebooklnstance  actions from only the VPC endpoints. Apply this policy to all IAM users, groups, and roles used to access the notebook instances."}, "option_flag": true}, {"option_text": {"zhcn": "为VPC添加NAT网关。将承载Amazon SageMaker笔记本实例的所有子网转换为私有子网。停止并重新启动所有笔记本实例，以仅重新分配私有IP地址。", "enus": "Add a NAT gateway to the VPC. Convert all of the subnets where the Amazon SageMaker notebook instances are hosted to private  subnets. Stop and start all of the notebook instances to reassign only private IP addresses."}, "option_flag": false}, {"option_text": {"zhcn": "请调整承载该笔记本的子网所关联的网络访问控制列表，以限制虚拟私有云外部的一切访问。", "enus": "Change the network ACL of the subnet the notebook is hosted in to restrict access to anyone outside the VPC."}, "option_flag": false}], "analysis": {"enus": "Reference: https://gmoein.github.io/files/Amazon%20SageMaker.pdf", "zhcn": ""}, "answer": "B"}, {"id": "143", "question": {"enus": "A company will use Amazon SageMaker to train and host a machine learning (ML) model for a marketing campaign. The majority of data is sensitive customer data. The data must be encrypted at rest. The company wants AWS to maintain the root of trust for the master keys and wants encryption key usage to be logged. Which implementation will meet these requirements? ", "zhcn": "一家公司计划利用Amazon SageMaker平台，为某项营销活动训练并部署机器学习模型。其所涉及的大部分数据均属敏感的客户信息，必须实现静态加密。该公司要求由AWS托管主密钥的信任根，并记录加密密钥的使用情况。下列哪种实施方案能满足上述要求？"}, "option": [{"option_text": {"zhcn": "利用存储于AWS Cloud HSM的加密密钥，对机器学习数据卷进行加密处理，同时用于保护Amazon S3中的模型制品及相关数据的加密存储。", "enus": "Use encryption keys that are stored in AWS Cloud HSM to encrypt the ML data volumes, and to encrypt the model artifacts and data in  Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker内置临时密钥对机器学习数据卷进行加密。为新建的亚马逊弹性块存储卷启用默认加密功能。", "enus": "Use SageMaker built-in transient keys to encrypt the ML data volumes. Enable default encryption for new Amazon Elastic Block Store  (Amazon EBS) volumes."}, "option_flag": false}, {"option_text": {"zhcn": "在AWS密钥管理服务（AWS KMS）中采用客户托管密钥，对ML数据卷进行加密，并对Amazon S3中的模型制品及数据实施加密保护。", "enus": "Use customer managed keys in AWS Key Management Service (AWS KMS) to encrypt the ML data volumes, and to encrypt the model  artifacts and data in Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "借助AWS安全令牌服务（AWS STS）生成临时令牌，用于加密机器学习存储卷，并对Amazon S3中的模型制品及数据进行加密保护。", "enus": "Use AWS Security Token Service (AWS STS) to create temporary tokens to encrypt the ML storage volumes, and to encrypt the model  artifacts and data in Amazon S3."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "144", "question": {"enus": "A machine learning specialist stores IoT soil sensor data in Amazon DynamoDB table and stores weather event data as JSON files in Amazon S3. The dataset in DynamoDB is 10 GB in size and the dataset in Amazon S3 is 5 GB in size. The specialist wants to train a model on this data to help predict soil moisture levels as a function of weather events using Amazon SageMaker. Which solution will accomplish the necessary transformation to train the Amazon SageMaker model with the LEAST amount of administrative overhead? ", "zhcn": "一位机器学习专家将物联网土壤传感器数据存储于Amazon DynamoDB表中，同时把气象事件数据以JSON文件形式存放于Amazon S3内。DynamoDB内数据集规模为10GB，而Amazon S3中的数据集为5GB。该专家希望基于这些数据在Amazon SageMaker平台上训练模型，从而通过气象事件预测土壤湿度水平。在满足模型训练所需数据转换的前提下，下列哪种方案能实现管理成本最小化？"}, "option": [{"option_text": {"zhcn": "启动Amazon EMR集群，为DynamoDB表与S3数据创建Apache Hive外部表。对Hive表进行关联查询，并将结果输出至Amazon S3。", "enus": "Launch an Amazon EMR cluster. Create an Apache Hive external table for the DynamoDB table and S3 data. Join the Hive tables and  write the results out to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue爬虫程序抓取数据，编写一个AWS Glue ETL作业，将两个数据表进行合并，并将处理结果导入至Amazon Redshift集群。", "enus": "Crawl the data using AWS Glue crawlers. Write an AWS Glue ETL job that merges the two tables and writes the output to an Amazon  Redshift cluster."}, "option_flag": false}, {"option_text": {"zhcn": "为传感器数据表启用Amazon DynamoDB流功能。创建AWS Lambda函数处理该数据流，并将处理结果追加至Amazon S3存储桶内现有的气象文件中。", "enus": "Enable Amazon DynamoDB Streams on the sensor table. Write an AWS Lambda function that consumes the stream and appends the  results to the existing weather files in Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "利用AWS Glue爬虫程序抓取数据，编写一个AWS Glue ETL作业，将两个表格合并，并以CSV格式将输出结果写入Amazon S3。", "enus": "Crawl the data using AWS Glue crawlers. Write an AWS Glue ETL job that merges the two tables and writes the output in CSV format to  Amazon S3."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "145", "question": {"enus": "A company sells thousands of products on a public website and wants to automatically identify products with potential durability problems. The company has 1.000 reviews with date, star rating, review text, review summary, and customer email fields, but many reviews are incomplete and have empty fields. Each review has already been labeled with the correct durability result. A machine learning specialist must train a model to identify reviews expressing concerns over product durability. The first model needs to be trained and ready to review in 2 days. What is the MOST direct approach to solve this problem within 2 days? ", "zhcn": "一家公司在公开网站上销售数千种商品，并希望自动识别存在潜在耐用性问题的产品。该公司拥有1,000条包含日期、星级评分、评论内容、评论摘要和客户邮箱字段的评论数据，但许多评论存在字段缺失的情况。每条评论均已标注了正确的耐用性判定结果。机器学习专家需要训练一个模型，用于识别表达产品耐用性质疑的评论。首个模型必须在两天内完成训练并投入审核。要在两天内解决此问题，最直接的应对方案是什么？"}, "option": [{"option_text": {"zhcn": "利用 Amazon Comprehend 训练定制分类器。", "enus": "Train a custom classifier by using Amazon Comprehend."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊SageMaker中运用Gluon与Apache MXNet构建循环神经网络（RNN）。", "enus": "Build a recurrent neural network (RNN) in Amazon SageMaker by using Gluon and Apache MXNet."}, "option_flag": true}, {"option_text": {"zhcn": "在Amazon SageMaker平台上，采用Word2Vec模式训练内置的BlazingText模型。", "enus": "Train a built-in BlazingText model using Word2Vec mode in Amazon SageMaker."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon SageMaker中使用内置的序列到序列模型。", "enus": "Use a built-in seq2seq model in Amazon SageMaker."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "146", "question": {"enus": "A company that runs an online library is implementing a chatbot using Amazon Lex to provide book recommendations based on category. This intent is fulfilled by an AWS Lambda function that queries an Amazon DynamoDB table for a list of book titles, given a particular category. For testing, there are only three categories implemented as the custom slot types: \"comedy,\" \"adventure,` and \"documentary.` A machine learning (ML) specialist notices that sometimes the request cannot be fulfilled because Amazon Lex cannot understand the category spoken by users with utterances such as \"funny,\" \"fun,\" and \"humor.\" The ML specialist needs to fix the problem without changing the Lambda code or data in DynamoDB. How should the ML specialist fix the problem? ", "zhcn": "一家运营在线图书馆的公司正利用Amazon Lex开发聊天机器人，旨在根据图书类别为用户推荐书籍。该功能由AWS Lambda函数实现，通过查询Amazon DynamoDB数据表，获取特定分类下的书籍清单。目前测试阶段仅设三种自定义槽位类别：\"喜剧\"、\"冒险\"和\"纪实\"。机器学习专家发现，当用户使用\"有趣的\"\"好玩儿\"\"幽默\"等表述时，系统时常无法识别类别导致推荐失败。在不修改Lambda代码或DynamoDB数据的前提下，这位专家应当如何解决该问题？"}, "option": [{"option_text": {"zhcn": "将枚举值列表中未识别的词汇添加为槽位类型的新值。", "enus": "Add the unrecognized words in the enumeration values list as new values in the slot type."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个新的自定义槽位类型，将未识别的词汇作为枚举值添加至该类型，并将此槽位类型应用于对应槽位。", "enus": "Create a new custom slot type, add the unrecognized words to this slot type as enumeration values, and use this slot type for the slot."}, "option_flag": false}, {"option_text": {"zhcn": "利用AMAZON.SearchQuery内置槽类型，可在数据库中实现自定义检索功能。", "enus": "Use the AMAZON.SearchQuery built-in slot types for custom searches in the database."}, "option_flag": true}, {"option_text": {"zhcn": "将未识别词汇添加为自定义槽位类型的同义词。", "enus": "Add the unrecognized words as synonyms in the custom slot type."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "147", "question": {"enus": "A manufacturing company uses machine learning (ML) models to detect quality issues. The models use images that are taken of the company's product at the end of each production step. The company has thousands of machines at the production site that generate one image per second on average. The company ran a successful pilot with a single manufacturing machine. For the pilot, ML specialists used an industrial PC that ran AWS IoT Greengrass with a long-running AWS Lambda function that uploaded the images to Amazon S3. The uploaded images invoked a Lambda function that was written in Python to perform inference by using an Amazon SageMaker endpoint that ran a custom model. The inference results were forwarded back to a web service that was hosted at the production site to prevent faulty products from being shipped. The company scaled the solution out to all manufacturing machines by installing similarly configured industrial PCs on each production machine. However, latency for predictions increased beyond acceptable limits. Analysis shows that the internet connection is at its capacity limit. How can the company resolve this issue MOST cost-effectively? ", "zhcn": "一家制造公司采用机器学习模型来检测产品质量问题。这些模型通过分析每道生产工序末端拍摄的产品图像进行质量监控。该企业生产线上部署了数千台设备，每台设备平均每秒生成一张图像。\n\n在单台设备试点阶段，公司取得了成功：机器学习专家采用工业计算机运行AWS IoT Greengrass平台，通过常驻AWS Lambda函数将图像上传至Amazon S3存储桶。上传图像会自动触发基于Python编写的Lambda函数，该函数调用运行定制模型的Amazon SageMaker终端节点进行推理分析，并将检测结果实时回传至生产现场部署的Web服务，有效拦截瑕疵品流出。\n\n当公司将此解决方案扩展至全部生产设备，为每台机器配置相同规格的工业计算机后，预测延迟却超出了可接受范围。经分析发现，现有网络带宽已达饱和状态。请问该公司如何以最具成本效益的方式解决此问题？"}, "option": [{"option_text": {"zhcn": "在生产站点与最近的AWS区域之间建立一条10 Gbps的AWS Direct Connect专用连接。通过该直连通道上传图像数据，并同步扩展SageMaker端点所使用实例的规格规模与部署数量。", "enus": "Set up a 10 Gbps AWS Direct Connect connection between the production site and the nearest AWS Region. Use the Direct Connect  connection to upload the images. Increase the size of the instances and the number of instances that are used by the SageMaker  endpoint."}, "option_flag": false}, {"option_text": {"zhcn": "将长期运行于AWS IoT Greengrass上的Lambda函数进行扩展，使其能够压缩图像并将压缩后的文件上传至Amazon S3。随后通过独立的Lambda函数解压这些文件，并调用现有Lambda函数启动推理流程。", "enus": "Extend the long-running Lambda function that runs on AWS IoT Greengrass to compress the images and upload the compressed files to  Amazon S3. Decompress the files by using a separate Lambda function that invokes the existing Lambda function to run the inference  pipeline."}, "option_flag": false}, {"option_text": {"zhcn": "为SageMaker配置自动扩缩容功能。在生产站点与最近的AWS区域之间建立AWS Direct Connect连接通道，通过该专用链路实现图像数据的上传。", "enus": "Use auto scaling for SageMaker. Set up an AWS Direct Connect connection between the production site and the nearest AWS Region.  Use the Direct Connect connection to upload the images."}, "option_flag": false}, {"option_text": {"zhcn": "将Lambda函数及机器学习模型部署至安装于每台工业计算机上的AWS IoT Greengrass核心系统。扩展在AWS IoT Greengrass上持续运行的Lambda函数，使其能够调用捕获图像的Lambda程序，并在边缘计算组件上执行推理分析，最终将结果直接传输至网络服务平台。", "enus": "Deploy the Lambda function and the ML models onto the AWS IoT Greengrass core that is running on the industrial PCs that are  installed on each machine. Extend the long-running Lambda function that runs on AWS IoT Greengrass to invoke the Lambda function with  the captured images and run the inference on the edge component that forwards the results directly to the web service."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "148", "question": {"enus": "A data scientist is using an Amazon SageMaker notebook instance and needs to securely access data stored in a specific Amazon S3 bucket. How should the data scientist accomplish this? ", "zhcn": "一位数据科学家正在使用Amazon SageMaker笔记本实例，需安全访问特定Amazon S3存储桶中的数据。该数据科学家应如何实现此操作？"}, "option": [{"option_text": {"zhcn": "为Amazon SageMaker笔记本ARN添加S3存储桶策略，授予其作为主体的GetObject、PutObject和ListBucket权限。", "enus": "Add an S3 bucket policy allowing GetObject, PutObject, and ListBucket permissions to the Amazon SageMaker notebook ARN as  principal."}, "option_flag": false}, {"option_text": {"zhcn": "使用仅限笔记簿所有者有权访问的自定义AWS密钥管理服务（AWS KMS）密钥，对S3存储桶中的对象进行加密。", "enus": "Encrypt the objects in the S3 bucket with a custom AWS Key Management Service (AWS KMS) key that only the notebook owner has  access to."}, "option_flag": false}, {"option_text": {"zhcn": "将策略附加到与笔记本关联的IAM角色，该策略允许对特定S3存储桶执行GetObject、PutObject和ListBucket操作。", "enus": "Attach the policy to the IAM role associated with the notebook that allows GetObject, PutObject, and ListBucket operations to the  specific S3 bucket."}, "option_flag": true}, {"option_text": {"zhcn": "在实例的生命周期配置中，通过脚本为AWS CLI配置访问密钥ID与保密凭证。", "enus": "Use a script in a lifecycle configuration to configure the AWS CLI on the instance with an access key ID and secret."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "149", "question": {"enus": "A company is launching a new product and needs to build a mechanism to monitor comments about the company and its new product on social media. The company needs to be able to evaluate the sentiment expressed in social media posts, and visualize trends and configure alarms based on various thresholds. The company needs to implement this solution quickly, and wants to minimize the infrastructure and data science resources needed to evaluate the messages. The company already has a solution in place to collect posts and store them within an Amazon S3 bucket. What services should the data science team use to deliver this solution? ", "zhcn": "某公司即将推出一款新产品，需构建一套社交媒体舆情监测机制。该系统需具备以下能力：分析社交媒体帖子中表达的情绪倾向，通过可视化图表展示舆情趋势，并能根据多种阈值配置预警通知。鉴于项目需快速落地，且希望最大限度减少基础设施与数据科学资源的投入，而该公司已部署了将社交媒体帖子采集并存储至Amazon S3桶的现有方案。请问数据科学团队应采用哪些服务来实现此解决方案？"}, "option": [{"option_text": {"zhcn": "在亚马逊SageMaker平台运用BlazingText算法训练模型，用于分析社交媒体帖文语料库的情感倾向。通过部署可被AWS Lambda调用的服务端点，当S3存储桶新增帖文时自动触发Lambda函数，调用该端点进行情感分析，并将分析结果记录至Amazon DynamoDB数据表及自定义的Amazon CloudWatch指标中。借助CloudWatch告警机制，当出现情感趋势变化时及时向分析人员发送通知。", "enus": "Train a model in Amazon SageMaker by using the BlazingText algorithm to detect sentiment in the corpus of social media posts.  Expose an endpoint that can be called by AWS Lambda. Trigger a Lambda function when posts are added to the S3 bucket to invoke the  endpoint and record the sentiment in an Amazon DynamoDB table and in a custom Amazon CloudWatch metric. Use CloudWatch alarms to  notify analysts of trends."}, "option_flag": true}, {"option_text": {"zhcn": "在亚马逊SageMaker中运用语义分割算法训练模型，对社交媒体帖文集中的语义内容进行建模分析。通过AWS Lambda可调用的端点发布模型功能，当S3存储桶新增对象时自动触发Lambda函数，调用该端点并将情感分析结果记录至Amazon DynamoDB表。另设定时启动的第二个Lambda函数，用于查询近期新增记录，并通过亚马逊简单通知服务（Amazon SNS）向分析人员发送趋势动态通知。", "enus": "Train a model in Amazon SageMaker by using the semantic segmentation algorithm to model the semantic content in the corpus of  social media posts. Expose an endpoint that can be called by AWS Lambda. Trigger a Lambda function when objects are added to the S3  bucket to invoke the endpoint and record the sentiment in an Amazon DynamoDB table. Schedule a second Lambda function to query  recently added records and send an Amazon Simple Notification Service (Amazon SNS) notification to notify analysts of trends."}, "option_flag": false}, {"option_text": {"zhcn": "当社交媒体内容存入S3存储桶时，触发AWS Lambda功能运行。系统将调用Amazon Comprehend服务对每篇贴文进行情感分析，并将分析结果记录在Amazon DynamoDB数据表中。同时设定第二个定时启动的Lambda功能，用于查询近期新增记录，并通过Amazon简单通知服务（SNS）向分析人员发送趋势动态提醒。", "enus": "Trigger an AWS Lambda function when social media posts are added to the S3 bucket. Call Amazon Comprehend for each post to  capture the sentiment in the message and record the sentiment in an Amazon DynamoDB table. Schedule a second Lambda function to  query recently added records and send an Amazon Simple Notification Service (Amazon SNS) notification to notify analysts of trends."}, "option_flag": false}, {"option_text": {"zhcn": "当社交媒体内容存入S3存储桶时，触发AWS Lambda功能。通过Amazon Comprehend服务对每条内容进行情绪分析，将分析结果记录至定制化的Amazon CloudWatch指标及S3存储系统中。同时利用CloudWatch告警机制，实时向分析人员推送趋势动态。", "enus": "Trigger an AWS Lambda function when social media posts are added to the S3 bucket. Call Amazon Comprehend for each post to  capture the sentiment in the message and record the sentiment in a custom Amazon CloudWatch metric and in S3. Use CloudWatch  alarms to notify analysts of trends."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "150", "question": {"enus": "A bank wants to launch a low-rate credit promotion. The bank is located in a town that recently experienced economic hardship. Only some of the bank's customers were affected by the crisis, so the bank's credit team must identify which customers to target with the promotion. However, the credit team wants to make sure that loyal customers' full credit history is considered when the decision is made. The bank's data science team developed a model that classifies account transactions and understands credit eligibility. The data science team used the XGBoost algorithm to train the model. The team used 7 years of bank transaction historical data for training and hyperparameter tuning over the course of several days. The accuracy of the model is suficient, but the credit team is struggling to explain accurately why the model denies credit to some customers. The credit team has almost no skill in data science. What should the data science team do to address this issue in the MOST operationally eficient manner? ", "zhcn": "某银行计划推出一项低利率信贷促销活动。该银行所在城镇近期遭遇经济困境，但仅部分客户受到危机影响，因此信贷部门需精准筛选促销活动的目标客群。与此同时，信贷团队强调必须充分考量忠诚客户的完整信用记录。银行数据科学团队已开发出一套能分类账户交易并评估信贷资质的模型，该模型采用XGBoost算法，经过长达数天的训练及超参数优化，并使用了七年期的银行交易历史数据。虽然模型准确度达到要求，但信贷团队难以向客户解释模型拒绝授信的具体原因，且该团队几乎不具备数据科学专业知识。在此情况下，数据科学团队应采取何种最具运营效率的解决方案？"}, "option": [{"option_text": {"zhcn": "使用Amazon SageMaker Studio重新构建模型。创建一个笔记本文档，调用XGBoost训练容器执行模型训练任务。将训练完成的模型部署至终端节点。启用Amazon SageMaker Model Monitor功能以存储推理结果，并基于这些结果生成沙普利值（Shapley values），用以解析模型决策逻辑。最终生成特征与SHAP（沙普利加性解释）值对应关系图，向信贷团队直观展示不同特征对模型输出结果的影响机制。", "enus": "Use Amazon SageMaker Studio to rebuild the model. Create a notebook that uses the XGBoost training container to perform model  training. Deploy the model at an endpoint. Enable Amazon SageMaker Model Monitor to store inferences. Use the inferences to create  Shapley values that help explain model behavior. Create a chart that shows features and SHapley Additive exPlanations (SHAP) values to  explain to the credit team how the features affect the model outcomes."}, "option_flag": false}, {"option_text": {"zhcn": "使用 Amazon SageMaker Studio 重新构建模型。创建一个基于 XGBoost 训练容器的笔记本来执行模型训练任务，同时启用 Amazon SageMaker Debugger 并配置其计算并收集 Shapley 值。最终生成特征与 SHAP 值（SHapley Additive exPlanations）关联图表，向信贷团队直观展示各特征对模型结果的影响机制。", "enus": "Use Amazon SageMaker Studio to rebuild the model. Create a notebook that uses the XGBoost training container to perform model  training. Activate Amazon SageMaker Debugger, and configure it to calculate and collect Shapley values. Create a chart that shows  features and SHapley Additive exPlanations (SHAP) values to explain to the credit team how the features affect the model outcomes."}, "option_flag": false}, {"option_text": {"zhcn": "创建Amazon SageMaker笔记本实例。通过该笔记本实例并利用XGBoost库对模型进行本地重训练。运用Python版XGBoost接口中的plot_importance()方法生成特征重要性图表，并借助该图表向信贷团队阐释各特征如何影响模型输出结果。", "enus": "Create an Amazon SageMaker notebook instance. Use the notebook instance and the XGBoost library to locally retrain the model. Use  the plot_importance() method in the Python XGBoost interface to create a feature importance chart. Use that chart to explain to the credit  team how the features affect the model outcomes."}, "option_flag": true}, {"option_text": {"zhcn": "使用Amazon SageStudio重新构建模型。创建基于XGBoost训练容器的笔记本来执行模型训练，并将模型部署至终端节点。通过Amazon SageMaker Processing对模型进行后续分析，自动生成特征重要性可解释性图表供信贷团队使用。", "enus": "Use Amazon SageMaker Studio to rebuild the model. Create a notebook that uses the XGBoost training container to perform model  training. Deploy the model at an endpoint. Use Amazon SageMaker Processing to post-analyze the model and create a feature importance  explainability chart automatically for the credit team."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "151", "question": {"enus": "A data science team is planning to build a natural language processing (NLP) application. The application's text preprocessing stage will include part-of-speech tagging and key phase extraction. The preprocessed text will be input to a custom classification algorithm that the data science team has already written and trained using Apache MXNet. Which solution can the team build MOST quickly to meet these requirements? ", "zhcn": "一个数据科学团队正计划构建自然语言处理应用。该应用的文本预处理阶段将包含词性标注与关键短语提取功能。经过预处理的文本将输入至团队已基于Apache MXNet框架编写并训练完成的自定义分类算法中。为满足这些需求，团队最快能采用何种解决方案？"}, "option": [{"option_text": {"zhcn": "利用Amazon Comprehend完成词性标注、关键短语提取及文本分类任务。", "enus": "Use Amazon Comprehend for the part-of-speech tagging, key phase extraction, and classification tasks."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊SageMaker中调用自然语言处理库进行词性标注，通过Amazon Comprehend服务实现关键短语提取，并基于AWS深度学习容器与Amazon SageMaker构建定制化分类器。", "enus": "Use an NLP library in Amazon SageMaker for the part-of-speech tagging. Use Amazon Comprehend for the key phase extraction. Use  AWS Deep Learning Containers with Amazon SageMaker to build the custom classifier."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Comprehend完成词性标注与关键短语提取任务，并采用Amazon SageMaker内置的潜在狄利克雷分布（LDA）算法构建定制化分类器。", "enus": "Use Amazon Comprehend for the part-of-speech tagging and key phase extraction tasks. Use Amazon SageMaker built-in Latent  Dirichlet Allocation (LDA) algorithm to build the custom classifier."}, "option_flag": false}, {"option_text": {"zhcn": "在词性标注与关键短语提取任务中运用Amazon Comprehend服务。通过搭载AWS深度学习容器的Amazon SageMaker平台来构建定制化分类器。", "enus": "Use Amazon Comprehend for the part-of-speech tagging and key phase extraction tasks. Use AWS Deep Learning Containers with  Amazon SageMaker to build the custom classifier."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "152", "question": {"enus": "A machine learning (ML) specialist must develop a classification model for a financial services company. A domain expert provides the dataset, which is tabular with 10,000 rows and 1,020 features. During exploratory data analysis, the specialist finds no missing values and a small percentage of duplicate rows. There are correlation scores of > 0.9 for 200 feature pairs. The mean value of each feature is similar to its 50th percentile. Which feature engineering strategy should the ML specialist use with Amazon SageMaker? ", "zhcn": "一位机器学习专家需要为某金融服务公司开发分类模型。领域专家提供的数据集为表格形式，包含一万行数据和一千零二十个特征。在探索性数据分析阶段，专家发现数据不存在缺失值，且重复行比例极低。其中两百组特征对呈现高于0.9的相关性系数，而各特征的均值与其五十分位数值较为接近。此时，该机器学习专家应当如何在Amazon SageMaker平台上制定特征工程策略？"}, "option": [{"option_text": {"zhcn": "采用主成分分析（PCA）算法进行降维处理。", "enus": "Apply dimensionality reduction by using the principal component analysis (PCA) algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "在Jupyter notebook中剔除相关度较低的变量。", "enus": "Drop the features with low correlation scores by using a Jupyter notebook."}, "option_flag": false}, {"option_text": {"zhcn": "运用随机切割森林（RCF）算法实施异常检测。", "enus": "Apply anomaly detection by using the Random Cut Forest (RCF) algorithm."}, "option_flag": true}, {"option_text": {"zhcn": "在Jupyter notebook中，将具有高相关性的特征加以整合串联。", "enus": "Concatenate the features with high correlation scores by using a Jupyter notebook."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "153", "question": {"enus": "A manufacturing company asks its machine learning specialist to develop a model that classifies defective parts into one of eight defect types. The company has provided roughly 100,000 images per defect type for training. During the initial training of the image classification model, the specialist notices that the validation accuracy is 80%, while the training accuracy is 90%. It is known that human-level performance for this type of image classification is around 90%. What should the specialist consider to fix this issue? ", "zhcn": "一家制造企业委托其机器学习专家开发一款模型，旨在将次品零件按八种缺陷类型进行分类。企业为每种缺陷类型提供了约十万张训练图像。在图像分类模型的初步训练阶段，专家发现验证集准确率为80%，而训练集准确率达90%。已知此类图像分类任务的人类判断准确率约为90%。针对这一差异，专家应从哪些方面着手改进？"}, "option": [{"option_text": {"zhcn": "延长训练时长", "enus": "A longer training time"}, "option_flag": false}, {"option_text": {"zhcn": "扩大网络规模", "enus": "Making the network larger"}, "option_flag": false}, {"option_text": {"zhcn": "采用另一种优化器", "enus": "Using a different optimizer"}, "option_flag": false}, {"option_text": {"zhcn": "采用某种正则化手段", "enus": "Using some form of regularization"}, "option_flag": true}], "analysis": {"enus": "Reference: https://acloud.guru/forums/aws-certified-machine-learning-specialty/discussion/- MGdBUKmQ02zC3uOq4VL/AWS%20Exam%20Machine%20Learning", "zhcn": ""}, "answer": "D"}, {"id": "154", "question": {"enus": "A machine learning specialist needs to analyze comments on a news website with users across the globe. The specialist must find the most discussed topics in the comments that are in either English or Spanish. What steps could be used to accomplish this task? (Choose two.) ", "zhcn": "一位机器学习专家需要分析某全球性新闻网站的用户评论。该专家必须从英文或西班牙文评论中找出最受热议的话题。下列哪两个步骤可用于完成此任务？"}, "option": [{"option_text": {"zhcn": "运用亚马逊SageMaker平台的BlazingText算法，可跨越语言界限自主识别文本主题。请依此展开分析。", "enus": "Use an Amazon SageMaker BlazingText algorithm to find the topics independently from language. Proceed with the analysis."}, "option_flag": false}, {"option_text": {"zhcn": "如确有必要，可采用亚马逊SageMaker序列到序列算法将西班牙语内容译为英文。同时运用SageMaker潜在狄利克雷分布（LDA）算法进行主题挖掘。", "enus": "Use an Amazon SageMaker seq2seq algorithm to translate from Spanish to English, if necessary. Use a SageMaker Latent Dirichlet  Allocation (LDA) algorithm to find the topics."}, "option_flag": true}, {"option_text": {"zhcn": "如需要，可使用Amazon Translate将西班牙语译为英语，并运用Amazon Comprehend主题建模功能进行主题分析。", "enus": "Use Amazon Translate to translate from Spanish to English, if necessary. Use Amazon Comprehend topic modeling to find the topics."}, "option_flag": false}, {"option_text": {"zhcn": "如需要，可使用Amazon Translate将西班牙语内容译为英语，并运用Amazon Lex从文本中提取主题信息。", "enus": "Use Amazon Translate to translate from Spanish to English, if necessary. Use Amazon Lex to extract topics form the content."}, "option_flag": false}, {"option_text": {"zhcn": "如需要，可使用Amazon Translate将西班牙语内容译为英语。随后运用Amazon SageMaker神经主题模型（NTM）进行主题挖掘。", "enus": "Use Amazon Translate to translate from Spanish to English, if necessary. Use Amazon SageMaker Neural Topic Model (NTM) to find the  topics."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/lda.html", "zhcn": ""}, "answer": "B"}, {"id": "155", "question": {"enus": "A machine learning (ML) specialist is administering a production Amazon SageMaker endpoint with model monitoring configured. Amazon SageMaker Model Monitor detects violations on the SageMaker endpoint, so the ML specialist retrains the model with the latest dataset. This dataset is statistically representative of the current production trafic. The ML specialist notices that even after deploying the new SageMaker model and running the first monitoring job, the SageMaker endpoint still has violations. What should the ML specialist do to resolve the violations? ", "zhcn": "一位机器学习专家正在管理一个已配置模型监控功能的亚马逊SageMaker生产终端。当亚马逊SageMaker模型监控器检测到该终端出现违规行为时，该专家使用最新数据集对模型进行重新训练。该数据集能准确反映当前生产环境的数据特征。然而专家发现，即使部署了新模型并运行首次监控任务后，终端仍存在违规现象。此时应采取何种措施以消除这些违规行为？"}, "option": [{"option_text": {"zhcn": "手动触发监控任务，重新评估SageMaker端点的流量样本。", "enus": "Manually trigger the monitoring job to re-evaluate the SageMaker endpoint trafic sample."}, "option_flag": false}, {"option_text": {"zhcn": "请针对新的训练集再次运行模型监控基线任务，并将模型监控配置为采用新的基线标准。", "enus": "Run the Model Monitor baseline job again on the new training set. Configure Model Monitor to use the new baseline."}, "option_flag": true}, {"option_text": {"zhcn": "删除该终端节点，并按照原有配置重新创建。", "enus": "Delete the endpoint and recreate it with the original configuration."}, "option_flag": false}, {"option_text": {"zhcn": "使用原始训练集与新训练集的组合，再次对模型进行训练。", "enus": "Retrain the model again by using a combination of the original training set and the new training set."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "156", "question": {"enus": "A company supplies wholesale clothing to thousands of retail stores. A data scientist must create a model that predicts the daily sales volume for each item for each store. The data scientist discovers that more than half of the stores have been in business for less than 6 months. Sales data is highly consistent from week to week. Daily data from the database has been aggregated weekly, and weeks with no sales are omitted from the current dataset. Five years (100 MB) of sales data is available in Amazon S3. Which factors will adversely impact the performance of the forecast model to be developed, and which actions should the data scientist take to mitigate them? (Choose two.) ", "zhcn": "一家公司向数千家零售门店供应服装批发业务。某数据科学家需构建一个模型，用于预测各门店每款商品的日销售量。该科学家发现，超过半数的门店开业时间不足六个月。销售数据在周与周之间呈现高度一致性。数据库中的每日数据已按周进行汇总，且当前数据集中已剔除无销售记录的周次。亚马逊S3平台存有五年累计100MB的销售数据。哪些因素会对拟开发的预测模型性能产生不利影响？数据科学家应采取哪两项措施来缓解这些影响？（请选择两项）"}, "option": [{"option_text": {"zhcn": "多数门店的季节性特征难以准确判定，需获取分类数据以便将新店与历史数据更完备的同类门店进行关联分析。", "enus": "Detecting seasonality for the majority of stores will be an issue. Request categorical data to relate new stores with similar stores that  have more historical data."}, "option_flag": true}, {"option_text": {"zhcn": "当前销售数据变异度不足，需引入跨行业的外部销售数据以增强模型的泛化能力。", "enus": "The sales data does not have enough variance. Request external sales data from other industries to improve the model's ability to  generalize."}, "option_flag": true}, {"option_text": {"zhcn": "销售数据按周汇总。需从源数据库获取每日销售数据，以便构建每日分析模型。", "enus": "Sales data is aggregated by week. Request daily sales data from the source database to enable building a daily model."}, "option_flag": false}, {"option_text": {"zhcn": "销售数据中缺失了商品销售额为零的条目。请确保源数据库提供的商品销售数据包含零值记录，以便顺利构建分析模型。", "enus": "The sales data is missing zero entries for item sales. Request that item sales data from the source database include zero entries to  enable building the model."}, "option_flag": false}, {"option_text": {"zhcn": "目前亚马逊S3中仅有100MB销售数据可用。需申请获取长达十年的销售数据，这将为模型提供200MB的训练数据。", "enus": "Only 100 MB of sales data is available in Amazon S3. Request 10 years of sales data, which would provide 200 MB of training data for  the model."}, "option_flag": false}], "analysis": {"enus": "Reference: https://towardsdatascience.com/sales-forecasting-from-time-series-to-deep-learning-5d115514bfac https://arxiv.org/ftp/arxiv/papers/1302/1302.6613.pdf", "zhcn": ""}, "answer": "AB"}, {"id": "157", "question": {"enus": "An ecommerce company is automating the categorization of its products based on images. A data scientist has trained a computer vision model using the Amazon SageMaker image classification algorithm. The images for each product are classified according to specific product lines. The accuracy of the model is too low when categorizing new products. All of the product images have the same dimensions and are stored within an Amazon S3 bucket. The company wants to improve the model so it can be used for new products as soon as possible. Which steps would improve the accuracy of the solution? (Choose three.) ", "zhcn": "一家电商公司正致力于根据商品图片实现产品分类的自动化。数据科学家运用亚马逊SageMaker平台的图像分类算法，训练出计算机视觉模型。每件商品的图像均按特定产品线进行分类。但在对新商品进行分类时，该模型的准确率始终不尽如人意。所有商品图像尺寸统一，并存储于亚马逊S3存储桶中。公司希望尽快优化模型以适用于新品分类。下列哪三项措施能有效提升该解决方案的准确率？"}, "option": [{"option_text": {"zhcn": "使用SageMaker语义分割算法训练新模型，以提升预测精准度。", "enus": "Use the SageMaker semantic segmentation algorithm to train a new model to achieve improved accuracy."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Rekognition的DetectLabels接口对数据集中的商品进行智能分类。", "enus": "Use the Amazon Rekognition DetectLabels API to classify the products in the dataset."}, "option_flag": true}, {"option_text": {"zhcn": "对数据集中的图像进行增强处理。利用开源工具库对图像进行裁剪、尺寸调整、翻转、旋转以及亮度与对比度的调节。", "enus": "Augment the images in the dataset. Use open source libraries to crop, resize, fiip, rotate, and adjust the brightness and contrast of the  images."}, "option_flag": true}, {"option_text": {"zhcn": "利用SageMaker笔记本来实现图像像素归一化与尺寸缩放处理，并将处理后的数据集存储至Amazon S3。", "enus": "Use a SageMaker notebook to implement the normalization of pixels and scaling of the images. Store the new dataset in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Rekognition Custom Labels训练新模型。", "enus": "Use Amazon Rekognition Custom Labels to train a new model."}, "option_flag": true}, {"option_text": {"zhcn": "请检查产品类别是否存在样本数量不均衡的情况，并根据需要采用过采样或欠采样方法进行处理。将处理后的新数据集存储至Amazon S3平台。", "enus": "Check whether there are class imbalances in the product categories, and apply oversampling or undersampling as required. Store the  new dataset in Amazon S3."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/rekognition/latest/dg/how-it-works-types.html https://towardsdatascience.com/image-processing-techniques- for-computer-vision-11f92f511e21 https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/training-model.html", "zhcn": ""}, "answer": "BCE"}, {"id": "158", "question": {"enus": "A data scientist is training a text classification model by using the Amazon SageMaker built-in BlazingText algorithm. There are 5 classes in the dataset, with 300 samples for category A, 292 samples for category B, 240 samples for category C, 258 samples for category D, and 310 samples for category E. The data scientist shufies the data and splits off 10% for testing. After training the model, the data scientist generates confusion matrices for the training and test sets. What could the data scientist conclude form these results? ", "zhcn": "一位数据科学家正在运用亚马逊SageMaker平台内置的BlazingText算法训练文本分类模型。数据集中包含5个类别，其中A类300个样本，B类292个样本，C类240个样本，D类258个样本，E类310个样本。数据科学家将数据随机打乱后，划分出10%作为测试集。完成模型训练后，生成了训练集和测试集的混淆矩阵。根据这些结果，数据科学家可能得出哪些结论？"}, "option": [{"option_text": {"zhcn": "C班与D班过于相近。", "enus": "Classes C and D are too similar."}, "option_flag": false}, {"option_text": {"zhcn": "数据集规模过小，不宜采用留出法进行交叉验证。", "enus": "The dataset is too small for holdout cross-validation."}, "option_flag": true}, {"option_text": {"zhcn": "数据分布呈现偏态。", "enus": "The data distribution is skewed."}, "option_flag": false}, {"option_text": {"zhcn": "该模型在B类和E类上出现了过拟合现象。", "enus": "The model is overfitting for classes B and E."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "159", "question": {"enus": "A company that manufactures mobile devices wants to determine and calibrate the appropriate sales price for its devices. The company is collecting the relevant data and is determining data features that it can use to train machine learning (ML) models. There are more than 1,000 features, and the company wants to determine the primary features that contribute to the sales price. Which techniques should the company use for feature selection? (Choose three.) ", "zhcn": "一家移动设备制造商欲为其产品制定并校准合宜的销售价格。该公司正在收集相关数据，并确定可用于训练机器学习模型的数据特征。现有特征数量逾千项，公司需要找出影响售价的核心特征。请问应采用哪三种特征筛选技术？（请选择三项。）"}, "option": [{"option_text": {"zhcn": "数据标准化与归一化处理", "enus": "Data scaling with standardization and normalization"}, "option_flag": false}, {"option_text": {"zhcn": "热力图关联分布图", "enus": "Correlation plot with heat maps"}, "option_flag": false}, {"option_text": {"zhcn": "数据分箱", "enus": "Data binning"}, "option_flag": true}, {"option_text": {"zhcn": "单变量筛选", "enus": "Univariate selection"}, "option_flag": true}, {"option_text": {"zhcn": "基于树形分类器的特征重要性分析", "enus": "Feature importance with a tree-based classifier"}, "option_flag": false}, {"option_text": {"zhcn": "数据增广", "enus": "Data augmentation"}, "option_flag": true}], "analysis": {"enus": "Reference: https://towardsdatascience.com/an-overview-of-data-preprocessing-features-enrichment-automatic-feature-selection-60b0c12d75ad https://towardsdatascience.com/feature-selection-using-python-for-classification-problem- b5f00a1c7028#:~:text=Univariate%20feature%20selection%20works% 20by,analysis%20of%20variance%20(ANOVA).&text=That%20is%20why%20it%20is%20called%20'univariate ' https://arxiv.org/abs/2101.04530", "zhcn": ""}, "answer": "CDF"}, {"id": "160", "question": {"enus": "A power company wants to forecast future energy consumption for its customers in residential properties and commercial business properties. Historical power consumption data for the last 10 years is available. A team of data scientists who performed the initial data analysis and feature selection will include the historical power consumption data and data such as weather, number of individuals on the property, and public holidays. The data scientists are using Amazon Forecast to generate the forecasts. Which algorithm in Forecast should the data scientists use to meet these requirements? ", "zhcn": "某电力公司需预测其住宅与商业物业客户的未来能耗水平。目前掌握了过去十年的历史用电量数据，由数据科学团队完成初步数据分析和特征筛选后，将纳入天气、物业内人员数量及公共假日等变量。该团队正采用Amazon Forecast平台进行预测建模。为满足上述需求，数据科学家应选用Forecast中的何种算法？"}, "option": [{"option_text": {"zhcn": "自回归积分滑动平均模型（AIRMA）", "enus": "Autoregressive Integrated Moving Average (AIRMA)"}, "option_flag": false}, {"option_text": {"zhcn": "指数平滑法（ETS）", "enus": "Exponential Smoothing (ETS)"}, "option_flag": true}, {"option_text": {"zhcn": "卷积神经网络-分位数回归（CNN-QR）", "enus": "Convolutional Neural Network - Quantile Regression (CNN-QR)"}, "option_flag": false}, {"option_text": {"zhcn": "先知", "enus": "Prophet"}, "option_flag": false}], "analysis": {"enus": "Reference: https://jesit.springeropen.com/articles/10.1186/s43067-020-00021-8", "zhcn": ""}, "answer": "B"}, {"id": "161", "question": {"enus": "A company wants to use automatic speech recognition (ASR) to transcribe messages that are less than 60 seconds long from a voicemail- style application. The company requires the correct identification of 200 unique product names, some of which have unique spellings or pronunciations. The company has 4,000 words of Amazon SageMaker Ground Truth voicemail transcripts it can use to customize the chosen ASR model. The company needs to ensure that everyone can update their customizations multiple times each hour. Which approach will maximize transcription accuracy during the development phase? ", "zhcn": "一家公司计划采用自动语音识别技术，为语音邮件类应用中的短消息（时长不超过60秒）生成文字转录。该公司需确保200种独特产品名称能被准确识别，其中部分名称具有非常规拼写或发音特点。目前企业拥有4,000词规模的亚马逊SageMaker Ground Truth语音邮件转录数据集，可用于定制所选ASR模型。业务要求支持所有操作人员每小时多次更新自定义配置。在开发阶段，采用何种方案能最大限度提升转录准确率？"}, "option": [{"option_text": {"zhcn": "运用语音驱动的Amazon Lex机器人实现自动语音识别定制化功能。在该机器人中创建专属客户槽位，用以精准识别所需的各类产品名称。通过Amazon Lex的同义词机制，为每个产品名称提供多种常见变体形式，以应对开发过程中可能出现的识别误差。", "enus": "Use a voice-driven Amazon Lex bot to perform the ASR customization. Create customer slots within the bot that specifically identify  each of the required product names. Use the Amazon Lex synonym mechanism to provide additional variations of each product name as  mis-transcriptions are identified in development."}, "option_flag": true}, {"option_text": {"zhcn": "运用亚马逊Transcribe服务进行语音识别定制化处理。通过分析转录文本中的词汇置信度评分，自动将低于可接受阈值的词汇添加至定制词汇表文件并进行动态更新。在后续所有转录任务中，请持续采用这份经过优化的定制词汇表文件。", "enus": "Use Amazon Transcribe to perform the ASR customization. Analyze the word confidence scores in the transcript, and automatically  create or update a custom vocabulary file with any word that has a confidence score below an acceptable threshold value. Use this  updated custom vocabulary file in all future transcription tasks."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个包含各产品名称及音标发音的自定义词汇表文件，将其与亚马逊转录服务配合使用以实现语音识别定制化。通过分析转录文本，对手动更新自定义词汇表文件，增补或修正未被准确识别的产品名称条目。", "enus": "Create a custom vocabulary file containing each product name with phonetic pronunciations, and use it with Amazon Transcribe to  perform the ASR customization. Analyze the transcripts and manually update the custom vocabulary file to include updated or additional  entries for those names that are not being correctly identified."}, "option_flag": false}, {"option_text": {"zhcn": "利用音频转录文本构建训练数据集，并以此训练亚马逊Transcribe定制化语言模型。通过分析现有转录内容，对产品名称识别有误的文本进行人工校正，据此更新训练数据集。最终基于优化后的数据生成升级版定制语言模型。", "enus": "Use the audio transcripts to create a training dataset and build an Amazon Transcribe custom language model. Analyze the transcripts  and update the training dataset with a manually corrected version of transcripts where product names are not being transcribed correctly.  Create an updated custom language model."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/lex/latest/dg/lex-dg.pdf", "zhcn": ""}, "answer": "A"}, {"id": "162", "question": {"enus": "A company is building a demand forecasting model based on machine learning (ML). In the development stage, an ML specialist uses an Amazon SageMaker notebook to perform feature engineering during work hours that consumes low amounts of CPU and memory resources. A data engineer uses the same notebook to perform data preprocessing once a day on average that requires very high memory and completes in only 2 hours. The data preprocessing is not configured to use GPU. All the processes are running well on an ml.m5.4xlarge notebook instance. The company receives an AWS Budgets alert that the billing for this month exceeds the allocated budget. Which solution will result in the MOST cost savings? ", "zhcn": "一家公司正基于机器学习（ML）构建需求预测模型。在开发阶段，机器学习专家使用亚马逊SageMaker笔记本来进行特征工程，该任务在工作时段运行，消耗较低的CPU和内存资源。数据工程师平均每日使用同一笔记本执行一次数据预处理，此过程需占用极高内存但仅需两小时即可完成，且未配置使用GPU。目前所有流程均在ml.m5.4xlarge笔记本实例上稳定运行。公司收到AWS预算警报，显示本月账单已超出 allocated budget。下列哪种解决方案能实现最大程度的成本节约？"}, "option": [{"option_text": {"zhcn": "将笔记本实例类型调整为内存优化型实例，其vCPU核心数量需与ml.m5.4xlarge实例保持一致。闲置时请暂停运行该实例。数据预处理与特征工程开发均需在此实例上执行。", "enus": "Change the notebook instance type to a memory optimized instance with the same vCPU number as the ml.m5.4xlarge instance has.  Stop the notebook when it is not in use. Run both data preprocessing and feature engineering development on that instance."}, "option_flag": false}, {"option_text": {"zhcn": "保持笔记本实例类型与规格不变，闲置时请及时停止运行。数据预处理任务需选用P3型实例执行，其内存容量应与ml.m5.4xlarge实例保持一致，可通过Amazon SageMaker Processing服务实现此操作。", "enus": "Keep the notebook instance type and size the same. Stop the notebook when it is not in use. Run data preprocessing on a P3 instance  type with the same memory as the ml.m5.4xlarge instance by using Amazon SageMaker Processing."}, "option_flag": true}, {"option_text": {"zhcn": "将笔记本实例类型调整为更小规格的通用型实例。闲置时请及时停止笔记本运行。数据预处理任务建议采用Amazon SageMaker Processing服务，选用内存容量与ml.m5.4xlarge实例相同的ml.r5实例来执行。", "enus": "Change the notebook instance type to a smaller general purpose instance. Stop the notebook when it is not in use. Run data  preprocessing on an ml.r5 instance with the same memory size as the ml.m5.4xlarge instance by using Amazon SageMaker Processing."}, "option_flag": false}, {"option_text": {"zhcn": "将笔记本实例类型调整为更小规格的通用型实例。闲置时请及时停止笔记本运行。通过预留实例选项，选用与ml.m5.4xlarge实例内存容量相当的R5实例执行数据预处理任务。", "enus": "Change the notebook instance type to a smaller general purpose instance. Stop the notebook when it is not in use. Run data  preprocessing on an R5 instance with the same memory size as the ml.m5.4xlarge instance by using the Reserved Instance option."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "163", "question": {"enus": "A machine learning specialist is developing a regression model to predict rental rates from rental listings. A variable named Wall_Color represents the most prominent exterior wall color of the property. The following is the sample data, excluding all other variables: The specialist chose a model that needs numerical input data. Which feature engineering approaches should the specialist use to allow the regression model to learn from the Wall_Color data? (Choose two.) ", "zhcn": "一位机器学习专家正在开发一个回归模型，旨在通过租赁房源信息预测租金价格。其中变量\"Wall_Color\"代表物业外立面最显著的墙体颜色。以下是剔除其他变量后的样本数据：该专家选择的模型需要数值型输入数据。为使回归模型能够从\"Wall_Color\"数据中学习，应采用哪两种特征工程方法？（请选择两项。）"}, "option": [{"option_text": {"zhcn": "对数值进行整数变换，设定红色对应1，白色对应5，绿色对应10。", "enus": "Apply integer transformation and set Red = 1, White = 5, and Green = 10."}, "option_flag": true}, {"option_text": {"zhcn": "添加新列，用于存储颜色的独热编码表示。", "enus": "Add new columns that store one-hot representation of colors."}, "option_flag": false}, {"option_text": {"zhcn": "将颜色名称字符串替换为其长度。", "enus": "Replace the color name string by its length."}, "option_flag": false}, {"option_text": {"zhcn": "创建三列以RGB格式编码颜色。", "enus": "Create three columns to encode the color in RGB format."}, "option_flag": true}, {"option_text": {"zhcn": "将每种颜色名称替换为其在训练集中的出现频次。", "enus": "Replace each color name by its training set frequency."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AD"}, {"id": "164", "question": {"enus": "A data scientist is working on a public sector project for an urban trafic system. While studying the trafic patterns, it is clear to the data scientist that the trafic behavior at each light is correlated, subject to a small stochastic error term. The data scientist must model the trafic behavior to analyze the trafic patterns and reduce congestion. How will the data scientist MOST effectively model the problem? ", "zhcn": "一位数据科学家正负责某城市交通系统的公共部门项目。在研究交通流模式时，这位科学家发现每个路口的交通行为相互关联，且存在微小的随机误差项。为分析交通规律并缓解拥堵，需对交通行为进行建模。下列哪种方法能最高效地构建该问题的模型？"}, "option": [{"option_text": {"zhcn": "数据科学家需将此类问题构建为多智能体强化学习模型，从而求得相关均衡策略。", "enus": "The data scientist should obtain a correlated equilibrium policy by formulating this problem as a multi-agent reinforcement learning  problem."}, "option_flag": false}, {"option_text": {"zhcn": "数据科学家需将此类问题构建为单智能体强化学习模型，从而求得最优均衡策略。", "enus": "The data scientist should obtain the optimal equilibrium policy by formulating this problem as a single-agent reinforcement learning  problem."}, "option_flag": false}, {"option_text": {"zhcn": "数据科学家的目标并非寻求某种平衡策略，而应借助历史数据，通过监督学习的方法构建精准的交通流量预测模型。", "enus": "Rather than finding an equilibrium policy, the data scientist should obtain accurate predictors of trafic fiow by using historical data  through a supervised learning approach."}, "option_flag": false}, {"option_text": {"zhcn": "数据科学家的任务并非寻求均衡策略，而应通过运用代表城市新型交通模式的无标注模拟数据，并采用无监督学习方法，来获取精准的交通流预测指标。", "enus": "Rather than finding an equilibrium policy, the data scientist should obtain accurate predictors of trafic fiow by using unlabeled  simulated data representing the new trafic patterns in the city and applying an unsupervised learning approach."}, "option_flag": true}], "analysis": {"enus": "Reference: https://www.hindawi.com/journals/jat/2021/8878011/", "zhcn": ""}, "answer": "D"}, {"id": "165", "question": {"enus": "A data scientist is using the Amazon SageMaker Neural Topic Model (NTM) algorithm to build a model that recommends tags from blog posts. The raw blog post data is stored in an Amazon S3 bucket in JSON format. During model evaluation, the data scientist discovered that the model recommends certain stopwords such as \"a,\" \"an,\" and \"the\" as tags to certain blog posts, along with a few rare words that are present only in certain blog entries. After a few iterations of tag review with the content team, the data scientist notices that the rare words are unusual but feasible. The data scientist also must ensure that the tag recommendations of the generated model do not include the stopwords. What should the data scientist do to meet these requirements? ", "zhcn": "一位数据科学家正借助亚马逊SageMaker的神经主题模型（NTM）算法，构建能够从博客内容中智能推荐标签的模型。原始博客数据以JSON格式存储于亚马逊S3存储桶中。模型评估阶段，该科学家发现模型会向部分博客推荐诸如\"a\"、\"an\"、\"the\"等停用词作为标签，同时也会推荐仅在某些特定条目中出现的生僻词汇。经过与内容团队的多轮标签评审，科学家注意到这些生僻词汇虽不常见但具有实际意义。当前需要确保生成模型所推荐的标签不再包含停用词。请问该数据科学家应采取何种措施以满足上述需求？"}, "option": [{"option_text": {"zhcn": "运用亚马逊Comprehend实体识别API接口，从博客文章数据中筛除识别出的特定词汇，并更新亚马逊S3存储桶中的博客数据源。", "enus": "Use the Amazon Comprehend entity recognition API operations. Remove the detected words from the blog post data. Replace the blog  post data source in the S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "以S3存储桶中的博文数据作为数据源，运行SageMaker内置的主成分分析（PCA）算法。随后将训练任务生成的结果数据更新至原S3存储桶中的博文数据存储位置。", "enus": "Run the SageMaker built-in principal component analysis (PCA) algorithm with the blog post data from the S3 bucket as the data  source. Replace the blog post data in the S3 bucket with the results of the training job."}, "option_flag": false}, {"option_text": {"zhcn": "请使用SageMaker内置的目标检测算法替代NTM算法来处理博客文章数据的训练任务。", "enus": "Use the SageMaker built-in Object Detection algorithm instead of the NTM algorithm for the training job to process the blog post data."}, "option_flag": false}, {"option_text": {"zhcn": "运用scikit-learn库中的CountVectorizer函数对博客文章数据进行停用词过滤，并将处理后的词向量结果更新至亚马逊S3存储桶中的原始数据位置。", "enus": "Remove the stopwords from the blog post data by using the CountVectorizer function in the scikit-learn library. Replace the blog post  data in the S3 bucket with the results of the vectorizer."}, "option_flag": true}], "analysis": {"enus": "Reference: https://towardsdatascience.com/natural-language-processing-count-vectorization-with-scikit-learn-e7804269bb5e", "zhcn": ""}, "answer": "D"}, {"id": "166", "question": {"enus": "A company wants to create a data repository in the AWS Cloud for machine learning (ML) projects. The company wants to use AWS to perform complete ML lifecycles and wants to use Amazon S3 for the data storage. All of the company's data currently resides on premises and is 40 ׀¢׀’ in size. The company wants a solution that can transfer and automatically update data between the on-premises object storage and Amazon S3. The solution must support encryption, scheduling, monitoring, and data integrity validation. Which solution meets these requirements? ", "zhcn": "某公司计划在AWS云平台构建一个用于机器学习项目的数据存储库。该公司希望借助AWS完成完整的机器学习生命周期，并采用Amazon S3作为数据存储方案。目前企业所有数据均存储于本地，总量达40TB。需要设计一套能够在本地对象存储与Amazon S3之间实现数据传输、自动同步的解决方案，该方案必须支持加密传输、定时同步、运行监控及数据完整性验证。请问下列哪种方案符合上述要求？"}, "option": [{"option_text": {"zhcn": "使用S3同步命令对比源S3存储桶与目标S3存储桶，识别目标存储桶中缺失的源文件以及已被修改的源文件。", "enus": "Use the S3 sync command to compare the source S3 bucket and the destination S3 bucket. Determine which source files do not exist in  the destination S3 bucket and which source files were modified."}, "option_flag": false}, {"option_text": {"zhcn": "借助 AWS Transfer for FTPS 服务，可将文件从本地存储设备安全传输至 Amazon S3。", "enus": "Use AWS Transfer for FTPS to transfer the files from the on-premises storage to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS DataSync完成数据集的首次全量同步，并设定定期增量传输机制以捕捉变更数据，最终实现从本地到AWS环境的平滑迁移。", "enus": "Use AWS DataSync to make an initial copy of the entire dataset. Schedule subsequent incremental transfers of changing data until the  final cutover from on premises to AWS."}, "option_flag": true}, {"option_text": {"zhcn": "利用S3批量操作功能，可定期从本地存储系统拉取数据。同时在S3存储桶中启用版本控制功能，有效防范数据遭意外覆盖的风险。", "enus": "Use S3 Batch Operations to pull data periodically from the on-premises storage. Enable S3 Versioning on the S3 bucket to protect  against accidental overwrites."}, "option_flag": false}], "analysis": {"enus": "Configure DataSync to make an initial copy of your entire dataset, and schedule subsequent incremental transfers of changing data until the final cut-over from on- premises to AWS. Reference: https://aws.amazon.com/datasync/faqs/", "zhcn": ""}, "answer": "C"}, {"id": "167", "question": {"enus": "A company has video feeds and images of a subway train station. The company wants to create a deep learning model that will alert the station manager if any passenger crosses the yellow safety line when there is no train in the station. The alert will be based on the video feeds. The company wants the model to detect the yellow line, the passengers who cross the yellow line, and the trains in the video feeds. This task requires labeling. The video data must remain confidential. A data scientist creates a bounding box to label the sample data and uses an object detection model. However, the object detection model cannot clearly demarcate the yellow line, the passengers who cross the yellow line, and the trains. Which labeling approach will help the company improve this model? ", "zhcn": "某公司掌握着某地铁站的视频监控资料与图像数据。该公司计划开发一种深度学习模型，当站台无列车停靠时若有乘客越过安全黄线，系统能立即向站务人员发出警报。这项警报功能将基于视频监控数据实现，要求模型能准确识别安全黄线、越线乘客及进出站列车。为实现该目标，需要对数据进行标注处理，且所有视频数据均需严格保密。\n\n数据科学家采用边界框对样本数据进行标注，并运用目标检测模型进行训练。但发现该模型在安全黄线、越线乘客及列车这三类目标的识别边界上存在模糊不清的问题。请问采用何种标注方案能有效提升该模型的识别精度？"}, "option": [{"option_text": {"zhcn": "运用亚马逊Rekognition定制标签功能对数据集进行标注，并构建定制化的亚马逊Rekognition目标检测模型。创建专属人工标注团队，通过亚马逊增强型人工智能（Amazon A2I）对低置信度预测结果进行复核，进而优化并重新训练定制的亚马逊Rekognition模型。", "enus": "Use Amazon Rekognition Custom Labels to label the dataset and create a custom Amazon Rekognition object detection model. Create  a private workforce. Use Amazon Augmented AI (Amazon A2I) to review the low-confidence predictions and retrain the custom Amazon  Rekognition model."}, "option_flag": false}, {"option_text": {"zhcn": "采用亚马逊SageMaker Ground Truth的目标检测标注任务，并选用亚马逊Mechanical Turk作为标注工作团队。", "enus": "Use an Amazon SageMaker Ground Truth object detection labeling task. Use Amazon Mechanical Turk as the labeling workforce."}, "option_flag": true}, {"option_text": {"zhcn": "借助Amazon Rekognition Custom Labels标注数据集并构建定制化的亚马逊Rekognition目标检测模型。通过第三方AWS Marketplace服务商组建标注团队，并运用Amazon Augmented AI（Amazon A2I）对低置信度预测结果进行人工复核，进而优化定制的Amazon Rekognition模型。", "enus": "Use Amazon Rekognition Custom Labels to label the dataset and create a custom Amazon Rekognition object detection model. Create  a workforce with a third-party AWS Marketplace vendor. Use Amazon Augmented AI (Amazon A2I) to review the low-confidence predictions  and retrain the custom Amazon Rekognition model."}, "option_flag": false}, {"option_text": {"zhcn": "采用亚马逊SageMaker Ground Truth语义分割标注任务，并选用专属人工团队作为标注工作团队。", "enus": "Use an Amazon SageMaker Ground Truth semantic segmentation labeling task. Use a private workforce as the labeling workforce."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-management-public.html", "zhcn": ""}, "answer": "B"}, {"id": "168", "question": {"enus": "A data engineer at a bank is evaluating a new tabular dataset that includes customer data. The data engineer will use the customer data to create a new model to predict customer behavior. After creating a correlation matrix for the variables, the data engineer notices that many of the 100 features are highly correlated with each other. Which steps should the data engineer take to address this issue? (Choose two.) ", "zhcn": "某银行数据工程师正在评估一份包含客户数据的新表格数据集，计划利用这些数据构建预测客户行为的模型。在生成变量相关性矩阵后，该工程师发现100个特征中有许多存在高度相关性。为处理此情况，数据工程师应采取以下哪两项措施？（请选择两项）"}, "option": [{"option_text": {"zhcn": "采用线性算法对模型进行训练。", "enus": "Use a linear-based algorithm to train the model."}, "option_flag": false}, {"option_text": {"zhcn": "运用主成分分析法（PCA）。", "enus": "Apply principal component analysis (PCA)."}, "option_flag": true}, {"option_text": {"zhcn": "从数据集中剔除部分高度相关的特征。", "enus": "Remove a portion of highly correlated features from the dataset."}, "option_flag": false}, {"option_text": {"zhcn": "对数据集应用最小-最大归一化处理。", "enus": "Apply min-max feature scaling to the dataset."}, "option_flag": true}, {"option_text": {"zhcn": "对类别型变量进行独热编码处理。", "enus": "Apply one-hot encoding category-based variables."}, "option_flag": false}], "analysis": {"enus": "Reference: https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202 https://scikit- learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html", "zhcn": ""}, "answer": "BD"}, {"id": "169", "question": {"enus": "A company is building a new version of a recommendation engine. Machine learning (ML) specialists need to keep adding new data from users to improve personalized recommendations. The ML specialists gather data from the users' interactions on the platform and from sources such as external websites and social media. The pipeline cleans, transforms, enriches, and compresses terabytes of data daily, and this data is stored in Amazon S3. A set of Python scripts was coded to do the job and is stored in a large Amazon EC2 instance. The whole process takes more than 20 hours to finish, with each script taking at least an hour. The company wants to move the scripts out of Amazon EC2 into a more managed solution that will eliminate the need to maintain servers. Which approach will address all of these requirements with the LEAST development effort? ", "zhcn": "一家公司正在开发新版推荐引擎。机器学习专家需要持续整合用户新增数据以优化个性化推荐效果。专家们从用户在平台上的交互行为以及外部网站、社交媒体等渠道采集数据。该数据处理管道每日需清洗、转换、增强并压缩数TB级别的数据，最终存储至亚马逊S3云存储服务。现有若干Python脚本被编写用于执行这些任务，这些脚本目前存放于大型亚马逊EC2云服务器实例中。整套流程耗时超过20小时，每个脚本运行时间均不低于一小时。公司希望将这些脚本从EC2实例迁移至更集约化的托管解决方案，从而免除服务器维护负担。若要同时满足所有需求且开发投入最小，应采用哪种实施方案？"}, "option": [{"option_text": {"zhcn": "将数据载入Amazon Redshift集群，通过SQL语句执行数据处理流程，最终将结果保存至Amazon S3存储空间。", "enus": "Load the data into an Amazon Redshift cluster. Execute the pipeline by using SQL. Store the results in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "将数据载入Amazon DynamoDB，将脚本转换为AWS Lambda函数，通过触发Lambda执行来运行流程，最终将结果存储于Amazon S3中。", "enus": "Load the data into Amazon DynamoDB. Convert the scripts to an AWS Lambda function. Execute the pipeline by triggering Lambda  executions. Store the results in Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "创建一项AWS Glue作业。将脚本转换为PySpark代码。执行数据处理流程。将最终结果存储至Amazon S3。", "enus": "Create an AWS Glue job. Convert the scripts to PySpark. Execute the pipeline. Store the results in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "创建一组独立的AWS Lambda函数，分别用于执行各个脚本。通过AWS Step Functions Data Science SDK构建步骤工作流，并将运行结果存储至Amazon S3。", "enus": "Create a set of individual AWS Lambda functions to execute each of the scripts. Build a step function by using the AWS Step Functions  Data Science SDK. Store the results in Amazon S3."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html", "zhcn": ""}, "answer": "B"}, {"id": "170", "question": {"enus": "A retail company is selling products through a global online marketplace. The company wants to use machine learning (ML) to analyze customer feedback and identify specific areas for improvement. A developer has built a tool that collects customer reviews from the online marketplace and stores them in an Amazon S3 bucket. This process yields a dataset of 40 reviews. A data scientist building the ML models must identify additional sources of data to increase the size of the dataset. Which data sources should the data scientist use to augment the dataset of reviews? (Choose three.) ", "zhcn": "一家零售企业正通过全球在线商城销售产品。该公司希望运用机器学习技术分析客户反馈，以确定需要改进的具体环节。开发人员已构建工具，从在线商城采集客户评价并存储至亚马逊S3存储桶，初步获得包含40条评论的数据集。为扩充数据集规模，机器学习模型构建者需寻找更多数据源。下列哪些数据源可用于增强评论数据集？（请选择三项）"}, "option": [{"option_text": {"zhcn": "客户与公司客服专员之间的往来邮件", "enus": "Emails exchanged by customers and the company's customer service agents"}, "option_flag": false}, {"option_text": {"zhcn": "含有公司名称或其产品的社交媒体内容", "enus": "Social media posts containing the name of the company or its products"}, "option_flag": true}, {"option_text": {"zhcn": "一份可公开查阅的新闻文集", "enus": "A publicly available collection of news articles"}, "option_flag": false}, {"option_text": {"zhcn": "一份可供公众查阅的客户评价集锦", "enus": "A publicly available collection of customer reviews"}, "option_flag": true}, {"option_text": {"zhcn": "公司产品销售收入数据", "enus": "Product sales revenue figures for the company"}, "option_flag": false}, {"option_text": {"zhcn": "本公司产品的使用指南", "enus": "Instruction manuals for the company's products"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BDF"}, {"id": "171", "question": {"enus": "A machine learning (ML) specialist wants to create a data preparation job that uses a PySpark script with complex window aggregation operations to create data for training and testing. The ML specialist needs to evaluate the impact of the number of features and the sample count on model performance. Which approach should the ML specialist use to determine the ideal data transformations for the model? ", "zhcn": "一位机器学习专家计划构建数据预处理任务，该任务需采用包含复杂窗口聚合操作的PySpark脚本来生成训练与测试数据。为评估特征数量与样本规模对模型性能的影响，该专家需要确定何种方法能帮助选定最适合模型的数据转换方案。"}, "option": [{"option_text": {"zhcn": "向脚本中添加一个Amazon SageMaker Debugger钩子，用于捕获关键指标。随后将该脚本作为AWS Glue任务运行。", "enus": "Add an Amazon SageMaker Debugger hook to the script to capture key metrics. Run the script as an AWS Glue job."}, "option_flag": false}, {"option_text": {"zhcn": "在脚本中添加一个Amazon SageMaker Experiments追踪器，用于记录关键指标。随后将该脚本作为AWS Glue任务运行。", "enus": "Add an Amazon SageMaker Experiments tracker to the script to capture key metrics. Run the script as an AWS Glue job."}, "option_flag": true}, {"option_text": {"zhcn": "向脚本中添加一个Amazon SageMaker Debugger钩子，用于捕获关键参数。随后以SageMaker处理作业的形式运行该脚本。", "enus": "Add an Amazon SageMaker Debugger hook to the script to capture key parameters. Run the script as a SageMaker processing job."}, "option_flag": false}, {"option_text": {"zhcn": "在脚本中加入一个Amazon SageMaker Experiments追踪器，用于记录关键参数。随后将该脚本作为SageMaker处理任务运行。", "enus": "Add an Amazon SageMaker Experiments tracker to the script to capture key parameters. Run the script as a SageMaker processing job."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html", "zhcn": ""}, "answer": "B"}, {"id": "172", "question": {"enus": "A data scientist has a dataset of machine part images stored in Amazon Elastic File System (Amazon EFS). The data scientist needs to use Amazon SageMaker to create and train an image classification machine learning model based on this dataset. Because of budget and time constraints, management wants the data scientist to create and train a model with the least number of steps and integration work required. How should the data scientist meet these requirements? ", "zhcn": "一位数据科学家拥有一组存储在Amazon Elastic File System（Amazon EFS）中的机械零件图像数据集。该数据科学家需运用Amazon SageMaker平台，基于此数据集构建并训练图像分类机器学习模型。鉴于预算与时间限制，管理层要求数据科学家以最简化的步骤和最少的集成工作完成模型创建与训练。数据科学家应如何满足这些要求？"}, "option": [{"option_text": {"zhcn": "将EFS文件系统挂载至SageMaker笔记本实例，执行脚本将数据同步至Amazon FSx for Lustre文件系统。随后以FSx for Lustre文件系统作为数据源，启动SageMaker模型训练任务。", "enus": "Mount the EFS file system to a SageMaker notebook and run a script that copies the data to an Amazon FSx for Lustre file system. Run  the SageMaker training job with the FSx for Lustre file system as the data source."}, "option_flag": true}, {"option_text": {"zhcn": "启动一个临时的Amazon EMR集群。配置相关步骤以挂载EFS文件系统，并运用S3DistCp将数据复制至Amazon S3存储桶。随后以Amazon S3作为数据源，运行SageMaker训练任务。", "enus": "Launch a transient Amazon EMR cluster. Configure steps to mount the EFS file system and copy the data to an Amazon S3 bucket by  using S3DistCp. Run the SageMaker training job with Amazon S3 as the data source."}, "option_flag": false}, {"option_text": {"zhcn": "将EFS文件系统挂载至Amazon EC2实例，通过AWS命令行工具将数据复制到Amazon S3存储桶中。随后以Amazon S3作为数据源，启动SageMaker训练任务。", "enus": "Mount the EFS file system to an Amazon EC2 instance and use the AWS CLI to copy the data to an Amazon S3 bucket. Run the  SageMaker training job with Amazon S3 as the data source."}, "option_flag": false}, {"option_text": {"zhcn": "以EFS文件系统作为数据源，运行SageMaker训练任务。", "enus": "Run a SageMaker training job with an EFS file system as the data source."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/about-aws/whats-new/2019/08/amazon-sagemaker-works-with-amazon-fsx-lustre-amazon-efs-model-training/", "zhcn": ""}, "answer": "A"}, {"id": "173", "question": {"enus": "A retail company uses a machine learning (ML) model for daily sales forecasting. The company's brand manager reports that the model has provided inaccurate results for the past 3 weeks. At the end of each day, an AWS Glue job consolidates the input data that is used for the forecasting with the actual daily sales data and the predictions of the model. The AWS Glue job stores the data in Amazon S3. The company's ML team is using an Amazon SageMaker Studio notebook to gain an understanding about the source of the model's inaccuracies. What should the ML team do on the SageMaker Studio notebook to visualize the model's degradation MOST accurately? ", "zhcn": "一家零售企业采用机器学习模型进行日常销售预测。品牌经理反映，该模型近三周的预测结果存在偏差。每日营业结束后，AWS Glue作业会整合三方面数据：模型预测所需的输入数据、当日实际销售数据以及模型预测值，并将这些数据存储于Amazon S3中。目前该企业的机器学习团队正通过Amazon SageMaker Studio笔记本分析模型失准根源。若要最精准地呈现模型性能衰减情况，该团队应在SageMaker Studio笔记本中采取何种可视化方案？"}, "option": [{"option_text": {"zhcn": "绘制过去三周每日销售额的分布直方图，同时还需制作该期间之前每日销售额的分布直方图。", "enus": "Create a histogram of the daily sales over the last 3 weeks. In addition, create a histogram of the daily sales from before that period."}, "option_flag": false}, {"option_text": {"zhcn": "绘制过去三周内模型误差的分布直方图，同时还需生成该时间段之前模型误差的分布直方图。", "enus": "Create a histogram of the model errors over the last 3 weeks. In addition, create a histogram of the model errors from before that  period."}, "option_flag": false}, {"option_text": {"zhcn": "绘制一幅折线图，展示模型每周的平均绝对误差（MAE）数据。", "enus": "Create a line chart with the weekly mean absolute error (MAE) of the model."}, "option_flag": true}, {"option_text": {"zhcn": "请绘制过去三周内每日销售额与模型误差的散点图。同时，另作一张该时期之前每日销售额与模型误差的散点图。", "enus": "Create a scatter plot of daily sales versus model error for the last 3 weeks. In addition, create a scatter plot of daily sales versus model  error from before that period."}, "option_flag": false}], "analysis": {"enus": "Reference: https://machinelearningmastery.com/time-series-forecasting-performance-measures-with-python/", "zhcn": ""}, "answer": "C"}, {"id": "174", "question": {"enus": "An ecommerce company sends a weekly email newsletter to all of its customers. Management has hired a team of writers to create additional targeted content. A data scientist needs to identify five customer segments based on age, income, and location. The customers' current segmentation is unknown. The data scientist previously built an XGBoost model to predict the likelihood of a customer responding to an email based on age, income, and location. Why does the XGBoost model NOT meet the current requirements, and how can this be fixed? ", "zhcn": "一家电商公司每周会向所有客户发送电子邮件通讯。管理层已聘请内容团队撰写更具针对性的定制化内容。数据科学家需要根据年龄、收入及地理位置将客户划分为五个群体，但目前客户细分维度尚未明确。该数据科学家曾建立XGBoost模型，通过年龄、收入和地理位置来预测客户对邮件的响应概率。为何当前场景下XGBoost模型无法满足需求？又该如何调整解决？"}, "option": [{"option_text": {"zhcn": "XGBoost模型可输出真/假二元判定结果。本方案采用五维特征的主成分分析（PCA）来预测数据片段。", "enus": "The XGBoost model provides a true/false binary output. Apply principal component analysis (PCA) with five feature dimensions to  predict a segment."}, "option_flag": false}, {"option_text": {"zhcn": "XGBoost模型原本输出的是真/假二元结果。现将其预测类别扩展至五类，以实现对细分市场的判断。", "enus": "The XGBoost model provides a true/false binary output. Increase the number of classes the XGBoost model predicts to five classes to  predict a segment."}, "option_flag": false}, {"option_text": {"zhcn": "XGBoost模型是一种监督式机器学习算法。现使用相同数据集训练K值为5的K近邻（kNN）模型，用于预测数据分类。", "enus": "The XGBoost model is a supervised machine learning algorithm. Train a k-Nearest-Neighbors (kNN) model with K = 5 on the same  dataset to predict a segment."}, "option_flag": true}, {"option_text": {"zhcn": "XGBoost模型是一种监督式机器学习算法。请在同一数据集上训练K值为5的K均值模型，用于预测细分群体。", "enus": "The XGBoost model is a supervised machine learning algorithm. Train a k-means model with K = 5 on the same dataset to predict a  segment."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "175", "question": {"enus": "A global financial company is using machine learning to automate its loan approval process. The company has a dataset of customer information. The dataset contains some categorical fields, such as customer location by city and housing status. The dataset also includes financial fields in different units, such as account balances in US dollars and monthly interest in US cents. The company's data scientists are using a gradient boosting regression model to infer the credit score for each customer. The model has a training accuracy of 99% and a testing accuracy of 75%. The data scientists want to improve the model's testing accuracy. Which process will improve the testing accuracy the MOST? ", "zhcn": "一家全球性金融公司正运用机器学习技术实现贷款审批流程的自动化。该公司拥有包含客户信息的数据集，其中既有按城市划分的客户所在地、住房状况等分类字段，也包含以不同计量单位记录的财务字段——例如以美元为单位的账户余额，以及以美分计价的月利息。数据科学家团队采用梯度提升回归模型来推算每位客户的信用评分，目前该模型的训练准确率高达99%，但测试准确率仅为75%。为提升模型的测试准确度，下列哪种方法能最有效地实现这一目标？"}, "option": [{"option_text": {"zhcn": "对数据集中的类别字段采用独热编码处理。针对财务相关字段执行标准化操作。在数据上应用L1正则化方法。", "enus": "Use a one-hot encoder for the categorical fields in the dataset. Perform standardization on the financial fields in the dataset. Apply L1  regularization to the data."}, "option_flag": false}, {"option_text": {"zhcn": "对数据集中的分类字段进行标记化处理。针对数据集中的财务字段执行分箱操作。通过采用Z分数方法剔除数据中的异常值。", "enus": "Use tokenization of the categorical fields in the dataset. Perform binning on the financial fields in the dataset. Remove the outliers in  the data by using the z- score."}, "option_flag": true}, {"option_text": {"zhcn": "对数据集中的分类字段采用标签编码处理。针对财务相关字段实施L1正则化，同时对其余数据采用L2正则化方法。", "enus": "Use a label encoder for the categorical fields in the dataset. Perform L1 regularization on the financial fields in the dataset. Apply L2  regularization to the data."}, "option_flag": false}, {"option_text": {"zhcn": "对数据集中的分类字段进行对数变换处理。针对数据集中的财务字段实施分段离散化操作。采用插补方法填充数据集中的缺失值。", "enus": "Use a logarithm transformation on the categorical fields in the dataset. Perform binning on the financial fields in the dataset. Use  imputation to populate missing values in the dataset."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "176", "question": {"enus": "A machine learning (ML) specialist needs to extract embedding vectors from a text series. The goal is to provide a ready-to-ingest feature space for a data scientist to develop downstream ML predictive models. The text consists of curated sentences in English. Many sentences use similar words but in different contexts. There are questions and answers among the sentences, and the embedding space must differentiate between them. Which options can produce the required embedding vectors that capture word context and sequential QA information? (Choose two.) ", "zhcn": "机器学习专家需要从一系列文本中提取嵌入向量，其目标是为数据科学家提供可直接输入的特征空间，用以开发下游的机器学习预测模型。该文本由经过筛选的英文句子组成，许多句子虽使用相似词汇但语境各异。文本中穿插着提问与回答，而嵌入空间必须能对二者加以区分。下列哪些方案能够生成符合要求的嵌入向量，既能捕捉词汇语境又能保留问答序列信息？（请选择两项。）"}, "option": [{"option_text": {"zhcn": "Amazon SageMaker 序列到序列算法", "enus": "Amazon SageMaker seq2seq algorithm"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon SageMaker BlazingText算法在Skip-gram模式下运行", "enus": "Amazon SageMaker BlazingText algorithm in Skip-gram mode"}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker Object2Vec 算法", "enus": "Amazon SageMaker Object2Vec algorithm"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon SageMaker BlazingText算法在连续词袋（CBOW）模式下", "enus": "Amazon SageMaker BlazingText algorithm in continuous bag-of-words (CBOW) mode"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊SageMaker平台BlazingText算法在批量Skip-gram模式下，与定制循环神经网络（RNN）的融合运用。", "enus": "Combination of the Amazon SageMaker BlazingText algorithm in Batch Skip-gram mode with a custom recurrent neural network (RNN)"}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/create-a-word-pronunciation-sequence-to-sequence-model-using-amazon-sagemaker/ https://docs.aws.amazon.com/sagemaker/latest/dg/object2vec.html", "zhcn": ""}, "answer": "AC"}, {"id": "177", "question": {"enus": "A retail company wants to update its customer support system. The company wants to implement automatic routing of customer claims to different queues to prioritize the claims by category. Currently, an operator manually performs the category assignment and routing. After the operator classifies and routes the claim, the company stores the claim's record in a central database. The claim's record includes the claim's category. The company has no data science team or experience in the field of machine learning (ML). The company's small development team needs a solution that requires no ML expertise. Which solution meets these requirements? ", "zhcn": "一家零售企业计划升级其客户服务系统，旨在通过自动将客户投诉按类别分流至不同队列，实现按优先级处理投诉的机制。目前该项分类与分流工作由人工操作完成：当客服专员完成投诉分类并分配至对应队列后，系统会将投诉记录存储至中央数据库，其中包含已标注的投诉类别。由于该企业尚未设立数据科学团队且缺乏机器学习领域经验，其小型开发团队需要一套无需机器学习专业能力即可实施的解决方案。请问下列哪种方案符合这些要求？"}, "option": [{"option_text": {"zhcn": "将数据库导出为包含两列（claim_label 和 claim_text）的.csv文件。运用Amazon SageMaker平台的Object2Vec算法，基于该.csv文件训练预测模型。通过SageMaker将模型部署至推理端点，并在应用程序中开发服务接口，借助该端点对传入的索赔请求进行实时分析、预测分类标签，并自动流转至对应的处理队列。", "enus": "Export the database to a .csv file with two columns: claim_label and claim_text. Use the Amazon SageMaker Object2Vec algorithm and  the .csv file to train a model. Use SageMaker to deploy the model to an inference endpoint. Develop a service in the application to use the  inference endpoint to process incoming claims, predict the labels, and route the claims to the appropriate queue."}, "option_flag": false}, {"option_text": {"zhcn": "将数据库导出为仅含claim_text单列的.csv文件。运用Amazon SageMaker平台的隐狄利克雷分布（LDA）算法，结合该.csv文件进行模型训练。通过LDA算法实现标签的自动识别，并借助SageMaker将模型部署至推理端点。需在应用程序中开发服务模块，调用该推理端点处理传入的索赔请求：先预测对应标签，再将其路由至相应的处理队列。", "enus": "Export the database to a .csv file with one column: claim_text. Use the Amazon SageMaker Latent Dirichlet Allocation (LDA) algorithm  and the .csv file to train a model. Use the LDA algorithm to detect labels automatically. Use SageMaker to deploy the model to an  inference endpoint. Develop a service in the application to use the inference endpoint to process incoming claims, predict the labels, and  route the claims to the appropriate queue."}, "option_flag": false}, {"option_text": {"zhcn": "运用Amazon Textract解析数据库，自动识别claim_label与claim_text两列数据。结合Amazon Comprehend定制分类功能，利用提取的信息训练专属分类模型。在应用程序中开发服务模块，通过调用Amazon Comprehend API处理传入的索赔申请，预测对应标签，并将申请自动分流至相应处理队列。", "enus": "Use Amazon Textract to process the database and automatically detect two columns: claim_label and claim_text. Use Amazon  Comprehend custom classification and the extracted information to train the custom classifier. Develop a service in the application to use  the Amazon Comprehend API to process incoming claims, predict the labels, and route the claims to the appropriate queue."}, "option_flag": true}, {"option_text": {"zhcn": "将数据库导出为包含两列（索赔标签与索赔文本）的CSV文件。运用Amazon Comprehend自定义分类功能，结合该CSV文件训练定制分类器。在应用程序中开发服务接口，通过调用Amazon Comprehend API处理传入的索赔数据，预测对应标签，并将索赔案件自动分配至相应的处理队列。", "enus": "Export the database to a .csv file with two columns: claim_label and claim_text. Use Amazon Comprehend custom classification and the  .csv file to train the custom classifier. Develop a service in the application to use the Amazon Comprehend API to process incoming  claims, predict the labels, and route the claims to the appropriate queue."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/intelligently-split-multi-form-document-packages-with-amazon-textract-and-amazon- comprehend/", "zhcn": ""}, "answer": "C"}, {"id": "178", "question": {"enus": "A machine learning (ML) specialist is using Amazon SageMaker hyperparameter optimization (HPO) to improve a model's accuracy. The learning rate parameter is specified in the following HPO configuration: During the results analysis, the ML specialist determines that most of the training jobs had a learning rate between 0.01 and 0.1. The best result had a learning rate of less than 0.01. Training jobs need to run regularly over a changing dataset. The ML specialist needs to find a tuning mechanism that uses different learning rates more evenly from the provided range between MinValue and MaxValue. Which solution provides the MOST accurate result? ", "zhcn": "一位机器学习专家正利用Amazon SageMaker的超参数优化功能来提升模型精度。在超参数配置中设定了学习率参数。结果分析显示，多数训练任务的学习率集中在0.01至0.1之间，而最佳结果对应的学习率却低于0.01。由于训练任务需基于动态变化的数据集定期执行，该专家需要找到一种调参机制，能够更均衡地采用MinValue与MaxValue区间内的不同学习率。请问下列哪种方案能得出最精确的结果？"}, "option": [{"option_text": {"zhcn": "请按如下方式调整超参数优化配置：  \n在此次超参数优化任务中选取精确度最高的参数组合。", "enus": "Modify the HPO configuration as follows:   Select the most  accurate hyperparameter configuration form this HPO job."}, "option_flag": false}, {"option_text": {"zhcn": "请执行三项不同的超参数优化（HPO）任务，每项任务分别采用以下学习率区间作为最小值和最大值的取值范围，并确保每项HPO任务的训练次数保持一致：  \n✧ [0.01, 0.1]  \n✧ [0.001, 0.01]  \n✧ [0.0001, 0.001]  \n最终从这三项HPO任务中选取超参数配置精度最高的方案。", "enus": "Run three different HPO jobs that use different learning rates form the following intervals for MinValue and MaxValue while using the  same number of training jobs for each HPO job: ✑ [0.01, 0.1] ✑ [0.001, 0.01] ✑ [0.0001, 0.001] Select the most accurate hyperparameter  configuration form these three HPO jobs."}, "option_flag": false}, {"option_text": {"zhcn": "请按如下方式调整超参数优化配置：  \n从本次训练任务中选取精度最高的超参数配置方案。", "enus": "Modify the HPO configuration as follows:   Select the most accurate  hyperparameter configuration form this training job."}, "option_flag": true}, {"option_text": {"zhcn": "请运行三项不同的超参数优化（HPO）任务，其学习率分别从以下区间的最小值与最大值中选取。将每项HPO任务的训练次数均分为三组进行：\n✑ [0.01, 0.1]  \n✑ [0.001, 0.01]  \n✑ [0.0001, 0.001]  \n最终从这三项HPO任务中选取超参数配置精度最高的方案。", "enus": "Run three different HPO jobs that use different learning rates form the following intervals for MinValue and MaxValue. Divide the  number of training jobs for each HPO job by three: ✑ [0.01, 0.1] ✑ [0.001, 0.01] [0.0001, 0.001]   Select the most accurate  hyperparameter configuration form these three HPO jobs."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "179", "question": {"enus": "A manufacturing company wants to use machine learning (ML) to automate quality control in its facilities. The facilities are in remote locations and have limited internet connectivity. The company has 20 ׀¢׀’ of training data that consists of labeled images of defective product parts. The training data is in the corporate on- premises data center. The company will use this data to train a model for real-time defect detection in new parts as the parts move on a conveyor belt in the facilities. The company needs a solution that minimizes costs for compute infrastructure and that maximizes the scalability of resources for training. The solution also must facilitate the company's use of an ML model in the low-connectivity environments. Which solution will meet these requirements? ", "zhcn": "一家制造企业计划在其工厂中采用机器学习技术以实现质量控制的自动化。这些工厂地处偏远地区，网络连接条件有限。企业拥有20TB由缺陷产品部件标注图像构成的训练数据，这些数据存储于企业本地数据中心。公司将利用该数据训练模型，以便在零部件通过工厂传送带时实时检测新部件的缺陷。企业需要的解决方案必须最大限度降低计算基础设施成本，同时实现训练资源的高度可扩展性。该方案还需确保在低网络连通性环境下能够有效部署机器学习模型。何种方案可满足这些需求？"}, "option": [{"option_text": {"zhcn": "将训练数据导入至Amazon S3存储桶后，通过Amazon SageMaker服务平台进行模型训练与效果评估。随后借助SageMaker Neo功能对模型进行深度优化，最终将其部署于SageMaker托管服务的终端节点上。", "enus": "Move the training data to an Amazon S3 bucket. Train and evaluate the model by using Amazon SageMaker. Optimize the model by  using SageMaker Neo. Deploy the model on a SageMaker hosting services endpoint."}, "option_flag": true}, {"option_text": {"zhcn": "在本地环境训练并评估模型后，将其上传至Amazon S3存储桶。随后通过Amazon SageMaker托管服务端点部署模型。", "enus": "Train and evaluate the model on premises. Upload the model to an Amazon S3 bucket. Deploy the model on an Amazon SageMaker  hosting services endpoint."}, "option_flag": false}, {"option_text": {"zhcn": "将训练数据移至Amazon S3存储桶中，运用Amazon SageMaker进行模型训练与评估，并借助SageMaker Neo对模型进行优化。在生产车间通过AWS IoT Greengrass配置边缘设备，最终将优化后的模型部署至该设备上。", "enus": "Move the training data to an Amazon S3 bucket. Train and evaluate the model by using Amazon SageMaker. Optimize the model by  using SageMaker Neo. Set up an edge device in the manufacturing facilities with AWS IoT Greengrass. Deploy the model on the edge  device."}, "option_flag": false}, {"option_text": {"zhcn": "在本地环境训练模型。将训练完成的模型上传至Amazon S3存储桶。通过AWS IoT Greengrass在制造车间配置边缘设备，并将模型部署于该设备之上。", "enus": "Train the model on premises. Upload the model to an Amazon S3 bucket. Set up an edge device in the manufacturing facilities with AWS  IoT Greengrass. Deploy the model on the edge device."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html", "zhcn": ""}, "answer": "A"}, {"id": "180", "question": {"enus": "A company has an ecommerce website with a product recommendation engine built in TensorFlow. The recommendation engine endpoint is hosted by Amazon SageMaker. Three compute-optimized instances support the expected peak load of the website. Response times on the product recommendation page are increasing at the beginning of each month. Some users are encountering errors. The website receives the majority of its trafic between 8 AM and 6 PM on weekdays in a single time zone. Which of the following options are the MOST effective in solving the issue while keeping costs to a minimum? (Choose two.) ", "zhcn": "某公司电商网站内置了一套基于TensorFlow构建的商品推荐引擎，其服务端点由Amazon SageMaker托管。为应对网站预期峰值流量，当前配置了三台计算优化型实例。每月初，商品推荐页面的响应时间持续延长，部分用户开始遭遇系统报错。该网站流量主要集中在同一时区工作日的上午8点至下午6点。在控制成本的前提下，下列哪两项措施能最高效解决此问题？（请选择两项）"}, "option": [{"option_text": {"zhcn": "将终端节点配置为使用Amazon Elastic Inference（EI）加速器。", "enus": "Configure the endpoint to use Amazon Elastic Inference (EI) accelerators."}, "option_flag": false}, {"option_text": {"zhcn": "创建新的端点配置，需包含两个生产变体。", "enus": "Create a new endpoint configuration with two production variants."}, "option_flag": true}, {"option_text": {"zhcn": "将端点配置为根据InvocationsPerInstance指标自动扩展。", "enus": "Configure the endpoint to automatically scale with the InvocationsPerInstance metric."}, "option_flag": false}, {"option_text": {"zhcn": "部署第二个实例池以支持模型的蓝绿部署。", "enus": "Deploy a second instance pool to support a blue/green deployment of models."}, "option_flag": true}, {"option_text": {"zhcn": "请将终端节点重新配置为使用可突增实例。", "enus": "Reconfigure the endpoint to use burstable instances."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ProductionVariant.html https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment", "zhcn": ""}, "answer": "BD"}, {"id": "181", "question": {"enus": "A real-estate company is launching a new product that predicts the prices of new houses. The historical data for the properties and prices is stored in .csv format in an Amazon S3 bucket. The data has a header, some categorical fields, and some missing values. The company's data scientists have used Python with a common open-source library to fill the missing values with zeros. The data scientists have dropped all of the categorical fields and have trained a model by using the open-source linear regression algorithm with the default parameters. The accuracy of the predictions with the current model is below 50%. The company wants to improve the model performance and launch the new product as soon as possible. Which solution will meet these requirements with the LEAST operational overhead? ", "zhcn": "一家房地产公司正推出一款预测新房价格的新产品。房产历史数据及价格以.csv格式存储于亚马逊S3存储桶中，数据包含表头、若干分类字段及部分缺失值。该公司的数据科学家已采用Python及常用开源库，将缺失值以零值填补，并删除了所有分类字段，继而使用默认参数的开源线性回归算法完成模型训练。当前模型的预测准确率低于50%。公司希望以最低运维成本提升模型性能，尽快推出新产品。下列哪种方案能以最小运维投入满足这些要求？"}, "option": [{"option_text": {"zhcn": "为亚马逊弹性容器服务（Amazon ECS）创建一个可访问S3存储桶的服务关联角色。基于AWS深度学习容器镜像构建一个ECS集群。编写实现特征工程的代码。训练用于价格预测的逻辑回归模型，并指向存有数据集的存储桶。等待训练任务完成后执行推理预测。", "enus": "Create a service-linked role for Amazon Elastic Container Service (Amazon ECS) with access to the S3 bucket. Create an ECS cluster  that is based on an AWS Deep Learning Containers image. Write the code to perform the feature engineering. Train a logistic regression  model for predicting the price, pointing to the bucket with the dataset. Wait for the training job to complete. Perform the inferences."}, "option_flag": true}, {"option_text": {"zhcn": "创建一个与笔记本关联的新IAM角色，并基于此角色配置Amazon SageMaker笔记本实例。从S3存储桶中提取数据集。系统性地探索特征工程转换、回归算法及超参数的不同组合方案，在笔记本中全面对比所有实验结果，最终将最优配置部署至预测端点。", "enus": "Create an Amazon SageMaker notebook with a new IAM role that is associated with the notebook. Pull the dataset from the S3 bucket.  Explore different combinations of feature engineering transformations, regression algorithms, and hyperparameters. Compare all the  results in the notebook, and deploy the most accurate configuration in an endpoint for predictions."}, "option_flag": false}, {"option_text": {"zhcn": "创建具有访问Amazon S3、Amazon SageMaker及AWS Lambda权限的IAM角色。使用SageMaker内置XGBoost模型创建训练任务，并指向存有数据集的存储桶。指定房价作为目标特征。等待任务完成后，将模型文件加载至Lambda函数，用于对新房屋价格进行预测推断。", "enus": "Create an IAM role with access to Amazon S3, Amazon SageMaker, and AWS Lambda. Create a training job with the SageMaker built-in  XGBoost model pointing to the bucket with the dataset. Specify the price as the target feature. Wait for the job to complete. Load the  model artifact to a Lambda function for inference on prices of new houses."}, "option_flag": false}, {"option_text": {"zhcn": "为Amazon SageMaker创建一个具有S3存储桶访问权限的IAM角色。使用指向包含数据集的存储桶的SageMaker Autopilot功能，创建SageMaker自动机器学习任务。将价格指定为目标属性。等待任务执行完毕。部署最优模型以进行预测。", "enus": "Create an IAM role for Amazon SageMaker with access to the S3 bucket. Create a SageMaker AutoML job with SageMaker Autopilot  pointing to the bucket with the dataset. Specify the price as the target attribute. Wait for the job to complete. Deploy the best model for  predictions."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-ecs-setup.html", "zhcn": ""}, "answer": "A"}, {"id": "182", "question": {"enus": "A data scientist is reviewing customer comments about a company's products. The data scientist needs to present an initial exploratory analysis by using charts and a word cloud. The data scientist must use feature engineering techniques to prepare this analysis before starting a natural language processing (NLP) model. Which combination of feature engineering techniques should the data scientist use to meet these requirements? (Choose two.) ", "zhcn": "一位数据分析师正在审阅客户对公司产品的评价。为完成初步探索性分析，该分析师需借助图表与文字云进行呈现。在启动自然语言处理模型之前，必须通过特征工程技术完成数据预处理。请问为满足上述需求，该分析师应采用哪两种特征工程技术？（请选择两项）"}, "option": [{"option_text": {"zhcn": "命名实体识别", "enus": "Named entity recognition"}, "option_flag": false}, {"option_text": {"zhcn": "指代关系", "enus": "Coreference"}, "option_flag": false}, {"option_text": {"zhcn": "词干提取", "enus": "Stemming"}, "option_flag": false}, {"option_text": {"zhcn": "词频-逆向文件频率（TF-IDF）", "enus": "Term frequency-inverse document frequency (TF-IDF)"}, "option_flag": true}, {"option_text": {"zhcn": "情感分析", "enus": "Sentiment analysis"}, "option_flag": true}], "analysis": {"enus": "Reference: https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/", "zhcn": ""}, "answer": "DE"}, {"id": "183", "question": {"enus": "A data scientist is evaluating a GluonTS on Amazon SageMaker DeepAR model. The evaluation metrics on the test set indicate that the coverage score is 0.489 and 0.889 at the 0.5 and 0.9 quantiles, respectively. What can the data scientist reasonably conclude about the distributional forecast related to the test set? ", "zhcn": "一位数据科学家正在评估基于亚马逊SageMaker平台DeepAR模型的GluonTS性能。测试集的评估指标显示，在0.5和0.9分位数下，覆盖度得分分别为0.489和0.889。关于测试集相关的分布预测，该数据科学家可以得出什么合理结论？"}, "option": [{"option_text": {"zhcn": "覆盖率得分表明，该分布预测的校准效果欠佳。理想情况下，各分位数的覆盖率应基本保持一致。", "enus": "The coverage scores indicate that the distributional forecast is poorly calibrated. These scores should be approximately equal to each  other at all quantiles."}, "option_flag": false}, {"option_text": {"zhcn": "覆盖率评分显示该分布预测的校准效果欠佳。理想状态下，这些分数应在中位数处达到峰值，而在分布两端逐渐降低。", "enus": "The coverage scores indicate that the distributional forecast is poorly calibrated. These scores should peak at the median and be lower  at the tails."}, "option_flag": false}, {"option_text": {"zhcn": "覆盖率分数表明该分布预测的校准准确无误。这些分数理应始终低于相应分位数。", "enus": "The coverage scores indicate that the distributional forecast is correctly calibrated. These scores should always fall below the quantile  itself."}, "option_flag": false}, {"option_text": {"zhcn": "覆盖率得分表明该分布预测已得到准确校准，这些数值应近似等于对应的分位数本身。", "enus": "The coverage scores indicate that the distributional forecast is correctly calibrated. These scores should be approximately equal to the  quantile itself."}, "option_flag": true}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/amazon-forecast-now-supports-the-generation-of-forecasts-at-a-quantile-of-your-choice/", "zhcn": ""}, "answer": "D"}, {"id": "184", "question": {"enus": "An energy company has wind turbines, weather stations, and solar panels that generate telemetry data. The company wants to perform predictive maintenance on these devices. The devices are in various locations and have unstable internet connectivity. A team of data scientists is using the telemetry data to perform machine learning (ML) to conduct anomaly detection and predict maintenance before the devices start to deteriorate. The team needs a scalable, secure, high-velocity data ingestion mechanism. The team has decided to use Amazon S3 as the data storage location. Which approach meets these requirements? ", "zhcn": "一家能源公司拥有风力发电机、气象监测站及太阳能电池板，这些设备持续生成遥测数据。该公司计划对上述设备实施预测性维护。由于设备分布地域广泛且网络连接不稳定，数据科学团队正利用遥测数据开展机器学习，旨在实现异常状态监测并在设备性能衰退前预测维护需求。该团队需要构建一套可扩展、高安全性且能高速处理数据流的采集机制。团队已确定选用亚马逊S3作为数据存储平台。下列哪种方案最符合这些要求？"}, "option": [{"option_text": {"zhcn": "通过调用托管于亚马逊EC2云服务器的HTTP接口进行数据摄取。采用弹性负载均衡器后接自动扩展组态的EC2实例架构，将数据载入亚马逊S3存储服务。", "enus": "Ingest the data by using an HTTP API call to a web server that is hosted on Amazon EC2. Set up EC2 instances in an Auto Scaling  configuration behind an Elastic Load Balancer to load the data into Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "通过MQTT协议将数据摄取至AWS IoT Core。在AWS IoT Core中配置规则，借助Amazon Kinesis Data Firehose将数据传送至Kinesis数据流，并预设该数据流将数据写入指定的S3存储桶。", "enus": "Ingest the data over Message Queuing Telemetry Transport (MQTT) to AWS IoT Core. Set up a rule in AWS IoT Core to use Amazon  Kinesis Data Firehose to send data to an Amazon Kinesis data stream that is configured to write to an S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "通过MQTT协议将数据接入AWS IoT Core。在AWS IoT Core中配置规则，将所有MQTT数据路由至已设定写入S3存储桶的Amazon Kinesis Data Firehose传输流。", "enus": "Ingest the data over Message Queuing Telemetry Transport (MQTT) to AWS IoT Core. Set up a rule in AWS IoT Core to direct all MQTT  data to an Amazon Kinesis Data Firehose delivery stream that is configured to write to an S3 bucket."}, "option_flag": true}, {"option_text": {"zhcn": "通过MQTT协议将数据摄取至Amazon Kinesis数据流，该数据流已配置为写入指定的S3存储桶。", "enus": "Ingest the data over Message Queuing Telemetry Transport (MQTT) to Amazon Kinesis data stream that is configured to write to an S3  bucket."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/industries/real-time-operational-monitoring-of-renewable-energy-assets-with-aws-iot/", "zhcn": ""}, "answer": "C"}, {"id": "185", "question": {"enus": "A retail company collects customer comments about its products from social media, the company website, and customer call logs. A team of data scientists and engineers wants to find common topics and determine which products the customers are referring to in their comments. The team is using natural language processing (NLP) to build a model to help with this classification. Each product can be classified into multiple categories that the company defines. These categories are related but are not mutually exclusive. For example, if there is mention of \"Sample Yogurt\" in the document of customer comments, then \"Sample Yogurt\" should be classified as \"yogurt,\" \"snack,\" and \"dairy product.\" The team is using Amazon Comprehend to train the model and must complete the project as soon as possible. Which functionality of Amazon Comprehend should the team use to meet these requirements? ", "zhcn": "一家零售企业从社交媒体、公司官网及客服通话记录中收集客户对其产品的评价。数据科学家与工程师团队旨在从中提炼常见主题，并精准识别客户评论中提及的具体产品。该团队正运用自然语言处理技术构建分类模型，每个产品可对应企业定义的多个非互斥关联类别。例如，若客户评论中出现\"试饮酸奶\"字样，则该内容需同时归类于\"酸奶\"\"零食\"和\"乳制品\"三大类别。目前团队采用Amazon Comprehend平台进行模型训练，且需高效完成项目。请问，为满足上述需求，该团队应当选用Amazon Comprehend的哪项核心功能？"}, "option": [{"option_text": {"zhcn": "多类别模式下的自定义分类", "enus": "Custom classification with multi-class mode"}, "option_flag": true}, {"option_text": {"zhcn": "多标签模式下的自定义分类", "enus": "Custom classification with multi-label mode"}, "option_flag": false}, {"option_text": {"zhcn": "定制化实体识别", "enus": "Custom entity recognition"}, "option_flag": false}, {"option_text": {"zhcn": "内置模型", "enus": "Built-in models"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "186", "question": {"enus": "A data engineer is using AWS Glue to create optimized, secure datasets in Amazon S3. The data science team wants the ability to access the ETL scripts directly from Amazon SageMaker notebooks within a VPC. After this setup is complete, the data science team wants the ability to run the AWS Glue job and invoke the SageMaker training job. Which combination of steps should the data engineer take to meet these requirements? (Choose three.) ", "zhcn": "一位数据工程师正利用AWS Glue在Amazon S3中创建经过优化且安全的数据集。数据科学团队需要能够通过VPC内的Amazon SageMaker笔记本直接访问ETL脚本。完成此设置后，数据科学团队还需具备运行AWS Glue任务并调用SageMaker训练任务的能力。为满足这些需求，该数据工程师应采取哪三项步骤组合？（请选择三项）"}, "option": [{"option_text": {"zhcn": "在数据科学团队的VPC中创建SageMaker开发端点。", "enus": "Create a SageMaker development endpoint in the data science team's VPC."}, "option_flag": true}, {"option_text": {"zhcn": "在数据科学团队的VPC中创建一个AWS Glue开发端点。", "enus": "Create an AWS Glue development endpoint in the data science team's VPC."}, "option_flag": false}, {"option_text": {"zhcn": "通过AWS Glue开发终端创建SageMaker笔记本。", "enus": "Create SageMaker notebooks by using the AWS Glue development endpoint."}, "option_flag": false}, {"option_text": {"zhcn": "通过SageMaker控制台创建SageMaker笔记本实例。", "enus": "Create SageMaker notebooks by using the SageMaker console."}, "option_flag": true}, {"option_text": {"zhcn": "为 SageMaker 笔记本配置解密策略。", "enus": "Attach a decryption policy to the SageMaker notebooks."}, "option_flag": false}, {"option_text": {"zhcn": "为SageMaker笔记本创建IAM策略与IAM角色。", "enus": "Create an IAM policy and an IAM role for the SageMaker notebooks."}, "option_flag": true}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/access-amazon-s3-data-managed-by-aws-glue-data-catalog-from-amazon-sagemaker- notebooks/", "zhcn": ""}, "answer": "ADF"}, {"id": "187", "question": {"enus": "A data engineer needs to provide a team of data scientists with the appropriate dataset to run machine learning training jobs. The data will be stored in Amazon S3. The data engineer is obtaining the data from an Amazon Redshift database and is using join queries to extract a single tabular dataset. A portion of the schema is as follows: TransactionTimestamp (Timestamp) CardName (Varchar) CardNo (Varchar) The data engineer must provide the data so that any row with a CardNo value of NULL is removed. Also, the TransactionTimestamp column must be separated into a TransactionDate column and a TransactionTime column. Finally, the CardName column must be renamed to NameOnCard. The data will be extracted on a monthly basis and will be loaded into an S3 bucket. The solution must minimize the effort that is needed to set up infrastructure for the ingestion and transformation. The solution also must be automated and must minimize the load on the Amazon Redshift cluster. Which solution meets these requirements? ", "zhcn": "数据工程师需为数据科学团队提供适宜的数据集以支持机器学习训练任务。数据将存储于Amazon S3中，当前工程师正从Amazon Redshift数据库通过连接查询提取单一表格数据集。部分数据模式如下：  \n- 交易时间戳（Timestamp）  \n- 持卡人姓名（Varchar）  \n- 卡号（Varchar）  \n\n数据处理需满足以下要求：  \n1. 剔除卡号为NULL的所有数据行  \n2. 将交易时间戳字段拆分为独立交易日期列与交易时间列  \n3. 将持卡人姓名列重命名为NameOnCard  \n数据需按月提取并加载至S3存储桶，解决方案须最大限度减少数据摄取与转换所需的基础设施搭建成本，同时实现自动化流程并减轻Redshift集群负载。  \n\n何种方案可同时满足上述要求？"}, "option": [{"option_text": {"zhcn": "部署一个Amazon EMR集群，创建Apache Spark任务用于从Amazon Redshift集群读取数据并进行转换。将处理后的数据加载至S3存储桶，并将该任务配置为按月定期执行。", "enus": "Set up an Amazon EMR cluster. Create an Apache Spark job to read the data from the Amazon Redshift cluster and transform the data.  Load the data into the S3 bucket. Schedule the job to run monthly."}, "option_flag": false}, {"option_text": {"zhcn": "配置一台安装有SQL客户端（例如SQL Workbench/J）的亚马逊EC2实例，用于直接查询Amazon Redshift集群中的数据。将查询结果数据集导出至文件后，上传至S3存储桶。上述操作需每月定期执行。", "enus": "Set up an Amazon EC2 instance with a SQL client tool, such as SQL Workbench/J, to query the data from the Amazon Redshift cluster  directly Export the resulting dataset into a file. Upload the file into the S3 bucket. Perform these tasks monthly."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个AWS Glue作业，以Amazon Redshift集群为数据源，S3存储桶为目标端。运用内置的Filter、Map及RenameField转换器实现所需的数据处理逻辑，并将该作业配置为按月自动执行。", "enus": "Set up an AWS Glue job that has the Amazon Redshift cluster as the source and the S3 bucket as the destination. Use the built-in  transforms Filter, Map, and RenameField to perform the required transformations. Schedule the job to run monthly."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Redshift Spectrum执行查询，将数据直接写入S3存储桶。同时创建AWS Lambda函数，按月自动运行该查询任务。", "enus": "Use Amazon Redshift Spectrum to run a query that writes the data directly to the S3 bucket. Create an AWS Lambda function to run the  query monthly."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "188", "question": {"enus": "A machine learning (ML) specialist wants to bring a custom training algorithm to Amazon SageMaker. The ML specialist implements the algorithm in a Docker container that is supported by SageMaker. How should the ML specialist package the Docker container so that SageMaker can launch the training correctly? ", "zhcn": "一位机器学习专家希望将自定义训练算法引入Amazon SageMaker平台。该专家已将算法实现在SageMaker支持的Docker容器中。为确保SageMaker能正确启动训练任务，专家应当如何封装该Docker容器？"}, "option": [{"option_text": {"zhcn": "在Dockerfile的ENTRYPOINT指令中指定服务器参数。", "enus": "Specify the server argument in the ENTRYPOINT instruction in the Dockerfile."}, "option_flag": false}, {"option_text": {"zhcn": "在Dockerfile中，请于ENTRYPOINT指令处明确定义训练程序。", "enus": "Specify the training program in the ENTRYPOINT instruction in the Dockerfile."}, "option_flag": true}, {"option_text": {"zhcn": "在打包容器时，请将训练数据的路径添加至Docker构建命令中。", "enus": "Include the path to the training data in the docker build command when packaging the container."}, "option_flag": false}, {"option_text": {"zhcn": "在 Dockerfile 中通过 COPY 指令将训练程序复制到 /opt/ml/train 目录。", "enus": "Use a COPY instruction in the Dockerfile to copy the training program to the /opt/ml/train directory."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "189", "question": {"enus": "An ecommerce company wants to use machine learning (ML) to monitor fraudulent transactions on its website. The company is using Amazon SageMaker to research, train, deploy, and monitor the ML models. The historical transactions data is in a .csv file that is stored in Amazon S3. The data contains features such as the user's IP address, navigation time, average time on each page, and the number of clicks for each session. There is no label in the data to indicate if a transaction is anomalous. Which models should the company use in combination to detect anomalous transactions? (Choose two.) ", "zhcn": "一家电子商务公司希望借助机器学习技术监测其网站上的欺诈交易。该公司正使用Amazon SageMaker进行机器学习模型的研究、训练、部署与监控。历史交易数据存储于Amazon S3的.csv格式文件中，包含用户IP地址、浏览时长、页面平均停留时间及单次会话点击量等特征。由于数据未标注交易是否异常，请问该公司应采用哪两种模型组合来实现异常交易检测？（请选择两项）"}, "option": [{"option_text": {"zhcn": "“IP洞察”", "enus": "IP Insights"}, "option_flag": true}, {"option_text": {"zhcn": "K-近邻算法（k-NN）", "enus": "K-nearest neighbors (k-NN)"}, "option_flag": false}, {"option_text": {"zhcn": "采用逻辑函数的线性学习器", "enus": "Linear learner with a logistic function"}, "option_flag": true}, {"option_text": {"zhcn": "随机切割森林（RCF）", "enus": "Random Cut Forest (RCF)"}, "option_flag": false}, {"option_text": {"zhcn": "XGBoost", "enus": "XGBoost"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AC"}, {"id": "190", "question": {"enus": "A healthcare company is using an Amazon SageMaker notebook instance to develop machine learning (ML) models. The company's data scientists will need to be able to access datasets stored in Amazon S3 to train the models. Due to regulatory requirements, access to the data from instances and services used for training must not be transmitted over the internet. Which combination of steps should an ML specialist take to provide this access? (Choose two.) ", "zhcn": "一家医疗公司正借助亚马逊SageMaker笔记本来开发机器学习模型。为确保数据科学家能够访问存储在亚马逊S3中用于训练模型的数据集，同时遵循监管要求（训练所用实例与服务的数据传输不得经由互联网），机器学习专家应采取哪两项措施实现此目标？（请选择两项）"}, "option": [{"option_text": {"zhcn": "将SageMaker笔记本实例配置为在启动时附加VPC并禁用互联网访问。", "enus": "Configure the SageMaker notebook instance to be launched with a VPC attached and internet access disabled."}, "option_flag": true}, {"option_text": {"zhcn": "在 SageMaker 与 Amazon S3 之间建立并配置 VPN 隧道。", "enus": "Create and configure a VPN tunnel between SageMaker and Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "创建并配置一个S3 VPC终端节点，将其关联至指定VPC。", "enus": "Create and configure an S3 VPC endpoint Attach it to the VPC."}, "option_flag": true}, {"option_text": {"zhcn": "创建一条S3存储桶策略，允许来自VPC的流量访问，同时拒绝来自互联网的流量访问。", "enus": "Create an S3 bucket policy that allows trafic from the VPC and denies trafic from the internet."}, "option_flag": false}, {"option_text": {"zhcn": "部署AWS中转网关，将S3存储桶与SageMaker实例连接至网关。", "enus": "Deploy AWS Transit Gateway Attach the S3 bucket and the SageMaker instance to the gateway."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AC"}, {"id": "191", "question": {"enus": "A machine learning (ML) specialist at a retail company is forecasting sales for one of the company's stores. The ML specialist is using data from the past 10 years. The company has provided a dataset that includes the total amount of money in sales each day for the store. Approximately 5% of the days are missing sales data. The ML specialist builds a simple forecasting model with the dataset and discovers that the model performs poorly. The performance is poor around the time of seasonal events, when the model consistently predicts sales figures that are too low or too high. Which actions should the ML specialist take to try to improve the model's performance? (Choose two.) ", "zhcn": "某零售公司的机器学习专家正在为旗下门店进行销售额预测。该专家采用了过去十年的历史数据，公司提供的数据集包含该门店每日销售总额，其中约5%的日期存在销售数据缺失。专家基于此数据集构建了一个简易预测模型，但发现模型在季节性活动期间表现不佳——其预测值总是系统性偏离实际值，或明显偏高或偏低。若要提升模型性能，该专家应采取哪两项改进措施？（请选择两项）"}, "option": [{"option_text": {"zhcn": "向数据集中补充该店铺的销售周期信息。", "enus": "Add information about the store's sales periods to the dataset."}, "option_flag": false}, {"option_text": {"zhcn": "邻近区域内各门店的销售数据汇总。", "enus": "Aggregate sales figures from stores in the same proximity."}, "option_flag": true}, {"option_text": {"zhcn": "对数据进行平滑处理以修正季节性波动。", "enus": "Apply smoothing to correct for seasonal variation."}, "option_flag": false}, {"option_text": {"zhcn": "将预测频率由每日调整为每周。", "enus": "Change the forecast frequency from daily to weekly."}, "option_flag": false}, {"option_text": {"zhcn": "采用线性插值法填补数据集中的缺失值。", "enus": "Replace missing values in the dataset by using linear interpolation."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BE"}, {"id": "192", "question": {"enus": "A newspaper publisher has a table of customer data that consists of several numerical and categorical features, such as age and education history, as well as subscription status. The company wants to build a targeted marketing model for predicting the subscription status based on the table data. Which Amazon SageMaker built-in algorithm should be used to model the targeted marketing? ", "zhcn": "一家报社拥有一份客户数据表，其中包含若干数值型与类别型特征，例如年龄与教育背景，以及订阅状态信息。该公司希望基于此表格数据构建精准营销模型，用以预测客户的订阅意向。在此场景下，应当选用亚马逊SageMaker平台中的哪种内置算法来建立该精准营销模型？"}, "option": [{"option_text": {"zhcn": "随机切割森林（RCF）", "enus": "Random Cut Forest (RCF)"}, "option_flag": false}, {"option_text": {"zhcn": "XGBoost", "enus": "XGBoost"}, "option_flag": false}, {"option_text": {"zhcn": "神经主题模型（Neural Topic Model，简称NTM）", "enus": "Neural Topic Model (NTM)"}, "option_flag": true}, {"option_text": {"zhcn": "DeepAR预测模型", "enus": "DeepAR forecasting"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "193", "question": {"enus": "A company will use Amazon SageMaker to train and host a machine learning model for a marketing campaign. The data must be encrypted at rest. Most of the data is sensitive customer data. The company wants AWS to maintain the root of trust for the encryption keys and wants key usage to be logged. Which solution will meet these requirements with the LEAST operational overhead? ", "zhcn": "一家公司将利用Amazon SageMaker平台，为营销活动训练并部署机器学习模型。所有静态数据均需加密存储，其中大部分为敏感的客户信息。该公司要求由AWS托管加密密钥的信任根，并记录密钥使用日志。在满足上述需求的前提下，哪种解决方案能最大限度降低运维复杂度？"}, "option": [{"option_text": {"zhcn": "借助AWS安全令牌服务（AWS STS）生成临时安全凭证，为所有SageMaker实例的存储卷进行加密，同时保护Amazon S3中的模型制品及数据。", "enus": "Use AWS Security Token Service (AWS STS) to create temporary tokens to encrypt the storage volumes for all SageMaker instances and  to encrypt the model artifacts and data in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在AWS密钥管理服务（AWS KMS）中采用客户托管密钥，对所有SageMaker实例的存储卷进行加密，并对Amazon S3中的模型工件及数据实施加密保护。", "enus": "Use customer managed keys in AWS Key Management Service (AWS KMS) to encrypt the storage volumes for all SageMaker instances  and to encrypt the model artifacts and data in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "借助AWS CloudHSM中存储的加密密钥，为所有SageMaker实例的存储卷进行加密，并对Amazon S3中的模型制品及数据实施加密保护。", "enus": "Use encryption keys stored in AWS CloudHSM to encrypt the storage volumes for all SageMaker instances and to encrypt the model  artifacts and data in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker内置临时密钥对所有SageMaker实例的存储卷进行加密。为新建的亚马逊弹性块存储卷启用默认加密功能。", "enus": "Use SageMaker built-in transient keys to encrypt the storage volumes for all SageMaker instances. Enable default encryption ffnew  Amazon Elastic Block Store (Amazon EBS) volumes."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "194", "question": {"enus": "A data scientist is working on a model to predict a company's required inventory stock levels. All historical data is stored in .csv files in the company's data lake on Amazon S3. The dataset consists of approximately 500 GB of data The data scientist wants to use SQL to explore the data before training the model. The company wants to minimize costs. Which option meets these requirements with the LEAST operational overhead? ", "zhcn": "一位数据科学家正在构建预测公司所需库存水平的模型。所有历史数据均以.csv格式存储于亚马逊S3平台的企业数据湖中，数据集规模约为500GB。该科学家计划在训练模型前使用SQL进行数据探查，且公司要求尽可能控制成本。在满足上述需求的前提下，下列方案中哪一项能以最低运维负担实现目标？"}, "option": [{"option_text": {"zhcn": "创建Amazon EMR集群。在Apache Hive元存储中建立外部表，使其指向存储于S3存储桶内的数据。随后可通过Hive控制台进行数据探查。", "enus": "Create an Amazon EMR cluster. Create external tables in the Apache Hive metastore, referencing the data that is stored in the S3  bucket. Explore the data from the Hive console."}, "option_flag": false}, {"option_text": {"zhcn": "借助AWS Glue对S3存储桶进行元数据爬取，并在AWS Glue数据目录中建立数据表。随后通过Amazon Athena对数据进行探索分析。", "enus": "Use AWS Glue to crawl the S3 bucket and create tables in the AWS Glue Data Catalog. Use Amazon Athena to explore the data."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个Amazon Redshift集群。通过COPY命令从Amazon S3导入数据。利用Amazon Redshift查询编辑器界面进行数据探索。", "enus": "Create an Amazon Redshift cluster. Use the COPY command to ingest the data from Amazon S3. Explore the data from the Amazon  Redshift query editor GUI."}, "option_flag": false}, {"option_text": {"zhcn": "创建Amazon Redshift集群。在外部模式中建立外部表，关联存储数据的S3桶。通过Amazon Redshift查询编辑器图形界面进行数据探查。", "enus": "Create an Amazon Redshift cluster. Create external tables in an external schema, referencing the S3 bucket that contains the data.  Explore the data from the Amazon Redshift query editor GUI."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "195", "question": {"enus": "A geospatial analysis company processes thousands of new satellite images each day to produce vessel detection data for commercial shipping. The company stores the training data in Amazon S3. The training data incrementally increases in size with new images each day. The company has configured an Amazon SageMaker training job to use a single ml.p2.xlarge instance with File input mode to train the built-in Object Detection algorithm. The training process was successful last month but is now failing because of a lack of storage. Aside from the addition of training data, nothing has changed in the model training process. A machine learning (ML) specialist needs to change the training configuration to fix the problem. The solution must optimize performance and must minimize the cost of training. Which solution will meet these requirements? ", "zhcn": "一家地理空间分析公司每日处理数千幅新增卫星影像，为商业航运提供船舶探测数据。该公司将训练数据存储于亚马逊S3服务中，随着每日新增影像的不断汇入，训练数据规模持续扩大。公司原采用亚马逊SageMaker训练任务，配置单台ml.p2.xlarge实例并以文件输入模式运行内置目标检测算法。上月训练流程尚能顺利完成，而今却因存储空间不足而中断。除训练数据增加外，模型训练流程未作任何变动。机器学习专家需调整训练配置以解决此问题，且解决方案必须兼顾性能优化与训练成本控制。请问下列哪种方案符合这些要求？"}, "option": [{"option_text": {"zhcn": "调整训练配置，采用两台ml.p2.xlarge实例进行模型训练。", "enus": "Modify the training configuration to use two ml.p2.xlarge instances."}, "option_flag": false}, {"option_text": {"zhcn": "调整训练配置，采用管道输入模式。", "enus": "Modify the training configuration to use Pipe input mode."}, "option_flag": false}, {"option_text": {"zhcn": "调整训练配置，采用单台ml.p3.2xlarge实例进行运算。", "enus": "Modify the training configuration to use a single ml.p3.2xlarge instance."}, "option_flag": true}, {"option_text": {"zhcn": "调整训练配置，采用亚马逊弹性文件系统（Amazon EFS）替代亚马逊S3，用于存储训练输入数据。", "enus": "Modify the training configuration to use Amazon Elastic File System (Amazon EFS) instead of Amazon S3 to store the input training  data."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "196", "question": {"enus": "A company is using Amazon SageMaker to build a machine learning (ML) model to predict customer churn based on customer call transcripts. Audio files from customer calls are located in an on-premises VoIP system that has petabytes of recorded calls. The on-premises infrastructure has high-velocity networking and connects to the company's AWS infrastructure through a VPN connection over a 100 Mbps connection. The company has an algorithm for transcribing customer calls that requires GPUs for inference. The company wants to store these transcriptions in an Amazon S3 bucket in the AWS Cloud for model development. Which solution should an ML specialist use to deliver the transcriptions to the S3 bucket as quickly as possible? ", "zhcn": "某公司正运用Amazon SageMaker构建机器学习模型，旨在通过客户通话记录预测用户流失情况。企业本地VoIP系统中存有数PB的客户通话音频文件，该本地基础设施具备高速网络特性，并通过100 Mbps带宽的VPN连接与公司AWS架构互联。公司现有一套需GPU进行推理的通话转录算法，希望将转录文本存储于AWS云端的Amazon S3存储桶中以支持模型开发。请问机器学习专家应采用何种解决方案，方能以最优速度将转录文件传输至S3存储桶？"}, "option": [{"option_text": {"zhcn": "请订购并使用配备NVIDIA Tesla模块的AWS Snowball Edge计算优化设备来运行转录算法。通过AWS DataSync将生成的转录文件传输至指定的转录S3存储桶。", "enus": "Order and use an AWS Snowball Edge Compute Optimized device with an NVIDIA Tesla module to run the transcription algorithm. Use  AWS DataSync to send the resulting transcriptions to the transcription S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "通过配置搭载Amazon EC2 Inf1实例的AWS Snowcone设备，部署并运行语音转码算法。随后借助AWS DataSync服务，将生成的转码文本传输至指定的S3存储桶。", "enus": "Order and use an AWS Snowcone device with Amazon EC2 Inf1 instances to run the transcription algorithm. Use AWS DataSync to send  the resulting transcriptions to the transcription S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "部署并启用AWS Outposts服务，在基于GPU的Amazon EC2实例上运行语音转文本算法。将生成的转录文件存储于专设的S3存储桶中。", "enus": "Order and use AWS Outposts to run the transcription algorithm on GPU-based Amazon EC2 instances. Store the resulting transcriptions  in the transcription S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "使用AWS DataSync将音频文件导入至Amazon S3存储服务。创建AWS Lambda函数，以便在音频文件上传至Amazon S3时自动运行转录算法。将该函数配置为将生成的转录结果写入指定的转录S3存储桶中。", "enus": "Use AWS DataSync to ingest the audio files to Amazon S3. Create an AWS Lambda function to run the transcription algorithm on the  audio files when they are uploaded to Amazon S3. Configure the function to write the resulting transcriptions to the transcription S3  bucket."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "197", "question": {"enus": "A company has a podcast platform that has thousands of users. The company has implemented an anomaly detection algorithm to detect low podcast engagement based on a 10-minute running window of user events such as listening, pausing, and exiting the podcast. A machine learning (ML) specialist is designing the data ingestion of these events with the knowledge that the event payload needs some small transformations before inference. How should the ML specialist design the data ingestion to meet these requirements with the LEAST operational overhead? ", "zhcn": "某公司旗下播客平台拥有数千名用户。为检测用户参与度低迷状况，该公司已部署异常检测算法，该算法基于十分钟滚动窗口内的用户行为（如收听、暂停、退出播客等）进行监测。鉴于事件载荷在推理前需进行微量数据转换，机器学习专家正在设计事件数据摄取方案。请问该专家应如何以最小运维成本实现这一数据摄取流程的设计？"}, "option": [{"option_text": {"zhcn": "通过AWS AppSync中的GraphQL API接收事件数据，将其存储于Amazon DynamoDB数据表。利用DynamoDB数据流触发AWS Lambda函数，在推理前对最近10分钟的数据进行转换处理。", "enus": "Ingest event data by using a GraphQLAPI in AWS AppSync. Store the data in an Amazon DynamoDB table. Use DynamoDB Streams to  call an AWS Lambda function to transform the most recent 10 minutes of data before inference."}, "option_flag": false}, {"option_text": {"zhcn": "通过亚马逊Kinesis数据流接收事件数据，借助亚马逊Kinesis数据火渠将信息存储于亚马逊S3存储服务。在推理前，运用AWS Glue对最近十分钟的数据进行转换处理。", "enus": "Ingest event data by using Amazon Kinesis Data Streams. Store the data in Amazon S3 by using Amazon Kinesis Data Firehose. Use  AWS Glue to transform the most recent 10 minutes of data before inference."}, "option_flag": true}, {"option_text": {"zhcn": "通过亚马逊Kinesis数据流接收事件数据，并借助基于Apache Flink的亚马逊Kinesis数据分析应用，在推理前对最近十分钟的数据进行实时处理。", "enus": "Ingest event data by using Amazon Kinesis Data Streams. Use an Amazon Kinesis Data Analytics for Apache Flink application to  transform the most recent 10 minutes of data before inference."}, "option_flag": false}, {"option_text": {"zhcn": "通过Amazon Managed Streaming for Apache Kafka（Amazon MSK）摄取事件数据，并利用AWS Lambda函数在推理前对最近10分钟的数据进行转换处理。", "enus": "Ingest event data by using Amazon Managed Streaming for Apache Kafka (Amazon MSK). Use an AWS Lambda function to transform  the most recent 10 minutes of data before inference."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "198", "question": {"enus": "A company wants to predict the classification of documents that are created from an application. New documents are saved to an Amazon S3 bucket every 3 seconds. The company has developed three versions of a machine learning (ML) model within Amazon SageMaker to classify document text. The company wants to deploy these three versions to predict the classification of each document. Which approach will meet these requirements with the LEAST operational overhead? ", "zhcn": "某公司需对应用程序生成的文档进行自动分类预测，新文档每三秒便会存入亚马逊S3存储桶。该公司已在Amazon SageMaker平台上开发了三个版本的机器学习模型用于文档文本分类，现希望部署这三个版本来实现每份文档的自动分类预测。在满足需求的前提下，下列哪种方案能最大限度降低运维复杂度？"}, "option": [{"option_text": {"zhcn": "配置S3事件通知机制，使其在创建新文档时自动触发AWS Lambda函数。同时设定该Lambda函数启动三项SageMaker批量转换任务——每份文档需分别通过三个模型各执行一次批量转换。", "enus": "Configure an S3 event notification that invokes an AWS Lambda function when new documents are created. Configure the Lambda  function to create three SageMaker batch transform jobs, one batch transform job for each model for each document."}, "option_flag": false}, {"option_text": {"zhcn": "将所有模型部署至单一SageMaker终端节点，每个模型作为独立的生产变体进行配置。设置S3事件通知机制，当有新文档创建时自动触发AWS Lambda函数。同时配置该Lambda函数，使其能够调用各个生产变体并返回每个模型的推理结果。", "enus": "Deploy all the models to a single SageMaker endpoint. Treat each model as a production variant. Configure an S3 event notification  that invokes an AWS Lambda function when new documents are created. Configure the Lambda function to call each production variant  and return the results of each model."}, "option_flag": false}, {"option_text": {"zhcn": "将每个模型部署至独立的SageMaker终端节点。配置S3事件通知机制，当有新文档生成时自动触发AWS Lambda函数。设定该Lambda函数依次调用各终端节点，并返回各模型的推理结果。", "enus": "Deploy each model to its own SageMaker endpoint Configure an S3 event notification that invokes an AWS Lambda function when new  documents are created. Configure the Lambda function to call each endpoint and return the results of each model."}, "option_flag": true}, {"option_text": {"zhcn": "将每个模型分别部署至独立的SageMaker终端节点。创建三个AWS Lambda函数，并配置每个函数分别调用不同的终端节点并返回结果。设置三个S3事件通知，以便在有新文档创建时自动触发相应的Lambda函数。", "enus": "Deploy each model to its own SageMaker endpoint. Create three AWS Lambda functions. Configure each Lambda function to call a  different endpoint and return the results. Configure three S3 event notifications to invoke the Lambda functions when new documents are  created."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "199", "question": {"enus": "A manufacturing company needs to identify returned smartphones that have been damaged by moisture. The company has an automated process that produces 2,000 diagnostic values for each phone. The database contains more than five million phone evaluations. The evaluation process is consistent, and there are no missing values in the data. A machine learning (ML) specialist has trained an Amazon SageMaker linear learner ML model to classify phones as moisture damaged or not moisture damaged by using all available features. The model's F1 score is 0.6. Which changes in model training would MOST likely improve the model's F1 score? (Choose two.) ", "zhcn": "一家制造公司需要甄别因受潮而损坏的退货智能手机。该公司采用自动化流程，为每部手机生成2000项诊断数据。数据库中已收录超过五百万次手机检测记录，评估流程标准统一，且数据无任何缺失。一位机器学习专家利用全部可用特征，训练了亚马逊SageMaker线性学习器模型，用以将手机划分为\"受潮损坏\"与\"未受潮损坏\"两类。当前模型的F1得分为0.6。若要提升该模型的F1得分，以下哪两项训练调整最可能见效？（请选择两项）"}, "option": [{"option_text": {"zhcn": "继续采用SageMaker线性学习器算法，同时运用SageMaker主成分分析（PCA）算法缩减特征变量数量。", "enus": "Continue to use the SageMaker linear learner algorithm. Reduce the number of features with the SageMaker principal component  analysis (PCA) algorithm."}, "option_flag": true}, {"option_text": {"zhcn": "继续采用SageMaker线性学习器算法，同时通过scikit-learn多维缩放（MDS）算法减少特征数量。", "enus": "Continue to use the SageMaker linear learner algorithm. Reduce the number of features with the scikit-learn multi-dimensional scaling  (MDS) algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "继续采用SageMaker线性学习器算法，并将预测器类型设定为回归器。", "enus": "Continue to use the SageMaker linear learner algorithm. Set the predictor type to regressor."}, "option_flag": false}, {"option_text": {"zhcn": "采用SageMaker平台的k-means算法，将聚类数k设为小于1000的值来训练模型。", "enus": "Use the SageMaker k-means algorithm with k of less than 1,000 to train the model."}, "option_flag": false}, {"option_text": {"zhcn": "使用SageMaker k近邻（k-NN）算法进行模型训练时，请将降维目标设定在1,000以下。", "enus": "Use the SageMaker k-nearest neighbors (k-NN) algorithm. Set a dimension reduction target of less than 1,000 to train the model."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AE"}, {"id": "200", "question": {"enus": "A company is building a machine learning (ML) model to classify images of plants. An ML specialist has trained the model using the Amazon SageMaker built-in Image Classification algorithm. The model is hosted using a SageMaker endpoint on an ml.m5.xlarge instance for real-time inference. When used by researchers in the field, the inference has greater latency than is acceptable. The latency gets worse when multiple researchers perform inference at the same time on their devices. Using Amazon CloudWatch metrics, the ML specialist notices that the ModelLatency metric shows a high value and is responsible for most of the response latency. The ML specialist needs to fix the performance issue so that researchers can experience less latency when performing inference from their devices. Which action should the ML specialist take to meet this requirement? ", "zhcn": "一家公司正在构建一个用于植物图像分类的机器学习模型。机器学习专家已使用Amazon SageMaker内置的图像分类算法完成模型训练，并通过部署在ml.m5.xlarge实例上的SageMaker端点提供实时推理服务。然而实地研究人员使用时发现推理延迟超出可接受范围，且当多名研究人员同时通过设备发起推理请求时延迟现象更为显著。通过Amazon CloudWatch指标监测，机器学习专家发现ModelLatency指标数值过高，是造成响应延迟的主要原因。为确保研究人员从设备端发起推理时获得更低的延迟体验，机器学习专家应采取下列哪项措施来满足这一需求？"}, "option": [{"option_text": {"zhcn": "将终端节点实例调整为与ml.m5.xlarge实例vCPU数量相同的ml.t3可突增实例。", "enus": "Change the endpoint instance to an ml.t3 burstable instance with the same vCPU number as the ml.m5.xlarge instance has."}, "option_flag": true}, {"option_text": {"zhcn": "为终端实例挂载一个Amazon Elastic Inference ml.eia2.medium加速器。", "enus": "Attach an Amazon Elastic Inference ml.eia2.medium accelerator to the endpoint instance."}, "option_flag": false}, {"option_text": {"zhcn": "启用Amazon SageMaker Autopilot功能，即可自动优化模型性能。", "enus": "Enable Amazon SageMaker Autopilot to automatically tune performance of the model."}, "option_flag": false}, {"option_text": {"zhcn": "将终端实例调整为采用内存优化的机器学习实例。", "enus": "Change the endpoint instance to use a memory optimized ML instance."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "201", "question": {"enus": "An automotive company is using computer vision in its autonomous cars. The company has trained its models successfully by using transfer learning from a convolutional neural network (CNN). The models are trained with PyTorch through the use of the Amazon SageMaker SDK. The company wants to reduce the time that is required for performing inferences, given the low latency that is required for self-driving. Which solution should the company use to evaluate and improve the performance of the models? ", "zhcn": "一家汽车制造商正将计算机视觉技术应用于其自动驾驶车辆。通过采用卷积神经网络（CNN）的迁移学习方案，该公司已成功完成模型训练。这些模型依托PyTorch框架，并借助亚马逊SageMaker SDK进行开发。鉴于自动驾驶对低延迟的严苛要求，该企业希望缩短模型推理所需的时间。此时应当采用何种解决方案来评估并提升模型性能？"}, "option": [{"option_text": {"zhcn": "利用Amazon CloudWatch算法指标，可清晰洞察SageMaker训练过程中的权重、梯度、偏置及激活输出数据。基于这些信息计算滤波器等级，通过剪枝技术剔除低阶滤波器，并重新设定权重参数。最终使用剪枝后的模型启动新一轮训练任务。", "enus": "Use Amazon CloudWatch algorithm metrics for visibility into the SageMaker training weights, gradients, biases, and activation outputs.  Compute the filter ranks based on this information. Apply pruning to remove the low-ranking filters. Set the new weights. Run a new  training job with the pruned model."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Debugger洞察训练过程中的权重、梯度、偏置及激活输出，动态调整模型超参数以优化推理效率，随后启动新一轮训练任务。", "enus": "Use SageMaker Debugger for visibility into the training weights, gradients, biases, and activation outputs. Adjust the model  hyperparameters, and look for lower inference times. Run a new training job."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Debugger洞察训练过程中的权重、梯度、偏置及激活输出数据，据此计算滤波器优先级。通过剪枝技术剔除低优先级滤波器，重新设定权重参数后，对精简后的模型启动新一轮训练任务。", "enus": "Use SageMaker Debugger for visibility into the training weights, gradients, biases, and activation outputs. Compute the filter ranks  based on this information. Apply pruning to remove the low-ranking filters. Set the new weights. Run a new training job with the pruned  model."}, "option_flag": true}, {"option_text": {"zhcn": "部署模型后，可利用SageMaker模型监控功能观测模型的推理延迟指标与资源开销延迟指标。通过调整模型超参数来优化推理耗时，并启动新一轮训练任务以提升性能。", "enus": "Use SageMaker Model Monitor for visibility into the ModelLatency metric and OverheadLatency metric of the model after the model is  deployed. Adjust the model hyperparameters, and look for lower inference times. Run a new training job."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "202", "question": {"enus": "A company's machine learning (ML) specialist is designing a scalable data storage solution for Amazon SageMaker. The company has an existing TensorFlow-based model that uses a train.py script. The model relies on static training data that is currently stored in TFRecord format. What should the ML specialist do to provide the training data to SageMaker with the LEAST development overhead? ", "zhcn": "一家公司的机器学习专家正在为Amazon SageMaker设计可扩展的数据存储方案。该公司现有一个基于TensorFlow的模型，使用train.py训练脚本。该模型依赖静态训练数据，目前以TFRecord格式存储。机器学习专家应以最小的开发工作量将训练数据提供给SageMaker，请问应当采取何种方案？"}, "option": [{"option_text": {"zhcn": "将TFRecord数据存入Amazon S3存储桶后，可选用AWS Glue或AWS Lambda对数据进行重组，转换为protobuf格式并存入另一个S3存储桶。最后将SageMaker训练任务的数据源指向第二个存储桶即可。", "enus": "Put the TFRecord data into an Amazon S3 bucket. Use AWS Glue or AWS Lambda to reformat the data to protobuf format and store the  data in a second S3 bucket. Point the SageMaker training invocation to the second S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "请将train.py脚本进行修改，增加将TFRecord数据转换为protobuf格式的模块。将SageMaker训练任务的数据指向路径设置为本地数据路径，并改为读取protobuf格式数据而非TFRecord数据。", "enus": "Rewrite the train.py script to add a section that converts TFRecord data to protobuf format. Point the SageMaker training invocation to  the local path of the data. Ingest the protobuf data instead of the TFRecord data."}, "option_flag": true}, {"option_text": {"zhcn": "采用SageMaker脚本模式，保持train.py文件不作改动。将SageMaker训练任务的数据路径指向本地原始数据目录，无需重新格式化训练数据。", "enus": "Use SageMaker script mode, and use train.py unchanged. Point the SageMaker training invocation to the local path of the data without  reformatting the training data."}, "option_flag": false}, {"option_text": {"zhcn": "采用SageMaker脚本模式，保持train.py文件不作改动。将TFRecord数据存入Amazon S3存储桶，并直接指向该S3存储桶启动SageMaker训练任务，无需对训练数据格式进行转换。", "enus": "Use SageMaker script mode, and use train.py unchanged. Put the TFRecord data into an Amazon S3 bucket. Point the SageMaker  training invocation to the S3 bucket without reformatting the training data."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "203", "question": {"enus": "An ecommerce company wants to train a large image classification model with 10,000 classes. The company runs multiple model training iterations and needs to minimize operational overhead and cost. The company also needs to avoid loss of work and model retraining. Which solution will meet these requirements? ", "zhcn": "一家电商企业计划训练包含一万个类别的大规模图像分类模型。在多次模型迭代训练过程中，该企业需最大限度降低运营成本与操作复杂度，同时确保训练成果不丢失且避免模型重复训练。何种方案可满足这些需求？"}, "option": [{"option_text": {"zhcn": "将训练任务创建为AWS Batch作业，使其在托管计算环境中调用亚马逊EC2竞价型实例。", "enus": "Create the training jobs as AWS Batch jobs that use Amazon EC2 Spot Instances in a managed compute environment."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊EC2竞价型实例运行训练任务。当收到竞价实例中断通知时，在实例终止前将模型快照保存至亚马逊S3存储空间。", "enus": "Use Amazon EC2 Spot Instances to run the training jobs. Use a Spot Instance interruption notice to save a snapshot of the model to  Amazon S3 before an instance is terminated."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Lambda执行训练任务，并将模型权重存储至Amazon S3。", "enus": "Use AWS Lambda to run the training jobs. Save model weights to Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "在Amazon SageMaker中启用托管式Spot训练功能，启动训练任务时需开启检查点设置。", "enus": "Use managed spot training in Amazon SageMaker. Launch the training jobs with checkpointing enabled."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "204", "question": {"enus": "A retail company uses a machine learning (ML) model for daily sales forecasting. The model has provided inaccurate results for the past 3 weeks. At the end of each day, an AWS Glue job consolidates the input data that is used for the forecasting with the actual daily sales data and the predictions of the model. The AWS Glue job stores the data in Amazon S3. The company's ML team determines that the inaccuracies are occurring because of a change in the value distributions of the model features. The ML team must implement a solution that will detect when this type of change occurs in the future. Which solution will meet these requirements with the LEAST amount of operational overhead? ", "zhcn": "一家零售企业采用机器学习模型进行日常销量预测。过去三周内，该模型持续出现预测失准情况。每日营业结束后，AWS Glue作业会整合三项数据：用于预测的输入数据、当日实际销售额度以及模型预测值，并将这些数据存储于Amazon S3中。经机器学习团队研判，预测失准源于模型特征值的分布发生变化。当前需设计一套解决方案，以期未来能自动侦测此类数据分布变化。在满足需求的前提下，下列哪种方案能最大限度降低运维复杂度？"}, "option": [{"option_text": {"zhcn": "使用Amazon SageMaker Model Monitor创建数据质量基线时，请确保在基线约束文件中将emit_metrics选项设为启用状态，并针对相关指标设置Amazon CloudWatch警报。", "enus": "Use Amazon SageMaker Model Monitor to create a data quality baseline. Confirm that the emit_metrics option is set to Enabled in the  baseline constraints file. Set up an Amazon CloudWatch alarm for the metric."}, "option_flag": true}, {"option_text": {"zhcn": "使用Amazon SageMaker模型监控功能创建模型质量基线。请确保在基线约束文件中将emit_metrics选项设置为启用状态，并为该指标配置Amazon CloudWatch告警。", "enus": "Use Amazon SageMaker Model Monitor to create a model quality baseline. Confirm that the emit_metrics option is set to Enabled in the  baseline constraints file. Set up an Amazon CloudWatch alarm for the metric."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker Debugger创建规则以捕获特征数值，并为相关规则配置Amazon CloudWatch告警机制。", "enus": "Use Amazon SageMaker Debugger to create rules to capture feature values Set up an Amazon CloudWatch alarm for the rules."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon CloudWatch对Amazon SageMaker终端节点进行监控，并通过分析Amazon CloudWatch Logs中的日志数据来检测数据漂移现象。", "enus": "Use Amazon CloudWatch to monitor Amazon SageMaker endpoints. Analyze logs in Amazon CloudWatch Logs to check for data drift."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "205", "question": {"enus": "A machine learning (ML) specialist has prepared and used a custom container image with Amazon SageMaker to train an image classification model. The ML specialist is performing hyperparameter optimization (HPO) with this custom container image to produce a higher quality image classifier. The ML specialist needs to determine whether HPO with the SageMaker built-in image classification algorithm will produce a better model than the model produced by HPO with the custom container image. All ML experiments and HPO jobs must be invoked from scripts inside SageMaker Studio notebooks. How can the ML specialist meet these requirements in the LEAST amount of time? ", "zhcn": "一位机器学习专家已准备并使用自定义容器镜像，在Amazon SageMaker上训练了一个图像分类模型。该专家正通过此自定义容器镜像进行超参数优化，旨在提升图像分类器的性能。现在需要判断：若改用SageMaker内置图像分类算法进行超参数优化，所得模型是否会优于当前自定义容器镜像的优化结果。所有机器学习实验及超参数优化任务必须通过SageMaker Studio笔记本中的脚本来触发。请问如何在最短时间内满足这些需求？"}, "option": [{"option_text": {"zhcn": "请编写一个定制化超参数优化脚本，该脚本需在SageMaker Studio的本地模式下运行多个训练任务，以优化基于自定义容器镜像的模型。利用SageMaker的自动模型调优功能并启用早停机制，对内置图像分类算法模型进行参数调优。最终选择具有最佳目标指标值的模型版本。", "enus": "Prepare a custom HPO script that runs multiple training jobs in SageMaker Studio in local mode to tune the model of the custom  container image. Use the automatic model tuning capability of SageMaker with early stopping enabled to tune the model of the built-in  image classification algorithm. Select the model with the best objective metric value."}, "option_flag": false}, {"option_text": {"zhcn": "使用SageMaker Autopilot对自定义容器镜像的模型进行调优。通过启用提前停止功能的SageMaker自动模型调优能力，对内置图像分类算法的模型进行调参。对比SageMaker Autopilot自动化机器学习任务与自动模型调优任务所得模型的目标指标数值，选取目标指标最优的模型。", "enus": "Use SageMaker Autopilot to tune the model of the custom container image. Use the automatic model tuning capability of SageMaker  with early stopping enabled to tune the model of the built-in image classification algorithm. Compare the objective metric values of the  resulting models of the SageMaker AutopilotAutoML job and the automatic model tuning job. Select the model with the best objective  metric value."}, "option_flag": true}, {"option_text": {"zhcn": "利用SageMaker Experiments运行管理多项训练任务，并优化自定义容器镜像的模型参数。通过SageMaker内置自动调参功能，对预置图像分类算法模型进行优化。最终选取目标评估指标最优的模型版本。", "enus": "Use SageMaker Experiments to run and manage multiple training jobs and tune the model of the custom container image. Use the  automatic model tuning capability of SageMaker to tune the model of the built-in image classification algorithm. Select the model with  the best objective metric value."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker的自动模型调优功能，同时优化自定义容器镜像与内置图像分类算法的模型参数，最终选取目标评估指标最优的模型。", "enus": "Use the automatic model tuning capability of SageMaker to tune the models of the custom container image and the built-in image  classification algorithm at the same time. Select the model with the best objective metric value."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "206", "question": {"enus": "A company wants to deliver digital car management services to its customers. The company plans to analyze data to predict the likelihood of users changing cars. The company has 10 TB of data that is stored in an Amazon Redshift cluster. The company's data engineering team is using Amazon SageMaker Studio for data analysis and model development. Only a subset of the data is relevant for developing the machine learning models. The data engineering team needs a secure and cost-effective way to export the data to a data repository in Amazon S3 for model development. Which solutions will meet these requirements? (Choose two.) ", "zhcn": "一家公司希望为客户提供数字化汽车管理服务，并计划通过数据分析预测用户的换车可能性。该公司拥有10 TB数据存储于Amazon Redshift集群中，数据工程团队正使用Amazon SageMaker Studio进行数据分析与模型开发。由于仅需部分数据用于机器学习模型开发，该团队需要一种安全且经济高效的方式，将数据导出至Amazon S3的数据存储库以供模型开发。下列哪两种解决方案符合这些要求？（请选择两项）"}, "option": [{"option_text": {"zhcn": "在分布式SageMaker处理任务中启动多个中型计算实例。通过预构建的Apache Spark Docker镜像查询并绘制相关数据，同时将Amazon Redshift中的相关数据导出至Amazon S3存储空间。", "enus": "Launch multiple medium-sized instances in a distributed SageMaker Processing job. Use the prebuilt Docker images for Apache Spark  to query and plot the relevant data and to export the relevant data from Amazon Redshift to Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "以分布式模式启动多个中等规格的PySpark内核笔记本实例。从Amazon Redshift将数据下载至笔记本集群，对相关数据进行查询分析与可视化制图，最终将筛选后的数据从笔记本集群导出至Amazon S3存储空间。", "enus": "Launch multiple medium-sized notebook instances with a PySpark kernel in distributed mode. Download the data from Amazon Redshift  to the notebook cluster. Query and plot the relevant data. Export the relevant data from the notebook cluster to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "借助AWS Secrets Manager妥善保管Amazon Redshift访问凭证。通过SageMaker Studio笔记本，调用已存储的认证信息，利用Python适配器建立与Amazon Redshift的安全连接。随后通过Python客户端执行数据查询，并将所需数据从Amazon Redshift导出至Amazon S3存储空间。", "enus": "Use AWS Secrets Manager to store the Amazon Redshift credentials. From a SageMaker Studio notebook, use the stored credentials to  connect to Amazon Redshift with a Python adapter. Use the Python client to query the relevant data and to export the relevant data from  Amazon Redshift to Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "运用AWS密钥管理服务存储Amazon Redshift的访问凭证。启动一个SageMaker超大型笔记本实例，并配置略大于10TB的块存储容量。通过Python连接器调用已存储的密钥建立与Amazon Redshift的连接，完成数据的下载、查询及可视化分析。最终将处理后的有效数据从本地笔记本驱动器导出至Amazon S3存储服务。", "enus": "Use AWS Secrets Manager to store the Amazon Redshift credentials. Launch a SageMaker extra-large notebook instance with block  storage that is slightly larger than 10 TB. Use the stored credentials to connect to Amazon Redshift with a Python adapter. Download,  query, and plot the relevant data. Export the relevant data from the local notebook drive to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "使用SageMaker Data Wrangler查询并绘制相关数据，同时将Amazon Redshift中的相关数据导出至Amazon S3。", "enus": "Use SageMaker Data Wrangler to query and plot the relevant data and to export the relevant data from Amazon Redshift to Amazon S3."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AC"}, {"id": "207", "question": {"enus": "A company is building an application that can predict spam email messages based on email text. The company can generate a few thousand human-labeled datasets that contain a list of email messages and a label of \"spam\" or \"not spam\" for each email message. A machine learning (ML) specialist wants to use transfer learning with a Bidirectional Encoder Representations from Transformers (BERT) model that is trained on English Wikipedia text data. What should the ML specialist do to initialize the model to fine-tune the model with the custom data? ", "zhcn": "一家公司正在开发一款能够根据邮件内容预测垃圾邮件的应用程序。该公司可生成数千条人工标注数据集，其中包含邮件列表及每封邮件对应的\"垃圾邮件\"或\"非垃圾邮件\"标签。一位机器学习专家希望采用基于英文维基百科文本数据训练的Transformer双向编码器表征模型进行迁移学习。为使该模型能通过定制数据完成精调，机器学习专家应如何对模型进行初始化？"}, "option": [{"option_text": {"zhcn": "初始化模型时，除最后一层全连接层外，其余各层均加载预训练权重。", "enus": "Initialize the model with pretrained weights in all layers except the last fully connected layer."}, "option_flag": false}, {"option_text": {"zhcn": "采用预训练权重对模型各层进行初始化，并在首层输出位置之上叠加分类器。利用标注数据对该分类器进行训练。", "enus": "Initialize the model with pretrained weights in all layers. Stack a classifier on top of the first output position. Train the classifier with the  labeled data."}, "option_flag": false}, {"option_text": {"zhcn": "在所有层中以随机权重初始化模型。将最后的全连接层替换为分类器，并利用标注数据对该分类器进行训练。", "enus": "Initialize the model with random weights in all layers. Replace the last fully connected layer with a classifier. Train the classifier with  the labeled data."}, "option_flag": false}, {"option_text": {"zhcn": "初始化模型时，所有层均加载预训练权重。将最后的全连接层替换为分类器，并利用标注数据对该分类器进行训练。", "enus": "Initialize the model with pretrained weights in all layers. Replace the last fully connected layer with a classifier. Train the classifier with  the labeled data."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "208", "question": {"enus": "A company is using a legacy telephony platform and has several years remaining on its contract. The company wants to move to AWS and wants to implement the following machine learning features: • Call transcription in multiple languages • Categorization of calls based on the transcript • Detection of the main customer issues in the calls • Customer sentiment analysis for each line of the transcript, with positive or negative indication and scoring of that sentiment Which AWS solution will meet these requirements with the LEAST amount of custom model training? ", "zhcn": "某公司目前仍在使用传统电话平台，且现有合约尚有数年才到期。该公司计划将业务迁移至亚马逊云服务（AWS），并希望实现以下机器学习功能：  \n- 支持多语言通话内容转写  \n- 根据转录文本实现通话自动分类  \n- 识别通话中客户反馈的核心问题  \n- 对转录文本逐行进行客户情绪分析，标注积极/消极倾向并给出情绪分值  \n\n在尽可能减少定制化模型训练的前提下，哪项AWS解决方案能够满足上述需求？"}, "option": [{"option_text": {"zhcn": "借助Amazon Transcribe处理音频通话，即可生成文字记录、实现通话分类并检测潜在问题。再通过Amazon Comprehend进行情感倾向分析。", "enus": "Use Amazon Transcribe to process audio calls to produce transcripts, categorize calls, and detect issues. Use Amazon Comprehend to  analyze sentiment."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Transcribe生成音频通话的文字记录，再通过Amazon Comprehend实现通话分类、问题侦测与情感倾向解析。", "enus": "Use Amazon Transcribe to process audio calls to produce transcripts. Use Amazon Comprehend to categorize calls, detect issues, and  analyze sentiment"}, "option_flag": false}, {"option_text": {"zhcn": "运用Amazon Connect的Contact Lens功能处理语音通话，可生成文字记录、实现通话分类、进行问题检测并完成情感分析。", "enus": "Use Contact Lens for Amazon Connect to process audio calls to produce transcripts, categorize calls, detect issues, and analyze  sentiment."}, "option_flag": false}, {"option_text": {"zhcn": "借助Amazon Connect的Contact Lens功能处理语音通话并生成文字记录。运用Amazon Comprehend服务实现通话分类、问题检测与情感倾向分析。", "enus": "Use Contact Lens for Amazon Connect to process audio calls to produce transcripts. Use Amazon Comprehend to categorize calls,  detect issues, and analyze sentiment."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "209", "question": {"enus": "A finance company needs to forecast the price of a commodity. The company has compiled a dataset of historical daily prices. A data scientist must train various forecasting models on 80% of the dataset and must validate the eficacy of those models on the remaining 20% of the dataset. How should the data scientist split the dataset into a training dataset and a validation dataset to compare model performance? ", "zhcn": "一家金融公司需对某商品价格进行走势预测，现已整理完成该商品的历史每日价格数据集。数据科学家需利用数据集的80%训练多种预测模型，并借助剩余20%的数据验证模型效能。为准确评估模型表现，应如何将数据集划分为训练集与验证集？"}, "option": [{"option_text": {"zhcn": "选定一个日期，使得80%的数据点位于该日期之前。将这部分数据点划为训练集，其余所有数据点则归入验证集。", "enus": "Pick a date so that 80% of the data points precede the date. Assign that group of data points as the training dataset. Assign all the  remaining data points to the validation dataset."}, "option_flag": false}, {"option_text": {"zhcn": "选定一个日期，使得80%的数据点位于该日期之后。将这部分数据点划为训练集，其余所有数据点则归入验证集。", "enus": "Pick a date so that 80% of the data points occur after the date. Assign that group of data points as the training dataset. Assign all the  remaining data points to the validation dataset."}, "option_flag": true}, {"option_text": {"zhcn": "从数据集的最早时间点开始，每次选取八个数据点作为训练集，两个数据点作为验证集。如此循环进行分层抽样，直至所有数据点分配完毕。", "enus": "Starting from the earliest date in the dataset, pick eight data points for the training dataset and two data points for the validation  dataset. Repeat this stratified sampling until no data points remain."}, "option_flag": false}, {"option_text": {"zhcn": "对数据点进行随机无放回抽样，使训练集包含80%的数据样本，并将剩余所有数据点归入验证集。", "enus": "Sample data points randomly without replacement so that 80% of the data points are in the training dataset. Assign all the remaining  data points to the validation dataset."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "210", "question": {"enus": "A retail company wants to build a recommendation system for the company's website. The system needs to provide recommendations for existing users and needs to base those recommendations on each user's past browsing history. The system also must filter out any items that the user previously purchased. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "一家零售企业计划为其官方网站构建一套商品推荐系统。该系统需根据现有用户的历史浏览记录提供个性化推荐，同时自动屏蔽用户已购买过的商品。在满足上述需求的前提下，哪种解决方案能以最小的开发量实现这一目标？"}, "option": [{"option_text": {"zhcn": "在Amazon SageMaker上运用基于用户的协同过滤算法训练模型，并将模型部署于SageMaker实时推理终端。通过配置Amazon API Gateway接口与AWS Lambda函数，处理网络应用发送的实时推理请求。在向网络应用返回结果前，自动筛除用户既往购买过的商品条目。", "enus": "Train a model by using a user-based collaborative filtering algorithm on Amazon SageMaker. Host the model on a SageMaker real-time  endpoint. Configure an Amazon API Gateway API and an AWS Lambda function to handle real-time inference requests that the web  application sends. Exclude the items that the user previously purchased from the results before sending the results back to the web  application."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon Personalize平台的PERSONALIZED_RANKING配方训练模型，建立实时过滤机制以排除用户历史购买商品。在Amazon Personalize上创建并部署推荐活动，通过GetPersonalizedRanking API接口获取实时动态推荐结果。", "enus": "Use an Amazon Personalize PERSONALIZED_RANKING recipe to train a model. Create a real-time filter to exclude items that the user  previously purchased. Create and deploy a campaign on Amazon Personalize. Use the GetPersonalizedRanking API operation to get the  real-time recommendations."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon Personalize平台的USER_PERSONALIZATION配方训练模型，并设置实时过滤器以排除用户已购买的商品。随后在Amazon Personalize中创建并部署推荐活动，通过调用GetRecommendations API接口获取实时个性化推荐结果。", "enus": "Use an Amazon Personalize USER_PERSONALIZATION recipe to train a model. Create a real-time filter to exclude items that the user  previously purchased. Create and deploy a campaign on Amazon Personalize. Use the GetRecommendations API operation to get the real-  time recommendations."}, "option_flag": true}, {"option_text": {"zhcn": "在亚马逊SageMaker平台上，利用GPU实例训练神经协同过滤模型。将训练完成的模型部署至SageMaker实时推理终端节点。通过配置亚马逊API网关接口与AWS Lambda函数，处理网络应用发送的实时推理请求。在向网络应用返回结果前，系统将自动过滤用户已购买过的商品条目。", "enus": "Train a neural collaborative filtering model on Amazon SageMaker by using GPU instances. Host the model on a SageMaker real-time  endpoint. Configure an Amazon API Gateway API and an AWS Lambda function to handle real-time inference requests that the web  application sends. Exclude the items that the user previously purchased from the results before sending the results back to the web  application."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "211", "question": {"enus": "A bank wants to use a machine learning (ML) model to predict if users will default on credit card payments. The training data consists of 30,000 labeled records and is evenly balanced between two categories. For the model, an ML specialist selects the Amazon SageMaker built- in XGBoost algorithm and configures a SageMaker automatic hyperparameter optimization job with the Bayesian method. The ML specialist uses the validation accuracy as the objective metric. When the bank implements the solution with this model, the prediction accuracy is 75%. The bank has given the ML specialist 1 day to improve the model in production. Which approach is the FASTEST way to improve the model's accuracy? ", "zhcn": "一家银行计划采用机器学习模型预测用户信用卡还款违约情况。训练数据包含3万条带标签记录，且两个类别分布完全均衡。机器学习专家选用亚马逊SageMaker平台内置的XGBoost算法，并采用贝叶斯方法配置了超参数自动优化任务，将验证准确率设为目标指标。实际部署该模型后，预测准确率为75%。银行要求机器学习专家在一天内提升生产环境中的模型性能，下列哪种方法能最快速提升模型准确率？"}, "option": [{"option_text": {"zhcn": "基于当前模型调优任务中的最佳候选模型，运行一次SageMaker增量训练。持续监控此前调优过程中使用的目标评估指标，并寻求性能提升。", "enus": "Run a SageMaker incremental training based on the best candidate from the current model's tuning job. Monitor the same metric that  was used as the objective metric in the previous tuning, and look for improvements."}, "option_flag": true}, {"option_text": {"zhcn": "将ROC曲线下面积（AUC）设定为新SageMaker超参数自动调优任务的目标评估指标。训练任务最大数量参数沿用此前调优任务的配置。", "enus": "Set the Area Under the ROC Curve (AUC) as the objective metric for a new SageMaker automatic hyperparameter tuning job. Use the  same maximum training jobs parameter that was used in the previous tuning job."}, "option_flag": false}, {"option_text": {"zhcn": "基于当前模型的超参数调优任务，启动一次SageMaker热启动调优。目标评估指标需与先前调优过程中所采用的指标保持一致。", "enus": "Run a SageMaker warm start hyperparameter tuning job based on the current model’s tuning job. Use the same objective metric that  was used in the previous tuning."}, "option_flag": false}, {"option_text": {"zhcn": "将F1分数设定为新SageMaker自动超参数调优任务的目标评估指标。将先前调优任务中使用的最大训练任务参数值提升至两倍。", "enus": "Set the F1 score as the objective metric for a new SageMaker automatic hyperparameter tuning job. Double the maximum training jobs  parameter that was used in the previous tuning job."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "212", "question": {"enus": "A data scientist has 20 TB of data in CSV format in an Amazon S3 bucket. The data scientist needs to convert the data to Apache Parquet format. How can the data scientist convert the file format with the LEAST amount of effort? ", "zhcn": "一位数据科学家在亚马逊S3存储桶中存有20TB的CSV格式数据。现需将数据转换为Apache Parquet格式，请问如何以最简捷的方式完成格式转换？"}, "option": [{"option_text": {"zhcn": "使用AWS Glue爬虫程序转换文件格式。", "enus": "Use an AWS Glue crawler to convert the file format."}, "option_flag": false}, {"option_text": {"zhcn": "编写一个脚本以转换文件格式，并将该脚本作为AWS Glue任务运行。", "enus": "Write a script to convert the file format. Run the script as an AWS Glue job."}, "option_flag": false}, {"option_text": {"zhcn": "编写一个用于转换文件格式的脚本，并在亚马逊EMR集群上运行该脚本。", "enus": "Write a script to convert the file format. Run the script on an Amazon EMR cluster."}, "option_flag": false}, {"option_text": {"zhcn": "编写一个脚本用于转换文件格式。在Amazon SageMaker笔记本中运行该脚本。", "enus": "Write a script to convert the file format. Run the script in an Amazon SageMaker notebook."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "213", "question": {"enus": "A company is building a pipeline that periodically retrains its machine learning (ML) models by using new streaming data from devices. The company's data engineering team wants to build a data ingestion system that has high throughput, durable storage, and scalability. The company can tolerate up to 5 minutes of latency for data ingestion. The company needs a solution that can apply basic data transformation during the ingestion process. Which solution will meet these requirements with the MOST operational eficiency? ", "zhcn": "某公司正在构建一套数据管道系统，通过设备端持续产生的新流数据定期对其机器学习模型进行再训练。该公司的数据工程团队需要搭建一套具备高吞吐量、持久化存储及弹性扩展能力的数据摄取系统，且数据接入延迟需控制在五分钟以内。该系统还需在数据接入阶段完成基础的数据转换处理。在满足上述所有要求的前提下，何种解决方案能实现最优运维效率？"}, "option": [{"option_text": {"zhcn": "将设备配置为向Amazon Kinesis数据流发送流式数据。设置Amazon Kinesis Data Firehose传输流，使其自动接收Kinesis数据流，通过AWS Lambda函数对数据进行转换，并将处理结果存储至Amazon S3存储桶中。", "enus": "Configure the devices to send streaming data to an Amazon Kinesis data stream. Configure an Amazon Kinesis Data Firehose delivery  stream to automatically consume the Kinesis data stream, transform the data with an AWS Lambda function, and save the output into an  Amazon S3 bucket."}, "option_flag": true}, {"option_text": {"zhcn": "将设备配置为向亚马逊S3存储桶发送流式数据。设置由S3事件通知触发的AWS Lambda函数，用于转换数据并将其载入亚马逊Kinesis数据流。配置亚马逊Kinesis Data Firehose传输流，使其自动摄取Kinesis数据流中的数据，并将处理结果回传至S3存储桶。", "enus": "Configure the devices to send streaming data to an Amazon S3 bucket. Configure an AWS Lambda function that is invoked by S3 event  notifications to transform the data and load the data into an Amazon Kinesis data stream. Configure an Amazon Kinesis Data Firehose  delivery stream to automatically consume the Kinesis data stream and load the output back into the S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "将设备配置为向Amazon S3存储桶发送流式数据。设置一个由S3事件通知触发的AWS Glue作业，用于读取数据、转换数据格式，并将处理结果载入新的S3存储桶。", "enus": "Configure the devices to send streaming data to an Amazon S3 bucket. Configure an AWS Glue job that is invoked by S3 event  notifications to read the data, transform the data, and load the output into a new S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "将设备配置为向Amazon Kinesis Data Firehose传输流发送实时数据流。设置一个AWS Glue作业，使其连接至该传输流以进行数据转换，并将处理结果导入Amazon S3存储桶。", "enus": "Configure the devices to send streaming data to an Amazon Kinesis Data Firehose delivery stream. Configure an AWS Glue job that  connects to the delivery stream to transform the data and load the output into an Amazon S3 bucket."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "214", "question": {"enus": "A retail company is ingesting purchasing records from its network of 20,000 stores to Amazon S3 by using Amazon Kinesis Data Firehose. The company uses a small, server-based application in each store to send the data to AWS over the internet. The company uses this data to train a machine learning model that is retrained each day. The company's data science team has identified existing attributes on these records that could be combined to create an improved model. Which change will create the required transformed records with the LEAST operational overhead? ", "zhcn": "一家零售企业正通过亚马逊Kinesis Data Firehose服务，将其两万家门店的采购记录实时传输至亚马逊S3存储平台。各门店通过基于服务器的小型应用程序，经由互联网将数据发送至AWS云平台。这些数据主要用于训练机器学习模型，该模型每日都会进行迭代更新。企业的数据科学团队发现，通过整合现有记录属性可构建更优化的模型。若要实现所需的记录转换，同时将运维负担降至最低，应采取哪种改进方案？"}, "option": [{"option_text": {"zhcn": "创建一个能够处理传入记录的AWS Lambda函数。在数据摄取Kinesis Data Firehose传输流中启用数据转换功能，并将该Lambda函数设定为调用目标。", "enus": "Create an AWS Lambda function that can transform the incoming records. Enable data transformation on the ingestion Kinesis Data  Firehose delivery stream. Use the Lambda function as the invocation target."}, "option_flag": false}, {"option_text": {"zhcn": "部署一个运行Apache Spark并包含转换逻辑的Amazon EMR集群。通过Amazon EventBridge（Amazon CloudWatch Events）设置定时任务，每日触发AWS Lambda函数启动该集群，对积存在Amazon S3中的记录进行转换处理，并将转换后的数据回传至Amazon S3。", "enus": "Deploy an Amazon EMR cluster that runs Apache Spark and includes the transformation logic. Use Amazon EventBridge (Amazon  CloudWatch Events) to schedule an AWS Lambda function to launch the cluster each day and transform the records that accumulate in  Amazon S3. Deliver the transformed records to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在各门店部署亚马逊S3文件网关，并升级店内软件以将数据传送至该网关。通过每日定时运行的AWS Glue任务，对经由S3文件网关传输至亚马逊S3存储服务的数据进行转换处理。", "enus": "Deploy an Amazon S3 File Gateway in the stores. Update the in-store software to deliver data to the S3 File Gateway. Use a scheduled  daily AWS Glue job to transform the data that the S3 File Gateway delivers to Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "部署一组集成转换逻辑的亚马逊EC2实例，通过每日定时任务配置自动处理积存在亚马逊S3中的记录文件，并将处理完成的数据回传至亚马逊S3存储空间。", "enus": "Launch a fieet of Amazon EC2 instances that include the transformation logic. Configure the EC2 instances with a daily cron job to  transform the records that accumulate in Amazon S3. Deliver the transformed records to Amazon S3."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "215", "question": {"enus": "A sports broadcasting company is planning to introduce subtitles in multiple languages for a live broadcast. The commentary is in English. The company needs the transcriptions to appear on screen in French or Spanish, depending on the broadcasting country. The transcriptions must be able to capture domain-specific terminology, names, and locations based on the commentary context. The company needs a solution that can support options to provide tuning data. Which combination of AWS services and features will meet these requirements with the LEAST operational overhead? (Choose two.) ", "zhcn": "一家体育转播公司计划为直播节目引入多语言字幕服务。其解说词为英文内容，需根据播出国家在屏幕上显示法语或西班牙语字幕。译文必须能够准确捕捉基于解说语境的领域专有术语、人名及地名。该公司需要一套支持提供调优数据选项的解决方案。以下哪两种AWS服务与功能的组合能以最小运维投入满足上述需求？（请选择两项。）"}, "option": [{"option_text": {"zhcn": "亚马逊Transcribe自定义词汇增强版", "enus": "Amazon Transcribe with custom vocabularies"}, "option_flag": false}, {"option_text": {"zhcn": "借助定制语言模型的亚马逊转录服务", "enus": "Amazon Transcribe with custom language models"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon SageMaker Seq2Seq", "enus": "Amazon SageMaker Seq2Seq"}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker 与 Hugging Face Speech2Text 的深度融合", "enus": "Amazon SageMaker with Hugging Face Speech2Text"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊翻译", "enus": "Amazon Translate"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BE"}, {"id": "216", "question": {"enus": "A data scientist at a retail company is forecasting sales for a product over the next 3 months. After preliminary analysis, the data scientist identifies that sales are seasonal and that holidays affect sales. The data scientist also determines that sales of the product are correlated with sales of other products in the same category. The data scientist needs to train a sales forecasting model that incorporates this information. Which solution will meet this requirement with the LEAST development effort? ", "zhcn": "某零售企业的数据分析师正在对一款产品未来三个月的销售额进行预测。初步分析显示，该产品的销售呈现季节性特征且受节假日影响，同时与同品类其他产品的销量存在关联性。现需开发一个能整合这些因素的销售预测模型，下列哪种方案能以最小开发成本满足需求？"}, "option": [{"option_text": {"zhcn": "结合亚马逊预测服务的节假日特征化功能与内置的自回归积分滑动平均（ARIMA）算法，对模型进行训练。", "enus": "Use Amazon Forecast with Holidays featurization and the built-in autoregressive integrated moving average (ARIMA) algorithm to train  the model."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊 Forecast 服务的节假日特征化功能，结合内置的 DeepAR+ 算法进行模型训练。", "enus": "Use Amazon Forecast with Holidays featurization and the built-in DeepAR+ algorithm to train the model."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon SageMaker Processing为数据添加节假日信息以进行增强。随后，采用SageMaker内置的DeepAR算法对模型进行训练。", "enus": "Use Amazon SageMaker Processing to enrich the data with holiday information. Train the model by using the SageMaker DeepAR built-  in algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker Processing为数据添加节假日信息以增强其特征。随后，采用Gluon时间序列工具包（GluonTS）进行模型训练。", "enus": "Use Amazon SageMaker Processing to enrich the data with holiday information. Train the model by using the Gluon Time Series  (GluonTS) toolkit."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "217", "question": {"enus": "A company is building a predictive maintenance model for its warehouse equipment. The model must predict the probability of failure of all machines in the warehouse. The company has collected 10,000 event samples within 3 months. The event samples include 100 failure cases that are evenly distributed across 50 different machine types. How should the company prepare the data for the model to improve the model's accuracy? ", "zhcn": "某公司正为其仓储设备构建一套预测性维护模型。该模型需精准预测仓库内所有设备的故障发生概率。在三个月内，企业已采集到一万条事件样本，其中包含均匀分布在50种不同机型中的100例故障记录。为提升模型预测精度，企业应如何对数据进行预处理？"}, "option": [{"option_text": {"zhcn": "根据设备类型调整类别权重，以平衡各类别的影响。", "enus": "Adjust the class weight to account for each machine type."}, "option_flag": false}, {"option_text": {"zhcn": "对少数类样本采用合成少数类过采样技术（SMOTE）进行扩增。", "enus": "Oversample the failure cases by using the Synthetic Minority Oversampling Technique (SMOTE)."}, "option_flag": false}, {"option_text": {"zhcn": "对非故障事件进行降采样处理，并依据机器类型对其进行分层抽样。", "enus": "Undersample the non-failure events. Stratify the non-failure events by machine type."}, "option_flag": false}, {"option_text": {"zhcn": "对非故障事件采用合成少数类过采样技术（SMOTE）进行降采样处理。", "enus": "Undersample the non-failure events by using the Synthetic Minority Oversampling Technique (SMOTE)."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "218", "question": {"enus": "A company stores its documents in Amazon S3 with no predefined product categories. A data scientist needs to build a machine learning model to categorize the documents for all the company's products. Which solution will meet these requirements with the MOST operational eficiency? ", "zhcn": "一家公司将其文档存储于Amazon S3中，且未预设产品类别。数据科学家需构建一个机器学习模型，以对公司所有产品的文档进行分类。下列哪种方案能以最高运作效率满足这些要求？"}, "option": [{"option_text": {"zhcn": "构建定制化聚类模型。编写Dockerfile文件并构建Docker镜像。将镜像注册至亚马逊弹性容器仓库（Amazon ECR）。通过该定制镜像在Amazon SageMaker平台生成训练完成的模型。", "enus": "Build a custom clustering model. Create a Dockerfile and build a Docker image. Register the Docker image in Amazon Elastic Container  Registry (Amazon ECR). Use the custom image in Amazon SageMaker to generate a trained model."}, "option_flag": false}, {"option_text": {"zhcn": "对数据进行分词处理并将其转换为表格形式。随后，训练亚马逊SageMaker平台的k-means模型以生成产品分类体系。", "enus": "Tokenize the data and transform the data into tabular data. Train an Amazon SageMaker k-means model to generate the product  categories."}, "option_flag": true}, {"option_text": {"zhcn": "在Amazon SageMaker平台上训练神经主题模型（NTM），用于自动生成产品分类体系。", "enus": "Train an Amazon SageMaker Neural Topic Model (NTM) model to generate the product categories."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊SageMaker平台上训练Blazing Text模型，以生成产品分类体系。", "enus": "Train an Amazon SageMaker Blazing Text model to generate the product categories."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "219", "question": {"enus": "A sports analytics company is providing services at a marathon. Each runner in the marathon will have their race ID printed as text on the front of their shirt. The company needs to extract race IDs from images of the runners. Which solution will meet these requirements with the LEAST operational overhead? ", "zhcn": "一家体育数据分析公司正在为一场马拉松赛事提供服务。每位参赛者的胸前都印有以文字显示的赛号。该公司需要从跑者的图像中提取这些赛号。哪种解决方案能够以最小的运维成本满足这一需求？"}, "option": [{"option_text": {"zhcn": "请使用亚马逊 Rekognition 服务。", "enus": "Use Amazon Rekognition."}, "option_flag": false}, {"option_text": {"zhcn": "采用定制化的卷积神经网络（CNN）架构。", "enus": "Use a custom convolutional neural network (CNN)."}, "option_flag": false}, {"option_text": {"zhcn": "请使用 Amazon SageMaker 目标检测算法。", "enus": "Use the Amazon SageMaker Object Detection algorithm."}, "option_flag": true}, {"option_text": {"zhcn": "请使用 Amazon Lookout for Vision。", "enus": "Use Amazon Lookout for Vision."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "220", "question": {"enus": "A manufacturing company wants to monitor its devices for anomalous behavior. A data scientist has trained an Amazon SageMaker scikit- learn model that classifies a device as normal or anomalous based on its 4-day telemetry. The 4-day telemetry of each device is collected in a separate file and is placed in an Amazon S3 bucket once every hour. The total time to run the model across the telemetry for all devices is 5 minutes. What is the MOST cost-effective solution for the company to use to run the model across the telemetry for all the devices? ", "zhcn": "一家制造企业希望监测其设备是否存在异常运行状态。数据科学家已基于亚马逊SageMaker平台训练出scikit-learn模型，该模型可根据设备连续四天的遥测数据将其判定为正常运行或出现异常。每台设备的四日遥测数据均独立存储于文件中，并以每小时一次的频率上传至亚马逊S3存储桶。若要对所有设备的遥测数据执行模型分析，总耗时约为五分钟。请问采用何种解决方案，能帮助企业以最具成本效益的方式完成全量设备的模型检测？"}, "option": [{"option_text": {"zhcn": "亚马逊 SageMaker 批量转换", "enus": "SageMaker Batch Transform"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊 SageMaker 异步推理服务", "enus": "SageMaker Asynchronous Inference"}, "option_flag": false}, {"option_text": {"zhcn": "**SageMaker 数据处理服务**", "enus": "SageMaker Processing"}, "option_flag": true}, {"option_text": {"zhcn": "SageMaker 多容器终端节点", "enus": "A SageMaker multi-container endpoint"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "221", "question": {"enus": "A company wants to segment a large group of customers into subgroups based on shared characteristics. The company’s data scientist is planning to use the Amazon SageMaker built-in k-means clustering algorithm for this task. The data scientist needs to determine the optimal number of subgroups (k) to use. Which data visualization approach will MOST accurately determine the optimal value of k? ", "zhcn": "某企业希望根据共同特征将大规模客户群体划分为不同子群。为此，该公司数据科学家计划采用Amazon SageMaker内置的k-means聚类算法。此时需要确定最优的子群数量（k值）。下列哪种数据可视化方法能最精准地确定k值的最优解？"}, "option": [{"option_text": {"zhcn": "计算主成分分析（PCA）的各主要成分。仅使用前两个主成分，针对不同的k值运行k均值聚类算法。针对每个k值生成散点图，并以不同颜色区分各聚类群组。当聚类结果呈现出明显分离态势时，对应的k值即为最优解。", "enus": "Calculate the principal component analysis (PCA) components. Run the k-means clustering algorithm for a range of k by using only the  first two PCA components. For each value of k, create a scatter plot with a different color for each cluster. The optimal value of k is the  value where the clusters start to look reasonably separated."}, "option_flag": true}, {"option_text": {"zhcn": "计算主成分分析（PCA）的各主成分分量。绘制成分数量与解释方差的折线图，当曲线开始呈线性下降趋势时，对应的主成分数量即为最优k值。", "enus": "Calculate the principal component analysis (PCA) components. Create a line plot of the number of components against the explained  variance. The optimal value of k is the number of PCA components after which the curve starts decreasing in a linear fashion."}, "option_flag": false}, {"option_text": {"zhcn": "为一系列困惑度数值生成t分布随机邻域嵌入图。当聚类结果开始呈现明显分离态势时，对应的困惑度k值即为最优解。", "enus": "Create a t-distributed stochastic neighbor embedding (t-SNE) plot for a range of perplexity values. The optimal value of k is the value of  perplexity, where the clusters start to look reasonably separated."}, "option_flag": false}, {"option_text": {"zhcn": "针对不同的k值运行k-means聚类算法，并分别计算每个k值对应的误差平方和（SSE）。绘制SSE随k值变化的折线图，当曲线结束快速下降阶段、开始呈现平缓下降趋势时，对应的k值即为最优解。", "enus": "Run the k-means clustering algorithm for a range of k. For each value of k, calculate the sum of squared errors (SSE). Plot a line chart of  the SSE for each value of k. The optimal value of k is the point after which the curve starts decreasing in a linear fashion."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "222", "question": {"enus": "A data scientist at a financial services company used Amazon SageMaker to train and deploy a model that predicts loan defaults. The model analyzes new loan applications and predicts the risk of loan default. To train the model, the data scientist manually extracted loan data from a database. The data scientist performed the model training and deployment steps in a Jupyter notebook that is hosted on SageMaker Studio notebooks. The model's prediction accuracy is decreasing over time. Which combination of steps is the MOST operationally eficient way for the data scientist to maintain the model's accuracy? (Choose two.) ", "zhcn": "某金融服务公司的数据科学家利用Amazon SageMaker训练并部署了一套贷款违约预测模型。该模型通过分析新增贷款申请来预判违约风险。在模型训练阶段，这位数据科学家曾手动从数据库提取贷款数据，并在SageMaker Studio notebooks托管的Jupyter笔记本中完成了模型训练与部署操作。目前该模型的预测准确率正随时间推移逐渐下降。请问下列哪两项措施组合最能帮助数据科学家以最高运维效率维持模型准确率？（请选择两项）"}, "option": [{"option_text": {"zhcn": "运用SageMaker Pipelines构建自动化工作流，实现数据动态提取、模型训练及新版模型的无缝部署。", "enus": "Use SageMaker Pipelines to create an automated workfiow that extracts fresh data, trains the model, and deploys a new version of the  model."}, "option_flag": false}, {"option_text": {"zhcn": "配置SageMaker模型监控器时需设定精度阈值以检测模型漂移。当数据超出阈值范围时，将触发Amazon CloudWatch告警。通过将SageMaker Pipelines工作流与CloudWatch告警关联，即可在监测到异常时自动启动模型重训练流程。", "enus": "Configure SageMaker Model Monitor with an accuracy threshold to check for model drift. Initiate an Amazon CloudWatch alarm when  the threshold is exceeded. Connect the workfiow in SageMaker Pipelines with the CloudWatch alarm to automatically initiate retraining."}, "option_flag": true}, {"option_text": {"zhcn": "将模型预测结果存储于Amazon S3。创建每日运行的SageMaker处理作业，该作业从Amazon S3读取预测数据，检测模型预测准确率的变化，并在发现显著波动时发送邮件通知。", "enus": "Store the model predictions in Amazon S3. Create a daily SageMaker Processing job that reads the predictions from Amazon S3, checks  for changes in model prediction accuracy, and sends an email notification if a significant change is detected."}, "option_flag": true}, {"option_text": {"zhcn": "请在SageMaker Studio notebooks托管的Jupyter笔记本中重新运行相关步骤，以重新训练模型并部署新版模型。", "enus": "Rerun the steps in the Jupyter notebook that is hosted on SageMaker Studio notebooks to retrain the model and redeploy a new version  of the model."}, "option_flag": false}, {"option_text": {"zhcn": "将训练与部署代码从SageMaker Studio笔记本导出为Python脚本，并将其封装为亚马逊弹性容器服务（Amazon ECS）任务，以便通过AWS Lambda函数触发执行。", "enus": "Export the training and deployment code from the SageMaker Studio notebooks into a Python script. Package the script into an Amazon  Elastic Container Service (Amazon ECS) task that an AWS Lambda function can initiate."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BC"}, {"id": "223", "question": {"enus": "A retail company wants to create a system that can predict sales based on the price of an item. A machine learning (ML) engineer built an initial linear model that resulted in the following residual plot: Which actions should the ML engineer take to improve the accuracy of the predictions in the next phase of model building? (Choose three.) ", "zhcn": "一家零售企业计划构建一套能够根据商品价格预测销量的系统。机器学习工程师初步建立的线性模型生成了如下残差图：在模型构建的下一阶段，该工程师应采取哪三项措施来提升预测精准度？（请选择三项）"}, "option": [{"option_text": {"zhcn": "将数据进行均匀降采样，以减少数据量。", "enus": "Downsample the data uniformly to reduce the amount of data."}, "option_flag": true}, {"option_text": {"zhcn": "为数据的不同部分建立两种不同的模型。", "enus": "Create two different models for different sections of the data."}, "option_flag": false}, {"option_text": {"zhcn": "在价格低于50的数据区间内进行降采样处理。", "enus": "Downsample the data in sections where Price < 50."}, "option_flag": true}, {"option_text": {"zhcn": "当价格高于50时，将输入数据偏移一个固定值。", "enus": "Offset the input data by a constant value where Price > 50."}, "option_flag": false}, {"option_text": {"zhcn": "在审视输入数据时，若遇合适情形，应采用非线性转换方法加以处理。", "enus": "Examine the input data, and apply non-linear data transformations where appropriate."}, "option_flag": true}, {"option_text": {"zhcn": "采用非线性模型替代线性模型。", "enus": "Use a non-linear model instead of a linear model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "ACE"}, {"id": "224", "question": {"enus": "A data scientist at a food production company wants to use an Amazon SageMaker built-in model to classify different vegetables. The current dataset has many features. The company wants to save on memory costs when the data scientist trains and deploys the model. The company also wants to be able to find similar data points for each test data point. Which algorithm will meet these requirements? ", "zhcn": "某食品生产企业的一位数据科学家计划采用亚马逊SageMaker平台的预置模型，以实现对不同蔬菜的精准分类。现有数据集特征维度丰富，而企业希望在模型训练与部署阶段降低内存消耗，同时要求能够针对每个测试数据点快速定位相似样本。何种算法可同时满足这些需求？"}, "option": [{"option_text": {"zhcn": "降维处理的K近邻算法（k-NN）", "enus": "K-nearest neighbors (k-NN) with dimension reduction"}, "option_flag": false}, {"option_text": {"zhcn": "采用早停策略的线性学习器", "enus": "Linear learner with early stopping"}, "option_flag": true}, {"option_text": {"zhcn": "K均值算法", "enus": "K-means"}, "option_flag": false}, {"option_text": {"zhcn": "采用随机算法模式的主成分分析（PCA）", "enus": "Principal component analysis (PCA) with the algorithm mode set to random"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "225", "question": {"enus": "A data scientist is training a large PyTorch model by using Amazon SageMaker. It takes 10 hours on average to train the model on GPU instances. The data scientist suspects that training is not converging and that resource utilization is not optimal. What should the data scientist do to identify and address training issues with the LEAST development effort? ", "zhcn": "一位数据科学家正在使用亚马逊SageMaker训练大型PyTorch模型。在GPU实例上完成模型训练平均需耗时十小时。该数据科学家怀疑训练过程未达到收敛状态，且资源利用率未臻最优。若要以最小的开发投入识别并解决训练问题，该数据科学家应采取何种措施？"}, "option": [{"option_text": {"zhcn": "利用亚马逊云监控（Amazon CloudWatch）中采集的CPU使用率指标，配置云监控警报机制，在检测到CPU使用率持续偏低时提前终止训练任务。", "enus": "Use CPU utilization metrics that are captured in Amazon CloudWatch. Configure a CloudWatch alarm to stop the training job early if low  CPU utilization occurs."}, "option_flag": false}, {"option_text": {"zhcn": "运用高分辨率定制指标集，这些指标由亚马逊云监控服务捕获。配置一个AWS Lambda函数，用于实时分析指标数据，并在检测到异常时提前终止训练任务。", "enus": "Use high-resolution custom metrics that are captured in Amazon CloudWatch. Configure an AWS Lambda function to analyze the  metrics and to stop the training job early if issues are detected."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Debugger内置的梯度消失与GPU低利用率检测规则，在发现异常时可自动触发训练任务终止操作。", "enus": "Use the SageMaker Debugger vanishing_gradient and LowGPUUtilization built-in rules to detect issues and to launch the  StopTrainingJob action if issues are detected."}, "option_flag": false}, {"option_text": {"zhcn": "请使用 SageMaker Debugger 内置的混淆度与特征重要性过载规则进行问题检测，一旦发现异常即触发停止训练任务操作。", "enus": "Use the SageMaker Debugger confusion and feature_importance_overweight built-in rules to detect issues and to launch the  StopTrainingJob action if issues are detected."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "226", "question": {"enus": "A bank wants to launch a low-rate credit promotion campaign. The bank must identify which customers to target with the promotion and wants to make sure that each customer's full credit history is considered when an approval or denial decision is made. The bank's data science team used the XGBoost algorithm to train a classification model based on account transaction features. The data science team deployed the model by using the Amazon SageMaker model hosting service. The accuracy of the model is suficient, but the data science team wants to be able to explain why the model denies the promotion to some customers. What should the data science team do to meet this requirement in the MOST operationally eficient manner? ", "zhcn": "一家银行计划推出低利率信用卡推广活动，需要精准筛选目标客群，并在审批过程中全面考量每位客户的信用记录。该银行的数据科学团队基于账户交易特征，运用XGBoost算法训练了分类模型，并通过Amazon SageMaker模型托管服务完成部署。虽然模型准确度已达要求，但团队仍需向业务部门解释模型拒绝部分客户申请的具体依据。请问数据科学团队应采取何种最高效的运营方案来满足这一需求？"}, "option": [{"option_text": {"zhcn": "创建一个SageMaker笔记本实例，将模型文件上传至该笔记本。运用Python XGBoost接口中的plot_importance()方法，为个体预测生成特征重要性图表。", "enus": "Create a SageMaker notebook instance. Upload the model artifact to the notebook. Use the plot_importance() method in the Python  XGBoost interface to create a feature importance chart for the individual predictions."}, "option_flag": false}, {"option_text": {"zhcn": "使用SageMaker Debugger重新训练模型，并配置该调试器以计算并收集沙普利值。通过绘制特征与SHAP（沙普利加和解释）值关系图，直观展示各特征对模型预测结果的影响机制。", "enus": "Retrain the model by using SageMaker Debugger. Configure Debugger to calculate and collect Shapley values. Create a chart that  shows features and SHapley. Additive explanations (SHAP) values to explain how the features affect the model outcomes."}, "option_flag": false}, {"option_text": {"zhcn": "配置并启动一项基于SageMaker Clarify的可解释性分析任务，以训练数据为基准对个体客户数据展开解析。生成特征与SHAP值（沙普利加和解释）关联图表，清晰呈现各特征对模型输出结果的影响机制。", "enus": "Set up and run an explainability job powered by SageMaker Clarify to analyze the individual customer data, using the training data as a  baseline. Create a chart that shows features and SHapley Additive explanations (SHAP) values to explain how the features affect the  model outcomes."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker模型监控功能生成沙普利值，以解析模型行为逻辑。将生成的沙普利值存储至Amazon S3服务中，并绘制特征与SHAP（沙普利加和解释）值的关系图表，清晰呈现各特征对模型决策结果的影响机制。", "enus": "Use SageMaker Model Monitor to create Shapley values that help explain model behavior. Store the Shapley values in Amazon S3.  Create a chart that shows features and SHapley Additive explanations (SHAP) values to explain how the features affect the model  outcomes."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "227", "question": {"enus": "A company has hired a data scientist to create a loan risk model. The dataset contains loan amounts and variables such as loan type, region, and other demographic variables. The data scientist wants to use Amazon SageMaker to test bias regarding the loan amount distribution with respect to some of these categorical variables. Which pretraining bias metrics should the data scientist use to check the bias distribution? (Choose three.) ", "zhcn": "某公司聘请一位数据科学家构建贷款风险模型。数据集包含贷款金额及贷款类型、地区与其他人口统计变量。该数据科学家计划使用Amazon SageMaker检验贷款金额分布在部分分类变量上的偏差。请问其应选用哪三项预训练偏差指标来评估偏差分布？"}, "option": [{"option_text": {"zhcn": "类别失衡", "enus": "Class imbalance"}, "option_flag": true}, {"option_text": {"zhcn": "条件性人口差异", "enus": "Conditional demographic disparity"}, "option_flag": false}, {"option_text": {"zhcn": "标签比例差异", "enus": "Difference in proportions of labels"}, "option_flag": true}, {"option_text": {"zhcn": "詹森-香农散度", "enus": "Jensen-Shannon divergence"}, "option_flag": false}, {"option_text": {"zhcn": "Kullback-Leieber散度", "enus": "Kullback-Leibler divergence"}, "option_flag": false}, {"option_text": {"zhcn": "“全变差距离”", "enus": "Total variation distance"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "ACF"}, {"id": "228", "question": {"enus": "A retail company wants to use Amazon Forecast to predict daily stock levels of inventory. The cost of running out of items in stock is much higher for the company than the cost of having excess inventory. The company has millions of data samples for multiple years for thousands of items. The company’s purchasing department needs to predict demand for 30-day cycles for each item to ensure that restocking occurs. A machine learning (ML) specialist wants to use item-related features such as \"category,\" \"brand,\" and \"safety stock count.\" The ML specialist also wants to use a binary time series feature that has \"promotion applied?\" as its name. Future promotion information is available only for the next 5 days. The ML specialist must choose an algorithm and an evaluation metric for a solution to produce prediction results that will maximize company profit. Which solution will meet these requirements? ", "zhcn": "一家零售企业计划采用Amazon Forecast服务来预测每日库存水平。由于缺货造成的损失远高于库存积压的成本，该公司拥有多年积累的数十亿条商品数据记录。采购部门需按30天周期预测各商品需求以安排补货计划。机器学习专家拟采用\"品类\"\"品牌\"\"安全库存量\"等商品特征，并加入以\"是否促销\"命名的二元时间序列特征——但未来促销信息仅能提前5天获取。该专家需选择能最大化企业利润的预测算法与评估指标。下列哪种方案最符合这些要求？"}, "option": [{"option_text": {"zhcn": "采用自回归积分滑动平均（ARIMA）算法训练模型，并基于0.75分位数加权损失函数（wQL）进行模型性能评估。", "enus": "Train a model by using the Autoregressive Integrated Moving Average (ARIMA) algorithm. Evaluate the model by using the Weighted  Quantile Loss (wQL) metric at 0.75 (P75)."}, "option_flag": false}, {"option_text": {"zhcn": "采用自回归积分滑动平均（ARIMA）算法对模型进行训练，并选用加权绝对百分比误差（WAPE）作为评估指标来检验模型性能。", "enus": "Train a model by using the Autoregressive Integrated Moving Average (ARIMA) algorithm. Evaluate the model by using the Weighted  Absolute Percentage Error (WAPE) metric."}, "option_flag": false}, {"option_text": {"zhcn": "采用卷积神经网络-分位数回归（CNN-QR）算法训练模型，并基于0.75分位数（P75）的加权分位数损失（wQL）指标进行模型性能评估。", "enus": "Train a model by using the Convolutional Neural Network - Quantile Regression (CNN-QR) algorithm. Evaluate the model by using the  Weighted Quantile Loss (wQL) metric at 0.75 (P75)."}, "option_flag": false}, {"option_text": {"zhcn": "采用卷积神经网络-分位数回归（CNN-QR）算法训练模型，并选用加权绝对百分比误差（WAPE）作为评估指标进行模型性能验证。", "enus": "Train a model by using the Convolutional Neural Network - Quantile Regression (CNN-QR) algorithm. Evaluate the model by using the  Weighted Absolute Percentage Error (WAPE) metric."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "229", "question": {"enus": "An online retail company wants to develop a natural language processing (NLP) model to improve customer service. A machine learning (ML) specialist is setting up distributed training of a Bidirectional Encoder Representations from Transformers (BERT) model on Amazon SageMaker. SageMaker will use eight compute instances for the distributed training. The ML specialist wants to ensure the security of the data during the distributed training. The data is stored in an Amazon S3 bucket. Which combination of steps should the ML specialist take to protect the data during the distributed training? (Choose three.) ", "zhcn": "一家网络零售公司计划开发自然语言处理模型以提升客户服务质量。一位机器学习专家正在亚马逊SageMaker平台上配置双向Transformer编码器模型的分布式训练任务。该训练将启用八个计算实例。为确保分布式训练期间的数据安全（训练数据存储于亚马逊S3存储桶中），机器学习专家应采取哪三项组合措施？（请选择三项）"}, "option": [{"option_text": {"zhcn": "在私有虚拟私有云中运行分布式训练任务，并启用容器间通信加密功能。", "enus": "Run distributed training jobs in a private VPC. Enable inter-container trafic encryption."}, "option_flag": false}, {"option_text": {"zhcn": "在多个虚拟私有云中运行分布式训练任务。启用虚拟私有云对等互联。", "enus": "Run distributed training jobs across multiple VPCs. Enable VPC peering."}, "option_flag": true}, {"option_text": {"zhcn": "创建S3 VPC终端节点，随后配置网络路由策略、终端节点策略及S3存储桶策略。", "enus": "Create an S3 VPC endpoint. Then configure network routes, endpoint policies, and S3 bucket policies."}, "option_flag": false}, {"option_text": {"zhcn": "通过使用IAM角色，授予对SageMaker资源的只读访问权限。", "enus": "Grant read-only access to SageMaker resources by using an IAM role."}, "option_flag": false}, {"option_text": {"zhcn": "创建一台NAT网关，并为该网关分配弹性IP地址。", "enus": "Create a NAT gateway. Assign an Elastic IP address for the NAT gateway."}, "option_flag": true}, {"option_text": {"zhcn": "配置入站规则，允许来自与训练实例关联的安全组的流量通过。", "enus": "Configure an inbound rule to allow trafic from a security group that is associated with the training instances."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BEF"}, {"id": "230", "question": {"enus": "An analytics company has an Amazon SageMaker hosted endpoint for an image classification model. The model is a custom-built convolutional neural network (CNN) and uses the PyTorch deep learning framework. The company wants to increase throughput and decrease latency for customers that use the model. Which solution will meet these requirements MOST cost-effectively? ", "zhcn": "一家数据分析公司为其图像分类模型部署了亚马逊SageMaker托管端点。该模型采用定制化卷积神经网络架构，基于PyTorch深度学习框架开发。为提升用户调用模型时的吞吐效率并降低响应延迟，下列哪种解决方案能以最具成本效益的方式满足这些需求？"}, "option": [{"option_text": {"zhcn": "在SageMaker托管终端节点上启用亚马逊弹性推理服务。", "enus": "Use Amazon Elastic Inference on the SageMaker hosted endpoint."}, "option_flag": false}, {"option_text": {"zhcn": "对CNN进行更深层次的训练，并采用更庞大的数据集加以优化。", "enus": "Retrain the CNN with more layers and a larger dataset."}, "option_flag": false}, {"option_text": {"zhcn": "对CNN进行再训练，增加网络层数并采用更精简的数据集。", "enus": "Retrain the CNN with more layers and a smaller dataset."}, "option_flag": true}, {"option_text": {"zhcn": "请选择配备多块GPU的SageMaker实例类型。", "enus": "Choose a SageMaker instance type that has multiple GPUs."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "231", "question": {"enus": "An ecommerce company is collecting structured data and unstructured data from its website, mobile apps, and IoT devices. The data is stored in several databases and Amazon S3 buckets. The company is implementing a scalable repository to store structured data and unstructured data. The company must implement a solution that provides a central data catalog, self-service access to the data, and granular data access policies and encryption to protect the data. Which combination of actions will meet these requirements with the LEAST amount of setup? (Choose three.) ", "zhcn": "一家电商企业正从其官方网站、移动应用及物联网设备中采集结构化与非结构化数据。这些数据目前存储于多个数据库及亚马逊S3存储桶中。该公司正在构建一个可扩展的数据存储库，用以统一存储两类数据。此方案需实现三大核心功能：建立统一数据目录、提供自助式数据查询服务、实施细粒度数据访问策略及加密保护机制。请问以下哪三项措施的组合能以最简配置满足上述需求？（请选择三项答案）"}, "option": [{"option_text": {"zhcn": "梳理数据库及S3存储桶中的现有数据，并将其接入AWS Lake Formation管理体系。", "enus": "Identify the existing data in the databases and S3 buckets. Link the data to AWS Lake Formation."}, "option_flag": true}, {"option_text": {"zhcn": "梳理数据库与S3存储桶中的现有数据，并将其关联至AWS Glue服务。", "enus": "Identify the existing data in the databases and S3 buckets. Link the data to AWS Glue."}, "option_flag": false}, {"option_text": {"zhcn": "对关联数据源运行AWS Glue爬虫程序，以构建统一的数据目录。", "enus": "Run AWS Glue crawlers on the linked data sources to create a central data catalog."}, "option_flag": false}, {"option_text": {"zhcn": "通过AWS身份与访问管理服务（IAM）实施精细化权限管控，并为每个数据源配置服务器端加密方案。", "enus": "Apply granular access policies by using AWS Identity and Access Management (1AM). Configure server-side encryption on each data  source."}, "option_flag": true}, {"option_text": {"zhcn": "借助AWS Lake Formation实施精细化的访问权限管控与数据加密机制。", "enus": "Apply granular access policies and encryption by using AWS Lake Formation."}, "option_flag": true}, {"option_text": {"zhcn": "借助AWS Glue实施精细化的访问策略与数据加密方案。", "enus": "Apply granular access policies and encryption by using AWS Glue."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "ADE"}, {"id": "232", "question": {"enus": "A machine learning (ML) specialist is developing a deep learning sentiment analysis model that is based on data from movie reviews. After the ML specialist trains the model and reviews the model results on the validation set, the ML specialist discovers that the model is overfitting. Which solutions will MOST improve the model generalization and reduce overfitting? (Choose three.) ", "zhcn": "一位机器学习专家正在开发一款基于影评数据的深度学习情感分析模型。在完成模型训练并验证验证集结果后，该专家发现模型存在过拟合现象。下列哪三项措施最能有效提升模型泛化能力并抑制过拟合？（请选择三项）"}, "option": [{"option_text": {"zhcn": "以不同随机种子打乱数据集。", "enus": "Shufie the dataset with a different seed."}, "option_flag": false}, {"option_text": {"zhcn": "降低学习速率。", "enus": "Decrease the learning rate."}, "option_flag": false}, {"option_text": {"zhcn": "增加网络层数。", "enus": "Increase the number of layers in the network."}, "option_flag": true}, {"option_text": {"zhcn": "加入L1正则化与L2正则化。", "enus": "Add L1 regularization and L2 regularization."}, "option_flag": false}, {"option_text": {"zhcn": "加入随机失活层。", "enus": "Add dropout."}, "option_flag": true}, {"option_text": {"zhcn": "减少网络层数。", "enus": "Decrease the number of layers in the network."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "CEF"}, {"id": "233", "question": {"enus": "An online advertising company is developing a linear model to predict the bid price of advertisements in real time with low-latency predictions. A data scientist has trained the linear model by using many features, but the model is overfitting the training dataset. The data scientist needs to prevent overfitting and must reduce the number of features. Which solution will meet these requirements? ", "zhcn": "一家在线广告公司正在开发一种线性模型，旨在通过低延迟预测来实时预估广告竞价。数据科学家已利用大量特征训练该模型，但出现了对训练集过度拟合的问题。当前需避免过度拟合，且必须削减特征数量。下列哪种方案可同时满足这些要求？"}, "option": [{"option_text": {"zhcn": "在模型重训过程中引入L1正则化约束。", "enus": "Retrain the model with L1 regularization applied."}, "option_flag": true}, {"option_text": {"zhcn": "在模型重新训练过程中引入L2正则化方法。", "enus": "Retrain the model with L2 regularization applied."}, "option_flag": false}, {"option_text": {"zhcn": "在模型重新训练过程中引入随机失活正则化方法。", "enus": "Retrain the model with dropout regularization applied."}, "option_flag": false}, {"option_text": {"zhcn": "通过增加数据量来重新训练模型。", "enus": "Retrain the model by using more data."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "234", "question": {"enus": "A credit card company wants to identify fraudulent transactions in real time. A data scientist builds a machine learning model for this purpose. The transactional data is captured and stored in Amazon S3. The historic data is already labeled with two classes: fraud (positive) and fair transactions (negative). The data scientist removes all the missing data and builds a classifier by using the XGBoost algorithm in Amazon SageMaker. The model produces the following results: • True positive rate (TPR): 0.700 • False negative rate (FNR): 0.300 • True negative rate (TNR): 0.977 • False positive rate (FPR): 0.023 • Overall accuracy: 0.949 Which solution should the data scientist use to improve the performance of the model? ", "zhcn": "一家信用卡公司希望实时识别欺诈交易。为此，一位数据科学家构建了机器学习模型。交易数据被采集并存储于Amazon S3中，历史数据已标注为两类：欺诈交易（阳性）与正常交易（阴性）。数据科学家清除了所有缺失数据，并运用Amazon SageMaker中的XGBoost算法训练出分类器。该模型产出如下结果：  \n• 真正例率：0.700  \n• 假反例率：0.300  \n• 真反例率：0.977  \n• 假正例率：0.023  \n• 整体准确率：0.949  \n数据科学家应采用何种方案来提升此模型的性能？"}, "option": [{"option_text": {"zhcn": "对训练数据集中的少数类应用合成少数类过采样技术（SMOTE），随后使用增强后的训练数据重新训练模型。", "enus": "Apply the Synthetic Minority Oversampling Technique (SMOTE) on the minority class in the training dataset. Retrain the model with the  updated training data."}, "option_flag": false}, {"option_text": {"zhcn": "对训练数据集中的多数类应用合成少数类过采样技术（SMOTE），随后使用更新后的训练数据重新训练模型。", "enus": "Apply the Synthetic Minority Oversampling Technique (SMOTE) on the majority class in the training dataset. Retrain the model with the  updated training data."}, "option_flag": false}, {"option_text": {"zhcn": "对少数类别进行欠采样处理。", "enus": "Undersample the minority class."}, "option_flag": true}, {"option_text": {"zhcn": "对多数类别进行过采样。", "enus": "Oversample the majority class."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "235", "question": {"enus": "A company is training machine learning (ML) models on Amazon SageMaker by using 200 TB of data that is stored in Amazon S3 buckets. The training data consists of individual files that are each larger than 200 MB in size. The company needs a data access solution that offers the shortest processing time and the least amount of setup. Which solution will meet these requirements? ", "zhcn": "一家公司正利用存储在亚马逊S3存储桶中的200 TB数据，在Amazon SageMaker上训练机器学习模型。训练数据由独立文件构成，每个文件大小均超过200 MB。该公司需要一种能实现最短处理时间且无需复杂配置的数据访问方案。何种方案可满足这些要求？"}, "option": [{"option_text": {"zhcn": "在 SageMaker 中启用文件模式，将数据集从 S3 存储桶复制至 ML 实例的本地存储中。", "enus": "Use File mode in SageMaker to copy the dataset from the S3 buckets to the ML instance storage."}, "option_flag": false}, {"option_text": {"zhcn": "创建一套适用于Lustre的Amazon FSx文件系统，并将该文件系统与S3存储桶建立关联。", "enus": "Create an Amazon FSx for Lustre file system. Link the file system to the S3 buckets."}, "option_flag": false}, {"option_text": {"zhcn": "创建一项亚马逊弹性文件系统（Amazon EFS）服务。将该文件系统挂载至训练实例。", "enus": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the file system to the training instances."}, "option_flag": false}, {"option_text": {"zhcn": "在 SageMaker 中启用 FastFile 模式，即可按需从 S3 存储桶流式传输文件。", "enus": "Use FastFile mode in SageMaker to stream the files on demand from the S3 buckets."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "236", "question": {"enus": "An online store is predicting future book sales by using a linear regression model that is based on past sales data. The data includes duration, a numerical feature that represents the number of days that a book has been listed in the online store. A data scientist performs an exploratory data analysis and discovers that the relationship between book sales and duration is skewed and non-linear. Which data transformation step should the data scientist take to improve the predictions of the model? ", "zhcn": "一家网络书店正基于历史销售数据，运用线性回归模型预测未来图书销量。该数据包含\"上架时长\"这一数值特征，即图书在书店陈列的天数。数据科学家在探索性分析中发现，图书销量与上架时长之间存在非对称的非线性关系。为提升模型预测精度，该科学家应采取何种数据转换步骤？"}, "option": [{"option_text": {"zhcn": "独热编码", "enus": "One-hot encoding"}, "option_flag": true}, {"option_text": {"zhcn": "笛卡尔积变换", "enus": "Cartesian product transformation"}, "option_flag": false}, {"option_text": {"zhcn": "分位数分组", "enus": "Quantile binning"}, "option_flag": false}, {"option_text": {"zhcn": "规整化", "enus": "Normalization"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "237", "question": {"enus": "A company's data engineer wants to use Amazon S3 to share datasets with data scientists. The data scientists work in three departments: Finance. Marketing, and Human Resources. Each department has its own IAM user group. Some datasets contain sensitive information and should be accessed only by the data scientists from the Finance department. How can the data engineer set up access to meet these requirements? ", "zhcn": "一家公司的数据工程师计划利用Amazon S3平台与数据科学家团队共享数据集。这些科学家分属三个部门：财务部、市场部及人力资源部，每个部门均设有独立的IAM用户组。部分数据集涉及敏感信息，仅允许财务部的数据科学家访问。请问数据工程师应如何配置权限以满足上述需求？"}, "option": [{"option_text": {"zhcn": "为每个数据集创建独立的S3存储桶，并为每个存储桶配置相应的访问控制列表。若存储桶包含敏感数据集，则将其访问权限限定为仅允许财务部门用户组访问；而对于存有非敏感数据集的存储桶，应向三大部门用户组全面开放访问权限。", "enus": "Create an S3 bucket for each dataset. Create an ACL for each S3 bucket. For each S3 bucket that contains a sensitive dataset, set the  ACL to allow access only from the Finance department user group. Allow all three department user groups to access each S3 bucket that  contains a non-sensitive dataset."}, "option_flag": false}, {"option_text": {"zhcn": "为每个数据集创建独立的S3存储桶。若存储桶包含敏感数据集，则设置其访问策略仅允许财务部门用户组调取；若存储桶包含非敏感数据集，则向三个部门用户组开放全部访问权限。", "enus": "Create an S3 bucket for each dataset. For each S3 bucket that contains a sensitive dataset, set the bucket policy to allow access only  from the Finance department user group. Allow all three department user groups to access each S3 bucket that contains a non-sensitive  dataset."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个包含两个文件夹的S3存储桶，用于区分敏感数据集与非敏感数据集。为财务部门用户组附加IAM策略，允许其访问两个文件夹；而为市场部与人力资源部用户组配置的IAM策略，仅允许其访问存放非敏感数据集的文件夹。", "enus": "Create a single S3 bucket that includes two folders to separate the sensitive datasets from the non-sensitive datasets. For the Finance  department user group, attach an IAM policy that provides access to both folders. For the Marketing and Human Resources department  user groups, attach an IAM policy that provides access to only the folder that contains the non-sensitive datasets."}, "option_flag": false}, {"option_text": {"zhcn": "创建一个包含两个文件夹的S3存储桶，用于区分敏感数据集与非敏感数据集。设置该S3存储桶的访问策略：仅允许财务部门用户组访问存放敏感数据集的文件夹，同时允许所有三个部门的用户组访问存放非敏感数据集的文件夹。", "enus": "Create a single S3 bucket that includes two folders to separate the sensitive datasets from the non-sensitive datasets. Set the policy  for the S3 bucket to allow only the Finance department user group to access the folder that contains the sensitive datasets. Allow all  three department user groups to access the folder that contains the non-sensitive datasets."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "238", "question": {"enus": "A company operates an amusement park. The company wants to collect, monitor, and store real-time trafic data at several park entrances by using strategically placed cameras. The company’s security team must be able to immediately access the data for viewing. Stored data must be indexed and must be accessible to the company’s data science team. Which solution will meet these requirements MOST cost-effectively? ", "zhcn": "某游乐园运营公司计划在园区多个入口处架设摄像头，用于实时采集、监测及存储客流数据。安保团队需能即时调取查看数据，存储数据需建立索引并供公司数据科学团队随时调用。要满足这些需求，最具成本效益的解决方案是什么？"}, "option": [{"option_text": {"zhcn": "借助亚马逊Kinesis视频流服务，可实现数据的实时摄取、智能索引与安全存储。通过其与亚马逊Rekognition的内置集成功能，安保团队可便捷调取视频内容进行审阅分析。", "enus": "Use Amazon Kinesis Video Streams to ingest, index, and store the data. Use the built-in integration with Amazon Rekognition for  viewing by the security team."}, "option_flag": false}, {"option_text": {"zhcn": "借助亚马逊Kinesis视频流服务，可实现数据的无缝摄取、智能索引与安全存储。其内置的HLS实时流传输功能，可让安防团队随时调取高清影像进行查看。", "enus": "Use Amazon Kinesis Video Streams to ingest, index, and store the data. Use the built-in HTTP live streaming (HLS) capability for  viewing by the security team."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Rekognition Video及GStreamer插件导入视频数据，供安防团队实时调阅分析。同时通过Amazon Kinesis Data Streams实现数据流的即时索引与云端存储。", "enus": "Use Amazon Rekognition Video and the GStreamer plugin to ingest the data for viewing by the security team. Use Amazon Kinesis Data  Streams to index and store the data."}, "option_flag": false}, {"option_text": {"zhcn": "借助亚马逊Kinesis数据流服务实现数据的采集、索引与存储，并通过内置的HTTP实时流传输（HLS）技术供安防团队进行动态监测。", "enus": "Use Amazon Kinesis Data Firehose to ingest, index, and store the data. Use the built-in HTTP live streaming (HLS) capability for viewing  by the security team."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "239", "question": {"enus": "An engraving company wants to automate its quality control process for plaques. The company performs the process before mailing each customized plaque to a customer. The company has created an Amazon S3 bucket that contains images of defects that should cause a plaque to be rejected. Low-confidence predictions must be sent to an internal team of reviewers who are using Amazon Augmented AI (Amazon A2I). Which solution will meet these requirements? ", "zhcn": "一家雕刻公司希望实现牌匾质检流程的自动化。该公司在每块定制牌匾邮寄给客户前需执行此质检流程。公司已创建一个亚马逊S3存储桶，其中收录了应当拒收牌匾的缺陷图像样本。对于置信度较低的预测结果，必须提交给使用亚马逊增强人工智能（Amazon A2I）的内部审核团队进行复核。下列哪种方案能满足这些要求？"}, "option": [{"option_text": {"zhcn": "采用Amazon Textract实现自动化处理，结合Amazon A2I与Amazon Mechanical Turk进行人工核验。", "enus": "Use Amazon Textract for automatic processing. Use Amazon A2I with Amazon Mechanical Turk for manual review."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Rekognition实现自动化处理，同时采用配备专属人工审核团队的Amazon A2I服务进行人工复核。", "enus": "Use Amazon Rekognition for automatic processing. Use Amazon A2I with a private workforce option for manual review."}, "option_flag": false}, {"option_text": {"zhcn": "采用Amazon Transcribe实现自动化处理，同时通过Amazon A2I的人工审核功能，启用专属团队进行人工复核。", "enus": "Use Amazon Transcribe for automatic processing. Use Amazon A2I with a private workforce option for manual review."}, "option_flag": true}, {"option_text": {"zhcn": "利用AWS Panorama实现自动化处理，通过Amazon A2I与Amazon Mechanical Turk相结合进行人工复核。", "enus": "Use AWS Panorama for automatic processing. Use Amazon A2I with Amazon Mechanical Turk for manual review."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "240", "question": {"enus": "A machine learning (ML) engineer at a bank is building a data ingestion solution to provide transaction features to financial ML models. Raw transactional data is available in an Amazon Kinesis data stream. The solution must compute rolling averages of the ingested data from the data stream and must store the results in Amazon SageMaker Feature Store. The solution also must serve the results to the models in near real time. Which solution will meet these requirements? ", "zhcn": "某银行的一位机器学习工程师正在构建数据摄取方案，旨在为金融机器学习模型提供交易特征。原始交易数据可通过亚马逊Kinesis数据流获取。该方案需根据数据流计算输入数据的滚动平均值，并将结果存储至亚马逊SageMaker特征库，同时还需以近实时方式将处理结果传输至模型端。请问何种方案可满足上述需求？"}, "option": [{"option_text": {"zhcn": "通过Amazon Kinesis Data Firehose将数据载入Amazon S3存储桶，随后借助SageMaker处理作业对数据进行聚合处理，并将结果以在线特征组的形式导入SageMaker特征存储库。", "enus": "Load the data into an Amazon S3 bucket by using Amazon Kinesis Data Firehose. Use a SageMaker Processing job to aggregate the  data and to load the results into SageMaker Feature Store as an online feature group."}, "option_flag": true}, {"option_text": {"zhcn": "将数据流直接写入SageMaker特征存储库，创建在线特征组。通过调用SageMaker GetRecord API操作，在特征存储库内实时计算滚动平均值。", "enus": "Write the data directly from the data stream into SageMaker Feature Store as an online feature group. Calculate the rolling averages in  place within SageMaker Feature Store by using the SageMaker GetRecord API operation."}, "option_flag": false}, {"option_text": {"zhcn": "通过亚马逊Kinesis数据分析平台的SQL应用程序对数据流进行实时处理，计算移动平均值并生成结果流。随后由定制化AWS Lambda函数接收结果流，将处理后的数据作为在线特征组发布至SageMaker特征存储平台。", "enus": "Consume the data stream by using an Amazon Kinesis Data Analytics SQL application that calculates the rolling averages. Generate a  result stream. Consume the result stream by using a custom AWS Lambda function that publishes the results to SageMaker Feature Store  as an online feature group."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Firehose将数据载入Amazon S3存储桶，随后通过SageMaker处理作业将数据作为离线特征组存入SageMaker特征库。查询时动态计算滚动平均值。", "enus": "Load the data into an Amazon S3 bucket by using Amazon Kinesis Data Firehose. Use a SageMaker Processing job to load the data into  SageMaker Feature Store as an ofiine feature group. Compute the rolling averages at query time."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "241", "question": {"enus": "Each morning, a data scientist at a rental car company creates insights about the previous day’s rental car reservation demands. The company needs to automate this process by streaming the data to Amazon S3 in near real time. The solution must detect high-demand rental cars at each of the company’s locations. The solution also must create a visualization dashboard that automatically refreshes with the most recent data. Which solution will meet these requirements with the LEAST development time? ", "zhcn": "每日清晨，某租车公司的数据科学家会针对前一日租车预订需求进行分析并生成洞察报告。该公司需通过近乎实时数据流将信息传输至Amazon S3来自动化此流程。解决方案必须能实时识别各营业点的高需求车型，同时自动生成可随最新数据动态更新的可视化仪表盘。在满足上述需求的前提下，何种方案能以最短开发周期实现该目标？"}, "option": [{"option_text": {"zhcn": "利用Amazon Kinesis Data Firehose将预约数据实时传输至Amazon S3存储服务，通过Amazon QuickSight的机器学习洞察功能识别高需求异常值，并在QuickSight平台实现数据可视化呈现。", "enus": "Use Amazon Kinesis Data Firehose to stream the reservation data directly to Amazon S3. Detect high-demand outliers by using Amazon  QuickSight ML Insights. Visualize the data in QuickSight."}, "option_flag": true}, {"option_text": {"zhcn": "利用亚马逊Kinesis数据流服务将预约数据实时传输至亚马逊S3存储平台。通过调用亚马逊SageMaker中经过训练的随机切割森林(RCF)模型，精准识别高需求异常数据点。最终在亚马逊QuickSight可视化平台呈现数据洞察。", "enus": "Use Amazon Kinesis Data Streams to stream the reservation data directly to Amazon S3. Detect high-demand outliers by using the  Random Cut Forest (RCF) trained model in Amazon SageMaker. Visualize the data in Amazon QuickSight."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Firehose将预约数据直接实时传输至Amazon S3存储服务，通过Amazon SageMaker中经过训练的随机切割森林（RCF）模型检测高需求异常值，最终在Amazon QuickSight平台实现数据可视化呈现。", "enus": "Use Amazon Kinesis Data Firehose to stream the reservation data directly to Amazon S3. Detect high-demand outliers by using the  Random Cut Forest (RCF) trained model in Amazon SageMaker. Visualize the data in Amazon QuickSight."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Streams将预约数据直接流式传输至Amazon S3存储服务，通过Amazon QuickSight ML Insights功能智能检测高需求异常值，并在QuickSight平台实现数据可视化呈现。", "enus": "Use Amazon Kinesis Data Streams to stream the reservation data directly to Amazon S3. Detect high-demand outliers by using Amazon  QuickSight ML Insights. Visualize the data in QuickSight."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "242", "question": {"enus": "A company is planning a marketing campaign to promote a new product to existing customers. The company has data for past promotions that are similar. The company decides to try an experiment to send a more expensive marketing package to a smaller number of customers. The company wants to target the marketing campaign to customers who are most likely to buy the new product. The experiment requires that at least 90% of the customers who are likely to purchase the new product receive the marketing materials. The company trains a model by using the linear learner algorithm in Amazon SageMaker. The model has a recall score of 80% and a precision of 75%. How should the company retrain the model to meet these requirements? ", "zhcn": "某公司正筹划一项面向现有客户的新品推广活动，并拥有过往类似促销活动的数据记录。公司决定尝试一项实验：向少量客户寄送成本更高的营销包裹，并希望将营销目标精准锁定在最有可能购买新产品的客户群体上。该实验要求潜在购买客户中至少有90%能够收到营销物料。公司通过亚马逊SageMaker平台的线性学习算法训练模型，当前模型的召回率为80%，精确率为75%。为达成实验要求，该公司应如何优化模型训练方案？"}, "option": [{"option_text": {"zhcn": "将目标召回率超参数设定为90%。将二元分类器模型选择标准超参数调整为基于目标精确度的召回率优化。", "enus": "Set the target_recall hyperparameter to 90%. Set the binary_classifier_model_selection_criteria hyperparameter to  recall_at_target_precision."}, "option_flag": false}, {"option_text": {"zhcn": "将目标精度超参数设定为90%。将二元分类器模型选择标准超参数设定为“目标召回率下的精确度”。", "enus": "Set the target_precision hyperparameter to 90%. Set the binary_classifier_model_selection_criteria hyperparameter to  precision_at_target_recall."}, "option_flag": true}, {"option_text": {"zhcn": "将90%的历史数据用于训练，迭代轮数设定为20次。", "enus": "Use 90% of the historical data for training. Set the number of epochs to 20."}, "option_flag": false}, {"option_text": {"zhcn": "将 normalize_label 超参数设为 true，类别数量设置为 2。", "enus": "Set the normalize_label hyperparameter to true. Set the number of classes to 2."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "243", "question": {"enus": "A wildlife research company has a set of images of lions and cheetahs. The company created a dataset of the images. The company labeled each image with a binary label that indicates whether an image contains a lion or cheetah. The company wants to train a model to identify whether new images contain a lion or cheetah. Which Amazon SageMaker algorithm will meet this requirement? ", "zhcn": "一家野生动物研究公司拥有一批狮子和猎豹的图像资料。该公司已将这批图像构建为数据集，并为每张图片标注了二元标签以区分内容为狮子或猎豹。现需训练一个模型用于识别新图像中的动物类别为狮子或猎豹。请问亚马逊SageMaker平台中哪种算法可满足此需求？"}, "option": [{"option_text": {"zhcn": "XGBoost", "enus": "XGBoost"}, "option_flag": false}, {"option_text": {"zhcn": "图像分类——TensorFlow", "enus": "Image Classification - TensorFlow"}, "option_flag": true}, {"option_text": {"zhcn": "目标检测 - TensorFlow", "enus": "Object Detection - TensorFlow"}, "option_flag": false}, {"option_text": {"zhcn": "语义分割——MXNet", "enus": "Semantic segmentation - MXNet"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "244", "question": {"enus": "A data scientist for a medical diagnostic testing company has developed a machine learning (ML) model to identify patients who have a specific disease. The dataset that the scientist used to train the model is imbalanced. The dataset contains a large number of healthy patients and only a small number of patients who have the disease. The model should consider that patients who are incorrectly identified as positive for the disease will increase costs for the company. Which metric will MOST accurately evaluate the performance of this model? ", "zhcn": "某医疗诊断公司的数据科学家开发了一个机器学习模型，用于识别罹患特定疾病的患者。该模型所使用的训练数据集存在样本不平衡问题：健康患者的数据占绝大多数，而确诊患者的数据仅占极小比例。同时需考虑，若模型将健康者误判为阳性，将导致公司成本上升。在此情况下，下列哪项指标能最精准地评估该模型的性能？"}, "option": [{"option_text": {"zhcn": "忆起", "enus": "Recall"}, "option_flag": false}, {"option_text": {"zhcn": "F1分数", "enus": "F1 score"}, "option_flag": false}, {"option_text": {"zhcn": "精准", "enus": "Accuracy"}, "option_flag": false}, {"option_text": {"zhcn": "精准", "enus": "Precision"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "245", "question": {"enus": "A machine learning (ML) specialist is training a linear regression model. The specialist notices that the model is overfitting. The specialist applies an L1 regularization parameter and runs the model again. This change results in all features having zero weights. What should the ML specialist do to improve the model results? ", "zhcn": "一位机器学习专家正在训练线性回归模型时，发现模型出现了过拟合现象。该专家随后应用了L1正则化参数并重新运行模型，但此举导致所有特征权重均归为零。为提升模型效果，机器学习专家应采取何种改进措施？"}, "option": [{"option_text": {"zhcn": "增强L1正则化参数，其余训练参数保持不变。", "enus": "Increase the L1 regularization parameter. Do not change any other training parameters."}, "option_flag": false}, {"option_text": {"zhcn": "降低L1正则化参数，其余训练参数保持不变。", "enus": "Decrease the L1 regularization parameter. Do not change any other training parameters."}, "option_flag": true}, {"option_text": {"zhcn": "引入一个较大的L2正则化参数，同时保持现有的L1正则化数值不变。", "enus": "Introduce a large L2 regularization parameter. Do not change the current L1 regularization value."}, "option_flag": false}, {"option_text": {"zhcn": "引入一个较小的L2正则化参数，同时保持现有的L1正则化数值不变。", "enus": "Introduce a small L2 regularization parameter. Do not change the current L1 regularization value."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "246", "question": {"enus": "A machine learning (ML) engineer is integrating a production model with a customer metadata repository for real-time inference. The repository is hosted in Amazon SageMaker Feature Store. The engineer wants to retrieve only the latest version of the customer metadata record for a single customer at a time. Which solution will meet these requirements? ", "zhcn": "一位机器学习工程师正在将生产环境中的模型与客户元数据库进行集成，以实现实时推理。该数据库托管于Amazon SageMaker特征存储平台。工程师需要每次仅获取单个客户的最新版本元数据记录。下列哪种方案能满足这一需求？"}, "option": [{"option_text": {"zhcn": "请使用SageMaker特征存储的BatchGetRecord接口，并传入记录标识符。通过筛选条件获取最新记录。", "enus": "Use the SageMaker Feature Store BatchGetRecord API with the record identifier. Filter to find the latest record."}, "option_flag": false}, {"option_text": {"zhcn": "编写一条Amazon Athena查询语句，用于从特征表中提取数据。", "enus": "Create an Amazon Athena query to retrieve the data from the feature table."}, "option_flag": false}, {"option_text": {"zhcn": "创建一条Amazon Athena查询语句，用于从特征表中提取数据。通过write_time字段筛选出最新记录。", "enus": "Create an Amazon Athena query to retrieve the data from the feature table. Use the write_time value to find the latest record."}, "option_flag": false}, {"option_text": {"zhcn": "请使用 SageMaker Feature Store 的 GetRecord API 并传入记录标识符。", "enus": "Use the SageMaker Feature Store GetRecord API with the record identifier."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "247", "question": {"enus": "A company’s data scientist has trained a new machine learning model that performs better on test data than the company’s existing model performs in the production environment. The data scientist wants to replace the existing model that runs on an Amazon SageMaker endpoint in the production environment. However, the company is concerned that the new model might not work well on the production environment data. The data scientist needs to perform A/B testing in the production environment to evaluate whether the new model performs well on production environment data. Which combination of steps must the data scientist take to perform the A/B testing? (Choose two.) ", "zhcn": "某公司的数据科学家训练出一款新的机器学习模型，其在测试数据上的表现优于公司生产环境中现有的模型。该数据科学家希望替换当前在生产环境中通过Amazon SageMaker端点运行的模型。然而公司担心新模型可能无法很好地适应生产环境的数据。数据科学家需要在生产环境中进行A/B测试，以评估新模型在实际生产数据上的表现。请问数据科学家必须采取哪两个步骤组合来完成此次A/B测试？（请选择两项）"}, "option": [{"option_text": {"zhcn": "创建一个新的端点配置，其中需包含针对两种模型各自的生产变体。", "enus": "Create a new endpoint configuration that includes a production variant for each of the two models."}, "option_flag": true}, {"option_text": {"zhcn": "新建一个端点配置，其中包含指向不同端点的两种目标变体。", "enus": "Create a new endpoint configuration that includes two target variants that point to different endpoints."}, "option_flag": false}, {"option_text": {"zhcn": "将新模型部署至现有终端节点。", "enus": "Deploy the new model to the existing endpoint."}, "option_flag": true}, {"option_text": {"zhcn": "更新现有端点以启用新模型。", "enus": "Update the existing endpoint to activate the new model."}, "option_flag": false}, {"option_text": {"zhcn": "请将现有终端更新为采用新版终端配置。", "enus": "Update the existing endpoint to use the new endpoint configuration."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AC"}, {"id": "248", "question": {"enus": "A data scientist is working on a forecast problem by using a dataset that consists of .csv files that are stored in Amazon S3. The files contain a timestamp variable in the following format: March 1st, 2020, 08:14pm - There is a hypothesis about seasonal differences in the dependent variable. This number could be higher or lower for weekdays because some days and hours present varying values, so the day of the week, month, or hour could be an important factor. As a result, the data scientist needs to transform the timestamp into weekdays, month, and day as three separate variables to conduct an analysis. Which solution requires the LEAST operational overhead to create a new dataset with the added features? ", "zhcn": "一位数据科学家正利用一组存储在Amazon S3中的.csv文件进行预测分析。这些文件中的时间戳变量格式如下：2020年3月1日晚上08点14分。现有假设认为因变量存在季节性差异——由于某些日期与时段会呈现波动数值，工作日的数据可能偏高或偏低，因此星期几、月份或具体小时可能成为关键影响因素。为此，数据科学家需将时间戳拆解为星期、月份和日期三个独立变量以便分析。在创建包含新增特征的数据集时，下列哪种方案能实现最低的操作复杂度？"}, "option": [{"option_text": {"zhcn": "创建亚马逊EMR集群。编写PySpark代码，实现以下功能：将时间戳变量作为字符串读取，进行数据转换并生成新变量，最终将数据集以新文件形式保存至亚马逊S3存储空间。", "enus": "Create an Amazon EMR cluster. Develop PySpark code that can read the timestamp variable as a string, transform and create the new  variables, and save the dataset as a new file in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon SageMaker中创建数据处理作业。编写Python代码，使其能够读取时间戳字符串变量，进行转换并生成新变量，最终将数据集以新文件形式保存至Amazon S3存储空间。", "enus": "Create a processing job in Amazon SageMaker. Develop Python code that can read the timestamp variable as a string, transform and  create the new variables, and save the dataset as a new file in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在 Amazon SageMaker Data Wrangler 中创建新的数据流。导入 S3 文件后，运用日期/时间特征化转换功能生成新变量，最终将数据集以新文件形式保存至 Amazon S3。", "enus": "Create a new fiow in Amazon SageMaker Data Wrangler. Import the S3 file, use the Featurize date/time transform to generate the new  variables, and save the dataset as a new file in Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "创建一个AWS Glue作业。编写代码实现以下功能：将时间戳变量作为字符串读取，经转换处理后生成新变量，最终将数据集以新文件形式存储至Amazon S3。", "enus": "Create an AWS Glue job. Develop code that can read the timestamp variable as a string, transform and create the new variables, and  save the dataset as a new file in Amazon S3."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "249", "question": {"enus": "A manufacturing company has a production line with sensors that collect hundreds of quality metrics. The company has stored sensor data and manual inspection results in a data lake for several months. To automate quality control, the machine learning team must build an automated mechanism that determines whether the produced goods are good quality, replacement market quality, or scrap quality based on the manual inspection results. Which modeling approach will deliver the MOST accurate prediction of product quality? ", "zhcn": "一家制造企业的生产线上装有传感器，可采集数百项质量指标。该公司已将数月内的传感器数据与人工检测结果存储于数据湖中。为实现质量控制的自动化，机器学习团队需要建立一种自动判别机制，依据人工检测结果判定产品属于优质品、替换市场品还是废品。请问采用哪种建模方法能够最精准地预测产品质量？"}, "option": [{"option_text": {"zhcn": "Amazon SageMaker DeepAR 时间序列预测算法", "enus": "Amazon SageMaker DeepAR forecasting algorithm"}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker XGBoost算法", "enus": "Amazon SageMaker XGBoost algorithm"}, "option_flag": true}, {"option_text": {"zhcn": "Amazon SageMaker 潜在狄利克雷分布（LDA）算法", "enus": "Amazon SageMaker Latent Dirichlet Allocation (LDA) algorithm"}, "option_flag": false}, {"option_text": {"zhcn": "卷积神经网络与ResNet。", "enus": "A convolutional neural network (CNN) and ResNet"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "250", "question": {"enus": "A healthcare company wants to create a machine learning (ML) model to predict patient outcomes. A data science team developed an ML model by using a custom ML library. The company wants to use Amazon SageMaker to train this model. The data science team creates a custom SageMaker image to train the model. When the team tries to launch the custom image in SageMaker Studio, the data scientists encounter an error within the application. Which service can the data scientists use to access the logs for this error? ", "zhcn": "一家医疗健康公司计划开发一个用于预测患者预后的机器学习模型。数据科学团队使用定制化的机器学习库构建了该模型，现拟通过Amazon SageMaker平台进行模型训练。为此，团队专门创建了适用于SageMaker的自定义镜像。然而，当团队尝试在SageMaker Studio中启动该定制镜像时，应用程序内出现了错误。此时，数据科学团队应通过何种服务获取该错误的相关日志信息？"}, "option": [{"option_text": {"zhcn": "亚马逊S3", "enus": "Amazon S3"}, "option_flag": true}, {"option_text": {"zhcn": "亚马逊弹性块存储（Amazon EBS）", "enus": "Amazon Elastic Block Store (Amazon EBS)"}, "option_flag": false}, {"option_text": {"zhcn": "AWS CloudTrail", "enus": "AWS CloudTrail"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊云监控", "enus": "Amazon CloudWatch"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "251", "question": {"enus": "A data scientist wants to build a financial trading bot to automate investment decisions. The financial bot should recommend the quantity and price of an asset to buy or sell to maximize long-term profit. The data scientist will continuously stream financial transactions to the bot for training purposes. The data scientist must select the appropriate machine learning (ML) algorithm to develop the financial trading bot. Which type of ML algorithm will meet these requirements? ", "zhcn": "一位数据科学家计划开发一款金融交易机器人，以实现投资决策的自动化。该金融机器人需具备推荐资产买卖数量与价格的功能，从而最大化长期收益。数据科学家将持续向该机器人输入实时金融交易数据以供训练。在此过程中，选择恰当的机器学习算法至关重要。请问何种类型的机器学习算法能够满足上述需求？"}, "option": [{"option_text": {"zhcn": "监督式学习", "enus": "Supervised learning"}, "option_flag": false}, {"option_text": {"zhcn": "无监督学习", "enus": "Unsupervised learning"}, "option_flag": false}, {"option_text": {"zhcn": "半监督学习", "enus": "Semi-supervised learning"}, "option_flag": true}, {"option_text": {"zhcn": "强化学习", "enus": "Reinforcement learning"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "252", "question": {"enus": "A manufacturing company wants to create a machine learning (ML) model to predict when equipment is likely to fail. A data science team already constructed a deep learning model by using TensorFlow and a custom Python script in a local environment. The company wants to use Amazon SageMaker to train the model. Which TensorFlow estimator configuration will train the model MOST cost-effectively? ", "zhcn": "一家制造企业希望构建机器学习模型来预测设备故障发生时间。数据科学团队已在本地环境中使用TensorFlow及自定义Python脚本完成了深度学习模型的搭建。现企业计划借助Amazon SageMaker平台进行模型训练，下列哪种TensorFlow评估器配置方案能实现最优成本效益？"}, "option": [{"option_text": {"zhcn": "启用SageMaker训练编译器时，只需在参数中添加`compiler_config=TrainingCompilerConfig()`配置项，并将训练脚本通过TensorFlow的`fit()`方法传递给估算器即可。", "enus": "Turn on SageMaker Training Compiler by adding compiler_config=TrainingCompilerConfig() as a parameter. Pass the script to the  estimator in the call to the TensorFlow fit() method."}, "option_flag": false}, {"option_text": {"zhcn": "启用SageMaker训练编译器只需在参数中添加`compiler_config=TrainingCompilerConfig()`即可。通过将`use_spot_instances`参数设为True可开启托管Spot训练。最后在调用TensorFlow的fit()方法时，将训练脚本传递给评估器即可完成配置。", "enus": "Turn on SageMaker Training Compiler by adding compiler_config=TrainingCompilerConfig() as a parameter. Turn on managed spot  training by setting the use_spot_instances parameter to True. Pass the script to the estimator in the call to the TensorFlow fit() method."}, "option_flag": false}, {"option_text": {"zhcn": "调整训练脚本以采用分布式数据并行模式。为分布参数设定合适的数值，并将该脚本传入估算器的TensorFlow fit()方法调用中。", "enus": "Adjust the training script to use distributed data parallelism. Specify appropriate values for the distribution parameter. Pass the script  to the estimator in the call to the TensorFlow fit() method."}, "option_flag": false}, {"option_text": {"zhcn": "开启SageMaker训练编译器功能时，只需在参数中添加`compiler_config=TrainingCompilerConfig()`即可。将`MaxWaitTimeInSeconds`参数的值设置为与`MaxRuntimeInSeconds`参数保持一致。最后通过调用TensorFlow的`fit()`方法将训练脚本传递给估算器。", "enus": "Turn on SageMaker Training Compiler by adding compiler_config=TrainingCompilerConfig() as a parameter. Set the  MaxWaitTimeInSeconds parameter to be equal to the MaxRuntimeInSeconds parameter. Pass the script to the estimator in the call to the  TensorFlow fit() method."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "253", "question": {"enus": "An automotive company uses computer vision in its autonomous cars. The company trained its object detection models successfully by using transfer learning from a convolutional neural network (CNN). The company trained the models by using PyTorch through the Amazon SageMaker SDK. The vehicles have limited hardware and compute power. The company wants to optimize the model to reduce memory, battery, and hardware consumption without a significant sacrifice in accuracy. Which solution will improve the computational eficiency of the models? ", "zhcn": "一家汽车制造商在其自动驾驶车辆中应用了计算机视觉技术。该公司通过迁移学习的方法，成功基于卷积神经网络训练出了目标检测模型，并借助亚马逊SageMaker软件开发工具包使用PyTorch框架完成了模型训练。由于车载硬件配置与算力有限，该企业希望在保持模型精度的前提下，通过优化手段降低内存占用、能耗及硬件负载。下列哪种方案能有效提升模型的计算效率？"}, "option": [{"option_text": {"zhcn": "运用亚马逊云监控指标洞察SageMaker训练过程中的权重、梯度、偏置与激活输出，依据训练数据计算滤波器等级。通过剪枝技术剔除低阶滤波器，基于优化后的滤波器集合重新设定权重，最终使用精简后的模型启动新一轮训练任务。", "enus": "Use Amazon CloudWatch metrics to gain visibility into the SageMaker training weights, gradients, biases, and activation outputs.  Compute the filter ranks based on the training information. Apply pruning to remove the low-ranking filters. Set new weights based on the  pruned set of filters. Run a new training job with the pruned model."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon SageMaker Ground Truth构建并运行数据标注工作流。通过标注流程收集更丰富的带标签数据集，随后结合既有训练数据与新标注数据，启动新一轮模型训练任务。", "enus": "Use Amazon SageMaker Ground Truth to build and run data labeling workfiows. Collect a larger labeled dataset with the labelling  workfiows. Run a new training job that uses the new labeled data with previous training data."}, "option_flag": false}, {"option_text": {"zhcn": "借助 Amazon SageMaker Debugger，您可以清晰洞察训练过程中的权重、梯度、偏置及激活输出。基于训练信息计算滤波器权重等级后，可对低阶滤波器实施剪枝处理。剪枝操作完成后，根据优化后的滤波器集重新设定权重参数，即可启动新一轮针对剪枝后模型的训练任务。", "enus": "Use Amazon SageMaker Debugger to gain visibility into the training weights, gradients, biases, and activation outputs. Compute the  filter ranks based on the training information. Apply pruning to remove the low-ranking filters. Set the new weights based on the pruned  set of filters. Run a new training job with the pruned model."}, "option_flag": true}, {"option_text": {"zhcn": "在企业部署模型后，运用亚马逊SageMaker模型监控器来洞察模型的延迟指标与资源开销指标。提升模型学习速率，并启动新一轮训练任务。", "enus": "Use Amazon SageMaker Model Monitor to gain visibility into the ModelLatency metric and OverheadLatency metric of the model after  the company deploys the model. Increase the model learning rate. Run a new training job."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "254", "question": {"enus": "A data scientist wants to improve the fit of a machine learning (ML) model that predicts house prices. The data scientist makes a first attempt to fit the model, but the fitted model has poor accuracy on both the training dataset and the test dataset. Which steps must the data scientist take to improve model accuracy? (Choose three.) ", "zhcn": "一位数据科学家希望优化预测房价的机器学习模型拟合效果。初次尝试建模后，发现模型在训练集和测试集上的预测精度均不理想。为提升模型准确性，该数据科学家应采取以下哪三项措施？（请选择三项）"}, "option": [{"option_text": {"zhcn": "增强模型所使用的正则化强度。", "enus": "Increase the amount of regularization that the model uses."}, "option_flag": false}, {"option_text": {"zhcn": "降低模型所使用的正则化强度。", "enus": "Decrease the amount of regularization that the model uses."}, "option_flag": true}, {"option_text": {"zhcn": "增加模型训练所用的样本数量。", "enus": "Increase the number of training examples that that model uses."}, "option_flag": false}, {"option_text": {"zhcn": "增加模型所用的测试样例数量。", "enus": "Increase the number of test examples that the model uses."}, "option_flag": true}, {"option_text": {"zhcn": "提升模型所采用的特征数量。", "enus": "Increase the number of model features that the model uses."}, "option_flag": false}, {"option_text": {"zhcn": "精简模型所使用的特征数量。", "enus": "Decrease the number of model features that the model uses."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BDF"}, {"id": "255", "question": {"enus": "A car company is developing a machine learning solution to detect whether a car is present in an image. The image dataset consists of one million images. Each image in the dataset is 200 pixels in height by 200 pixels in width. Each image is labeled as either having a car or not having a car. Which architecture is MOST likely to produce a model that detects whether a car is present in an image with the highest accuracy? ", "zhcn": "一家汽车公司正着手开发一套机器学习系统，用于识别图像中是否出现汽车。该图像数据集包含一百万张样本，每张图像尺寸为200像素×200像素，并已标注是否存在汽车。下列哪种架构最有可能以最高准确率实现车辆存在性的图像识别？"}, "option": [{"option_text": {"zhcn": "采用深度卷积神经网络（CNN）分类器对图像进行识别处理。网络末端需设置线性输出层，用于生成图像中包含汽车的概率估值。", "enus": "Use a deep convolutional neural network (CNN) classifier with the images as input. Include a linear output layer that outputs the  probability that an image contains a car."}, "option_flag": false}, {"option_text": {"zhcn": "采用深度卷积神经网络（CNN）分类器对图像进行识别处理。网络末端需设置柔性最大值输出层，用于生成图像中是否存在车辆的置信概率。", "enus": "Use a deep convolutional neural network (CNN) classifier with the images as input. Include a softmax output layer that outputs the  probability that an image contains a car."}, "option_flag": false}, {"option_text": {"zhcn": "采用深度多层感知机（MLP）分类器，以图像作为输入。输出层采用线性设计，用于计算图像中包含汽车的概率。", "enus": "Use a deep multilayer perceptron (MLP) classifier with the images as input. Include a linear output layer that outputs the probability  that an image contains a car."}, "option_flag": false}, {"option_text": {"zhcn": "采用深度多层感知器（MLP）分类器，以图像作为输入。该模型包含一个softmax输出层，用于计算图像中包含汽车的概率。", "enus": "Use a deep multilayer perceptron (MLP) classifier with the images as input. Include a softmax output layer that outputs the probability  that an image contains a car."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "256", "question": {"enus": "A company is creating an application to identify, count, and classify animal images that are uploaded to the company’s website. The company is using the Amazon SageMaker image classification algorithm with an ImageNetV2 convolutional neural network (CNN). The solution works well for most animal images but does not recognize many animal species that are less common. The company obtains 10,000 labeled images of less common animal species and stores the images in Amazon S3. A machine learning (ML) engineer needs to incorporate the images into the model by using Pipe mode in SageMaker. Which combination of steps should the ML engineer take to train the model? (Choose two.) ", "zhcn": "某公司正在开发一款应用程序，用于识别、计数和分类用户上传至其网站的动物图像。该公司采用亚马逊SageMaker图像分类算法，并搭配ImageNetV2卷积神经网络（CNN）架构。该解决方案对大多数常见动物图像识别效果良好，但对许多较为罕见的动物物种却难以辨识。公司现已获取一万张稀有动物物种的标注图像，并存储于亚马逊S3服务中。机器学习工程师需通过SageMaker的Pipe模式将这些图像数据整合到模型中。请问该工程师应采取哪两种步骤组合来完成模型训练？（请选择两项正确答案）"}, "option": [{"option_text": {"zhcn": "采用ResNet架构。通过随机初始化网络权重，开启完整训练模式。", "enus": "Use a ResNet model. Initiate full training mode by initializing the network with random weights."}, "option_flag": false}, {"option_text": {"zhcn": "采用SageMaker图像分类算法中提供的Inception模型进行实现。", "enus": "Use an Inception model that is available with the SageMaker image classification algorithm."}, "option_flag": true}, {"option_text": {"zhcn": "创建一个包含图像文件及对应类别标签列表的.lst文件，并将该文件上传至Amazon S3存储空间。", "enus": "Create a .lst file that contains a list of image files and corresponding class labels. Upload the .lst file to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "启动迁移学习。利用较为稀有物种的图像数据对模型进行训练。", "enus": "Initiate transfer learning. Train the model by using the images of less common species."}, "option_flag": true}, {"option_text": {"zhcn": "采用JSON Lines格式的增强清单文件。", "enus": "Use an augmented manifest file in JSON Lines format."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BD"}, {"id": "257", "question": {"enus": "A music streaming company is building a pipeline to extract features. The company wants to store the features for ofiine model training and online inference. The company wants to track feature history and to give the company’s data science teams access to the features. Which solution will meet these requirements with the MOST operational eficiency? ", "zhcn": "一家音乐流媒体公司正在构建特征提取流水线。该公司需要存储特征数据以支持离线模型训练与在线推理，同时要求能够追溯特征历史版本，并为内部数据科学团队提供特征数据调用权限。在满足上述需求的前提下，何种解决方案能实现最高运营效率？"}, "option": [{"option_text": {"zhcn": "使用Amazon SageMaker特征存储服务，可集中管理模型训练与推理所需的特征数据。您可创建在线特征库支持实时推理，同时构建离线特征库用于模型训练。此外，需配置IAM角色以便数据科学家安全访问并检索特征组数据。", "enus": "Use Amazon SageMaker Feature Store to store features for model training and inference. Create an online store for online inference.  Create an ofiine store for model training. Create an IAM role for data scientists to access and search through feature groups."}, "option_flag": false}, {"option_text": {"zhcn": "使用亚马逊SageMaker特征存储库来存储模型训练与推理所需的特征量。创建可同时支持在线推理与模型训练的特征在线库，并为数据科学家设立IAM权限角色，使其能够访问并检索特征组数据。", "enus": "Use Amazon SageMaker Feature Store to store features for model training and inference. Create an online store for both online  inference and model training. Create an IAM role for data scientists to access and search through feature groups."}, "option_flag": true}, {"option_text": {"zhcn": "创建一个Amazon S3存储桶用于存放在线推理特征数据，再创建第二个S3存储桶专门存储离线模型训练特征。为这两个S3存储桶启用版本控制功能，并通过标签系统明确区分在线推理特征与离线模型训练特征的用途。使用Amazon Athena查询在线推理所需的S3存储桶数据，同时将离线模型训练对应的S3存储桶关联至SageMaker训练任务。最后配置IAM策略，授予数据科学家同时访问这两个存储桶的权限。", "enus": "Create one Amazon S3 bucket to store online inference features. Create a second S3 bucket to store ofiine model training features.  Turn on versioning for the S3 buckets and use tags to specify which tags are for online inference features and which are for ofiine model  training features. Use Amazon Athena to query the S3 bucket for online inference. Connect the S3 bucket for ofiine model training to a  SageMaker training job. Create an IAM policy that allows data scientists to access both buckets."}, "option_flag": false}, {"option_text": {"zhcn": "创建两个独立的Amazon DynamoDB数据表，分别用于存储在线推理特征与离线模型训练特征。两张表均需启用基于时间版本的记录管理。在线推理时直接查询DynamoDB中的对应数据表，当新的SageMaker训练任务启动时，将数据从DynamoDB迁移至Amazon S3存储。同时需配置IAM策略，允许数据科学家访问这两个数据表。", "enus": "Create two separate Amazon DynamoDB tables to store online inference features and ofiine model training features. Use time-based  versioning on both tables. Query the DynamoDB table for online inference. Move the data from DynamoDB to Amazon S3 when a new  SageMaker training job is launched. Create an IAM policy that allows data scientists to access both tables."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "258", "question": {"enus": "A beauty supply store wants to understand some characteristics of visitors to the store. The store has security video recordings from the past several years. The store wants to generate a report of hourly visitors from the recordings. The report should group visitors by hair style and hair color. Which solution will meet these requirements with the LEAST amount of effort? ", "zhcn": "一家美妆用品店希望了解店内顾客的若干特征。该店拥有过去数年的监控录像资料，现需根据录像生成每小时客流量分析报告，要求按顾客的发型与发色进行分类统计。哪种解决方案能以最小工作量满足这些需求？"}, "option": [{"option_text": {"zhcn": "运用目标检测算法从视频画面中定位访客的发丝区域，随后将识别出的头发图像输入ResNet-50模型，用以精准分析发型特征与发色色调。", "enus": "Use an object detection algorithm to identify a visitor’s hair in video frames. Pass the identified hair to an ResNet-50 algorithm to  determine hair style and hair color."}, "option_flag": false}, {"option_text": {"zhcn": "运用目标检测算法从视频帧中识别访客的发型轮廓，随后将检测到的头发区域输入XGBoost算法，以此精准判断其发型样式与发色特征。", "enus": "Use an object detection algorithm to identify a visitor’s hair in video frames. Pass the identified hair to an XGBoost algorithm to  determine hair style and hair color."}, "option_flag": false}, {"option_text": {"zhcn": "采用语义分割算法从视频帧中识别访客的发丝轮廓，随后将识别出的头发区域输入ResNet-50模型，用以精准分析发型特征与发色属性。", "enus": "Use a semantic segmentation algorithm to identify a visitor’s hair in video frames. Pass the identified hair to an ResNet-50 algorithm to  determine hair style and hair color."}, "option_flag": true}, {"option_text": {"zhcn": "采用语义分割算法对视频帧中访客的头发进行识别定位，随后将识别出的头发区域输入XGBoost算法模型，以精准判断其发型与发质特征。", "enus": "Use a semantic segmentation algorithm to identify a visitor’s hair in video frames. Pass the identified hair to an XGBoost algorithm to  determine hair style and hair."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "259", "question": {"enus": "A financial services company wants to automate its loan approval process by building a machine learning (ML) model. Each loan data point contains credit history from a third-party data source and demographic information about the customer. Each loan approval prediction must come with a report that contains an explanation for why the customer was approved for a loan or was denied for a loan. The company will use Amazon SageMaker to build the model. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "一家金融服务公司计划通过构建机器学习模型来实现贷款审批流程的自动化。每笔贷款数据均包含来自第三方数据源的信用记录及客户背景信息。系统在输出每笔贷款审批结果时，需同步生成说明报告，详细解释贷款获批或遭拒的原因。该公司将使用Amazon SageMaker平台开发模型。在满足上述所有要求的前提下，哪种解决方案能以最小的开发量实现这一目标？"}, "option": [{"option_text": {"zhcn": "利用SageMaker模型调试器自动检测预测结果，生成解析说明，并附上详细的诊断报告。", "enus": "Use SageMaker Model Debugger to automatically debug the predictions, generate the explanation, and attach the explanation report."}, "option_flag": true}, {"option_text": {"zhcn": "利用AWS Lambda生成特征重要性及部分依赖图，并借助这些图表制作解释报告予以附呈。", "enus": "Use AWS Lambda to provide feature importance and partial dependence plots. Use the plots to generate and attach the explanation  report."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Clarify生成解读报告，并将该报告与预测结果一并呈现。", "enus": "Use SageMaker Clarify to generate the explanation report. Attach the report to the predicted results."}, "option_flag": false}, {"option_text": {"zhcn": "利用自定义的亚马逊云监控指标生成解析报告，并将该报告附于预测结果之中。", "enus": "Use custom Amazon CloudWatch metrics to generate the explanation report. Attach the report to the predicted results."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "260", "question": {"enus": "A financial company sends special offers to customers through weekly email campaigns. A bulk email marketing system takes the list of email addresses as an input and sends the marketing campaign messages in batches. Few customers use the offers from the campaign messages. The company does not want to send irrelevant offers to customers. A machine learning (ML) team at the company is using Amazon SageMaker to build a model to recommend specific offers to each customer based on the customer's profile and the offers that the customer has accepted in the past. Which solution will meet these requirements with the MOST operational eficiency? ", "zhcn": "一家金融公司通过每周的电子邮件活动向客户发送专属优惠。批量邮件营销系统将邮箱地址列表作为输入内容，分批发送营销活动信息。但仅有少数客户会使用活动邮件中的优惠。该公司不希望向客户发送无关的优惠信息。该公司的机器学习团队正利用Amazon SageMaker构建模型，旨在根据客户画像及其过往接受的优惠记录，为每位客户推荐特定优惠方案。若要最大程度满足运营效率要求，应当采用何种解决方案？"}, "option": [{"option_text": {"zhcn": "采用因子分解机算法构建模型，为顾客生成个性化优惠推荐方案。通过部署SageMaker服务端点实现优惠推荐的实时计算，并将推荐结果无缝对接至群发邮件营销系统。", "enus": "Use the Factorization Machines algorithm to build a model that can generate personalized offer recommendations for customers.  Deploy a SageMaker endpoint to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system."}, "option_flag": false}, {"option_text": {"zhcn": "运用神经协同过滤算法构建模型，为顾客生成个性化优惠推荐方案。通过部署SageMaker服务端点实现优惠推荐的实时计算，并将推荐结果导入批量邮件营销系统进行精准触达。", "enus": "Use the Neural Collaborative Filtering algorithm to build a model that can generate personalized offer recommendations for customers.  Deploy a SageMaker endpoint to generate offer recommendations. Feed the offer recommendations into the bulk email marketing system."}, "option_flag": false}, {"option_text": {"zhcn": "运用神经协同过滤算法构建模型，为顾客生成个性化优惠推荐方案。通过部署SageMaker批量推理任务来生成推荐结果，并将这些优惠推荐信息导入群发邮件营销系统。", "enus": "Use the Neural Collaborative Filtering algorithm to build a model that can generate personalized offer recommendations for customers.  Deploy a SageMaker batch inference job to generate offer recommendations. Feed the offer recommendations into the bulk email  marketing system."}, "option_flag": true}, {"option_text": {"zhcn": "运用因子分解机算法构建模型，为客户生成个性化优惠推荐方案。通过部署SageMaker批量推理任务来生成推荐结果，并将这些推荐信息导入群发邮件营销系统进行精准投放。", "enus": "Use the Factorization Machines algorithm to build a model that can generate personalized offer recommendations for customers.  Deploy a SageMaker batch inference job to generate offer recommendations. Feed the offer recommendations into the bulk email  marketing system."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "261", "question": {"enus": "A social media company wants to develop a machine learning (ML) model to detect inappropriate or offensive content in images. The company has collected a large dataset of labeled images and plans to use the built-in Amazon SageMaker image classification algorithm to train the model. The company also intends to use SageMaker pipe mode to speed up the training. The company splits the dataset into training, validation, and testing datasets. The company stores the training and validation images in folders that are named Training and Validation, respectively. The folders contain subfolders that correspond to the names of the dataset classes. The company resizes the images to the same size and generates two input manifest files named training.lst and validation.lst, for the training dataset and the validation dataset, respectively. Finally, the company creates two separate Amazon S3 buckets for uploads of the training dataset and the validation dataset. Which additional data preparation steps should the company take before uploading the files to Amazon S3? ", "zhcn": "一家社交媒体公司计划开发机器学习模型，用于检测图像中的不当或冒犯性内容。公司已收集大量带标签的图像数据集，并准备采用亚马逊SageMaker内置的图像分类算法进行模型训练。为加速训练过程，公司将使用SageMaker管道模式。  \n\n公司将数据集划分为训练集、验证集和测试集三部分，并分别将训练图像与验证图像存放于名为\"Training\"和\"Validation\"的文件夹中。这些文件夹内设有与数据集类别对应的子文件夹。所有图像已统一调整为相同尺寸，并生成了训练集和验证集对应的输入清单文件training.lst与validation.lst。  \n\n最后，公司创建了两个独立的亚马逊S3存储桶，分别用于上传训练数据集和验证数据集。在上传文件至亚马逊S3之前，公司还需完成哪些额外的数据准备工作？"}, "option": [{"option_text": {"zhcn": "通过将图像读入Pandas数据框架，并将数据框架存储为Parquet格式，生成training.parquet与validation.parquet两个Apache Parquet文件。随后将生成的Parquet文件上传至训练用的S3存储桶中。", "enus": "Generate two Apache Parquet files, training.parquet and validation.parquet, by reading the images into a Pandas data frame and  storing the data frame as a Parquet file. Upload the Parquet files to the training S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "使用Snappy压缩库对训练集与验证集目录进行压缩处理。将清单文件及压缩后的数据上传至训练用的S3存储桶中。", "enus": "Compress the training and validation directories by using the Snappy compression library. Upload the manifest and compressed files to  the training S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "使用gzip压缩库对训练集与验证集目录进行压缩处理。将清单文件及压缩后的数据上传至训练专用的S3存储桶。", "enus": "Compress the training and validation directories by using the gzip compression library. Upload the manifest and compressed files to the  training S3 bucket."}, "option_flag": true}, {"option_text": {"zhcn": "使用Apache MXNet工具集中的im2rec实用程序，依据清单文件生成training.rec与validation.rec两个RecordIO格式文件，并将其上传至训练专用的S3存储桶中。", "enus": "Generate two RecordIO files, training.rec and validation.rec, from the manifest files by using the im2rec Apache MXNet utility tool.  Upload the RecordIO files to the training S3 bucket."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "262", "question": {"enus": "A media company wants to create a solution that identifies celebrities in pictures that users upload. The company also wants to identify the IP address and the timestamp details from the users so the company can prevent users from uploading pictures from unauthorized locations. Which solution will meet these requirements with LEAST development effort? ", "zhcn": "一家传媒公司计划开发一套系统，用于识别用户上传图片中的公众人物。该公司还希望获取用户的IP地址与时间戳信息，以防止用户从未经授权的地理位置上传图片。在满足上述需求的前提下，何种方案能以最小的开发成本实现？"}, "option": [{"option_text": {"zhcn": "借助AWS Panorama识别图片中的知名人士，并通过AWS CloudTrail记录IP地址与时间戳信息。", "enus": "Use AWS Panorama to identify celebrities in the pictures. Use AWS CloudTrail to capture IP address and timestamp details."}, "option_flag": false}, {"option_text": {"zhcn": "运用AWS Panorama技术识别图像中的知名人士，并通过调用AWS Panorama设备开发工具包获取设备的IP地址与时间戳信息。", "enus": "Use AWS Panorama to identify celebrities in the pictures. Make calls to the AWS Panorama Device SDK to capture IP address and  timestamp details."}, "option_flag": false}, {"option_text": {"zhcn": "借助亚马逊Rekognition服务，可精准识别图像中的知名人士。通过AWS CloudTrail功能，能够记录访问来源的IP地址及操作时间戳等详细信息。", "enus": "Use Amazon Rekognition to identify celebrities in the pictures. Use AWS CloudTrail to capture IP address and timestamp details."}, "option_flag": true}, {"option_text": {"zhcn": "借助亚马逊Rekognition图像识别服务，可精准辨识影像中的公众人物。通过其文本检测功能，还能自动提取图片内包含的IP地址与时间戳信息。", "enus": "Use Amazon Rekognition to identify celebrities in the pictures. Use the text detection feature to capture IP address and timestamp  details."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "263", "question": {"enus": "A pharmaceutical company performs periodic audits of clinical trial sites to quickly resolve critical findings. The company stores audit documents in text format. Auditors have requested help from a data science team to quickly analyze the documents. The auditors need to discover the 10 main topics within the documents to prioritize and distribute the review work among the auditing team members. Documents that describe adverse events must receive the highest priority. A data scientist will use statistical modeling to discover abstract topics and to provide a list of the top words for each category to help the auditors assess the relevance of the topic. Which algorithms are best suited to this scenario? (Choose two.) ", "zhcn": "一家制药公司定期对临床试验基地开展审计，以便迅速处理关键发现。该公司以文本格式存储审计文件。审计人员请求数据科学团队协助快速分析这些文件，旨在从文档中识别十大核心主题，从而合理分配审计团队的审阅工作优先级。其中，描述不良事件的文档必须列为最高优先级别。数据科学家将采用统计建模方法挖掘抽象主题，并为每个类别提供核心词汇列表，以辅助审计人员评估主题相关性。请问下列哪种算法最适用于此场景？（请选择两项。）"}, "option": [{"option_text": {"zhcn": "潜在狄利克雷分布（LDA）", "enus": "Latent Dirichlet allocation (LDA)"}, "option_flag": false}, {"option_text": {"zhcn": "随机森林分类器", "enus": "Random forest classifier"}, "option_flag": true}, {"option_text": {"zhcn": "神经主题建模（NTM）", "enus": "Neural topic modeling (NTM)"}, "option_flag": true}, {"option_text": {"zhcn": "线性支持向量机", "enus": "Linear support vector machine"}, "option_flag": false}, {"option_text": {"zhcn": "线性回归", "enus": "Linear regression"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BC"}, {"id": "264", "question": {"enus": "A company needs to deploy a chatbot to answer common questions from customers. The chatbot must base its answers on company documentation. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "一家公司需要部署聊天机器人来解答客户的常见问题。该聊天机器人必须依据公司文档内容进行回答。哪种方案能以最小的开发工作量满足这些需求？"}, "option": [{"option_text": {"zhcn": "借助Amazon Kendra实现企业文档的智能索引。通过调用Amazon Kendra查询API接口，将聊天机器人与Amazon Kendra无缝集成，从而精准解答客户咨询。", "enus": "Index company documents by using Amazon Kendra. Integrate the chatbot with Amazon Kendra by using the Amazon Kendra Query API  operation to answer customer questions."}, "option_flag": false}, {"option_text": {"zhcn": "基于历史客户问题与公司文档，训练双向注意力流（BiDAF）神经网络模型。将该模型部署为实时亚马逊SageMaker服务端点，并通过SageMaker运行时InvokeEndpoint接口与聊天机器人系统集成，用于智能应答客户咨询。", "enus": "Train a Bidirectional Attention Flow (BiDAF) network based on past customer questions and company documents. Deploy the model as  a real-time Amazon SageMaker endpoint. Integrate the model with the chatbot by using the SageMaker Runtime InvokeEndpoint API  operation to answer customer questions."}, "option_flag": true}, {"option_text": {"zhcn": "基于历史客户问询与公司内部文档，训练亚马逊SageMaker Blazing Text模型。将该模型部署为实时SageMaker服务终端，并通过SageMaker运行时调用终端节点API接口，与聊天机器人系统集成，实现智能应答客户问题。", "enus": "Train an Amazon SageMaker Blazing Text model based on past customer questions and company documents. Deploy the model as a  real-time SageMaker endpoint. Integrate the model with the chatbot by using the SageMaker Runtime InvokeEndpoint API operation to  answer customer questions."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊OpenSearch服务构建公司文档索引系统。通过集成OpenSearch服务的k近邻查询接口，使智能客服能够调用该接口精准解答客户咨询。", "enus": "Index company documents by using Amazon OpenSearch Service. Integrate the chatbot with OpenSearch Service by using the  OpenSearch Service k-nearest neighbors (k-NN) Query API operation to answer customer questions."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "265", "question": {"enus": "A company wants to conduct targeted marketing to sell solar panels to homeowners. The company wants to use machine learning (ML) technologies to identify which houses already have solar panels. The company has collected 8,000 satellite images as training data and will use Amazon SageMaker Ground Truth to label the data. The company has a small internal team that is working on the project. The internal team has no ML expertise and no ML experience. Which solution will meet these requirements with the LEAST amount of effort from the internal team? ", "zhcn": "一家公司计划向房主开展定向营销，推广太阳能电池板销售业务。该公司拟采用机器学习技术识别已安装太阳能电池板的住宅，目前已收集8000张卫星图像作为训练数据，并准备使用Amazon SageMaker Ground Truth进行数据标注。公司内部有一个小型项目团队负责此项工作，但团队成员既缺乏机器学习专业知识，也未曾有过相关实战经验。请问在最大限度减少内部团队工作量的前提下，最能满足这些需求的解决方案是什么？"}, "option": [{"option_text": {"zhcn": "组建一支由内部团队构成的专属标注团队。利用该专属团队及SageMaker Ground Truth的主动学习功能完成数据标注工作，随后通过Amazon Rekognition Custom Labels服务进行模型训练与部署。", "enus": "Set up a private workforce that consists of the internal team. Use the private workforce and the SageMaker Ground Truth active learning  feature to label the data. Use Amazon Rekognition Custom Labels for model training and hosting."}, "option_flag": false}, {"option_text": {"zhcn": "组建一支由内部团队构成的专属标注团队，利用该团队进行数据标注工作。随后采用Amazon Rekognition Custom Labels服务进行模型训练与部署。", "enus": "Set up a private workforce that consists of the internal team. Use the private workforce to label the data. Use Amazon Rekognition  Custom Labels for model training and hosting."}, "option_flag": true}, {"option_text": {"zhcn": "组建一支由内部团队构成的专属标注队伍。运用该专属团队及SageMaker Ground Truth的主动学习功能完成数据标注工作。采用SageMaker目标检测算法进行模型训练，并通过SageMaker批量转换技术实现推理预测。", "enus": "Set up a private workforce that consists of the internal team. Use the private workforce and the SageMaker Ground Truth active learning  feature to label the data. Use the SageMaker Object Detection algorithm to train a model. Use SageMaker batch transform for inference."}, "option_flag": false}, {"option_text": {"zhcn": "组建一支公共标注团队，由该团队负责数据标注工作。随后采用SageMaker目标检测算法进行模型训练，最终通过SageMaker批量转换功能实现推理预测。", "enus": "Set up a public workforce. Use the public workforce to label the data. Use the SageMaker Object Detection algorithm to train a model.  Use SageMaker batch transform for inference."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "266", "question": {"enus": "A company hosts a machine learning (ML) dataset repository on Amazon S3. A data scientist is preparing the repository to train a model. The data scientist needs to redact personally identifiable information (PH) from the dataset. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "某公司在亚马逊S3云存储平台托管了一个机器学习数据集库。一位数据科学家正在准备用该数据仓库训练模型，需对数据集中的个人身份信息进行脱敏处理。在满足上述需求的前提下，下列哪种解决方案所需的开发工作量最小？"}, "option": [{"option_text": {"zhcn": "借助Amazon SageMaker Data Wrangler的自定义转换功能，可精准识别并隐去个人身份信息。", "enus": "Use Amazon SageMaker Data Wrangler with a custom transformation to identify and redact the PII."}, "option_flag": true}, {"option_text": {"zhcn": "编写一个定制的AWS Lambda函数，用于读取文件、识别其中的个人身份信息，并对这些信息进行脱敏处理。", "enus": "Create a custom AWS Lambda function to read the files, identify the PII. and redact the PII"}, "option_flag": false}, {"option_text": {"zhcn": "使用AWS Glue DataBrew识别并脱敏个人身份信息。", "enus": "Use AWS Glue DataBrew to identity and redact the PII"}, "option_flag": false}, {"option_text": {"zhcn": "借助AWS Glue开发终端，在笔记本中即可实现个人身份信息的自动化遮蔽处理。", "enus": "Use an AWS Glue development endpoint to implement the PII redaction from within a notebook"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "267", "question": {"enus": "A company is deploying a new machine learning (ML) model in a production environment. The company is concerned that the ML model will drift over time, so the company creates a script to aggregate all inputs and predictions into a single file at the end of each day. The company stores the file as an object in an Amazon S3 bucket. The total size of the daily file is 100 GB. The daily file size will increase over time. Four times a year, the company samples the data from the previous 90 days to check the ML model for drift. After the 90-day period, the company must keep the files for compliance reasons. The company needs to use S3 storage classes to minimize costs. The company wants to maintain the same storage durability of the data. Which solution will meet these requirements? ", "zhcn": "某公司正在生产环境中部署一套全新的机器学习模型。由于担心该模型会随时间推移发生漂移，公司开发了一套脚本，用于每日汇总所有输入数据与预测结果，并将其整合为单一文件。这些文件以对象形式存储于亚马逊S3存储桶中，每日文件体积为100GB，且容量将随时间递增。公司每年四次对过去90天的数据进行抽样检测，以验证模型是否发生漂移。根据合规要求，90天后的数据仍需继续保留。在确保数据存储持久性不变的前提下，公司需通过S3存储分级方案实现成本优化。请问何种解决方案可满足上述需求？"}, "option": [{"option_text": {"zhcn": "将日常物件存放于S3标准低频访问存储层级。设置S3生命周期管理策略，使存储满90日的物件自动转存至S3 Glacier灵活检索存储层。", "enus": "Store the daily objects in the S3 Standard-InfrequentAccess (S3 Standard-IA) storage class. Configure an S3 Lifecycle rule to move the  objects to S3 Glacier Flexible Retrieval after 90 days."}, "option_flag": false}, {"option_text": {"zhcn": "将日常存取对象存储于S3单区低频访问存储类别中，并配置S3生命周期策略，使这些对象在90天后自动归档至S3 Glacier灵活检索存储层。", "enus": "Store the daily objects in the S3 One Zone-Infrequent Access (S3 One Zone-IA) storage class. Configure an S3 Lifecycle rule to move the  objects to S3 Glacier Flexible Retrieval after 90 days."}, "option_flag": false}, {"option_text": {"zhcn": "将日常物件存放于S3标准低频访问存储层级，并设置生命周期策略，使这些物件在90天后自动转存至S3冰川深度归档存储。", "enus": "Store the daily objects in the S3 Standard-InfrequentAccess (S3 Standard-IA) storage class. Configure an S3 Lifecycle rule to move the  objects to S3 Glacier Deep Archive after 90 days."}, "option_flag": true}, {"option_text": {"zhcn": "将日常存取对象存储于S3单区低频访问存储层级中，并设置生命周期管理策略，使数据在90天后自动归档至S3 Glacier深度归档存储。", "enus": "Store the daily objects in the S3 One Zone-Infrequent Access (S3 One Zone-IA) storage class. Configure an S3 Lifecycle rule to move the  objects to S3 Glacier Deep Archive after 90 days."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "268", "question": {"enus": "A company wants to enhance audits for its machine learning (ML) systems. The auditing system must be able to perform metadata analysis on the features that the ML models use. The audit solution must generate a report that analyzes the metadata. The solution also must be able to set the data sensitivity and authorship of features. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "某公司计划加强其机器学习系统的审计功能。审计系统需能对模型所使用的特征进行元数据分析，并生成包含元数据分析的报告。该方案还需支持设定特征的数据敏感度与作者信息。在满足上述要求的前提下，哪种方案能以最小的开发量实现？"}, "option": [{"option_text": {"zhcn": "使用Amazon SageMaker特征库进行特征筛选，构建数据流以执行特征级元数据分析。创建Amazon DynamoDB表用于存储特征级元数据，并借助Amazon QuickSight对元数据进行可视化分析。", "enus": "Use Amazon SageMaker Feature Store to select the features. Create a data fiow to perform feature-level metadata analysis. Create an  Amazon DynamoDB table to store feature-level metadata. Use Amazon QuickSight to analyze the metadata."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker特征存储功能，为当前机器学习模型所使用的特征创建特征组。为每个特征配置必要的元数据，并通过SageMaker Studio平台实现对元数据的可视化分析。", "enus": "Use Amazon SageMaker Feature Store to set feature groups for the current features that the ML models use. Assign the required  metadata for each feature. Use SageMaker Studio to analyze the metadata."}, "option_flag": true}, {"option_text": {"zhcn": "运用亚马逊SageMaker特征存储功能，对企业所需的特征级元数据实施定制化算法分析。通过创建亚马逊DynamoDB数据表存储特征级元数据，并借助亚马逊QuickSight可视化工具实现元数据的深度解析。", "enus": "Use Amazon SageMaker Features Store to apply custom algorithms to analyze the feature-level metadata that the company requires.  Create an Amazon DynamoDB table to store feature-level metadata. Use Amazon QuickSight to analyze the metadata."}, "option_flag": false}, {"option_text": {"zhcn": "运用亚马逊SageMaker特征存储服务，为当前机器学习模型所使用的特征创建特征组，并为每个特征配置必要的元数据。随后可借助亚马逊QuickSight工具对元数据进行可视化分析。", "enus": "Use Amazon SageMaker Feature Store to set feature groups for the current features that the ML models use. Assign the required  metadata for each feature. Use Amazon QuickSight to analyze the metadata."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "269", "question": {"enus": "A machine learning (ML) specialist uploads a dataset to an Amazon S3 bucket that is protected by server-side encryption with AWS KMS keys (SSE-KMS). The ML specialist needs to ensure that an Amazon SageMaker notebook instance can read the dataset that is in Amazon S3. Which solution will meet these requirements? ", "zhcn": "一位机器学习专家将数据集上传至受AWS KMS密钥服务器端加密（SSE-KMS）保护的Amazon S3存储桶中。为确保Amazon SageMaker笔记本实例能够读取该S3数据集，下列哪项方案符合要求？"}, "option": [{"option_text": {"zhcn": "配置安全组规则，允许所有HTTP入站与出站流量通行。随后将此安全组关联至SageMaker笔记本实例。", "enus": "Define security groups to allow all HTTP inbound and outbound trafic. Assign the security groups to the SageMaker notebook instance."}, "option_flag": false}, {"option_text": {"zhcn": "请将SageMaker笔记本实例配置为可访问该虚拟私有云。", "enus": "Configure the SageMaker notebook instance to have access to the VP"}, "option_flag": false}, {"option_text": {"zhcn": "在AWS密钥管理服务（AWS KMS）的密钥策略中，为笔记本所属的VPC授予访问权限。  \n其次，为SageMaker笔记本分配一个具有S3数据集读取权限的IAM角色，并在KMS密钥策略中向该IAM角色授予相应权限。", "enus": "Grant permission in the AWS Key Management Service (AWS  KMS) key policy to the notebook’s VPC.  C. Assign an IAM role that provides S3 read access for the dataset to the SageMaker notebook. Grant permission in the KMS key policy to  the IAM role."}, "option_flag": true}, {"option_text": {"zhcn": "为SageMaker笔记本实例配置与加密Amazon S3数据相同的KMS密钥。", "enus": "Assign the same KMS key that encrypts the data in Amazon S3 to the SageMaker notebook instance."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "270", "question": {"enus": "A company has a podcast platform that has thousands of users. The company implemented an algorithm to detect low podcast engagement based on a 10-minute running window of user events such as listening to, pausing, and closing the podcast. A machine learning (ML) specialist is designing the ingestion process for these events. The ML specialist needs to transform the data to prepare the data for inference. How should the ML specialist design the transformation step to meet these requirements with the LEAST operational effort? ", "zhcn": "某公司旗下播客平台拥有数千名用户。为检测用户参与度较低的播客内容，该公司采用基于10分钟滚动窗口的算法，通过分析用户收听、暂停及关闭播客等行为数据进行判断。当前，一位机器学习专家正在设计这些行为数据的采集流程。该专家需对原始数据进行转换处理，以满足模型推理需求。在满足各项技术要求的前提下，如何以最小的运维成本设计数据转换环节？"}, "option": [{"option_text": {"zhcn": "采用亚马逊托管式Apache Kafka流处理服务（Amazon MSK）集群接收事件数据流，并通过亚马逊Kinesis数据分析服务（Amazon Kinesis Data Analytics）在推理前对最近10分钟的数据进行实时转换。", "enus": "Use an Amazon Managed Streaming for Apache Kafka (Amazon MSK) cluster to ingest event data. Use Amazon Kinesis Data Analytics  to transform the most recent 10 minutes of data before inference."}, "option_flag": false}, {"option_text": {"zhcn": "运用亚马逊Kinesis数据流实时采集事件数据，通过亚马逊Kinesis Data Firehose将数据存储至亚马逊S3对象存储服务。在模型推理前，采用AWS Lambda函数对最近十分钟的数据流进行动态处理。", "enus": "Use Amazon Kinesis Data Streams to ingest event data. Store the data in Amazon S3 by using Amazon Kinesis Data Firehose. Use AWS  Lambda to transform the most recent 10 minutes of data before inference."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊Kinesis数据流实时采集事件数据，并通过亚马逊Kinesis数据分析服务对最近十分钟的数据进行预处理，继而完成推理计算。", "enus": "Use Amazon Kinesis Data Streams to ingest event data. Use Amazon Kinesis Data Analytics to transform the most recent 10 minutes of  data before inference."}, "option_flag": true}, {"option_text": {"zhcn": "利用亚马逊托管式Apache Kafka流处理服务（Amazon MSK）集群接收事件数据流，并通过AWS Lambda在推理前对最近10分钟的数据进行实时转换。", "enus": "Use an Amazon Managed Streaming for Apache Kafka (Amazon MSK) cluster to ingest event data. Use AWS Lambda to transform the  most recent 10 minutes of data before inference."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "271", "question": {"enus": "A machine learning (ML) specialist is training a multilayer perceptron (MLP) on a dataset with multiple classes. The target class of interest is unique compared to the other classes in the dataset, but it does not achieve an acceptable recall metric. The ML specialist varies the number and size of the MLP's hidden layers, but the results do not improve significantly. Which solution will improve recall in the LEAST amount of time? ", "zhcn": "一位机器学习专家正在利用包含多个类别的数据集训练多层感知器模型。尽管目标类别在数据集中独具特色，但其召回率指标始终未能达到理想水平。该专家尝试调整隐藏层的数量和规模，却未见明显改善。若要耗时最短地提升召回率，应采取下列哪种方案？"}, "option": [{"option_text": {"zhcn": "在MLP的损失函数中加入类别权重，然后重新进行训练。", "enus": "Add class weights to the MLP's loss function, and then retrain."}, "option_flag": true}, {"option_text": {"zhcn": "通过亚马逊土耳其机器人（Amazon Mechanical Turk）收集更多数据，随后进行模型重训练。", "enus": "Gather more data by using Amazon Mechanical Turk, and then retrain."}, "option_flag": false}, {"option_text": {"zhcn": "训练一个k-means算法，而非多层感知机。", "enus": "Train a k-means algorithm instead of an MLP."}, "option_flag": false}, {"option_text": {"zhcn": "训练异常检测模型，而非多层感知机。", "enus": "Train an anomaly detection model instead of an MLP."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "272", "question": {"enus": "A machine learning (ML) specialist uploads 5 TB of data to an Amazon SageMaker Studio environment. The ML specialist performs initial data cleansing. Before the ML specialist begins to train a model, the ML specialist needs to create and view an analysis report that details potential bias in the uploaded data. Which combination of actions will meet these requirements with the LEAST operational overhead? (Choose two.) ", "zhcn": "一位机器学习专家将5 TB数据上传至Amazon SageMaker Studio环境，并完成了初步的数据清洗。在开始训练模型之前，该专家需生成并查阅一份分析报告，其中需详细说明所上传数据中可能存在的偏差。若要满足以上需求，同时尽可能降低运维负担，应选择哪两项操作组合？（请选出两项正确答案）"}, "option": [{"option_text": {"zhcn": "利用SageMaker Clarify自动检测数据偏差。", "enus": "Use SageMaker Clarify to automatically detect data bias"}, "option_flag": true}, {"option_text": {"zhcn": "在SageMaker Ground Truth中启用偏差检测功能，即可自动分析数据特征。", "enus": "Turn on the bias detection option in SageMaker Ground Truth to automatically analyze data features."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Model Monitor生成偏差漂移报告。", "enus": "Use SageMaker Model Monitor to generate a bias drift report."}, "option_flag": false}, {"option_text": {"zhcn": "配置SageMaker Data Wrangler以生成偏差报告。", "enus": "Configure SageMaker Data Wrangler to generate a bias report."}, "option_flag": true}, {"option_text": {"zhcn": "利用SageMaker Experiments进行数据校验。", "enus": "Use SageMaker Experiments to perform a data check"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AD"}, {"id": "273", "question": {"enus": "A network security vendor needs to ingest telemetry data from thousands of endpoints that run all over the world. The data is transmitted every 30 seconds in the form of records that contain 50 fields. Each record is up to 1 KB in size. The security vendor uses Amazon Kinesis Data Streams to ingest the data. The vendor requires hourly summaries of the records that Kinesis Data Streams ingests. The vendor will use Amazon Athena to query the records and to generate the summaries. The Athena queries will target 7 to 12 of the available data fields. Which solution will meet these requirements with the LEAST amount of customization to transform and store the ingested data? ", "zhcn": "一家网络安全服务商需要接收来自全球各地数千个终端设备的遥测数据。这些数据每30秒以记录形式传输，每条记录包含50个字段，最大容量为1KB。该服务商采用亚马逊Kinesis数据流进行数据接入，并要求每小时对接入的记录生成汇总报告。后续将使用亚马逊雅典娜服务查询数据记录并生成摘要，查询操作将针对50个可用字段中的7至12个字段。请问在满足以下条件的前提下，哪种解决方案能够以最小的数据转换与存储定制化成本实现上述需求？"}, "option": [{"option_text": {"zhcn": "利用AWS Lambda每小时读取并汇总数据，通过亚马逊Kinesis Data Firehose对数据进行转换后，存储至Amazon S3中。", "enus": "Use AWS Lambda to read and aggregate the data hourly. Transform the data and store it in Amazon S3 by using Amazon Kinesis Data  Firehose."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Firehose每小时读取并聚合数据，通过临时搭建的Amazon EMR集群对数据进行转换后，存储至Amazon S3中。", "enus": "Use Amazon Kinesis Data Firehose to read and aggregate the data hourly. Transform the data and store it in Amazon S3 by using a  short-lived Amazon EMR cluster."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Analytics对数据进行每小时读取与聚合处理，并通过Amazon Kinesis Data Firehose转换数据格式后，将其存储至Amazon S3中。", "enus": "Use Amazon Kinesis Data Analytics to read and aggregate the data hourly. Transform the data and store it in Amazon S3 by using  Amazon Kinesis Data Firehose."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Firehose每小时读取并聚合数据，再通过AWS Lambda对数据进行转换后存储至Amazon S3。", "enus": "Use Amazon Kinesis Data Firehose to read and aggregate the data hourly. Transform the data and store it in Amazon S3 by using AWS  Lambda."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "274", "question": {"enus": "A medical device company is building a machine learning (ML) model to predict the likelihood of device recall based on customer data that the company collects from a plain text survey. One of the survey questions asks which medications the customer is taking. The data for this field contains the names of medications that customers enter manually. Customers misspell some of the medication names. The column that contains the medication name data gives a categorical feature with high cardinality but redundancy. What is the MOST effective way to encode this categorical feature into a numeric feature? ", "zhcn": "一家医疗器械公司正基于客户填写的纯文本调查数据，构建机器学习模型以预测设备召回概率。其中一项调查询问客户当前服用药物名称，该字段数据由客户手动输入，存在药品名称拼写错误的情况。这使得包含药物名称的数据列呈现高基数且存在冗余的分类特征。将此分类特征转化为数值特征时，最高效的编码方式是什么？"}, "option": [{"option_text": {"zhcn": "对该列进行拼写检查。采用亚马逊SageMaker独热编码技术，将分类特征转换为数值特征。", "enus": "Spell check the column. Use Amazon SageMaker one-hot encoding on the column to transform a categorical feature to a numerical  feature."}, "option_flag": false}, {"option_text": {"zhcn": "使用字符级循环神经网络修正该列拼写错误。借助亚马逊SageMaker数据整理工具中的独热编码技术，将分类特征转换为数值特征。", "enus": "Fix the spelling in the column by using char-RNN. Use Amazon SageMaker Data Wrangler one-hot encoding to transform a categorical  feature to a numerical feature."}, "option_flag": false}, {"option_text": {"zhcn": "对指定列采用Amazon SageMaker Data Wrangler的相似度编码技术，将其转化为实数向量形式的嵌入表示。", "enus": "Use Amazon SageMaker Data Wrangler similarity encoding on the column to create embeddings of vectors of real numbers."}, "option_flag": false}, {"option_text": {"zhcn": "对指定列采用Amazon SageMaker Data Wrangler序数编码方法，将分类数据转换为介于0到该列总分类数之间的整数值。", "enus": "Use Amazon SageMaker Data Wrangler ordinal encoding on the column to encode categories into an integer between 0 and the total  number of categories in the column."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "275", "question": {"enus": "A machine learning (ML) engineer has created a feature repository in Amazon SageMaker Feature Store for the company. The company has AWS accounts for development, integration, and production. The company hosts a feature store in the development account. The company uses Amazon S3 buckets to store feature values ofiine. The company wants to share features and to allow the integration account and the production account to reuse the features that are in the feature repository. Which combination of steps will meet these requirements? (Choose two.) ", "zhcn": "一位机器学习工程师在公司内部的Amazon SageMaker特征存储中创建了一个特征库。该公司分别设有开发、集成和生产环境的AWS账户，其中特征存储部署于开发账户，并采用Amazon S3存储桶离线保存特征值。现需实现特征共享功能，使集成账户与生产账户能够复用特征库中的特征。下列哪两项步骤组合可满足此需求？（请选择两项）"}, "option": [{"option_text": {"zhcn": "在开发账户中创建一个IAM角色，供集成账户和生产账户担任。为该角色附加IAM策略，允许其访问特征存储库和S3存储桶。", "enus": "Create an IAM role in the development account that the integration account and production account can assume. Attach IAM policies to  the role that allow access to the feature repository and the S3 buckets."}, "option_flag": true}, {"option_text": {"zhcn": "通过AWS资源访问管理器（AWS RAM），将开发账户中关联S3存储桶的特征库共享至集成账户与生产账户。", "enus": "Share the feature repository that is associated the S3 buckets from the development account to the integration account and the  production account by using AWS Resource Access Manager (AWS RAM)."}, "option_flag": false}, {"option_text": {"zhcn": "使用集成账户和生产账户中的AWS安全令牌服务（AWS STS）获取开发环境的访问凭证。", "enus": "Use AWS Security Token Service (AWS STS) from the integration account and the production account to retrieve credentials for the  development account."}, "option_flag": false}, {"option_text": {"zhcn": "在开发环境的S3存储桶与集成及生产环境的S3存储桶之间配置数据同步机制。", "enus": "Set up S3 replication between the development S3 buckets and the integration and production S3 buckets."}, "option_flag": true}, {"option_text": {"zhcn": "在开发账户中为 SageMaker 创建 AWS PrivateLink 端点。", "enus": "Create an AWS PrivateLink endpoint in the development account for SageMaker."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AD"}, {"id": "276", "question": {"enus": "A company is building a new supervised classification model in an AWS environment. The company's data science team notices that the dataset has a large quantity of variables. All the variables are numeric. The model accuracy for training and validation is low. The model's processing time is affected by high latency. The data science team needs to increase the accuracy of the model and decrease the processing time. What should the data science team do to meet these requirements? ", "zhcn": "某公司正在AWS云环境中构建一个新型监督分类模型。数据科学团队发现数据集包含大量数值型变量，但当前模型的训练与验证准确率均不理想，且因延迟过高导致处理时间过长。为提升模型精度并缩短处理时长，数据科学团队应采取哪些措施？"}, "option": [{"option_text": {"zhcn": "生成新特征并构建交互变量。", "enus": "Create new features and interaction variables."}, "option_flag": false}, {"option_text": {"zhcn": "采用主成分分析（PCA）模型。", "enus": "Use a principal component analysis (PCA) model."}, "option_flag": true}, {"option_text": {"zhcn": "对特征集进行归一化处理。", "enus": "Apply normalization on the feature set."}, "option_flag": false}, {"option_text": {"zhcn": "采用多重对应分析（MCA）模型。", "enus": "Use a multiple correspondence analysis (MCA) model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "277", "question": {"enus": "An exercise analytics company wants to predict running speeds for its customers by using a dataset that contains multiple health-related features for each customer. Some of the features originate from sensors that provide extremely noisy values. The company is training a regression model by using the built-in Amazon SageMaker linear learner algorithm to predict the running speeds. While the company is training the model, a data scientist observes that the training loss decreases to almost zero, but validation loss increases. Which technique should the data scientist use to optimally fit the model? ", "zhcn": "一家运动分析公司希望通过客户健康特征数据集预测其跑步速度，该数据集包含多项健康指标。其中部分指标来源于传感器，所采集的数据存在严重噪声干扰。该公司目前采用亚马逊SageMaker平台内置的线性学习算法训练回归模型，但在训练过程中，数据科学家发现训练损失值已趋近于零，验证损失值却持续上升。此时，数据科学家应采用何种技术手段以实现模型的最优拟合？"}, "option": [{"option_text": {"zhcn": "在线性学习器回归模型中引入L1正则化。", "enus": "Add L1 regularization to the linear learner regression model."}, "option_flag": false}, {"option_text": {"zhcn": "对数据集进行主成分分析（PCA），并采用线性学习器回归模型进行建模。", "enus": "Perform a principal component analysis (PCA) on the dataset. Use the linear learner regression model."}, "option_flag": false}, {"option_text": {"zhcn": "通过引入二次项与三次项进行特征工程，随后训练线性学习回归模型。", "enus": "Perform feature engineering by including quadratic and cubic terms. Train the linear learner regression model."}, "option_flag": true}, {"option_text": {"zhcn": "在线性回归学习模型中引入L2正则化。", "enus": "Add L2 regularization to the linear learner regression model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "278", "question": {"enus": "A company's machine learning (ML) specialist is building a computer vision model to classify 10 different trafic signs. The company has stored 100 images of each class in Amazon S3, and the company has another 10,000 unlabeled images. All the images come from dash cameras and are a size of 224 pixels × 224 pixels. After several training runs, the model is overfitting on the training data. Which actions should the ML specialist take to address this problem? (Choose two.) ", "zhcn": "某公司的机器学习专家正在构建一个计算机视觉模型，旨在对10种不同的交通标志进行分类。该公司已将每个类别的100张图像存储于Amazon S3中，同时还有10,000张未标注的图像。所有图像均采集自行车记录仪，尺寸为224像素×224像素。经过多次训练后，模型在训练数据上出现了过拟合现象。机器学习专家应采取哪两项措施来解决此问题？（请选择两项）"}, "option": [{"option_text": {"zhcn": "利用Amazon SageMaker Ground Truth对未标注图像进行智能标记。", "enus": "Use Amazon SageMaker Ground Truth to label the unlabeled images."}, "option_flag": false}, {"option_text": {"zhcn": "运用图像预处理技术将图片转换为灰度图像。", "enus": "Use image preprocessing to transform the images into grayscale images."}, "option_flag": false}, {"option_text": {"zhcn": "对标注图像进行旋转与平移的数据增强处理。", "enus": "Use data augmentation to rotate and translate the labeled images."}, "option_flag": false}, {"option_text": {"zhcn": "将最后一层的激活函数替换为S形函数。", "enus": "Replace the activation of the last layer with a sigmoid."}, "option_flag": true}, {"option_text": {"zhcn": "利用亚马逊SageMaker平台的k近邻（k-NN）算法，对未标注图像进行智能分类。", "enus": "Use the Amazon SageMaker k-nearest neighbors (k-NN) algorithm to label the unlabeled images."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "DE"}, {"id": "279", "question": {"enus": "A data science team is working with a tabular dataset that the team stores in Amazon S3. The team wants to experiment with different feature transformations such as categorical feature encoding. Then the team wants to visualize the resulting distribution of the dataset. After the team finds an appropriate set of feature transformations, the team wants to automate the workfiow for feature transformations. Which solution will meet these requirements with the MOST operational eficiency? ", "zhcn": "一支数据科学团队正在处理存储在Amazon S3中的表格数据集。团队需尝试多种特征变换方法（如分类特征编码），继而将变换后的数据分布进行可视化分析。在确定合适的特征变换组合后，团队希望将特征变换流程自动化。要同时满足这些需求且实现最高运营效率，下列哪种解决方案最为适宜？"}, "option": [{"option_text": {"zhcn": "利用Amazon SageMaker Data Wrangler预置的转换功能，可对特征变换进行探索分析。通过SageMaker Data Wrangler提供的可视化模板，实现数据特征的直观呈现。将特征处理工作流导出至SageMaker管道，即可实现全流程自动化部署。", "enus": "Use Amazon SageMaker Data Wrangler preconfigured transformations to explore feature transformations. Use SageMaker Data  Wrangler templates for visualization. Export the feature processing workfiow to a SageMaker pipeline for automation."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker笔记本实例进行多样化特征转换实验，将处理后的特征数据存储至Amazon S3。通过Amazon QuickSight实现可视化分析，并将特征处理流程封装为AWS Lambda函数以实现自动化运行。", "enus": "Use an Amazon SageMaker notebook instance to experiment with different feature transformations. Save the transformations to  Amazon S3. Use Amazon QuickSight for visualization. Package the feature processing steps into an AWS Lambda function for automation."}, "option_flag": false}, {"option_text": {"zhcn": "运用AWS Glue Studio结合自定义代码，尝试多种特征转换方案，并将转换结果存储至Amazon S3。通过Amazon QuickSight实现数据可视化，最后将特征处理流程封装至AWS Lambda函数，实现自动化运行。", "enus": "Use AWS Glue Studio with custom code to experiment with different feature transformations. Save the transformations to Amazon S3.  Use Amazon QuickSight for visualization. Package the feature processing steps into an AWS Lambda function for automation."}, "option_flag": true}, {"option_text": {"zhcn": "运用Amazon SageMaker Data Wrangler预置的数据转换功能，可灵活尝试多种特征转换方案。将转换后的数据存储至Amazon S3中，并通过Amazon QuickSight实现可视化呈现。每个特征转换环节应封装为独立的AWS Lambda函数，再借助AWS Step Functions实现工作流程的自动化编排。", "enus": "Use Amazon SageMaker Data Wrangler preconfigured transformations to experiment with different feature transformations. Save the  transformations to Amazon S3. Use Amazon QuickSight for visualization. Package each feature transformation step into a separate AWS  Lambda function. Use AWS Step Functions for workfiow automation."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "280", "question": {"enus": "A company plans to build a custom natural language processing (NLP) model to classify and prioritize user feedback. The company hosts the data and all machine learning (ML) infrastructure in the AWS Cloud. The ML team works from the company's ofice, which has an IPsec VPN connection to one VPC in the AWS Cloud. The company has set both the enableDnsHostnames attribute and the enableDnsSupport attribute of the VPC to true. The company's DNS resolvers point to the VPC DNS. The company does not allow the ML team to access Amazon SageMaker notebooks through connections that use the public internet. The connection must stay within a private network and within the AWS internal network. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "某公司计划构建一个定制化的自然语言处理模型，用于对用户反馈进行分类和优先级排序。该公司将所有数据及机器学习基础设施部署在AWS云平台，其机器学习团队通过IPsec VPN从公司办公室连接至AWS云内的某个虚拟私有云（VPC）。该VPC已同时开启DNS主机名支持与DNS解析支持功能，且公司DNS解析器指向VPC的DNS服务。公司要求机器学习团队不得通过公共互联网访问Amazon SageMaker笔记本，所有连接必须严格限定在私有网络及AWS内部网络环境中。在满足上述要求的前提下，以下哪种解决方案能最大限度降低开发复杂度？"}, "option": [{"option_text": {"zhcn": "在VPC内为SageMaker笔记本创建接口端点。通过VPN连接及VPC端点访问该笔记本。", "enus": "Create a VPC interface endpoint for the SageMaker notebook in the VPC. Access the notebook through a VPN connection and the VPC  endpoint."}, "option_flag": false}, {"option_text": {"zhcn": "在虚拟私有云（VPC）的公共子网中，通过亚马逊EC2实例构建堡垒主机。", "enus": "Create a bastion host by using Amazon EC2 in a public subnet within the VP"}, "option_flag": true}, {"option_text": {"zhcn": "通过VPN连接登录至堡垒主机，经由堡垒主机访问SageMaker笔记本。  \nC. 在配备NAT网关的VPC私有子网中，使用Amazon EC2创建堡垒主机。通过VPN连接登录堡垒主机后，即可从该主机访问SageMaker笔记本。", "enus": "Log in to the bastion host through a VPN connection.  Access the SageMaker notebook from the bastion host.  C. Create a bastion host by using Amazon EC2 in a private subnet within the VPC with a NAT gateway. Log in to the bastion host through a  VPN connection. Access the SageMaker notebook from the bastion host."}, "option_flag": false}, {"option_text": {"zhcn": "在该VPC中创建NAT网关。通过VPN连接及NAT网关访问SageMaker笔记本的HTTPS端点。", "enus": "Create a NAT gateway in the VPC. Access the SageMaker notebook HTTPS endpoint through a VPN connection and the NAT gateway."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "281", "question": {"enus": "A data scientist is using Amazon Comprehend to perform sentiment analysis on a dataset of one million social media posts. Which approach will process the dataset in the LEAST time? ", "zhcn": "一位数据科学家正借助Amazon Comprehend对百万条社交媒体帖子进行情感分析。下列哪种方案能以最短时间完成该数据集的处理？"}, "option": [{"option_text": {"zhcn": "采用AWS Step Functions与AWS Lambda函数相结合的方式，逐条同步调用DetectSentiment接口对帖子进行情感分析。", "enus": "Use a combination of AWS Step Functions and an AWS Lambda function to call the DetectSentiment API operation for each post  synchronously."}, "option_flag": false}, {"option_text": {"zhcn": "采用AWS Step Functions与AWS Lambda函数相结合的方式，每次调用BatchDetectSentiment API时可批量处理最多25条帖子。", "enus": "Use a combination of AWS Step Functions and an AWS Lambda function to call the BatchDetectSentiment API operation with batches of  up to 25 posts at a time."}, "option_flag": false}, {"option_text": {"zhcn": "将文章内容上传至亚马逊S3存储服务，随后将S3存储路径传递给调用StartSentimentDetectionJob接口的AWS Lambda函数。", "enus": "Upload the posts to Amazon S3. Pass the S3 storage path to an AWS Lambda function that calls the StartSentimentDetectionJob API  operation."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Lambda函数调用BatchDetectSentiment接口，对完整数据集进行情感分析。", "enus": "Use an AWS Lambda function to call the BatchDetectSentiment API operation with the whole dataset."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "282", "question": {"enus": "A machine learning (ML) specialist at a retail company must build a system to forecast the daily sales for one of the company's stores. The company provided the ML specialist with sales data for this store from the past 10 years. The historical dataset includes the total amount of sales on each day for the store. Approximately 10% of the days in the historical dataset are missing sales data. The ML specialist builds a forecasting model based on the historical dataset. The specialist discovers that the model does not meet the performance standards that the company requires. Which action will MOST likely improve the performance for the forecasting model? ", "zhcn": "某零售公司的机器学习专家需要构建一套系统，用于预测旗下某门店的每日销售额。公司向该专家提供了该门店过去十年的销售数据，这份历史数据集包含该门店每日销售总额，但其中约10%的日期存在数据缺失。基于此历史数据集，专家构建了预测模型，却发现模型未能达到公司要求的性能标准。下列哪项措施最有可能提升该预测模型的性能？"}, "option": [{"option_text": {"zhcn": "同一地理区域内各门店的销售总额。", "enus": "Aggregate sales from stores in the same geographic area."}, "option_flag": true}, {"option_text": {"zhcn": "对数据进行平滑处理以修正季节性波动。", "enus": "Apply smoothing to correct for seasonal variation."}, "option_flag": false}, {"option_text": {"zhcn": "将预测频率由每日调整为每周。", "enus": "Change the forecast frequency from daily to weekly."}, "option_flag": false}, {"option_text": {"zhcn": "采用线性插值法填补数据集中的缺失值。", "enus": "Replace missing values in the dataset by using linear interpolation."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "283", "question": {"enus": "A mining company wants to use machine learning (ML) models to identify mineral images in real time. A data science team built an image recognition model that is based on convolutional neural network (CNN). The team trained the model on Amazon SageMaker by using GPU instances. The team will deploy the model to a SageMaker endpoint. The data science team already knows the workload trafic patterns. The team must determine instance type and configuration for the workloads. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "一家矿业公司希望运用机器学习模型实时识别矿物图像。某数据科学团队基于卷积神经网络开发了图像识别模型，并借助GPU实例在Amazon SageMaker平台上完成了模型训练。团队计划将该模型部署至SageMaker终端节点。鉴于已掌握工作负载的流量规律，团队需为运算任务确定最合适的实例类型与配置方案。在满足所有需求的前提下，何种解决方案能最大程度降低开发投入？"}, "option": [{"option_text": {"zhcn": "将模型制品及容器注册至SageMaker模型注册库。选用SageMaker推理推荐器的默认任务类型。通过提供已知流量模式进行负载测试，从而根据工作负载筛选最优实例类型与配置方案。", "enus": "Register the model artifact and container to the SageMaker Model Registry. Use the SageMaker Inference Recommender Default job  type. Provide the known trafic pattern for load testing to select the best instance type and configuration based on the workloads."}, "option_flag": false}, {"option_text": {"zhcn": "将模型制品及相关容器注册至SageMaker模型注册库。选用SageMaker推理推荐器的高级任务模式，并提交已知流量模式以进行负载测试，从而根据实际工作负载筛选最优实例类型与配置方案。", "enus": "Register the model artifact and container to the SageMaker Model Registry. Use the SageMaker Inference Recommender Advanced job  type. Provide the known trafic pattern for load testing to select the best instance type and configuration based on the workloads."}, "option_flag": true}, {"option_text": {"zhcn": "将模型部署至基于GPU实例的终端节点。利用AWS Lambda与Amazon API Gateway处理来自网络的调用请求，并借助开源工具对终端节点进行负载测试，以选定最优实例类型与配置方案。", "enus": "Deploy the model to an endpoint by using GPU instances. Use AWS Lambda and Amazon API Gateway to handle invocations from the  web. Use open-source tools to perform load testing against the endpoint and to select the best instance type and configuration."}, "option_flag": false}, {"option_text": {"zhcn": "使用CPU实例将模型部署至服务终端。通过AWS Lambda与Amazon API Gateway处理来自网络的调用请求，并借助开源工具对终端进行负载测试，以选定最优实例类型与配置方案。", "enus": "Deploy the model to an endpoint by using CPU instances. Use AWS Lambda and Amazon API Gateway to handle invocations from the  web. Use open-source tools to perform load testing against the endpoint and to select the best instance type and configuration."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "284", "question": {"enus": "A company is building custom deep learning models in Amazon SageMaker by using training and inference containers that run on Amazon EC2 instances. The company wants to reduce training costs but does not want to change the current architecture. The SageMaker training job can finish after interruptions. The company can wait days for the results. Which combination of resources should the company use to meet these requirements MOST cost-effectively? (Choose two.) ", "zhcn": "某公司正通过运行在亚马逊EC2实例上的训练与推理容器，在Amazon SageMaker中构建定制深度学习模型。公司希望降低训练成本，但需维持现有架构不变。当前SageMaker训练任务在中断后仍可完成，且公司能够接受数日的结果等待周期。要最高性价比地满足这些需求，应选择哪两种资源组合？（请选择两项）"}, "option": [{"option_text": {"zhcn": "按需实例", "enus": "On-Demand Instances"}, "option_flag": false}, {"option_text": {"zhcn": "检查点", "enus": "Checkpoints"}, "option_flag": false}, {"option_text": {"zhcn": "预留实例", "enus": "Reserved Instances"}, "option_flag": true}, {"option_text": {"zhcn": "渐进式训练", "enus": "Incremental training"}, "option_flag": false}, {"option_text": {"zhcn": "竞价实例", "enus": "Spot instances"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "CE"}, {"id": "285", "question": {"enus": "A company hosts a public web application on AWS. The application provides a user feedback feature that consists of free-text fields where users can submit text to provide feedback. The company receives a large amount of free-text user feedback from the online web application. The product managers at the company classify the feedback into a set of fixed categories including user interface issues, performance issues, new feature request, and chat issues for further actions by the company's engineering teams. A machine learning (ML) engineer at the company must automate the classification of new user feedback into these fixed categories by using Amazon SageMaker. A large set of accurate data is available from the historical user feedback that the product managers previously classified. Which solution should the ML engineer apply to perform multi-class text classification of the user feedback? ", "zhcn": "一家公司在AWS上托管了一款公共网络应用程序。该应用程序设有一个用户反馈功能，包含自由文本字段供用户提交反馈意见。公司通过这款在线网络应用接收到大量自由文本形式的用户反馈。公司的产品经理将这些反馈按固定类别进行分类，包括界面问题、性能问题、新功能请求和聊天问题，以便工程团队后续处理。公司的一位机器学习工程师需要利用Amazon SageMaker服务，将新增用户反馈自动归类至这些固定类别。目前已有大量由产品经理预先分类过的历史用户反馈数据可供使用。针对用户反馈的多类别文本分类需求，这位机器学习工程师应当采用何种解决方案？"}, "option": [{"option_text": {"zhcn": "使用SageMaker平台的隐含狄利克雷分布（LDA）算法。", "enus": "Use the SageMaker Latent Dirichlet Allocation (LDA) algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "请使用SageMaker BlazingText算法。", "enus": "Use the SageMaker BlazingText algorithm."}, "option_flag": true}, {"option_text": {"zhcn": "请使用SageMaker神经主题模型（NTM）算法。", "enus": "Use the SageMaker Neural Topic Model (NTM) algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "请使用 SageMaker CatBoost 算法。", "enus": "Use the SageMaker CatBoost algorithm."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "286", "question": {"enus": "A digital media company wants to build a customer churn prediction model by using tabular data. The model should clearly indicate whether a customer will stop using the company's services. The company wants to clean the data because the data contains some empty fields, duplicate values, and rare values. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "一家数字媒体公司计划利用表格数据构建客户流失预测模型。该模型需明确显示客户是否会停止使用公司服务。由于数据中存在部分空白字段、重复值及罕见数值，公司需要对数据进行清洗。哪种方案能够以最小的开发量满足这些需求？"}, "option": [{"option_text": {"zhcn": "利用SageMaker Canvas自动完成数据清洗工作，并构建分类模型。", "enus": "Use SageMaker Canvas to automatically clean the data and to prepare a categorical model."}, "option_flag": true}, {"option_text": {"zhcn": "利用SageMaker Data Wrangler进行数据清洗，并借助内置的SageMaker XGBoost算法训练分类模型。", "enus": "Use SageMaker Data Wrangler to clean the data. Use the built-in SageMaker XGBoost algorithm to train a classification model."}, "option_flag": false}, {"option_text": {"zhcn": "运用SageMaker Canvas的自动化数据清洗与整理工具，通过内置的SageMaker XGBoost算法训练回归模型。", "enus": "Use SageMaker Canvas automatic data cleaning and preparation tools. Use the built-in SageMaker XGBoost algorithm to train a  regression model."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Data Wrangler进行数据清洗，并通过SageMaker Autopilot训练回归模型。", "enus": "Use SageMaker Data Wrangler to clean the data. Use the SageMaker Autopilot to train a regression model"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "287", "question": {"enus": "A data engineer is evaluating customer data in Amazon SageMaker Data Wrangler. The data engineer will use the customer data to create a new model to predict customer behavior. The engineer needs to increase the model performance by checking for multicollinearity in the dataset. Which steps can the data engineer take to accomplish this with the LEAST operational effort? (Choose two.) ", "zhcn": "一位数据工程师正在亚马逊SageMaker数据整理平台中评估客户数据。该工程师计划利用这些客户数据构建预测用户行为的新模型。为提升模型性能，需检测数据集中的多重共线性现象。以下哪两项措施能以最小操作量实现此目标？（请选择两项）"}, "option": [{"option_text": {"zhcn": "利用SageMaker Data Wrangler对数据集进行重构与转换，通过对分类变量实施独热编码处理。", "enus": "Use SageMaker Data Wrangler to refit and transform the dataset by applying one-hot encoding to category-based variables."}, "option_flag": true}, {"option_text": {"zhcn": "运用SageMaker Data Wrangler的诊断可视化功能，通过主成分分析（PCA）与奇异值分解（SVD）方法计算奇异值。", "enus": "Use SageMaker Data Wrangler diagnostic visualization. Use principal components analysis (PCA) and singular value decomposition  (SVD) to calculate singular values."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Data Wrangler的快速模型可视化功能，可迅速评估数据集并生成各特征的重要性评分。", "enus": "Use the SageMaker Data Wrangler Quick Model visualization to quickly evaluate the dataset and to produce importance scores for each  feature."}, "option_flag": false}, {"option_text": {"zhcn": "使用SageMaker Data Wrangler的最小最大缩放器转换功能对数据进行归一化处理。", "enus": "Use the SageMaker Data Wrangler Min Max Scaler transform to normalize the data."}, "option_flag": false}, {"option_text": {"zhcn": "使用SageMaker Data Wrangler的诊断可视化功能。通过最小绝对值收敛选择算子（LASSO）算法，对基于该数据集训练的LASSO模型绘制系数值分布图。", "enus": "Use SageMaker Data Wrangler diagnostic visualization. Use least absolute shrinkage and selection operator (LASSO) to plot coeficient  values from a LASSO model that is trained on the dataset."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AE"}, {"id": "288", "question": {"enus": "A company processes millions of orders every day. The company uses Amazon DynamoDB tables to store order information. When customers submit new orders, the new orders are immediately added to the DynamoDB tables. New orders arrive in the DynamoDB tables continuously. A data scientist must build a peak-time prediction solution. The data scientist must also create an Amazon QuickSight dashboard to display near real-time order insights. The data scientist needs to build a solution that will give QuickSight access to the data as soon as new order information arrives. Which solution will meet these requirements with the LEAST delay between when a new order is processed and when QuickSight can access the new order information? ", "zhcn": "一家公司每日需处理数百万笔订单。该公司采用Amazon DynamoDB数据表存储订单信息。当客户提交新订单时，这些订单会即时录入DynamoDB数据表中。新订单数据持续不断地流入DynamoDB数据表。数据科学家需要构建一套高峰时段预测方案，同时创建Amazon QuickSight仪表板以呈现近实时订单洞察。该方案需确保QuickSight能在新订单数据录入后立即获取信息。请问在满足以下条件的前提下，哪种方案能最大程度缩短新订单处理完成与QuickSight获取新订单信息之间的延迟？"}, "option": [{"option_text": {"zhcn": "使用AWS Glue将数据从Amazon DynamoDB导出至Amazon S3，并配置QuickSight以访问Amazon S3中的数据。", "enus": "Use AWS Glue to export the data from Amazon DynamoDB to Amazon S3. Configure QuickSight to access the data in Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Streams将Amazon DynamoDB中的数据导出至Amazon S3，并配置QuickSight以访问Amazon S3内的数据。", "enus": "Use Amazon Kinesis Data Streams to export the data from Amazon DynamoDB to Amazon S3. Configure QuickSight to access the data  in Amazon S3."}, "option_flag": true}, {"option_text": {"zhcn": "借助 QuickSight 的 API 接口，可直接调用存储在 Amazon DynamoDB 中的数据。", "enus": "Use an API call from QuickSight to access the data that is in Amazon DynamoDB directly."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Kinesis Data Firehose将Amazon DynamoDB中的数据导出至Amazon S3存储服务，并配置QuickSight数据分析工具以访问Amazon S3内的数据资源。", "enus": "Use Amazon Kinesis Data Firehose to export the data from Amazon DynamoDB to Amazon S3. Configure QuickSight to access the data  in Amazon S3."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "289", "question": {"enus": "A data engineer is preparing a dataset that a retail company will use to predict the number of visitors to stores. The data engineer created an Amazon S3 bucket. The engineer subscribed the S3 bucket to an AWS Data Exchange data product for general economic indicators. The data engineer wants to join the economic indicator data to an existing table in Amazon Athena to merge with the business data. All these transformations must finish running in 30-60 minutes. Which solution will meet these requirements MOST cost-effectively? ", "zhcn": "一位数据工程师正在为某零售公司准备用于预测门店客流量的数据集。该工程师创建了一个Amazon S3存储桶，并为其订阅了AWS Data Exchange中关于通用经济指标的数据产品。现需将经济指标数据与Amazon Athena内现有业务数据表进行关联整合，且所有数据转换操作必须在30-60分钟内完成。下列哪种解决方案能以最具成本效益的方式满足这些需求？"}, "option": [{"option_text": {"zhcn": "将AWS Data Exchange产品配置为Amazon Kinesis数据流的生产源，通过Amazon Kinesis Data Firehose传输流将数据实时输送至Amazon S3存储桶。随后运行AWS Glue作业，将既有业务数据与Athena数据表进行整合处理，最终将处理结果回写至Amazon S3。", "enus": "Configure the AWS Data Exchange product as a producer for an Amazon Kinesis data stream. Use an Amazon Kinesis Data Firehose  delivery stream to transfer the data to Amazon S3. Run an AWS Glue job that will merge the existing business data with the Athena table.  Write the result set back to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在AWS Data Exchange S3存储桶上配置S3事件以触发AWS Lambda函数。通过Lambda函数调用Amazon SageMaker Data Wrangler，将现有业务数据与Athena数据表进行整合处理，并将最终结果集回传至Amazon S3存储空间。", "enus": "Use an S3 event on the AWS Data Exchange S3 bucket to invoke an AWS Lambda function. Program the Lambda function to use Amazon  SageMaker Data Wrangler to merge the existing business data with the Athena table. Write the result set back to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "在AWS Data Exchange S3存储桶上配置S3事件以触发AWS Lambda函数。通过Lambda函数调用AWS Glue作业，将现有业务数据与Athena表进行整合，最终将处理结果回传至Amazon S3。", "enus": "Use an S3 event on the AWS Data Exchange S3 bucket to invoke an AWS Lambda function. Program the Lambda function to run an AWS  Glue job that will merge the existing business data with the Athena table. Write the results back to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "部署一套Amazon Redshift集群，订阅AWS Data Exchange服务并利用该服务创建Amazon Redshift数据表。在Redshift中完成数据整合处理，最终将处理结果回传至Amazon S3存储空间。", "enus": "Provision an Amazon Redshift cluster. Subscribe to the AWS Data Exchange product and use the product to create an Amazon Redshift  table. Merge the data in Amazon Redshift. Write the results back to Amazon S3."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "290", "question": {"enus": "A company operates large cranes at a busy port The company plans to use machine learning (ML) for predictive maintenance of the cranes to avoid unexpected breakdowns and to improve productivity. The company already uses sensor data from each crane to monitor the health of the cranes in real time. The sensor data includes rotation speed, tension, energy consumption, vibration, pressure, and temperature for each crane. The company contracts AWS ML experts to implement an ML solution. Which potential findings would indicate that an ML-based solution is suitable for this scenario? (Choose two.) ", "zhcn": "某公司在繁忙港口运营大型起重机，计划采用机器学习技术实施预测性维护，以期避免意外停机并提升作业效率。目前公司已通过每台起重机的传感器数据实时监测设备运行状态，采集指标包括旋转速度、张力、能耗、振动、压力及温度等。现聘请AWS机器学习专家部署解决方案。下列哪两项潜在发现可表明该场景适合采用基于机器学习的解决方案？（请选择两项）"}, "option": [{"option_text": {"zhcn": "特定时段的历史传感器数据在数据点数量与属性维度上均存在显著缺失。", "enus": "The historical sensor data does not include a significant number of data points and attributes for certain time periods."}, "option_flag": true}, {"option_text": {"zhcn": "历史传感器数据表明，基于规则的简单阈值设定即可预测起重机故障。", "enus": "The historical sensor data shows that simple rule-based thresholds can predict crane failures."}, "option_flag": false}, {"option_text": {"zhcn": "现有历史传感器数据仅涵盖一种在役起重机型号的故障记录，而多数其他在役起重机类型的故障数据尚属空白。", "enus": "The historical sensor data contains failure data for only one type of crane model that is in operation and lacks failure data of most  other types of crane that are in operation."}, "option_flag": false}, {"option_text": {"zhcn": "过去三年间，起重机的历史传感器数据均以精细粒度完整记录在册。", "enus": "The historical sensor data from the cranes are available with high granularity for the last 3 years."}, "option_flag": true}, {"option_text": {"zhcn": "历史传感器数据涵盖了该公司希望预测的大部分常见起重机故障类型。", "enus": "The historical sensor data contains most common types of crane failures that the company wants to predict."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AD"}, {"id": "291", "question": {"enus": "A company wants to create an artificial intelligence (AШ) yoga instructor that can lead large classes of students. The company needs to create a feature that can accurately count the number of students who are in a class. The company also needs a feature that can differentiate students who are performing a yoga stretch correctly from students who are performing a stretch incorrectly. Determine whether students are performing a stretch correctly, the solution needs to measure the location and angle of each student’s arms and legs. A data scientist must use Amazon SageMaker to access video footage of a yoga class by extracting image frames and applying computer vision models. Which combination of models will meet these requirements with the LEAST effort? (Choose two.) ", "zhcn": "一家公司计划开发人工智能瑜伽教练系统，用于指导大规模团体课程。该系统需具备两项核心功能：一是精确统计课堂学员人数，二是能准确区分学员的瑜伽伸展动作是否标准。为实现动作标准度判定，解决方案需测量每位学员四肢的位置与角度数据。数据科学家需利用Amazon SageMaker平台，通过提取视频图像帧并应用计算机视觉模型来处理瑜伽课堂录像。为以最小工作量满足上述需求，应选择哪两种模型组合？（请选择两项）"}, "option": [{"option_text": {"zhcn": "图像分类", "enus": "Image Classification"}, "option_flag": true}, {"option_text": {"zhcn": "光学字符识别（OCR）", "enus": "Optical Character Recognition (OCR)"}, "option_flag": false}, {"option_text": {"zhcn": "目标检测", "enus": "Object Detection"}, "option_flag": false}, {"option_text": {"zhcn": "姿态估计", "enus": "Pose estimation"}, "option_flag": false}, {"option_text": {"zhcn": "图像生成对抗网络（GANs）", "enus": "Image Generative Adversarial Networks (GANs)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "292", "question": {"enus": "An ecommerce company has used Amazon SageMaker to deploy a factorization machines (FM) model to suggest products for customers. The company’s data science team has developed two new models by using the TensorFlow and PyTorch deep learning frameworks. The company needs to use A/B testing to evaluate the new models against the deployed model. The required A/B testing setup is as follows: • Send 70% of trafic to the FM model, 15% of trafic to the TensorFlow model, and 15% of trafic to the PyTorch model. • For customers who are from Europe, send all trafic to the TensorFlow model. Which architecture can the company use to implement the required A/B testing setup? ", "zhcn": "一家电商公司目前正运用Amazon SageMaker平台部署了因子分解机（FM）模型，用于向客户推荐商品。该公司的数据科学团队近期基于TensorFlow和PyTorch两种深度学习框架，开发了两款全新模型。现需通过A/B测试将新模型与已部署模型进行效果评估，具体要求如下：  \n• 将70%的流量分配至FM模型，TensorFlow模型与PyTorch模型各获得15%的流量；  \n• 对欧洲地区用户，全部流量定向至TensorFlow模型。  \n请问该公司可采用何种架构方案实现此A/B测试需求？"}, "option": [{"option_text": {"zhcn": "在现有SageMaker端点基础上，为TensorFlow和PyTorch模型分别创建两个新的SageMaker端点。部署一个应用负载均衡器，并为每个端点创建对应的目标群组。配置监听器规则并为各目标群组设置流量权重。针对欧洲地区用户，需额外设置监听器规则，将其访问流量定向至TensorFlow模型对应的目标群组。", "enus": "Create two new SageMaker endpoints for the TensorFlow and PyTorch models in addition to the existing SageMaker endpoint. Create  an Application Load Balancer. Create a target group for each endpoint. Configure listener rules and add weight to the target groups. To  send trafic to the TensorFlow model for customers who are from Europe, create an additional listener rule to forward trafic to the  TensorFlow target group."}, "option_flag": false}, {"option_text": {"zhcn": "为TensorFlow与PyTorch模型分别创建两个生产版本。配置自动扩缩策略并设定流量分配权重，以引导请求分发至各生产版本。将自动扩缩策略应用于现有SageMaker端点的更新。针对欧洲地区用户，需在请求中设置TargetVariant头部，将其指向TensorFlow模型对应的版本名称以实现定向流量分发。", "enus": "Create two production variants for the TensorFlow and PyTorch models. Create an auto scaling policy and configure the desired A/B  weights to direct trafic to each production variant. Update the existing SageMaker endpoint with the auto scaling policy. To send trafic to  the TensorFlow model for customers who are from Europe, set the TargetVariant header in the request to point to the variant name of the  TensorFlow model."}, "option_flag": false}, {"option_text": {"zhcn": "在为现有SageMaker端点提供服务的基础上，需为TensorFlow与PyTorch模型分别创建新的SageMaker端点。随后部署网络负载均衡器，并为每个端点创建对应目标组。通过配置监听器规则为各目标组分配流量权重。针对欧洲地区用户，需专门增设监听器规则，将其访问请求定向至TensorFlow模型对应的目标组。", "enus": "Create two new SageMaker endpoints for the TensorFlow and PyTorch models in addition to the existing SageMaker endpoint. Create a  Network Load Balancer. Create a target group for each endpoint. Configure listener rules and add weight to the target groups. To send  trafic to the TensorFlow model for customers who are from Europe, create an additional listener rule to forward trafic to the TensorFlow  target group."}, "option_flag": false}, {"option_text": {"zhcn": "为TensorFlow与PyTorch模型分别创建两个生产版本。在SageMaker端点配置中指定各生产版本的流量分配权重，并依据新配置更新现有SageMaker端点。针对欧洲地区用户，需在请求中设置TargetVariant头部指向TensorFlow模型对应的版本名称，以确保流量定向至该模型。", "enus": "Create two production variants for the TensorFlow and PyTorch models. Specify the weight for each production variant in the  SageMaker endpoint configuration. Update the existing SageMaker endpoint with the new configuration. To send trafic to the TensorFlow  model for customers who are from Europe, set the TargetVariant header in the request to point to the variant name of the TensorFlow  model."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "293", "question": {"enus": "A data scientist stores financial datasets in Amazon S3. The data scientist uses Amazon Athena to query the datasets by using SQL. The data scientist uses Amazon SageMaker to deploy a machine learning (ML) model. The data scientist wants to obtain inferences from the model at the SageMaker endpoint. However, when the data scientist attempts to invoke the SageMaker endpoint, the data scientist receives SQL statement failures. The data scientist’s IAM user is currently unable to invoke the SageMaker endpoint. Which combination of actions will give the data scientist’s IAM user the ability to invoke the SageMaker endpoint? (Choose three.) ", "zhcn": "一位数据科学家将金融数据集存储于Amazon S3中，并借助SQL语言通过Amazon Athena对这些数据集进行查询。随后，该科学家使用Amazon SageMaker部署了一套机器学习模型，并期望通过SageMaker端点从模型中获取推断结果。然而，在尝试调用SageMaker端点时，却出现了SQL语句执行失败的问题。目前，该数据科学家的IAM用户权限尚无法成功调用SageMaker端点。请问需要采取哪三项组合措施，方可赋予该IAM用户调用SageMaker端点的权限？（请选择三项。）"}, "option": [{"option_text": {"zhcn": "为该用户身份附加AmazonAthenaFullAccess这一AWS托管策略。", "enus": "Attach the AmazonAthenaFullAccess AWS managed policy to the user identity."}, "option_flag": false}, {"option_text": {"zhcn": "为数据科学家的IAM用户添加一项策略声明，允许该用户执行sagemaker:InvokeEndpoint操作。", "enus": "Include a policy statement for the data scientist's IAM user that allows the IAM user to perform the sagemaker:InvokeEndpoint action."}, "option_flag": false}, {"option_text": {"zhcn": "为数据科学家的IAM用户添加内联策略，使其能够通过SageMaker读取S3存储桶中的对象。", "enus": "Include an inline policy for the data scientist’s IAM user that allows SageMaker to read S3 objects."}, "option_flag": false}, {"option_text": {"zhcn": "为数据科学家的IAM用户添加策略声明，允许该IAM用户执行sagemaker:GetRecord操作。", "enus": "Include a policy statement for the data scientist’s IAM user that allows the IAM user to perform the sagemaker:GetRecord action."}, "option_flag": true}, {"option_text": {"zhcn": "在Athena SQL查询中需加入以下SQL语句：\"USING EXTERNAL FUNCTION ml_function_name\"。", "enus": "Include the SQL statement \"USING EXTERNAL FUNCTION ml_function_name'' in the Athena SQL query."}, "option_flag": false}, {"option_text": {"zhcn": "在SageMaker中执行用户重映射，将当前IAM用户关联至托管终端节点上的另一IAM用户。", "enus": "Perform a user remapping in SageMaker to map the IAM user to another IAM user that is on the hosted endpoint."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "294", "question": {"enus": "A data scientist is building a linear regression model. The scientist inspects the dataset and notices that the mode of the distribution is lower than the median, and the median is lower than the mean. Which data transformation will give the data scientist the ability to apply a linear regression model? ", "zhcn": "一位数据科学家正在构建线性回归模型。在检查数据集时，他发现数据分布的众数低于中位数，而中位数又低于均值。哪种数据变换方法能让这位科学家成功应用线性回归模型？"}, "option": [{"option_text": {"zhcn": "指数级蜕变", "enus": "Exponential transformation"}, "option_flag": false}, {"option_text": {"zhcn": "对数变换", "enus": "Logarithmic transformation"}, "option_flag": false}, {"option_text": {"zhcn": "多项式变换", "enus": "Polynomial transformation"}, "option_flag": false}, {"option_text": {"zhcn": "正弦变换", "enus": "Sinusoidal transformation"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "295", "question": {"enus": "A data scientist receives a collection of insurance claim records. Each record includes a claim ID. the final outcome of the insurance claim, and the date of the final outcome. The final outcome of each claim is a selection from among 200 outcome categories. Some claim records include only partial information. However, incomplete claim records include only 3 or 4 outcome categories from among the 200 available outcome categories. The collection includes hundreds of records for each outcome category. The records are from the previous 3 years. The data scientist must create a solution to predict the number of claims that will be in each outcome category every month, several months in advance. Which solution will meet these requirements? ", "zhcn": "一位数据科学家收到一组保险理赔记录。每份记录包含理赔编号、理赔最终结果及其确定日期。每项理赔的最终结果均从200种分类中选定。部分记录存在信息缺失，但残缺记录仅涉及200个分类中的3至4种结果类别。该数据集收录了过去三年的记录，每个结果类别下均有数百条数据。数据科学家需要构建一个预测模型，能够提前数月精准预测每月各分类下的理赔数量。何种解决方案可满足这些要求？"}, "option": [{"option_text": {"zhcn": "每月依据理赔内容，通过监督学习方式对200项结果类别进行分类处理。", "enus": "Perform classification every month by using supervised learning of the 200 outcome categories based on claim contents."}, "option_flag": false}, {"option_text": {"zhcn": "利用理赔编号与日期信息开展强化学习，指导提交理赔记录的保险代理人按月预估各结果分类项的预期理赔数量。", "enus": "Perform reinforcement learning by using claim IDs and dates. Instruct the insurance agents who submit the claim records to estimate  the expected number of claims in each outcome category every month."}, "option_flag": false}, {"option_text": {"zhcn": "通过索赔编号与日期进行预测，以确定每月各结果类别中的预期索赔数量。", "enus": "Perform forecasting by using claim IDs and dates to identify the expected number of claims in each outcome category every month."}, "option_flag": true}, {"option_text": {"zhcn": "对已提供部分索赔内容信息的赔付类别，采用监督学习进行分类预测；对其余类别的赔付结果，则依据索赔编号与日期进行趋势推演。", "enus": "Perform classification by using supervised learning of the outcome categories for which partial information on claim contents is  provided. Perform forecasting by using claim IDs and dates for all other outcome categories."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "296", "question": {"enus": "A retail company stores 100 GB of daily transactional data in Amazon S3 at periodic intervals. The company wants to identify the schema of the transactional data. The company also wants to perform transformations on the transactional data that is in Amazon S3. The company wants to use a machine learning (ML) approach to detect fraud in the transformed data. Which combination of solutions will meet these requirements with the LEAST operational overhead? (Choose three.) ", "zhcn": "一家零售企业定期将每日100 GB的交易数据存储于亚马逊S3中。该公司需要明确这些交易数据的结构模式，并对其中的数据进行转换处理。此外，企业还希望采用机器学习方法，在转换后的数据中实现欺诈行为检测。若要同时满足这些需求且将运维负担降至最低，应选择哪三种解决方案的组合？（请选出三项。）"}, "option": [{"option_text": {"zhcn": "利用Amazon Athena对数据进行扫描并解析其结构。", "enus": "Use Amazon Athena to scan the data and identify the schema."}, "option_flag": false}, {"option_text": {"zhcn": "借助AWS Glue爬虫程序自动扫描数据并智能识别其结构模式。", "enus": "Use AWS Glue crawlers to scan the data and identify the schema."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Redshift存储过程，实现数据转换处理。", "enus": "Use Amazon Redshift to store procedures to perform data transformations."}, "option_flag": false}, {"option_text": {"zhcn": "借助AWS Glue工作流与作业功能，实现数据转换处理。", "enus": "Use AWS Glue workfiows and AWS Glue jobs to perform data transformations."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Redshift ML训练模型以识别欺诈行为。", "enus": "Use Amazon Redshift ML to train a model to detect fraud."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Fraud Detector训练模型以识别欺诈行为。", "enus": "Use Amazon Fraud Detector to train a model to detect fraud."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BDF"}, {"id": "297", "question": {"enus": "A data scientist uses Amazon SageMaker Data Wrangler to define and perform transformations and feature engineering on historical data. The data scientist saves the transformations to SageMaker Feature Store. The historical data is periodically uploaded to an Amazon S3 bucket. The data scientist needs to transform the new historic data and add it to the online feature store. The data scientist needs to prepare the new historic data for training and inference by using native integrations. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "一位数据科学家借助Amazon SageMaker Data Wrangler对历史数据进行转换与特征工程定义，并将转换流程保存至SageMaker Feature Store。历史数据会定期上传至亚马逊S3存储桶。该科学家需对新入库的历史数据实施相同转换，并将其添加入线特征库，同时通过原生集成功能为模型训练与推理准备数据。要满足上述需求且最大限度降低开发工作量，应当采用何种解决方案？"}, "option": [{"option_text": {"zhcn": "利用AWS Lambda触发预设的SageMaker流程，对每份上传至S3存储桶的新数据集自动执行转换操作。", "enus": "Use AWS Lambda to run a predefined SageMaker pipeline to perform the transformations on each new dataset that arrives in the S3  bucket."}, "option_flag": false}, {"option_text": {"zhcn": "每当S3存储桶中有新的数据集抵达时，系统将自动执行AWS Step Functions工作流步骤，并调用预定义的SageMaker管道来完成数据转换处理。", "enus": "Run an AWS Step Functions step and a predefined SageMaker pipeline to perform the transformations on each new dataset that arrives  in the S3 bucket."}, "option_flag": false}, {"option_text": {"zhcn": "利用Apache Airflow对传入S3存储桶的每个新数据集执行一系列预定义的数据转换流程编排。", "enus": "Use Apache Airfiow to orchestrate a set of predefined transformations on each new dataset that arrives in the S3 bucket."}, "option_flag": true}, {"option_text": {"zhcn": "当检测到S3存储桶中出现新数据时，配置Amazon EventBridge以运行预定义的SageMaker管道来执行数据转换操作。", "enus": "Configure Amazon EventBridge to run a predefined SageMaker pipeline to perform the transformations when a new data is detected in  the S3 bucket."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "298", "question": {"enus": "An insurance company developed a new experimental machine learning (ML) model to replace an existing model that is in production. The company must validate the quality of predictions from the new experimental model in a production environment before the company uses the new experimental model to serve general user requests. New one model can serve user requests at a time. The company must measure the performance of the new experimental model without affecting the current live trafic. Which solution will meet these requirements? ", "zhcn": "一家保险公司研发出一款全新的实验性机器学习模型，旨在替代当前投入生产的现有模型。在将该实验模型正式用于处理常规用户请求之前，公司需在生产环境中验证其预测质量。系统每次仅能启用一个模型处理用户请求。公司必须在不影响现有实时流量的前提下，评估新实验模型的性能表现。何种解决方案可满足上述需求？"}, "option": [{"option_text": {"zhcn": "A/B 测试", "enus": "A/B testing"}, "option_flag": false}, {"option_text": {"zhcn": "金丝雀发布", "enus": "Canary release"}, "option_flag": false}, {"option_text": {"zhcn": "暗影部署", "enus": "Shadow deployment"}, "option_flag": false}, {"option_text": {"zhcn": "蓝绿部署", "enus": "Blue/green deployment"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "299", "question": {"enus": "A company deployed a machine learning (ML) model on the company website to predict real estate prices. Several months after deployment, an ML engineer notices that the accuracy of the model has gradually decreased. The ML engineer needs to improve the accuracy of the model. The engineer also needs to receive notifications for any future performance issues. Which solution will meet these requirements? ", "zhcn": "某公司在官方网站部署了一套机器学习模型，用于预测房地产价格。上线数月后，机器学习工程师发现模型预测准确度逐渐下降。该工程师需提升模型精度，同时建立未来性能异常的自动通知机制。请问下列哪种方案能同时满足这些需求？"}, "option": [{"option_text": {"zhcn": "对模型进行增量训练以完成更新。启用亚马逊SageMaker模型监控功能，以便检测模型性能问题并发送通知。", "enus": "Perform incremental training to update the model. Activate Amazon SageMaker Model Monitor to detect model performance issues and  to send notifications."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon SageMaker模型治理功能。通过配置模型治理自动调整模型超参数。在Amazon CloudWatch中创建性能阈值告警以便发送通知。", "enus": "Use Amazon SageMaker Model Governance. Configure Model Governance to automatically adjust model hyperparameters. Create a  performance threshold alarm in Amazon CloudWatch to send notifications."}, "option_flag": false}, {"option_text": {"zhcn": "合理设定阈值以启用Amazon SageMaker Debugger，配置调试器向团队发送Amazon CloudWatch警报。仅采用过去数月的数据对模型进行重新训练。", "enus": "Use Amazon SageMaker Debugger with appropriate thresholds. Configure Debugger to send Amazon CloudWatch alarms to alert the  team. Retrain the model by using only data from the previous several months."}, "option_flag": true}, {"option_text": {"zhcn": "仅采用近数月的数据进行增量训练，以完成模型迭代更新。通过亚马逊SageMaker模型监测平台及时侦测模型性能异常，并自动发送预警通知。", "enus": "Use only data from the previous several months to perform incremental training to update the model. Use Amazon SageMaker Model  Monitor to detect model performance issues and to send notifications."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "300", "question": {"enus": "A university wants to develop a targeted recruitment strategy to increase new student enrollment. A data scientist gathers information about the academic performance history of students. The data scientist wants to use the data to build student profiles. The university will use the profiles to direct resources to recruit students who are likely to enroll in the university. Which combination of steps should the data scientist take to predict whether a particular student applicant is likely to enroll in the university? (Choose two.) ", "zhcn": "某大学计划制定精准招生策略以提升新生录取率。一位数据科学家着手收集学生过往学业表现的相关信息，旨在通过数据分析构建学生画像。校方将借助这些画像精准配置招生资源，重点吸纳入学意愿强烈的申请者。为预测特定申请人是否倾向于就读该校，数据科学家应当采取下列哪两项组合步骤？（请选择两项）"}, "option": [{"option_text": {"zhcn": "利用Amazon SageMaker Ground Truth将数据归类至\"enrolled\"（已注册）与\"not enrolled\"（未注册）两个分组中。", "enus": "Use Amazon SageMaker Ground Truth to sort the data into two groups named \"enrolled\" or \"not enrolled.\""}, "option_flag": false}, {"option_text": {"zhcn": "运用预测算法进行趋势推演。", "enus": "Use a forecasting algorithm to run predictions."}, "option_flag": false}, {"option_text": {"zhcn": "运用回归算法进行预测分析。", "enus": "Use a regression algorithm to run predictions."}, "option_flag": false}, {"option_text": {"zhcn": "运用分类算法进行预测分析。", "enus": "Use a classification algorithm to run predictions."}, "option_flag": true}, {"option_text": {"zhcn": "运用亚马逊SageMaker内置的k均值算法，将数据划分为名为\"已注册\"与\"未注册\"的两个群组。", "enus": "Use the built-in Amazon SageMaker k-means algorithm to cluster the data into two groups named \"enrolled\" or \"not enrolled.\""}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "301", "question": {"enus": "A machine learning (ML) specialist is using the Amazon SageMaker DeepAR forecasting algorithm to train a model on CPU-based Amazon EC2 On-Demand instances. The model currently takes multiple hours to train. The ML specialist wants to decrease the training time of the model. Which approaches will meet this requirement? (Choose two.) ", "zhcn": "一位机器学习专家正利用基于CPU的亚马逊EC2按需实例，通过Amazon SageMaker平台的DeepAR预测算法训练模型。当前模型训练耗时数小时之久。该专家希望缩短模型训练时长，下列哪两种方法可实现此目标？（请选择两项正确答案）"}, "option": [{"option_text": {"zhcn": "将按需实例替换为竞价实例。", "enus": "Replace On-Demand Instances with Spot Instances."}, "option_flag": true}, {"option_text": {"zhcn": "根据负载变化动态配置模型自动扩缩容，实现实例数量自主调节。", "enus": "Configure model auto scaling dynamically to adjust the number of instances automatically."}, "option_flag": false}, {"option_text": {"zhcn": "将基于CPU的EC2实例更换为基于GPU的EC2实例。", "enus": "Replace CPU-based EC2 instances with GPU-based EC2 instances."}, "option_flag": false}, {"option_text": {"zhcn": "采用多组训练样本。", "enus": "Use multiple training instances."}, "option_flag": true}, {"option_text": {"zhcn": "建议使用模型的预训练版本，并在此基础上进行增量训练。", "enus": "Use a pre-trained version of the model. Run incremental training."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AD"}, {"id": "302", "question": {"enus": "A chemical company has developed several machine learning (ML) solutions to identify chemical process abnormalities. The time series values of independent variables and the labels are available for the past 2 years and are suficient to accurately model the problem. The regular operation label is marked as 0 The abnormal operation label is marked as 1. Process abnormalities have a significant negative effect on the company’s profits. The company must avoid these abnormalities. Which metrics will indicate an ML solution that will provide the GREATEST probability of detecting an abnormality? ", "zhcn": "某化工企业已开发出多项机器学习解决方案，用于识别化工流程异常。过去两年的自变量时间序列数据和对应标签完备可用，足以精准构建问题模型。正常工况标记为0，异常工况标记为1。流程异常会对企业利润产生重大负面影响，必须彻底规避此类异常。在下列评估指标中，哪项能最能确保机器学习方案捕获异常现象的最大概率？"}, "option": [{"option_text": {"zhcn": "精确率 = 0.91 - 召回率 = 0.6", "enus": "Precision = 0.91 -  Recall = 0.6"}, "option_flag": true}, {"option_text": {"zhcn": "精确率 = 0.61 - 召回率 = 0.98", "enus": "Precision = 0.61 -  Recall = 0.98"}, "option_flag": false}, {"option_text": {"zhcn": "精确率 = 0.7 - 召回率 = 0.9", "enus": "Precision = 0.7 -  Recall = 0.9"}, "option_flag": false}, {"option_text": {"zhcn": "精确率 = 0.98 - 召回率 = 0.8", "enus": "Precision = 0.98 -  Recall = 0.8"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "303", "question": {"enus": "An online delivery company wants to choose the fastest courier for each delivery at the moment an order is placed. The company wants to implement this feature for existing users and new users of its application. Data scientists have trained separate models with XGBoost for this purpose, and the models are stored in Amazon S3. There is one model for each city where the company operates. Operation engineers are hosting these models in Amazon EC2 for responding to the web client requests, with one instance for each model, but the instances have only a 5% utilization in CPU and memory. The operation engineers want to avoid managing unnecessary resources. Which solution will enable the company to achieve its goal with the LEAST operational overhead? ", "zhcn": "一家外卖配送公司希望在用户下单时，就能为每笔订单匹配最快的骑手。公司计划为现有用户及新用户的应用端同步实现这一功能。数据科学家已基于XGBoost算法针对不同城市训练了独立预测模型，并将模型存储于亚马逊S3服务中。目前运维团队为每个城市模型单独配置了亚马逊EC2实例以响应客户端请求，但实例的CPU与内存利用率仅达5%。为避免资源空置，运维团队希望尽可能减少冗余管理成本。下列哪种方案能以最低运维负担实现该目标？"}, "option": [{"option_text": {"zhcn": "创建一个Amazon SageMaker笔记本实例，用于通过boto3库从Amazon S3拉取所有模型。删除现有实例，并利用该笔记本执行SageMaker批量转换任务，为所有城市中的潜在用户实现离线推理。将结果以独立文件形式存储于Amazon S3中，并将网络客户端指向这些文件。", "enus": "Create an Amazon SageMaker notebook instance for pulling all the models from Amazon S3 using the boto3 library. Remove the  existing instances and use the notebook to perform a SageMaker batch transform for performing inferences ofiine for all the possible  users in all the cities. Store the results in different files in Amazon S3. Point the web client to the files."}, "option_flag": false}, {"option_text": {"zhcn": "基于开源多模型服务器，构建一个亚马逊SageMaker的Docker容器。移除现有实例，转而在SageMaker中创建多模型端点，并将其指向存储所有模型的S3存储桶。在运行时通过Web客户端调用该端点，并依据每项请求对应的城市信息指定TargetModel参数。", "enus": "Prepare an Amazon SageMaker Docker container based on the open-source multi-model server. Remove the existing instances and  create a multi-model endpoint in SageMaker instead, pointing to the S3 bucket containing all the models. Invoke the endpoint from the  web client at runtime, specifying the TargetModel parameter according to the city of each request."}, "option_flag": true}, {"option_text": {"zhcn": "仅保留单一EC2实例承载所有模型。在该实例中部署模型服务器，并通过从Amazon S3拉取模型文件的方式加载各模型。通过Amazon API网关将实例与网页客户端集成，实现实时请求响应，并依据每项请求所在城市指定目标资源。", "enus": "Keep only a single EC2 instance for hosting all the models. Install a model server in the instance and load each model by pulling it from  Amazon S3. Integrate the instance with the web client using Amazon API Gateway for responding to the requests in real time, specifying  the target resource according to the city of each request."}, "option_flag": false}, {"option_text": {"zhcn": "基于亚马逊SageMaker预构建镜像准备Docker容器。将现有实例替换为独立的SageMaker端点，为该公司运营的每个城市分别部署一个。通过网页客户端调用这些端点，根据请求所属城市指定对应的URL和端点名称参数。", "enus": "Prepare a Docker container based on the prebuilt images in Amazon SageMaker. Replace the existing instances with separate  SageMaker endpoints, one for each city where the company operates. Invoke the endpoints from the web client, specifying the URL and  EndpointName parameter according to the city of each request."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "304", "question": {"enus": "A company builds computer-vision models that use deep learning for the autonomous vehicle industry. A machine learning (ML) specialist uses an Amazon EC2 instance that has a CPU:GPU ratio of 12:1 to train the models. The ML specialist examines the instance metric logs and notices that the GPU is idle half of the time. The ML specialist must reduce training costs without increasing the duration of the training jobs. Which solution will meet these requirements? ", "zhcn": "一家公司为自动驾驶汽车行业开发基于深度学习的计算机视觉模型。一位机器学习专家采用CPU与GPU配比为12:1的亚马逊EC2实例进行模型训练。该专家在分析实例运行指标时发现，GPU有半数时间处于闲置状态。现需在不延长训练时长的前提下降低训练成本，下列哪项方案符合此要求？"}, "option": [{"option_text": {"zhcn": "切换至仅配备CPU的实例类型。", "enus": "Switch to an instance type that has only CPUs."}, "option_flag": false}, {"option_text": {"zhcn": "在一个异构集群中部署两组不同的实例组。", "enus": "Use a heterogeneous cluster that has two different instances groups."}, "option_flag": false}, {"option_text": {"zhcn": "训练任务可采用内存优化的EC2竞价型实例。", "enus": "Use memory-optimized EC2 Spot Instances for the training jobs."}, "option_flag": true}, {"option_text": {"zhcn": "请切换至CPU与GPU配比为6:1的实例类型。", "enus": "Switch to an instance type that has a CPU:GPU ratio of 6:1."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "305", "question": {"enus": "A company wants to forecast the daily price of newly launched products based on 3 years of data for older product prices, sales, and rebates. The time-series data has irregular timestamps and is missing some values. Data scientist must build a dataset to replace the missing values. The data scientist needs a solution that resamples the data daily and exports the data for further modeling. Which solution will meet these requirements with the LEAST implementation effort? ", "zhcn": "某公司希望依据过去三年旧产品的价格、销量及折扣数据，预测新产品的每日价格。现有时间序列数据存在时间戳不规则及部分数值缺失的问题。数据科学家需构建数据集以填补缺失值，并要求解决方案能实现每日数据重采样，同时导出数据供后续建模使用。在满足上述需求的前提下，哪种方案能以最小实施成本达成目标？"}, "option": [{"option_text": {"zhcn": "借助 Amazon EMR Serverless 运行 PySpark 作业。", "enus": "Use Amazon EMR Serverless with PySpark."}, "option_flag": false}, {"option_text": {"zhcn": "使用 AWS Glue DataBrew。", "enus": "Use AWS Glue DataBrew."}, "option_flag": true}, {"option_text": {"zhcn": "请使用 Amazon SageStudio 数据整理器。", "enus": "Use Amazon SageMaker Studio Data Wrangler."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊SageMaker Studio Notebook中运用Pandas进行数据分析。", "enus": "Use Amazon SageMaker Studio Notebook with Pandas."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "306", "question": {"enus": "A data scientist is building a forecasting model for a retail company by using the most recent 5 years of sales records that are stored in a data warehouse. The dataset contains sales records for each of the company’s stores across five commercial regions. The data scientist creates a working dataset with StoreID. Region. Date, and Sales Amount as columns. The data scientist wants to analyze yearly average sales for each region. The scientist also wants to compare how each region performed compared to average sales across all commercial regions. Which visualization will help the data scientist better understand the data trend? ", "zhcn": "一位数据科学家正在利用数据仓库中近五年的销售记录为某零售企业构建预测模型。该数据集涵盖五大商业区域各门店的销售记录。科学家已创建包含门店编号、所属区域、日期及销售额的工作数据集。为分析各区域年度平均销售额，并对比各区域与整体商业区域平均值的表现差异，应采用何种可视化方案方能更清晰地呈现数据趋势？"}, "option": [{"option_text": {"zhcn": "使用Pandas的GroupBy功能按年份和门店汇总数据，生成各门店逐年平均销售额的聚合数据集。以年份为分面绘制柱状图，展示各门店平均销售额。每个分面中添加独立柱体，用以呈现整体平均销售额水平。", "enus": "Create an aggregated dataset by using the Pandas GroupBy function to get average sales for each year for each store. Create a bar  plot, faceted by year, of average sales for each store. Add an extra bar in each facet to represent average sales."}, "option_flag": true}, {"option_text": {"zhcn": "请使用Pandas的GroupBy功能创建聚合数据集，计算每家门店每年的平均销售额。绘制按地区着色的柱状图，以年份为分面展示各门店平均销售额，并在每个分面中添加代表平均销售额的水平参考线。", "enus": "Create an aggregated dataset by using the Pandas GroupBy function to get average sales for each year for each store. Create a bar  plot, colored by region and faceted by year, of average sales for each store. Add a horizontal line in each facet to represent average sales."}, "option_flag": false}, {"option_text": {"zhcn": "请使用Pandas的GroupBy功能创建聚合数据集，获取各区域每年平均销售额。绘制各区域平均销售额的条形图，并在每个分区中添加额外条形以表示平均销售额。", "enus": "Create an aggregated dataset by using the Pandas GroupBy function to get average sales for each year for each region. Create a bar  plot of average sales for each region. Add an extra bar in each facet to represent average sales."}, "option_flag": false}, {"option_text": {"zhcn": "使用Pandas的GroupBy功能按年份和地区汇总数据，生成各区域每年平均销售额的数据集。通过分面柱状图展示各区域平均销售额，每个年份单独呈现一个子图，并在各子图中添加代表平均销售额的水平参考线。", "enus": "Create an aggregated dataset by using the Pandas GroupBy function to get average sales for each year for each region. Create a bar  plot, faceted by year, of average sales for each region. Add a horizontal line in each facet to represent average sales."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "307", "question": {"enus": "A company uses sensors on devices such as motor engines and factory machines to measure parameters, temperature and pressure. The company wants to use the sensor data to predict equipment malfunctions and reduce services outages. Machine learning (ML) specialist needs to gather the sensors data to train a model to predict device malfunctions. The ML specialist must ensure that the data does not contain outliers before training the model. How can the ML specialist meet these requirements with the LEAST operational overhead? ", "zhcn": "某企业通过在电机引擎与工厂机械等设备上安装传感器，用以监测各项运行参数、温度及压力数据。该企业旨在运用传感器数据预测设备故障，从而减少服务中断情况。机器学习专家需要采集传感器数据以训练预测设备故障的模型。在模型训练前，专家必须确保数据不含异常值。请问机器学习专家如何以最低运维成本满足这些需求？"}, "option": [{"option_text": {"zhcn": "将数据载入Amazon SageMaker Studio笔记本，计算第一与第三四分位数值。随后通过SageMaker Data Wrangler数据流处理功能，精准剔除仅超出该四分位数范围的数据点。", "enus": "Load the data into an Amazon SageMaker Studio notebook. Calculate the first and third quartile. Use a SageMaker Data Wrangler data  fiow to remove only values that are outside of those quartiles."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊SageMaker数据整理工具的偏差报告识别数据集中的异常值，随后通过数据流处理功能，依据偏差分析结果剔除异常数据。", "enus": "Use an Amazon SageMaker Data Wrangler bias report to find outliers in the dataset. Use a Data Wrangler data fiow to remove outliers  based on the bias report."}, "option_flag": false}, {"option_text": {"zhcn": "借助亚马逊SageMaker数据整理器的异常检测可视化功能，可精准定位数据集中的异常值。通过在数据整理流程中添加转换步骤，即可有效剔除异常数据点。", "enus": "Use an Amazon SageMaker Data Wrangler anomaly detection visualization to find outliers in the dataset. Add a transformation to a  Data Wrangler data fiow to remove outliers."}, "option_flag": true}, {"option_text": {"zhcn": "运用亚马逊设备监测服务（Amazon Lookout for Equipment）从数据集中识别并剔除异常值。", "enus": "Use Amazon Lookout for Equipment to find and remove outliers from the dataset."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "308", "question": {"enus": "A data scientist obtains a tabular dataset that contains 150 correlated features with different ranges to build a regression model. The data scientist needs to achieve more eficient model training by implementing a solution that minimizes impact on the model’s performance. The data scientist decides to perform a principal component analysis (PCA) preprocessing step to reduce the number of features to a smaller set of independent features before the data scientist uses the new features in the regression model. Which preprocessing step will meet these requirements? ", "zhcn": "一位数据科学家获得了一个包含150个相关特征且数值范围各异的表格数据集，旨在构建回归模型。为实现更高效的模型训练，需采用一种对模型性能影响最小的解决方案。该科学家决定在执行回归模型前，先通过主成分分析（PCA）预处理步骤，将特征数量缩减为少量独立的新特征。何种预处理方法可满足上述需求？"}, "option": [{"option_text": {"zhcn": "对数据集应用Amazon SageMaker内置的主成分分析算法，以实现数据转换。", "enus": "Use the Amazon SageMaker built-in algorithm for PCA on the dataset to transform the data."}, "option_flag": false}, {"option_text": {"zhcn": "将数据载入亚马逊SageMaker数据整理平台，通过最小-最大缩放转换步骤对数据进行标准化处理。随后在缩放后的数据集上运用SageMaker内置的主成分分析算法，完成数据转换。", "enus": "Load the data into Amazon SageMaker Data Wrangler. Scale the data with a Min Max Scaler transformation step. Use the SageMaker  built-in algorithm for PCA on the scaled dataset to transform the data."}, "option_flag": false}, {"option_text": {"zhcn": "通过剔除相关性最高的特征来降低数据集的维度。将数据加载至Amazon SageMaker Data Wrangler后，执行标准缩放转换步骤以规范化数据尺度。随后在缩放后的数据集上运用SageMaker内置的PCA算法实现数据转换。", "enus": "Reduce the dimensionality of the dataset by removing the features that have the highest correlation. Load the data into Amazon  SageMaker Data Wrangler. Perform a Standard Scaler transformation step to scale the data. Use the SageMaker built-in algorithm for PCA  on the scaled dataset to transform the data."}, "option_flag": false}, {"option_text": {"zhcn": "通过剔除相关性最弱的特征来降低数据集的维度。将数据加载至Amazon SageMaker Data Wrangler后，执行最小最大缩放变换步骤以标准化数据范围。随后在缩放后的数据集上运用SageMaker内置的主成分分析算法，实现数据转换。", "enus": "Reduce the dimensionality of the dataset by removing the features that have the lowest correlation. Load the data into Amazon  SageMaker Data Wrangler. Perform a Min Max Scaler transformation step to scale the data. Use the SageMaker built-in algorithm for PCA  on the scaled dataset to transform the data."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "309", "question": {"enus": "An online retailer collects the following data on customer orders: demographics, behaviors, location, shipment progress, and delivery time. A data scientist joins all the collected datasets. The result is a single dataset that includes 980 variables. The data scientist must develop a machine learning (ML) model to identify groups of customers who are likely to respond to a marketing campaign. Which combination of algorithms should the data scientist use to meet this requirement? (Choose two.) ", "zhcn": "某电商平台收集了以下客户订单数据：用户画像、行为特征、地理位置、物流状态及交付时长。数据科学家将全部采集到的数据集进行整合后，生成了一个包含980个变量的统一数据集。此时需要开发一个机器学习模型，用于精准定位可能对营销活动产生兴趣的客户群体。为达成此目标，数据科学家应当采用哪两种算法的组合方案？（请选择两项）"}, "option": [{"option_text": {"zhcn": "潜在狄利克雷分布（LDA）", "enus": "Latent Dirichlet Allocation (LDA)"}, "option_flag": true}, {"option_text": {"zhcn": "K-means 聚类算法", "enus": "K-means"}, "option_flag": false}, {"option_text": {"zhcn": "语义分割", "enus": "Semantic segmentation"}, "option_flag": false}, {"option_text": {"zhcn": "主成分分析（PCA）", "enus": "Principal component analysis (PCA)"}, "option_flag": false}, {"option_text": {"zhcn": "因子分解机（Factorization Machines，简称FM）", "enus": "Factorization machines (FM)"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AE"}, {"id": "310", "question": {"enus": "A machine learning engineer is building a bird classification model. The engineer randomly separates a dataset into a training dataset and a validation dataset. During the training phase, the model achieves very high accuracy. However, the model did not generalize well during validation of the validation dataset. The engineer realizes that the original dataset was imbalanced. What should the engineer do to improve the validation accuracy of the model? ", "zhcn": "一位机器学习工程师正在构建鸟类分类模型。该工程师将数据集随机划分为训练集和验证集。训练阶段模型表现出极高的准确率，但在验证集上却未能展现出良好的泛化能力。工程师意识到原数据集存在样本失衡问题。为提升模型在验证集上的准确率，该采取哪些改进措施？"}, "option": [{"option_text": {"zhcn": "对原始数据集进行分层抽样。", "enus": "Perform stratified sampling on the original dataset."}, "option_flag": true}, {"option_text": {"zhcn": "在原数据集中，对多数类别进行进一步的数据采集。", "enus": "Acquire additional data about the majority classes in the original dataset."}, "option_flag": false}, {"option_text": {"zhcn": "采用规模更小、经过随机抽样的训练数据集版本。", "enus": "Use a smaller, randomly sampled version of the training dataset."}, "option_flag": false}, {"option_text": {"zhcn": "对原始数据集进行系统抽样。", "enus": "Perform systematic sampling on the original dataset."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "311", "question": {"enus": "A data engineer wants to perform exploratory data analysis (EDA) on a petabyte of data. The data engineer does not want to manage compute resources and wants to pay only for queries that are run. The data engineer must write the analysis by using Python from a Jupyter notebook. Which solution will meet these requirements? ", "zhcn": "一位数据工程师希望对PB级数据进行探索性数据分析（EDA）。该工程师不愿自行管理计算资源，且仅希望按实际执行的查询量付费。分析代码需通过Jupyter笔记本使用Python编写。何种方案可满足这些需求？"}, "option": [{"option_text": {"zhcn": "在亚马逊 Athena 中集成使用 Apache Spark。", "enus": "Use Apache Spark from within Amazon Athena."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon SageMaker环境中集成Apache Spark进行数据处理。", "enus": "Use Apache Spark from within Amazon SageMaker."}, "option_flag": true}, {"option_text": {"zhcn": "在 Amazon EMR 集群环境中运行 Apache Spark。", "enus": "Use Apache Spark from within an Amazon EMR cluster."}, "option_flag": false}, {"option_text": {"zhcn": "通过集成Amazon Redshift使用Apache Spark。", "enus": "Use Apache Spark through an integration with Amazon Redshift."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "312", "question": {"enus": "A data scientist receives a new dataset in .csv format and stores the dataset in Amazon S3. The data scientist will use the dataset to train a machine learning (ML) model. The data scientist first needs to identify any potential data quality issues in the dataset. The data scientist must identify values that are missing or values that are not valid. The data scientist must also identify the number of outliers in the dataset. Which solution will meet these requirements with the LEAST operational effort? ", "zhcn": "一位数据科学家收到一份.csv格式的新数据集，并将其存储于Amazon S3中。该数据集将用于训练机器学习模型。数据科学家首先需要识别其中潜在的数据质量问题，包括缺失值、无效数值以及异常值数量。在满足这些要求的前提下，何种解决方案能以最小的操作量实现目标？"}, "option": [{"option_text": {"zhcn": "创建一个AWS Glue作业，用于将数据从.csv格式转换为Apache Parquet格式。通过配置AWS Glue爬虫程序，结合Amazon Athena并运用恰当的SQL查询语句来提取所需信息。", "enus": "Create an AWS Glue job to transform the data from .csv format to Apache Parquet format. Use an AWS Glue crawler and Amazon Athena  with appropriate SQL queries to retrieve the required information."}, "option_flag": false}, {"option_text": {"zhcn": "请将数据集保留为.csv格式，通过AWS Glue爬虫程序与Amazon Athena服务，配合恰当的SQL查询语句来提取所需信息。", "enus": "Leave the dataset in .csv format. Use an AWS Glue crawler and Amazon Athena with appropriate SQL queries to retrieve the required  information."}, "option_flag": false}, {"option_text": {"zhcn": "创建一项AWS Glue作业，用于将数据从.csv格式转换为Apache Parquet格式。将处理后的数据导入Amazon SageMaker Data Wrangler，随后通过数据质量与洞察报告获取所需分析信息。", "enus": "Create an AWS Glue job to transform the data from .csv format to Apache Parquet format. Import the data into Amazon SageMaker Data  Wrangler. Use the Data Quality and Insights Report to retrieve the required information."}, "option_flag": false}, {"option_text": {"zhcn": "将数据集保留为.csv格式，将其导入Amazon SageMaker Data Wrangler中，随后通过数据质量与洞察报告获取所需信息。", "enus": "Leave the dataset in .csv format. Import the data into Amazon SageMaker Data Wrangler. Use the Data Quality and Insights Report to  retrieve the required information."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "313", "question": {"enus": "An ecommerce company has developed a XGBoost model in Amazon SageMaker to predict whether a customer will return a purchased item. The dataset is imbalanced. Only 5% of customers return items. A data scientist must find the hyperparameters to capture as many instances of returned items as possible. The company has a small budget for compute. How should the data scientist meet these requirements MOST cost-effectively? ", "zhcn": "一家电商公司利用亚马逊SageMaker平台开发了XGBoost模型，用于预测顾客是否会退回所购商品。当前数据集存在不平衡问题，仅5%的顾客选择退货。数据科学家需在有限的计算资源预算内，通过超参数调优尽可能精准识别退货案例。在此条件下，如何以最具成本效益的方式达成该目标？"}, "option": [{"option_text": {"zhcn": "采用自动模型调优（AMT）对所有可调超参数进行优化。优化目标设定为：{\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:accuracy\", \"Type\": \"Maximize\"}}，以最大化验证集准确率为导向。", "enus": "Tune all possible hyperparameters by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\":  {\"MetricName\": \"validation:accuracy\", \"Type\": \"Maximize\"}}."}, "option_flag": false}, {"option_text": {"zhcn": "通过自动模型调优（AMT）对csv_weight超参数与scale_pos_weight超参数进行调校。优化目标设定为：{\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation'll\", \"Type\": \"Maximize\"}}。", "enus": "Tune the csv_weight hyperparameter and the scale_pos_weight hyperparameter by using automatic model tuning (AMT). Optimize on  {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation'll\", \"Type\": \"Maximize\"}}."}, "option_flag": false}, {"option_text": {"zhcn": "通过自动模型调优（AMT）对所有可调超参数进行优化，以最大化验证集F1分数（{\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:f1\", \"Type\": \"Maximize\"}}）为目标进行调优。", "enus": "Tune all possible hyperparameters by using automatic model tuning (AMT). Optimize on {\"HyperParameterTuningJobObjective\":  {\"MetricName\": \"validation:f1\", \"Type\": \"Maximize\"}}."}, "option_flag": true}, {"option_text": {"zhcn": "通过自动模型调优（AMT）调整 `csv_weight` 超参数与 `scale_pos_weight` 超参数，并以最小化验证集F1分数为目标进行优化：`{\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:f1\", \"Type\": \"Minimize\"}}`。", "enus": "Tune the csv_weight hyperparameter and the scale_pos_weight hyperparameter by using automatic model tuning (AMT). Optimize on  {\"HyperParameterTuningJobObjective\": {\"MetricName\": \"validation:f1\", \"Type\": \"Minimize\"}}."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "314", "question": {"enus": "A data scientist is trying to improve the accuracy of a neural network classification model. The data scientist wants to run a large hyperparameter tuning job in Amazon SageMaker. However, previous smaller tuning jobs on the same model often ran for several weeks. The ML specialist wants to reduce the computation time required to run the tuning job. Which actions will MOST reduce the computation time for the hyperparameter tuning job? (Choose two.) ", "zhcn": "一位数据科学家正致力于提升神经网络分类模型的准确率。他计划在Amazon SageMaker平台上运行大规模超参数调优任务，但此前相同模型的较小规模调优作业往往需耗时数周。为缩短调优任务的计算时间，该机器学习专家应采取哪两项最能显著提升效率的措施？（请选择两项）"}, "option": [{"option_text": {"zhcn": "采用超带优化策略。", "enus": "Use the Hyperband tuning strategy."}, "option_flag": true}, {"option_text": {"zhcn": "增加超参数的数量。", "enus": "Increase the number of hyperparameters."}, "option_flag": false}, {"option_text": {"zhcn": "将 MaxNumberOfTrainingJobs 参数的值适当调低。", "enus": "Set a lower value for the MaxNumberOfTrainingJobs parameter."}, "option_flag": true}, {"option_text": {"zhcn": "采用网格搜索调优策略。", "enus": "Use the grid search tuning strategy."}, "option_flag": false}, {"option_text": {"zhcn": "将 MaxParallelTrainingJobs 参数的值适当调低。", "enus": "Set a lower value for the MaxParallelTrainingJobs parameter."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AC"}, {"id": "315", "question": {"enus": "A machine learning (ML) specialist needs to solve a binary classification problem for a marketing dataset. The ML specialist must maximize the Area Under the ROC Curve (AUC) of the algorithm by training an XGBoost algorithm. The ML specialist must find values for the eta, alpha, min_child_weight, and max_depth hyperparameters that will generate the most accurate model. Which approach will meet these requirements with the LEAST operational overhead? ", "zhcn": "一位机器学习专家需要针对营销数据集解决二分类问题。该专家必须通过训练XGBoost算法来最大化模型的ROC曲线下面积（AUC），并寻找能使模型达到最高准确度的eta、alpha、min_child_weight和max_depth超参数组合。在满足这些要求的前提下，哪种方法能以最小的操作成本实现目标？"}, "option": [{"option_text": {"zhcn": "在Amazon EMR集群上通过引导脚本安装scikit-learn库。部署EMR集群后，对算法采用k折交叉验证方法进行评估。", "enus": "Use a bootstrap script to install scikit-learn on an Amazon EMR cluster. Deploy the EMR cluster. Apply k-fold cross-validation methods to  the algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "部署预置scikit-learn环境的Amazon SageMaker Docker镜像，对算法实施k折交叉验证方法。", "enus": "Deploy Amazon SageMaker prebuilt Docker images that have scikit-learn installed. Apply k-fold cross-validation methods to the  algorithm."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon SageMaker自动模型调优（AMT）功能。为每个超参数设定一个取值范围。", "enus": "Use Amazon SageMaker automatic model tuning (AMT). Specify a range of values for each hyperparameter."}, "option_flag": true}, {"option_text": {"zhcn": "订阅一款发布于AWS Marketplace的AUC算法。为每个超参数设定相应的数值范围。", "enus": "Subscribe to an AUC algorithm that is on AWS Marketplace. Specify a range of values for each hyperparameter."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "316", "question": {"enus": "A machine learning (ML) developer for an online retailer recently uploaded a sales dataset into Amazon SageMaker Studio. The ML developer wants to obtain importance scores for each feature of the dataset. The ML developer will use the importance scores to feature engineer the dataset. Which solution will meet this requirement with the LEAST development effort? ", "zhcn": "某在线零售商的机器学习开发人员近日将一份销售数据集上传至Amazon SageMaker Studio。该开发人员需要获取数据集中各特征的重要性评分，以便用于特征工程处理。在满足此需求的前提下，下列哪种解决方案所需开发工作量最小？"}, "option": [{"option_text": {"zhcn": "利用SageMaker Data Wrangler进行基尼重要性评分分析。", "enus": "Use SageMaker Data Wrangler to perform a Gini importance score analysis."}, "option_flag": true}, {"option_text": {"zhcn": "使用SageMaker笔记实例执行主成分分析（PCA）。", "enus": "Use a SageMaker notebook instance to perform principal component analysis (PCA)."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker笔记本实例进行奇异值分解分析。", "enus": "Use a SageMaker notebook instance to perform a singular value decomposition analysis."}, "option_flag": false}, {"option_text": {"zhcn": "运用多重共线性特性进行LASSO特征筛选，进而完成重要性评分分析。", "enus": "Use the multicollinearity feature to perform a lasso feature selection to perform an importance scores analysis."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "317", "question": {"enus": "A company is setting up a mechanism for data scientists and engineers from different departments to access an Amazon SageMaker Studio domain. Each department has a unique SageMaker Studio domain. The company wants to build a central proxy application that data scientists and engineers can log in to by using their corporate credentials. The proxy application will authenticate users by using the company's existing Identity provider (IdP). The application will then route users to the appropriate SageMaker Studio domain. The company plans to maintain a table in Amazon DynamoDB that contains SageMaker domains for each department. How should the company meet these requirements? ", "zhcn": "某公司正着手建立一套机制，使不同部门的数据科学家与工程师能够访问各自的亚马逊SageMaker Studio工作域。每个部门均拥有独立的SageMaker Studio域环境。该公司计划构建一个中央代理应用程序，科研人员可通过企业身份凭证登录该应用。该代理程序将借助企业现有身份提供商（IdP）完成用户认证，随后将用户引导至对应的SageMaker Studio域。公司拟在Amazon DynamoDB中维护一张数据表，用于存储各部门对应的SageMaker域信息。请问应如何设计该解决方案以满足上述需求？"}, "option": [{"option_text": {"zhcn": "请调用SageMaker的CreatePresignedDomainUrl接口，依据DynamoDB表中的每个域名生成对应的预签名网址，并将该网址传递至代理应用程序。", "enus": "Use the SageMaker CreatePresignedDomainUrl API to generate a presigned URL for each domain according to the DynamoDB table.  Pass the presigned URL to the proxy application."}, "option_flag": true}, {"option_text": {"zhcn": "请使用 SageMaker CreateHumanTaskUi API 生成用户界面链接，并将该链接传递给代理应用程序。", "enus": "Use the SageMaker CreateHumanTaskUi API to generate a UI URL. Pass the URL to the proxy application."}, "option_flag": false}, {"option_text": {"zhcn": "请调用Amazon SageMaker的ListHumanTaskUis接口获取所有任务界面URL，并将对应地址传递至DynamoDB表中，以便代理应用程序调用该链接。", "enus": "Use the Amazon SageMaker ListHumanTaskUis API to list all UI URLs. Pass the appropriate URL to the DynamoDB table so that the  proxy application can use the URL."}, "option_flag": false}, {"option_text": {"zhcn": "请调用 SageMaker 的 CreatePresignedNotebookInstanceUrl 接口生成预签名网址，并将该网址传递至代理应用程序。", "enus": "Use the SageMaker CreatePresignedNotebooklnstanceUrl API to generate a presigned URL. Pass the presigned URL to the proxy  application."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "318", "question": {"enus": "An insurance company is creating an application to automate car insurance claims. A machine learning (ML) specialist used an Amazon SageMaker Object Detection - TensorFlow built-in algorithm to train a model to detect scratches and dents in images of cars. After the model was trained, the ML specialist noticed that the model performed better on the training dataset than on the testing dataset. Which approach should the ML specialist use to improve the performance of the model on the testing data? ", "zhcn": "一家保险公司正在开发一款自动化车险理赔应用程序。机器学习专家采用亚马逊SageMaker平台内置的TensorFlow目标检测算法，训练出可识别汽车图像中刮痕和凹痕的模型。训练完成后，专家发现该模型在训练数据集上的表现优于测试数据集。为提升模型在测试数据上的性能表现，专家应当采取何种优化策略？"}, "option": [{"option_text": {"zhcn": "增大动量超参数的数值。", "enus": "Increase the value of the momentum hyperparameter."}, "option_flag": false}, {"option_text": {"zhcn": "适当调低dropout_rate超参数的数值。", "enus": "Reduce the value of the dropout_rate hyperparameter."}, "option_flag": true}, {"option_text": {"zhcn": "降低学习率超参数的数值。", "enus": "Reduce the value of the learning_rate hyperparameter"}, "option_flag": false}, {"option_text": {"zhcn": "提升L2超参数的数值。", "enus": "Increase the value of the L2 hyperparameter."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "319", "question": {"enus": "A developer at a retail company is creating a daily demand forecasting model. The company stores the historical hourly demand data in an Amazon S3 bucket. However, the historical data does not include demand data for some hours. The developer wants to verify that an autoregressive integrated moving average (ARIMA) approach will be a suitable model for the use case. How should the developer verify the suitability of an ARIMA approach? ", "zhcn": "某零售企业的一位开发人员正在构建每日需求预测模型。该公司将历史每小时需求数据存储在亚马逊S3存储桶中，但部分时段的历史需求数据存在缺失。开发人员希望验证自回归积分滑动平均模型（ARIMA）是否适用于该场景。请问应如何评估ARIMA模型在此案例中的适用性？"}, "option": [{"option_text": {"zhcn": "使用Amazon SageMaker Data Wrangler。从Amazon S3导入数据。对每小时缺失数据进行填补。执行季节性趋势分解。", "enus": "Use Amazon SageMaker Data Wrangler. Import the data from Amazon S3. Impute hourly missing data. Perform a Seasonal Trend  decomposition."}, "option_flag": false}, {"option_text": {"zhcn": "使用Amazon SageMaker Autopilot，创建一个指定S3数据位置的新实验。选择ARIMA作为机器学习问题类型，并评估模型性能。", "enus": "Use Amazon SageMaker Autopilot. Create a new experiment that specifies the S3 data location. Choose ARIMA as the machine learning  (ML) problem. Check the model performance."}, "option_flag": false}, {"option_text": {"zhcn": "使用 Amazon SageMaker Data Wrangler。从 Amazon S3 导入数据，通过聚合日总量进行数据重采样，并执行季节性趋势分解。", "enus": "Use Amazon SageMaker Data Wrangler. Import the data from Amazon S3. Resample data by using the aggregate daily total. Perform a  Seasonal Trend decomposition."}, "option_flag": true}, {"option_text": {"zhcn": "使用Amazon SageMaker Autopilot，创建一项新实验并指定S3数据存储路径。对缺失的每小时数据进行填补处理。选择ARIMA作为机器学习（ML）问题类型，最后评估模型性能。", "enus": "Use Amazon SageMaker Autopilot. Create a new experiment that specifies the S3 data location. Impute missing hourly values. Choose  ARIMA as the machine learning (ML) problem. Check the model performance."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "320", "question": {"enus": "A company decides to use Amazon SageMaker to develop machine learning (ML) models. The company will host SageMaker notebook instances in a VPC. The company stores training data in an Amazon S3 bucket. Company security policy states that SageMaker notebook instances must not have internet connectivity. Which solution will meet the company’s security requirements? ", "zhcn": "一家公司决定采用Amazon SageMaker进行机器学习模型的研发。该公司计划将SageMaker笔记本实例部署在虚拟私有云（VPC）中，并将训练数据存储于亚马逊S3存储桶。根据企业安全政策要求，SageMaker笔记本实例需禁止连接互联网。何种解决方案能够满足该公司的安全要求？"}, "option": [{"option_text": {"zhcn": "通过AWS站点到站点VPN连接位于VPC内的SageMaker笔记本实例，对所有出站互联网流量进行加密传输。配置VPC流日志监控功能，全面追踪网络流量动态，以便及时侦测并阻断任何恶意活动。", "enus": "Connect the SageMaker notebook instances that are in the VPC by using AWS Site-to-Site VPN to encrypt all internet-bound trafic.  Configure VPC fiow logs. Monitor all network trafic to detect and prevent any malicious activity."}, "option_flag": false}, {"option_text": {"zhcn": "请将包含SageMaker笔记本实例的VPC配置为使用VPC接口端点来建立训练和托管连接。修改与VPC接口端点关联的所有现有安全组，仅允许训练和托管所需的出站连接。", "enus": "Configure the VPC that contains the SageMaker notebook instances to use VPC interface endpoints to establish connections for  training and hosting. Modify any existing security groups that are associated with the VPC interface endpoint to allow only outbound  connections for training and hosting."}, "option_flag": true}, {"option_text": {"zhcn": "创建一项禁止访问互联网的IAM策略。将该IAM策略应用于某个IAM角色。除了实例已分配的任何IAM角色外，还需将此IAM角色分配给SageMaker笔记本实例。", "enus": "Create an IAM policy that prevents access the internet. Apply the IAM policy to an IAM role. Assign the IAM role to the SageMaker  notebook instances in addition to any IAM roles that are already assigned to the instances."}, "option_flag": false}, {"option_text": {"zhcn": "创建虚拟私有云安全组以阻断所有出入流量，并将该安全组配置至SageMaker笔记本实例。", "enus": "Create VPC security groups to prevent all incoming and outgoing trafic. Assign the security groups to the SageMaker notebook  instances."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "321", "question": {"enus": "A machine learning (ML) engineer uses Bayesian optimization for a hyperpara meter tuning job in Amazon SageMaker. The ML engineer uses precision as the objective metric. The ML engineer wants to use recall as the objective metric. The ML engineer also wants to expand the hyperparameter range for a new hyperparameter tuning job. The new hyperparameter range will include the range of the previously performed tuning job. Which approach will run the new hyperparameter tuning job in the LEAST amount of time? ", "zhcn": "一位机器学习工程师在亚马逊SageMaker平台上使用贝叶斯优化进行超参数调优任务。该工程师原采用精确率作为优化目标指标，现计划改用召回率作为新目标指标，并希望扩展超参数范围至包含此前已完成的调优作业区间。若要实现新的超参数调优任务，何种方案能以最短耗时完成？"}, "option": [{"option_text": {"zhcn": "采用热启动超参数调优任务。", "enus": "Use a warm start hyperparameter tuning job."}, "option_flag": true}, {"option_text": {"zhcn": "采用检查点超参数调优任务。", "enus": "Use a checkpointing hyperparameter tuning job."}, "option_flag": false}, {"option_text": {"zhcn": "为超参数调优任务使用相同的随机种子。", "enus": "Use the same random seed for the hyperparameter tuning job."}, "option_flag": false}, {"option_text": {"zhcn": "为超参数调优任务并行运行多个作业。", "enus": "Use multiple jobs in parallel for the hyperparameter tuning job."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "322", "question": {"enus": "A news company is developing an article search tool for its editors. The search tool should look for the articles that are most relevant and representative for particular words that are queried among a corpus of historical news documents. The editors test the first version of the tool and report that the tool seems to look for word matches in general. The editors have to spend additional time to filter the results to look for the articles where the queried words are most important. A group of data scientists must redesign the tool so that it isolates the most frequently used words in a document. The tool also must capture the relevance and importance of words for each document in the corpus. Which solution meets these requirements? ", "zhcn": "一家新闻机构正为其编辑研发一款文章检索工具。该工具需从历史新闻文档库中精准找出与查询词汇最相关且最具代表性的文章。编辑们对初版工具进行测试后反馈，现有检索机制仅停留在普通词汇匹配层面，导致他们需要耗费额外时间筛选结果，才能找到查询词汇处于核心地位的文章。数据科学家团队需要重新设计该工具，使其能自动识别文档中的高频词汇，同时精准捕捉每个文档内词汇的相关性与重要程度。现有方案中哪项能满足这些要求？"}, "option": [{"option_text": {"zhcn": "运用隐狄利克雷分布（LDA）主题建模技术从每篇文章中提取主题，并通过累加文章中各词项的主题频次作为评分，构建主题词频统计表。配置该工具时，设定检索规则为：当查询词在文章中的主题词频评分较高时，即优先调取相应文章。", "enus": "Extract the topics from each article by using Latent Dirichlet Allocation (LDA) topic modeling. Create a topic table by assigning the sum  of the topic counts as a score for each word in the articles. Configure the tool to retrieve the articles where this topic count score is higher  for the queried words."}, "option_flag": false}, {"option_text": {"zhcn": "为每篇文章中的词语构建一个按文章长度加权的词频指标，同时基于语料库全部文献为每个词语计算逆向文档频率。将这两项频率指标的乘积定义为最终的高亮评分。将此工具配置为：当查询词条的高亮评分较高时，即可检索出对应文献。", "enus": "Build a term frequency for each word in the articles that is weighted with the article's length. Build an inverse document frequency for  each word that is weighted with all articles in the corpus. Define a final highlight score as the product of both of these frequencies.  Configure the tool to retrieve the articles where this highlight score is higher for the queried words."}, "option_flag": true}, {"option_text": {"zhcn": "下载预训练的词嵌入对照表。为语料库中每篇文章计算标题词嵌入的平均值，构建标题嵌入表。定义每个词的凸显分数，使其与词嵌入和标题嵌入之间的空间距离成反比。配置检索工具，使其能够根据查询词的凸显分数高低筛选出相关文章。", "enus": "Download a pretrained word-embedding lookup table. Create a titles-embedding table by averaging the title's word embedding for each  article in the corpus. Define a highlight score for each word as inversely proportional to the distance between its embedding and the title  embedding. Configure the tool to retrieve the articles where this highlight score is higher for the queried words."}, "option_flag": false}, {"option_text": {"zhcn": "为语料库中每篇文章的词汇建立词频评分表。停用词一律记零分。其余词汇按其在该文章中的出现频次计分。将工具设置为可检索查询词汇得分较高的文章。", "enus": "Build a term frequency score table for each word in each article of the corpus. Assign a score of zero to all stop words. For any other  words, assign a score as the word’s frequency in the article. Configure the tool to retrieve the articles where this frequency score is higher  for the queried words."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "323", "question": {"enus": "A growing company has a business-critical key performance indicator (KPI) for the uptime of a machine learning (ML) recommendation system. The company is using Amazon SageMaker hosting services to develop a recommendation model in a single Availability Zone within an AWS Region. A machine learning (ML) specialist must develop a solution to achieve high availability. The solution must have a recovery time objective (RTO) of 5 minutes. Which solution will meet these requirements with the LEAST effort? ", "zhcn": "一家处于成长期的企业将其机器学习推荐系统的持续运行时间视为关键业务指标。该公司目前使用Amazon SageMaker托管服务，在AWS区域的单个可用区内开发推荐模型。为确保系统高可用性，机器学习专家需制定解决方案，且必须满足5分钟恢复时间目标。下列哪种方案能以最小成本满足这些要求？"}, "option": [{"option_text": {"zhcn": "在横跨至少两个区域（Region）的虚拟私有云（VPC）中，为每个终端节点部署多个实例。", "enus": "Deploy multiple instances for each endpoint in a VPC that spans at least two Regions."}, "option_flag": false}, {"option_text": {"zhcn": "为托管的推荐模型启用SageMaker自动扩缩容功能。", "enus": "Use the SageMaker auto scaling feature for the hosted recommendation models."}, "option_flag": false}, {"option_text": {"zhcn": "为每个生产端点部署多个实例，这些实例应置于跨越至少两个子网的虚拟私有云中，且这些子网需位于不同的可用区。", "enus": "Deploy multiple instances for each production endpoint in a VPC that spans least two subnets that are in a second Availability Zone."}, "option_flag": true}, {"option_text": {"zhcn": "请定期为生产推荐模型生成备份，并将备份部署于第二区域。", "enus": "Frequently generate backups of the production recommendation model. Deploy the backups in a second Region."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "324", "question": {"enus": "A global company receives and processes hundreds of documents daily. The documents are in printed .pdf format or .jpg format. A machine learning (ML) specialist wants to build an automated document processing workfiow to extract text from specific fields from the documents and to classify the documents. The ML specialist wants a solution that requires low maintenance. Which solution will meet these requirements with the LEAST operational effort? ", "zhcn": "一家跨国企业每日需接收并处理数百份文件，这些文件以打印版PDF或JPG格式存在。一位机器学习专家计划构建自动化文档处理流程，旨在从文件中特定区域提取文本内容并对文档进行分类。该专家希望采用运维需求较低的解决方案。在满足上述条件的前提下，何种方案能以最小的运维投入实现目标？"}, "option": [{"option_text": {"zhcn": "在 Amazon SageMaker 中调用 PaddleOCR 模型以检测并提取所需文本及字段，并借助 SageMaker 文本分类模型对文档进行自动归类。", "enus": "Use a PaddleOCR model in Amazon SageMaker to detect and extract the required text and fields. Use a SageMaker text classification  model to classify the document."}, "option_flag": false}, {"option_text": {"zhcn": "在 Amazon SageMaker 中调用 PaddleOCR 模型，对所需文本及字段进行检测与提取，并借助 Amazon Comprehend 实现文档的智能分类。", "enus": "Use a PaddleOCR model in Amazon SageMaker to detect and extract the required text and fields. Use Amazon Comprehend to classify  the document."}, "option_flag": false}, {"option_text": {"zhcn": "借助Amazon Textract识别并提取所需文本与字段，运用Amazon Rekognition对文档进行智能分类。", "enus": "Use Amazon Textract to detect and extract the required text and fields. Use Amazon Rekognition to classify the document."}, "option_flag": false}, {"option_text": {"zhcn": "借助Amazon Textract精准识别并提取所需文本与字段，运用Amazon Comprehend对文档进行智能分类。", "enus": "Use Amazon Textract to detect and extract the required text and fields. Use Amazon Comprehend to classify the document."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "325", "question": {"enus": "A company wants to detect credit card fraud. The company has observed that an average of 2% of credit card transactions are fraudulent. A data scientist trains a classifier on a year's worth of credit card transaction data. The classifier needs to identify the fraudulent transactions. The company wants to accurately capture as many fraudulent transactions as possible. Which metrics should the data scientist use to optimize the classifier? (Choose two.) ", "zhcn": "一家公司希望检测信用卡欺诈行为。据该公司观察，信用卡交易中平均有2%属于欺诈交易。数据科学家利用一整年的信用卡交易数据训练了一个分类器，该分类器需要识别出欺诈交易。公司希望尽可能准确地捕捉尽可能多的欺诈交易。数据科学家应采用哪些指标来优化该分类器？（请选择两项。）"}, "option": [{"option_text": {"zhcn": "精准", "enus": "Specificity"}, "option_flag": false}, {"option_text": {"zhcn": "误报率", "enus": "False positive rate"}, "option_flag": false}, {"option_text": {"zhcn": "精确", "enus": "Accuracy"}, "option_flag": false}, {"option_text": {"zhcn": "F1分数", "enus": "F1 score"}, "option_flag": true}, {"option_text": {"zhcn": "真阳性率", "enus": "True positive rate"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "DE"}, {"id": "326", "question": {"enus": "A data scientist is designing a repository that will contain many images of vehicles. The repository must scale automatically in size to store new images every day. The repository must support versioning of the images. The data scientist must implement a solution that maintains multiple immediately accessible copies of the data in different AWS Regions. Which solution will meet these requirements? ", "zhcn": "一位数据科学家正在设计一个用于存储大量车辆图像的资料库。该资料库需具备自动扩容能力，以应对每日新增的图像存储需求，同时必须支持图像版本管理。此外，资料库方案需实现在不同AWS区域保持多个可即时调取的数据副本。何种方案能够满足上述所有要求？"}, "option": [{"option_text": {"zhcn": "\"Amazon S3 跨区域复制（CRR）功能\"", "enus": "Amazon S3 with S3 Cross-Region Replication (CRR)"}, "option_flag": true}, {"option_text": {"zhcn": "在辅助区域共享快照的亚马逊弹性块存储（Amazon EBS）", "enus": "Amazon Elastic Block Store (Amazon EBS) with snapshots that are shared in a secondary Region"}, "option_flag": false}, {"option_text": {"zhcn": "亚马逊弹性文件系统（Amazon EFS）标准存储，采用区域可用性配置。", "enus": "Amazon Elastic File System (Amazon EFS) Standard storage that is configured with Regional availability"}, "option_flag": false}, {"option_text": {"zhcn": "AWS存储网关之卷网关", "enus": "AWS Storage Gateway Volume Gateway"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "327", "question": {"enus": "An ecommerce company wants to update a production real-time machine learning (ML) recommendation engine API that uses Amazon SageMaker. The company wants to release a new model but does not want to make changes to applications that rely on the API. The company also wants to evaluate the performance of the new model in production trafic before the company fully rolls out the new model to all users. Which solution will meet these requirements with the LEAST operational overhead? ", "zhcn": "一家电子商务公司计划升级其基于亚马逊SageMaker的生产级实时机器学习推荐引擎API。在保持依赖该API的应用程序无需改动的前提下，公司希望部署新模型，并计划在向全体用户全面推广前，先于实际生产流量中评估新模型的性能。哪种方案能以最低运维成本满足这些需求？"}, "option": [{"option_text": {"zhcn": "为新型号创建全新的SageMaker终端节点。配置应用负载均衡器（ALB），使流量在旧模型与新模型之间实现智能分发。", "enus": "Create a new SageMaker endpoint for the new model. Configure an Application Load Balancer (ALB) to distribute trafic between the  old model and the new model."}, "option_flag": false}, {"option_text": {"zhcn": "将现有终端节点调整为使用SageMaker生产变体，以便在旧模型与新模型之间分配流量。", "enus": "Modify the existing endpoint to use SageMaker production variants to distribute trafic between the old model and the new model."}, "option_flag": true}, {"option_text": {"zhcn": "对现有端点进行改造，采用SageMaker批量转换技术，实现新旧模型之间的流量分配。", "enus": "Modify the existing endpoint to use SageMaker batch transform to distribute trafic between the old model and the new model."}, "option_flag": false}, {"option_text": {"zhcn": "为新型号创建全新的SageMaker终端节点。配置网络负载均衡器（NLB），以便在旧模型与新模型之间实现流量分发。", "enus": "Create a new SageMaker endpoint for the new model. Configure a Network Load Balancer (NLB) to distribute trafic between the old  model and the new model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "328", "question": {"enus": "A machine learning (ML) specialist at a manufacturing company uses Amazon SageMaker DeepAR to forecast input materials and energy requirements for the company. Most of the data in the training dataset is missing values for the target variable. The company stores the training dataset as JSON files. The ML specialist develop a solution by using Amazon SageMaker DeepAR to account for the missing values in the training dataset. Which approach will meet these requirements with the LEAST development effort? ", "zhcn": "某制造企业的机器学习专家运用亚马逊SageMaker DeepAR平台，旨在精准预测企业所需的原材料与能源消耗量。然而训练数据集中的目标变量存在大量数值缺失，且企业当前以JSON格式存储训练数据。该专家需基于亚马逊SageMaker DeepAR框架，以最小开发成本构建能够处理训练数据缺失值的解决方案。下列哪种方法最高效契合需求？"}, "option": [{"option_text": {"zhcn": "采用线性回归方法对缺失值进行填补，继而利用完整数据集及填补后的数值训练DeepAR模型。", "enus": "Impute the missing values by using the linear regression method. Use the entire dataset and the imputed values to train the DeepAR  model."}, "option_flag": false}, {"option_text": {"zhcn": "将缺失值替换为NaN（非数值）。利用完整数据集及经过编码的缺失值来训练DeepAR模型。", "enus": "Replace the missing values with not a number (NaN). Use the entire dataset and the encoded missing values to train the DeepAR  model."}, "option_flag": false}, {"option_text": {"zhcn": "采用前向填充法补全缺失值，并运用完整数据集及填补后的数值训练DeepAR模型。", "enus": "Impute the missing values by using a forward fill. Use the entire dataset and the imputed values to train the DeepAR model."}, "option_flag": false}, {"option_text": {"zhcn": "采用均值填补缺失值后，结合完整数据集与填补后的数值训练DeepAR模型。", "enus": "Impute the missing values by using the mean value. Use the entire dataset and the imputed values to train the DeepAR model."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "329", "question": {"enus": "A law firm handles thousands of contracts every day. Every contract must be signed. Currently, a lawyer manually checks all contracts for signatures. The law firm is developing a machine learning (ML) solution to automate signature detection for each contract. The ML solution must also provide a confidence score for each contract page. Which Amazon Textract API action can the law firm use to generate a confidence score for each page of each contract? ", "zhcn": "一家律师事务所每日处理数以千计的合同文件，每份合同均需完成签署。目前由律师人工核验所有合同的签名情况。该事务所正研发机器学习解决方案，旨在实现合同签名自动识别功能。此方案还需为每页合同生成可信度评分。请问律师事务所应采用亚马逊Textract的哪项API操作，才能为每份合同的每一页生成可信度评分？"}, "option": [{"option_text": {"zhcn": "请调用AnalyzeDocument API接口，将FeatureTypes参数设置为SIGNATURES，并返回每一页签名区域的置信度评分。", "enus": "Use the AnalyzeDocument API action. Set the FeatureTypes parameter to SIGNATURES. Return the confidence scores for each page."}, "option_flag": false}, {"option_text": {"zhcn": "对文档调用预测接口，返回每页的签名信息及置信度评分。", "enus": "Use the Prediction API call on the documents. Return the signatures and confidence scores for each page."}, "option_flag": false}, {"option_text": {"zhcn": "调用StartDocumentAnalysis接口操作以检测签名区域，并返回每页签名的置信度评分。", "enus": "Use the StartDocumentAnalysis API action to detect the signatures. Return the confidence scores for each page."}, "option_flag": true}, {"option_text": {"zhcn": "调用GetDocumentAnalysis接口功能以检测文档中的签名区域，并返回每一页签名的置信度评分。", "enus": "Use the GetDocumentAnalysis API action to detect the signatures. Return the confidence scores for each page."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "330", "question": {"enus": "A company that operates oil platforms uses drones to photograph locations on oil platforms that are difficult for humans to access to search for corrosion. Experienced engineers review the photos to determine the severity of corrosion. There can be several corroded areas in a single photo. The engineers determine whether the identified corrosion needs to be fixed immediately, scheduled for future maintenance, or requires no action. The corrosion appears in an average of 0.1% of all photos. A data science team needs to create a solution that automates the process of reviewing the photos and classifying the need for maintenance. Which combination of steps will meet these requirements? (Choose three.) ", "zhcn": "一家运营海上石油平台的企业采用无人机拍摄平台人员难以抵达区域的照片，以探查腐蚀状况。经验丰富的工程师通过审阅这些照片评估腐蚀严重程度，单张图像中可能呈现多处腐蚀区域。工程师需判断已识别的腐蚀点是需要立即修复、安排后续维护，抑或无需采取行动。在所有拍摄图像中，腐蚀现象的出现概率平均为0.1%。数据科学团队需构建一套自动化解决方案，实现照片审阅及维护需求分类的智能化处理。下列哪三项步骤组合能够满足上述需求？（请选择三项）"}, "option": [{"option_text": {"zhcn": "采用目标检测算法训练模型，用于识别照片中的腐蚀区域。最高赞方案", "enus": "Use an object detection algorithm to train a model to identify corrosion areas of a photo. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "对照片启用亚马逊Rekognition的标签识别功能。", "enus": "Use Amazon Rekognition with label detection on the photos."}, "option_flag": false}, {"option_text": {"zhcn": "采用k均值聚类算法训练模型，实现对照片中腐蚀程度的智能分级。", "enus": "Use a k-means clustering algorithm to train a model to classify the severity of corrosion in a photo."}, "option_flag": false}, {"option_text": {"zhcn": "采用XGBoost算法训练模型，对照片中的腐蚀程度进行等级分类。最高票选方案。", "enus": "Use an XGBoost algorithm to train a model to classify the severity of corrosion in a photo. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "对含有腐蚀痕迹的照片进行图像增强处理。最多赞同", "enus": "Perform image augmentation on photos that contain corrosion. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "对不含腐蚀痕迹的照片进行图像增强处理。", "enus": "Perform image augmentation on photos that do not contain corrosion."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "ADE"}, {"id": "331", "question": {"enus": "A company maintains a 2 TB dataset that contains information about customer behaviors. The company stores the dataset in Amazon S3. The company stores a trained model container in Amazon Elastic Container Registry (Amazon ECR). A machine learning (ML) specialist needs to score a batch model for the dataset to predict customer behavior. The ML specialist must select a scalable approach to score the model. Which solution will meet these requirements MOST cost-effectively? ", "zhcn": "某公司存有一套容量为2 TB的客户行为数据集，存放于亚马逊S3云存储服务中。该公司已将训练好的模型容器托管于亚马逊弹性容器注册表（Amazon ECR）。一位机器学习专家需对该数据集进行批量模型评分以预测客户行为，此时必须选择可扩展的评分方案。下列哪种解决方案最能符合成本效益要求？"}, "option": [{"option_text": {"zhcn": "利用AWS Batch管理的亚马逊EC2预留实例对模型进行评分。创建亚马逊EC2实例存储卷，并将其挂载至预留实例。", "enus": "Score the model by using AWS Batch managed Amazon EC2 Reserved Instances. Create an Amazon EC2 instance store volume and mount it to the Reserved Instances."}, "option_flag": false}, {"option_text": {"zhcn": "采用AWS Batch托管型Amazon EC2竞价型实例对模型进行评分。创建Amazon FSx for Lustre存储卷并将其挂载至竞价型实例。获赞最多方案", "enus": "Score the model by using AWS Batch managed Amazon EC2 Spot Instances. Create an Amazon FSx for Lustre volume and mount it to the Spot Instances. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "在亚马逊EC2预留实例上运行Amazon SageMaker笔记本以评估模型性能。创建亚马逊EBS存储卷并将其挂载至预留实例。", "enus": "Score the model by using an Amazon SageMaker notebook on Amazon EC2 Reserved Instances. Create an Amazon EBS volume and mount it to the Reserved Instances."}, "option_flag": false}, {"option_text": {"zhcn": "在亚马逊EC2 Spot实例上通过Amazon SageMaker笔记本对模型进行评分。创建亚马逊弹性文件系统（Amazon EFS）并挂载至Spot实例。B（100%）", "enus": "Score the model by using Amazon SageMaker notebook on Amazon EC2 Spot Instances. Create an Amazon Elastic File System (Amazon EFS) file system and mount it to the Spot Instances.  B (100%)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "332", "question": {"enus": "A data scientist is implementing a deep learning neural network model for an object detection task on images. The data scientist wants to experiment with a large number of parallel hyperparameter tuning jobs to find hyperparameters that optimize compute time. The data scientist must ensure that jobs that underperform are stopped. The data scientist must allocate computational resources to well-performing hyperparameter configurations. The data scientist is using the hyperparameter tuning job to tune the stochastic gradient descent (SGD) learning rate, momentum, epoch, and mini-batch size. Which technique will meet these requirements with LEAST computational time? ", "zhcn": "一位数据科学家正在为图像目标检测任务部署深度学习神经网络模型。该数据科学家希望通过并行运行大量超参数调优任务，寻找能最大化计算效率的最佳参数组合。在此过程中，需及时终止表现不佳的训练任务，并将计算资源动态分配给表现优异的参数配置。本次超参数调优主要针对随机梯度下降法（SGD）的学习率、动量参数、训练轮次及小批量样本规模。若要满足上述需求且最大限度缩短计算时间，应采用下列哪种技术方案？"}, "option": [{"option_text": {"zhcn": "网格搜索", "enus": "Grid search"}, "option_flag": false}, {"option_text": {"zhcn": "随机寻优", "enus": "Random search"}, "option_flag": false}, {"option_text": {"zhcn": "贝叶斯优化", "enus": "Bayesian optimization"}, "option_flag": false}, {"option_text": {"zhcn": "超频优选（Hyperband Most Voted）\n\n注：采用\"超频\"对应\"Hyper\"的技术感，\"优选\"对应\"Most Voted\"的集体决策内涵，既保留算法领域特性，又通过四字格提升中文韵律美感。专有名词部分保留英文原称置于括号内，符合学术规范。", "enus": "Hyperband Most Voted"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "333", "question": {"enus": "An agriculture company wants to improve crop yield forecasting for the upcoming season by using crop yields from the last three seasons. The company wants to compare the performance of its new scikit-learn model to the benchmark. A data scientist needs to package the code into a container that computes both the new model forecast and the benchmark. The data scientist wants AWS to be responsible for the operational maintenance of the container. Which solution will meet these requirements? ", "zhcn": "一家农业公司希望利用过去三个季度的作物产量数据，提升对新一季作物产量的预测精度。该公司计划将其新开发的scikit-learn模型与基准模型进行性能比较。一位数据科学家需要将相关代码封装至容器中，使其能够同时运行新模型预测与基准模型计算。该数据科学家希望由AWS负责容器的运维管理。何种解决方案可满足上述需求？"}, "option": [{"option_text": {"zhcn": "将代码打包为适用于 Amazon SageMaker scikit-learn 容器的训练脚本。", "enus": "Package the code as the training script for an Amazon SageMaker scikit-learn container."}, "option_flag": false}, {"option_text": {"zhcn": "将代码封装至定制容器中，随后把容器推送至亚马逊弹性容器仓库（Amazon ECR）。", "enus": "Package the code into a custom-built container. Push the container to Amazon Elastic Container Registry (Amazon ECR)."}, "option_flag": false}, {"option_text": {"zhcn": "将代码封装至定制容器中，随后将该容器推送至AWS Fargate服务平台。", "enus": "Package the code into a custom-built container. Push the container to AWS Fargate."}, "option_flag": false}, {"option_text": {"zhcn": "通过扩展亚马逊SageMaker的scikit-learn容器对代码进行封装。投票结果：D选项（50%）获最高支持，A选项（33%）次之，C选项（17%）位列第三。", "enus": "Package the code by extending an Amazon SageMaker scikit-learn container. Most Voted  D (50%)  A (33%)  C (17%)"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "334", "question": {"enus": "A cybersecurity company is collecting on-premises server logs, mobile app logs, and IoT sensor data. The company backs up the ingested data in an Amazon S3 bucket and sends the ingested data to Amazon OpenSearch Service for further analysis. Currently, the company has a custom ingestion pipeline that is running on Amazon EC2 instances. The company needs to implement a new serverless ingestion pipeline that can automatically scale to handle sudden changes in the data flow. Which solution will meet these requirements MOST cost-effectively? ", "zhcn": "一家网络安全公司正在采集本地服务器日志、移动应用日志及物联网传感器数据。该公司将采集的数据备份至亚马逊S3存储桶，并传送至亚马逊OpenSearch服务进行深度分析。当前其采用的自定义数据摄取管道运行于亚马逊EC2实例之上。现需构建一套全新的无服务器数据摄取管道，该管道需具备自动扩展能力以应对数据流的突发波动。在满足这些需求的前提下，何种解决方案能实现最优成本效益？"}, "option": [{"option_text": {"zhcn": "创建两条亚马逊数据火线（Amazon Data Firehose）传输流，用于将数据分别传送至S3存储桶与OpenSearch服务。配置数据源以使其向这两条传输流发送数据。", "enus": "Create two Amazon Data Firehose delivery streams to send data to the S3 bucket and OpenSearch Service. Configure the data sources to send data to the delivery streams."}, "option_flag": false}, {"option_text": {"zhcn": "创建一条Amazon Kinesis数据流。  \n设立两条Amazon Data Firehose传输流，分别将数据传送至S3存储桶与OpenSearch服务。  \n将两条传输流与数据流建立连接。  \n配置各数据源，使其向数据流持续输送数据。", "enus": "Create one Amazon Kinesis data stream. Create two Amazon Data Firehose delivery streams to send data to the S3 bucket and OpenSearch Service. Connect the delivery streams to the data stream. Configure the data sources to send data to the data stream."}, "option_flag": false}, {"option_text": {"zhcn": "创建一条亚马逊数据火线（Amazon Data Firehose）传输流，将数据传送至OpenSearch服务。配置该传输流时，需将原始数据备份至S3存储桶。同时设置数据源，使其能够向传输流发送数据。", "enus": "Create one Amazon Data Firehose delivery stream to send data to OpenSearch Service. Configure the delivery stream to back up the raw data to the S3 bucket. Configure the data sources to send data to the delivery stream. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "创建一条Amazon Kinesis数据流。建立一条Amazon Data Firehose传输流，将数据发送至OpenSearch Service。配置该传输流将数据备份至S3存储桶。把传输流与数据流相连接。配置数据源使其向数据流发送数据。C (100%)", "enus": "Create one Amazon Kinesis data stream. Create one Amazon Data Firehose delivery stream to send data to OpenSearch Service. Configure the delivery stream to back up the data to the S3 bucket. Connect the delivery stream to the data stream. Configure the data sources to send data to the data stream.  C (100%)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "335", "question": {"enus": "A bank has collected customer data for 10 years in CSV format. The bank stores the data in an on-premises server. A data science team wants to use Amazon SageMaker to build and train a machine learning (ML) model to predict churn probability. The team will use the historical data. The data scientists want to perform data transformations quickly and to generate data insights before the team builds a model for production. Which solution will meet these requirements with the LEAST development effort? ", "zhcn": "一家银行以CSV格式积累了长达十年的客户数据，这些数据存储于本地服务器。数据科学团队计划利用Amazon SageMaker构建并训练机器学习模型，用于预测客户流失概率。团队将基于历史数据开展工作，希望在构建生产模型前快速完成数据转换并生成数据洞察。要满足上述需求且开发投入最少，应当采用哪种解决方案？"}, "option": [{"option_text": {"zhcn": "将数据直接上传至SageMaker Data Wrangler控制台，即可在平台内完成数据转换并生成深度分析报告。", "enus": "Upload the data into the SageMaker Data Wrangler console directly. Perform data transformations and generate insights within Data Wrangler."}, "option_flag": false}, {"option_text": {"zhcn": "将数据上传至Amazon S3存储桶，并授权SageMaker访问桶内数据。随后将数据从S3存储桶导入SageMaker Data Wrangler，通过该工具进行数据转换并生成分析洞察。此为最高票选方案。", "enus": "Upload the data into an Amazon S3 bucket. Allow SageMaker to access the data that is in the bucket. Import the data from the S3 bucket into SageMaker Data Wrangler. Perform data transformations and generate insights within Data Wrangler. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "将数据直接上传至SageMaker Data Wrangler控制台。授权SageMaker与Amazon QuickSight访问存储于Amazon S3存储桶中的数据。在Data Wrangler中执行数据转换操作，并将处理后的数据保存至另一个S3存储桶。最后通过QuickSight生成数据洞察分析结果。", "enus": "Upload the data into the SageMaker Data Wrangler console directly. Allow SageMaker and Amazon QuickSight to access the data that is in an Amazon S3 bucket. Perform data transformations in Data Wrangler and save the transformed data into a second S3 bucket. Use QuickSight to generate data insights."}, "option_flag": false}, {"option_text": {"zhcn": "将数据上传至Amazon S3存储桶，并授权SageMaker访问桶内数据。将数据从存储桶导入SageMaker Data Wrangler后，在Data Wrangler中进行数据转换处理。完成转换后将数据保存至第二个S3存储桶，最终通过SageMaker Studio笔记本生成数据洞察分析。", "enus": "Upload the data into an Amazon S3 bucket. Allow SageMaker to access the data that is in the bucket. Import the data from the bucket into SageMaker Data Wrangler. Perform data transformations in Data Wrangler. Save the data into a second S3 bucket. Use a SageMaker Studio notebook to generate data insights."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "336", "question": {"enus": "A media company wants to deploy a machine learning (ML) model that uses Amazon SageMaker to recommend new articles to the company’s readers. The company's readers are primarily located in a single city. The company notices that the heaviest reader traffic predictably occurs early in the morning, after lunch, and again after work hours. There is very little traffic at other times of day. The media company needs to minimize the time required to deliver recommendations to its readers. The expected amount of data that the API call will return for inference is less than 4 MB. Which solution will meet these requirements in the MOST cost-effective way? ", "zhcn": "一家传媒公司计划部署基于亚马逊SageMaker的机器学习模型，用于向读者推荐新闻资讯。该公司读者主要集中在单一城市，数据显示访问流量高峰呈现规律性分布：清晨、午休后及下班后时段最为密集，其余时段流量显著回落。为确保读者能即时获取推荐内容，公司需最大限度缩短推荐模型的响应延迟。已知API调用返回的推理数据量预计低于4MB。请问下列哪种解决方案能以最具成本效益的方式满足上述需求？"}, "option": [{"option_text": {"zhcn": "自动扩缩容实时推理", "enus": "Real-time inference with auto scaling"}, "option_flag": false}, {"option_text": {"zhcn": "无服务器推理与预置并发\n最高票选\nB（83%）\nA（17%）", "enus": "Serverless inference with provisioned concurrency Most Voted  B (83%)  A (17%)"}, "option_flag": true}, {"option_text": {"zhcn": "异步推理", "enus": "Asynchronous inference"}, "option_flag": false}, {"option_text": {"zhcn": "批量转换任务", "enus": "A batch transform task"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "337", "question": {"enus": "A machine learning (ML) engineer is using Amazon SageMaker automatic model tuning (AMT) to optimize a model's hyperparameters. The ML engineer notices that the tuning jobs take a long time to run. The tuning jobs continue even when the jobs are not significantly improving against the objective metric. The ML engineer needs the training jobs to optimize the hyperparameters more quickly. How should the ML engineer configure the SageMaker AMT data types to meet these requirements? ", "zhcn": "一位机器学习工程师正借助Amazon SageMaker自动模型调优功能优化模型超参数。该工程师发现调优任务运行耗时过长，且即使目标指标未出现显著提升时，调优进程仍持续进行。为加速超参数优化进程，该工程师应如何配置SageMaker自动模型调优的数据类型以满足需求？"}, "option": [{"option_text": {"zhcn": "将策略设定为贝叶斯值。", "enus": "Set Strategy to the Bayesian value."}, "option_flag": false}, {"option_text": {"zhcn": "将重试策略设置为1。", "enus": "Set RetryStrategy to a value of 1."}, "option_flag": false}, {"option_text": {"zhcn": "将参数范围设定为基于先前超参数任务所推断出的精确区间。", "enus": "Set ParameterRanges to the narrow range Inferred from previous hyperparameter jobs."}, "option_flag": false}, {"option_text": {"zhcn": "将 TrainingJobEarlyStoppingType 设为 AUTO 值。此为最高票选方案。", "enus": "Set TrainingJobEarlyStoppingType to the AUTO value. Most Voted"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "338", "question": {"enus": "A global bank requires a solution to predict whether customers will leave the bank and choose another bank. The bank is using a dataset to train a model to predict customer loss. The training dataset has 1,000 rows. The training dataset includes 100 instances of customers who left the bank. A machine learning (ML) specialist is using Amazon SageMaker Data Wrangler to train a churn prediction model by using a SageMaker training job. After training, the ML specialist notices that the model returns only false results. The ML specialist must correct the model so that it returns more accurate predictions. Which solution will meet these requirements? ", "zhcn": "一家国际银行需要一套解决方案，用于预测客户是否会流失并选择其他银行。该银行正利用某个数据集训练模型以预测客户流失情况，训练数据集包含1000条记录，其中涉及100例已流失客户。一位机器学习专家正在使用Amazon SageMaker Data Wrangler工具，通过SageMaker训练任务来训练客户流失预测模型。训练完成后，该专家发现模型仅返回错误结果。当前必须修正模型以提升预测准确性，请问下列哪种方案能满足需求？"}, "option": [{"option_text": {"zhcn": "在模型训练前，先运用异常检测技术剔除训练数据集中的离群值。", "enus": "Apply anomaly detection to remove outliers from the training dataset before training."}, "option_flag": false}, {"option_text": {"zhcn": "在模型训练前，对训练数据集采用合成少数类过采样技术（SMOTE）。最高票选方案。", "enus": "Apply Synthetic Minority Oversampling Technique (SMOTE) to the training dataset before training. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "在训练开始前，需对训练集的特征数据进行归一化处理。", "enus": "Apply normalization to the features of the training dataset before training."}, "option_flag": false}, {"option_text": {"zhcn": "在训练开始前，对训练集进行欠采样处理。", "enus": "Apply undersampling to the training dataset before training."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "339", "question": {"enus": "A banking company provides financial products to customers around the world. A machine learning (ML) specialist collected transaction data from internal customers. The ML specialist split the dataset into training, testing, and validation datasets. The ML specialist analyzed the training dataset by using Amazon SageMaker Clarify. The analysis found that the training dataset contained fewer examples of customers in the 40 to 55 year-old age group compared to the other age groups. Which type of pretraining bias did the ML specialist observe in the training dataset? ", "zhcn": "一家银行企业为全球客户提供金融产品。一位机器学习专家从内部客户处收集了交易数据，并将数据集划分为训练集、测试集和验证集。该专家运用Amazon SageMaker Clarify工具对训练数据集进行分析，发现与其他年龄段相比，40至55岁年龄组客户的样本数量明显偏少。请问这位机器学习专家在训练数据集中观察到的是哪种预训练偏差？"}, "option": [{"option_text": {"zhcn": "标签比例差异（DPL）", "enus": "Difference in proportions of labels (DPL)"}, "option_flag": false}, {"option_text": {"zhcn": "\"类别不均衡（CI）最高票选\"", "enus": "Class imbalance (CI) Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "条件性人口差异（CDD）", "enus": "Conditional demographic disparity (CDD)"}, "option_flag": false}, {"option_text": {"zhcn": "柯尔莫哥洛夫-斯米尔诺夫检验", "enus": "Kolmogorov-Smirnov (KS)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "340", "question": {"enus": "A tourism company uses a machine learning (ML) model to make recommendations to customers. The company uses an Amazon SageMaker environment and set hyperparameter tuning completion criteria to MaxNumberOfTrainingJobs. An ML specialist wants to change the hyperparameter tuning completion criteria. The ML specialist wants to stop tuning immediately after an internal algorithm determines that tuning job is unlikely to improve more than 1% over the objective metric from the best training job. Which completion criteria will meet this requirement? ", "zhcn": "一家旅游公司采用机器学习模型为客户提供个性化推荐。该公司基于亚马逊SageMaker平台构建了算法环境，并将超参数调优的终止条件设定为\"最大训练任务数\"。现有一位机器学习专家需要调整该终止条件，希望当系统内部算法判定调优结果相比最佳训练任务的目标指标提升空间不足1%时，立即终止调优流程。下列哪种终止条件符合这一需求？"}, "option": [{"option_text": {"zhcn": "最大运行时长（秒）", "enus": "MaxRuntimeInSeconds"}, "option_flag": false}, {"option_text": {"zhcn": "目标指标数值", "enus": "TargetObjectiveMetricValue"}, "option_flag": false}, {"option_text": {"zhcn": "CompleteOnConvergence 最高票当选", "enus": "CompleteOnConvergence Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "训练任务数量已达上限但未见改善", "enus": "MaxNumberOfTrainingJobsNotImproving"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "341", "question": {"enus": "A car company has dealership locations in multiple cities. The company uses a machine learning (ML) recommendation system to market cars to its customers. An ML engineer trained the ML recommendation model on a dataset that includes multiple attributes about each car. The dataset includes attributes such as car brand, car type, fuel efficiency, and price. The ML engineer uses Amazon SageMaker Data Wrangler to analyze and visualize data. The ML engineer needs to identify the distribution of car prices for a specific type of car. Which type of visualization should the ML engineer use to meet these requirements? ", "zhcn": "一家汽车公司在多个城市设有经销网点。该公司采用机器学习推荐系统向客户进行汽车营销。一位机器学习工程师基于包含每辆汽车多项属性的数据集，训练了该推荐模型。数据集涵盖品牌、车型、燃油效率及价格等属性。该工程师运用Amazon SageMaker Data Wrangler进行数据分析和可视化，现需针对特定车型分析其价格分布规律。为满足此需求，应采用何种可视化图表类型？"}, "option": [{"option_text": {"zhcn": "利用SageMaker Data Wrangler的散点图可视化功能，可以直观地观察汽车价格与车型之间的关联分布。", "enus": "Use the SageMaker Data Wrangler scatter plot visualization to inspect the relationship between the car price and type of car."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Data Wrangler的快速模型可视化功能，可迅速评估数据，并为汽车价格与车型生成重要性评分。", "enus": "Use the SageMaker Data Wrangler quick model visualization to quickly evaluate the data and produce importance scores for the car price and type of car."}, "option_flag": false}, {"option_text": {"zhcn": "借助SageMaker Data Wrangler的异常检测可视化功能，可精准定位特定特征中的异常数据点。", "enus": "Use the SageMaker Data Wrangler anomaly detection visualization to Identify outliers for the specific features."}, "option_flag": false}, {"option_text": {"zhcn": "借助SageMaker Data Wrangler的直方图可视化功能，可清晰呈现特定特征的数值分布范围。", "enus": "Use the SageMaker Data Wrangler histogram visualization to inspect the range of values for the specific feature.  Most Voted"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "342", "question": {"enus": "A media company is building a computer vision model to analyze images that are on social media. The model consists of CNNs that the company trained by using images that the company stores in Amazon S3. The company used an Amazon SageMaker training job in File mode with a single Amazon EC2 On-Demand Instance. Every day, the company updates the model by using about 10,000 images that the company has collected in the last 24 hours. The company configures training with only one epoch. The company wants to speed up training and lower costs without the need to make any code changes. Which solution will meet these requirements? ", "zhcn": "一家传媒公司正构建计算机视觉模型，用于分析社交媒体上的图像。该模型基于卷积神经网络，其训练数据来自公司存储在Amazon S3中的图像资源。公司目前采用Amazon SageMaker训练任务的文件模式，配合单台按需分配的Amazon EC2实例进行模型训练。每日，公司会使用过去24小时内收集的约一万张新图像更新模型，并将训练周期设定为单次迭代。为在无需修改代码的前提下加速训练过程并降低成本，下列哪项方案能同时满足这两项需求？"}, "option": [{"option_text": {"zhcn": "请将SageMaker训练任务配置为使用管道模式，而非文件模式。通过管道实时读取数据流。", "enus": "Instead of File mode, configure the SageMaker training job to use Pipe mode. Ingest the data from a pipe."}, "option_flag": false}, {"option_text": {"zhcn": "相较于文件模式，建议将SageMaker训练任务配置调整为快速文件模式，无需其他改动。此为最高票推荐方案。", "enus": "Instead of File mode, configure the SageMaker training job to use FastFile mode with no other changes. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "“请将SageMaker训练任务配置为使用竞价型实例，而非按需实例。其余设置保持不变。”", "enus": "Instead of On-Demand Instances, configure the SageMaker training job to use Spot Instances. Make no other changes,"}, "option_flag": false}, {"option_text": {"zhcn": "可将SageMaker训练任务配置为使用竞价实例替代按需实例，并启用模型检查点功能。", "enus": "Instead of On-Demand Instances, configure the SageMaker training job to use Spot Instances, implement model checkpoints."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "343", "question": {"enus": "A telecommunications company has deployed a machine learning model using Amazon SageMaker. The model identifies customers who are likely to cancel their contract when calling customer service. These customers are then directed to a specialist service team. The model has been trained on historical data from multiple years relating to customer contracts and customer service interactions in a single geographic region. The company is planning to launch a new global product that will use this model. Management is concerned that the model might incorrectly direct a large number of calls from customers in regions without historical data to the specialist service team. Which approach would MOST effectively address this issue? ", "zhcn": "一家电信公司运用亚马逊SageMaker平台部署了机器学习模型。该模型能识别出那些在致电客服时可能解约的客户，并将其转接至专家服务团队。此模型基于单一地理区域内多年积累的客户合同及客服互动历史数据训练而成。公司计划推出一项采用该模型的全球新产品，但管理层担忧模型可能误将来自缺乏历史数据地区的客户来电大量转接至专家团队。下列哪种方法能最高效地解决此问题？"}, "option": [{"option_text": {"zhcn": "启用模型端点的Amazon SageMaker模型监控数据捕获功能。基于训练数据集创建监控基线。设定定期监控任务。当区域客户数据的数值分布未通过基线漂移检验时，通过Amazon CloudWatch向数据科学家发送告警。利用更广泛的数据源重新评估训练集并优化模型。最高票选方案", "enus": "Enable Amazon SageMaker Model Monitor data capture on the model endpoint. Create a monitoring baseline on the training dataset. Schedule monitoring jobs. Use Amazon CloudWatch to alert the data scientists when the numerical distance of regional customer data fails the baseline drift check. Reevaluate the training set with the larger data source and retrain the model. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "在模型端点上启用Amazon SageMaker Debugger功能。创建自定义规则以衡量与基准训练数据集的偏差程度。通过Amazon CloudWatch在规则触发时向数据科学家发送告警通知。利用更庞大的数据源重新评估训练集，并对模型进行迭代训练。", "enus": "Enable Amazon SageMaker Debugger on the model endpoint. Create a custom rule to measure the variance from the baseline training dataset. Use Amazon CloudWatch to alert the data scientists when the rule is invoked. Reevaluate the training set with the larger data source and retrain the model."}, "option_flag": false}, {"option_text": {"zhcn": "将转接至专家服务团队的所有客户通话录音存档于Amazon S3中。设定定时监控任务，抓取全部真阳性与真阴性判定结果，将其与训练数据集进行关联比对并计算准确率。当准确率出现下降时，通过Amazon CloudWatch向数据科学家发送预警。结合专家服务团队提供的增量数据重新评估训练集，并对模型进行迭代训练。", "enus": "Capture all customer calls routed to the specialist service team in Amazon S3. Schedule a monitoring job to capture all the true positives and true negatives, correlate them to the training dataset, and calculate the accuracy. Use Amazon CloudWatch to alert the data scientists when the accuracy decreases. Reevaluate the training set with the additional data from the specialist service team and retrain the model."}, "option_flag": false}, {"option_text": {"zhcn": "在模型端点上启用Amazon CloudWatch监控服务。通过Amazon CloudWatch日志捕获指标数据并传输至Amazon S3存储。将监测结果与训练数据基线进行比对分析，若发现偏离幅度超过区域客户差异阈值，则需重新评估训练集并优化模型。", "enus": "Enable Amazon CloudWatch on the model endpoint. Capture metrics using Amazon CloudWatch Logs and send them to Amazon S3. Analyze the monitored results against the training data baseline. When the variance from the baseline exceeds the regional customer variance, reevaluate the training set and retrain the model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "344", "question": {"enus": "A machine learning (ML) engineer is creating a binary classification model. The ML engineer will use the model in a highly sensitive environment. There is no cost associated with missing a positive label. However, the cost of making a false positive inference is extremely high. What is the most important metric to optimize the model for in this scenario? ", "zhcn": "机器学习工程师正在构建一个用于高敏感场景的二元分类模型。该场景下漏报阳性标签不会产生代价，但误判为阳性的代价极其高昂。在此情况下，优化模型时应优先考量哪个关键指标？"}, "option": [{"option_text": {"zhcn": "精准", "enus": "Accuracy"}, "option_flag": false}, {"option_text": {"zhcn": "“精准之选”", "enus": "Precision Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "忆起", "enus": "Recall"}, "option_flag": false}, {"option_text": {"zhcn": "一级方程式赛车", "enus": "F1"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "345", "question": {"enus": "An ecommerce company discovers that the search tool for the company's website is not presenting the top search results to customers. The company needs to resolve the issue so the search tool will present results that customers are most likely to want to purchase. Which solution will meet this requirement with the LEAST operational effort? ", "zhcn": "一家电商企业发现，其网站搜索工具未能向客户展示最相关的搜索结果。该公司需要解决此问题，以确保搜索工具能呈现客户最可能有意向购买的商品。在满足这一需求的前提下，何种解决方案所需的运营投入最低？"}, "option": [{"option_text": {"zhcn": "运用Amazon SageMaker BlazingText算法，通过查询扩展技术为搜索结果增添语境信息。", "enus": "Use the Amazon SageMaker BlazingText algorithm to add context to search results through query expansion."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊SageMaker平台的XGBoost算法优化候选项目排序效果。", "enus": "Use the Amazon SageMaker XGBoost algorithm to improve candidate ranking."}, "option_flag": false}, {"option_text": {"zhcn": "采用亚马逊云搜索服务，并按搜索相关度得分对结果进行排序。最多赞同", "enus": "Use Amazon CloudSearch and sort results by the search relevance score. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "利用亚马逊云搜索服务，并按照地理位置对结果进行排序。", "enus": "Use Amazon CloudSearch and sort results by the geographic location."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "346", "question": {"enus": "A machine learning (ML) specialist collected daily product usage data for a group of customers. The ML specialist appended customer metadata such as age and gender from an external data source. The ML specialist wants to understand product usage patterns for each day of the week for customers in specific age groups. The ML specialist creates two categorical features named dayofweek and binned_age, respectively. Which approach should the ML specialist use discover the relationship between the two new categorical features? ", "zhcn": "一位机器学习专家收集了一组客户的日常产品使用数据，并从外部数据源补充了客户的年龄、性别等元数据。为探究特定年龄段客户在一周内各天的产品使用规律，该专家创建了名为\"dayofweek\"（星期几）和\"binned_age\"（分段年龄）的两个分类特征。此时应采用何种分析方法来揭示这两个分类特征之间的关联性？"}, "option": [{"option_text": {"zhcn": "请绘制一张关于星期几与年龄段分布的散点图。", "enus": "Create a scatterplot for day_of_week and binned_age."}, "option_flag": false}, {"option_text": {"zhcn": "为\"day_of_week\"与\"binned_age\"创建交叉分析表。最多票选", "enus": "Create crosstabs for day_of_week and binned_age. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "为“星期几”和“年龄分段”生成文字云图。", "enus": "Create word clouds for day_of_week and binned_age."}, "option_flag": false}, {"option_text": {"zhcn": "为\"星期几\"与\"年龄分段\"绘制箱线图。", "enus": "Create a boxplot for day_of_week and binned_age."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "347", "question": {"enus": "A company needs to develop a model that uses a machine learning (ML) model for risk analysis. An ML engineer needs to evaluate the contribution each feature of a training dataset makes to the prediction of the target variable before the ML engineer selects features. How should the ML engineer predict the contribution of each feature? ", "zhcn": "一家公司需要开发一个利用机器学习模型进行风险分析的解决方案。在筛选特征变量之前，机器学习工程师需先评估训练数据集中每个特征对目标变量预测的贡献度。请问工程师应当如何科学预测各特征的贡献程度？"}, "option": [{"option_text": {"zhcn": "利用Amazon SageMaker Data Wrangler的多重共线性检测功能，结合主成分分析（PCA）算法，可计算数据集在特征空间多维方向上的方差分布。", "enus": "Use the Amazon SageMaker Data Wrangler multicollinearity measurement features and the principal component analysis (PCA) algorithm to calculate the variance of the dataset along multiple directions in the feature space."}, "option_flag": false}, {"option_text": {"zhcn": "运用亚马逊SageMaker数据整理器的快速模型可视化功能，筛选出特征重要性评分介于0.5至1之间的结果。此为最高票选方案。", "enus": "Use an Amazon SageMaker Data Wrangler quick model visualization to find feature importance scores that are between 0.5 and 1. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon SageMaker Data Wrangler的偏差报告，可识别特征工程相关数据中可能存在的潜在偏差。", "enus": "Use the Amazon SageMaker Data Wrangler bias report to identify potential biases in the data related to feature engineering."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker Data Wrangler数据流构建并优化数据预处理流程，同时手动添加特征评分。", "enus": "Use an Amazon SageMaker Data Wrangler data flow to create and modify a data preparation pipeline. Manually add the feature scores."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "348", "question": {"enus": "A company is building a predictive maintenance system using real-time data from devices on remote sites. There is no AWS Direct Connect connection or VPN connection between the sites and the company's VPC. The data needs to be ingested in real time from the devices into Amazon S3. Transformation is needed to convert the raw data into clean .csv data to be fed into the machine learning (ML) model. The transformation needs to happen during the ingestion process. When transformation fails, the records need to be stored in a specific location in Amazon S3 for human review. The raw data before transformation also needs to be stored in Amazon S3. How should an ML specialist architect the solution to meet these requirements with the LEAST effort? ", "zhcn": "某公司正基于远程站点设备采集的实时数据构建预测性维护系统。站点与公司虚拟私有云（VPC）之间未配置AWS Direct Connect专线或VPN连接。需将设备生成的原始数据实时摄取至Amazon S3存储服务，并在数据注入过程中完成格式转换，将其处理为可供机器学习模型使用的规整CSV格式。若转换失败，相关记录需存储至Amazon S3的指定路径供人工核查，且转换前的原始数据也需保留在Amazon S3中。机器学习架构师应如何以最小工作量设计满足上述需求的解决方案？"}, "option": [{"option_text": {"zhcn": "将Amazon Data Firehose与Amazon S3搭配使用，并以后者作为数据目的地。配置Firehose调用AWS Lambda函数实现数据格式转换，同时启用Firehose的源记录备份功能。", "enus": "Use Amazon Data Firehose with Amazon S3 as the destination. Configure Firehose to invoke an AWS Lambda function for data transformation. Enable source record backup on Firehose."}, "option_flag": true}, {"option_text": {"zhcn": "采用Amazon Managed Streaming for Apache Kafka（全托管式Apache Kafka服务），在Amazon Elastic Container Service（亚马逊弹性容器服务，简称Amazon ECS）中部署工作节点，将数据从Kafka代理实时传输至Amazon S3存储服务，并在此过程中完成数据格式转换。需配置工作节点，将原始数据与转换失败的数据分别存储至不同的S3存储桶中。", "enus": "Use Amazon Managed Streaming for Apache Kafka. Set up workers in Amazon Elastic Container Service (Amazon ECS) to move data from Kafka brokers to Amazon S3 while transforming it. Configure workers to store raw and unsuccessfully transformed data in different S3 buckets."}, "option_flag": false}, {"option_text": {"zhcn": "以Amazon S3为目标端配置Amazon Data Firehose服务，设定Firehose调用AWS Glue中的Apache Spark作业进行数据转换。启用源数据记录备份功能并配置错误日志存储路径。此为最高票选方案。", "enus": "Use Amazon Data Firehose with Amazon S3 as the destination. Configure Firehose to invoke an Apache Spark job in AWS Glue for data transformation. Enable source record backup and configure the error prefix. Most Voted"}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon Data Firehose前接入Amazon Kinesis数据流，通过Kinesis数据流与AWS Lambda的协同运作，将原始数据存储至Amazon S3。同时配置Firehose服务，使其调用Lambda函数进行数据转换处理，并以Amazon S3作为最终存储目的地。", "enus": "Use Amazon Kinesis Data Streams in front of Amazon Data Firehose. Use Kinesis Data Streams with AWS Lambda to store raw data in Amazon S3. Configure Firehose to invoke a Lambda function for data transformation with Amazon S3 as the destination."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "349", "question": {"enus": "A company wants to use machine learning (ML) to improve its customer churn prediction model. The company stores data in an Amazon Redshift data warehouse. A data science team wants to use Amazon Redshift machine learning (Amazon Redshift ML) to build a model and run predictions for new data directly within the data warehouse. Which combination of steps should the company take to use Amazon Redshift ML to meet these requirements? (Choose three.) ", "zhcn": "某公司计划运用机器学习技术优化其客户流失预测模型。该企业将数据存储于Amazon Redshift数据仓库中，数据科学团队希望借助Amazon Redshift机器学习功能，直接在数据仓库内构建模型并对新数据执行预测。为实现这一目标，该公司应采取以下哪三项组合步骤？（请选择三项）"}, "option": [{"option_text": {"zhcn": "为构建客户流失预测模型，需明确特征变量与目标变量。", "enus": "Define the feature variables and target variable for the churn prediction model. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "运用SOL EXPLAIN_MODEL函数执行预测分析。", "enus": "Use the SOL EXPLAIN_MODEL function to run predictions."}, "option_flag": false}, {"option_text": {"zhcn": "编写一条创建模型的CREATE MODEL SQL语句。最高票选方案", "enus": "Write a CREATE MODEL SQL statement to create a model. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Redshift Spectrum对模型进行训练。", "enus": "Use Amazon Redshift Spectrum to train the model."}, "option_flag": false}, {"option_text": {"zhcn": "请将训练数据手动导出至Amazon S3。", "enus": "Manually export the training data to Amazon S3."}, "option_flag": false}, {"option_text": {"zhcn": "运用SQL预测函数执行数据推演，采纳最高票选结果。", "enus": "Use the SQL prediction function to run predictions. Most Voted"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "ACF"}, {"id": "350", "question": {"enus": "A company’s machine learning (ML) team needs to build a system that can detect whether people in a collection of images are wearing the company’s logo. The company has a set of labeled training data. Which algorithm should the ML team use to meet this requirement? ", "zhcn": "某公司的机器学习团队需构建一套系统，用于检测图集中的人物是否佩戴公司标识。目前企业已具备标注完成的训练数据集。为达成此目标，该团队应采用何种算法更为适宜？"}, "option": [{"option_text": {"zhcn": "主成分分析（PCA）", "enus": "Principal component analysis (PCA)"}, "option_flag": false}, {"option_text": {"zhcn": "循环神经网络（RNN）", "enus": "Recurrent neural network (RNN)"}, "option_flag": false}, {"option_text": {"zhcn": "K-近邻算法（k-NN）", "enus": "К-nearest neighbors (k-NN)"}, "option_flag": false}, {"option_text": {"zhcn": "卷积神经网络（CNN） 高票精选", "enus": "Convolutional neural network (CNN) Most Voted"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "351", "question": {"enus": "A data scientist uses Amazon SageMaker Data Wrangler to obtain a feature summary from a dataset that the data scientist imported from Amazon S3. The data scientist notices that the prediction power for a dataset feature has a score of 1. What is the cause of the score? ", "zhcn": "数据科学家使用Amazon SageMaker Data Wrangler，对从Amazon S3导入的数据集进行特征摘要分析时，发现某一数据特征的预测力评分为1。此评分结果的可能成因是什么？"}, "option": [{"option_text": {"zhcn": "导入数据集中出现了目标变量泄露。多数投票结果如此。", "enus": "Target leakage occurred in the imported dataset. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "数据科学家并未对训练集与验证集的划分进行精细调整。", "enus": "The data scientist did not fine-tune the training and validation split."}, "option_flag": false}, {"option_text": {"zhcn": "数据科学家采用的SageMaker Data Wrangler算法未能为每个特征找到最优的模型拟合方案，从而无法准确评估其预测效力。", "enus": "The SageMaker Data Wrangler algorithm that the data scientist used did not find an optimal model fit for each feature to calculate the prediction power."}, "option_flag": false}, {"option_text": {"zhcn": "数据科学家未能对特征进行充分处理，以致无法精确评估其预测效力。", "enus": "The data scientist did not process the features enough to accurately calculate prediction power."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "352", "question": {"enus": "A data scientist is conducting exploratory data analysis (EDA) on a dataset that contains information about product suppliers. The dataset records the country where each product supplier is located as a two-letter text code. For example, the code for New Zealand is \"NZ.\" The data scientist needs to transform the country codes for model training. The data scientist must choose the solution that will result in the smallest increase in dimensionality. The solution must not result in any information loss. Which solution will meet these requirements? ", "zhcn": "一位数据科学家正在对包含产品供应商信息的数据集进行探索性数据分析（EDA）。该数据集以双字母文本代码的形式记录每位产品供应商所在的国家，例如新西兰的代码为\"NZ\"。为进行模型训练，数据科学家需对国家代码进行转换，且必须选择能实现维度增加最小的解决方案，同时确保不丢失任何信息。何种方案可满足这些要求？"}, "option": [{"option_text": {"zhcn": "添加一个包含完整国家名称的新数据列。", "enus": "Add a new column of data that includes the full country name."}, "option_flag": false}, {"option_text": {"zhcn": "将国家代码通过相似性编码转化为数值变量。", "enus": "Encode the country codes into numeric variables by using similarity encoding."}, "option_flag": false}, {"option_text": {"zhcn": "将国家代码与对应的大洲名称进行映射。", "enus": "Map the country codes to continent names."}, "option_flag": false}, {"option_text": {"zhcn": "将国家代码通过独热编码转换为数值变量。最高票当选。", "enus": "Encode the country codes into numeric variables by using one-hot encoding. Most Voted"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "353", "question": {"enus": "A data scientist is building a new model for an ecommerce company. The model will predict how many minutes it will take to deliver a package. During model training, the data scientist needs to evaluate model performance. Which metrics should the data scientist use to meet this requirement? (Choose two.) ", "zhcn": "一位数据科学家正在为某电商企业构建新模型，该模型旨在预测包裹投递所需时长。在模型训练过程中，需对模型性能进行评估。为达成此目标，该数据科学家应采用哪两项评估指标？（请选择两项）"}, "option": [{"option_text": {"zhcn": "推理延迟", "enus": "InferenceLatency"}, "option_flag": false}, {"option_text": {"zhcn": "均方误差（MSE） 获赞最多", "enus": "Mean squared error (MSE) Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "均方根误差（RMSE） 获赞最多", "enus": "Root mean squared error (RMSE) Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "精准", "enus": "Precision"}, "option_flag": false}, {"option_text": {"zhcn": "精准", "enus": "Accuracy"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BC"}, {"id": "354", "question": {"enus": "A machine learning (ML) specialist is developing a model for a company. The model will classify and predict sequences of objects that are displayed in a video. The ML specialist decides to use a hybrid architecture that consists of a convolutional neural network (CNN) followed by a classifier three-layer recurrent neural network (RNN). The company developed a similar model previously but trained the model to classify a different set of objects. The ML specialist wants to save time by using the previously trained model and adapting the model for the current use case and set of objects. Which combination of steps will accomplish this goal with the LEAST amount of effort? (Choose two.) ", "zhcn": "一位机器学习专家正为公司开发一款视频物体序列分类与预测模型。该专家决定采用由卷积神经网络（CNN）与三层循环神经网络（RNN）分类器构成的混合架构。该公司曾开发过类似模型，但当时训练所用物体类别与当前不同。为节省时间，专家计划基于已有模型进行适应性调整。以下哪两种步骤组合能以最小工作量实现这一目标？（请选择两项）"}, "option": [{"option_text": {"zhcn": "重新初始化整个卷积神经网络的权重。利用新的物体数据集，对网络进行图像分类任务的再次训练。", "enus": "Reinitialize the weights of the entire CNN. Retrain the CNN on the classification task by using the new set of objects."}, "option_flag": false}, {"option_text": {"zhcn": "重新初始化整个网络的权重。利用新的对象集合，对网络进行整体重构，以完成预测任务的训练。", "enus": "Reinitialize the weights of the entire network. Retrain the entire network on the prediction task by using the new set of objects."}, "option_flag": false}, {"option_text": {"zhcn": "重新初始化整个循环神经网络的权重参数，利用新增对象集合对模型进行完整重训练，以优化其预测性能。", "enus": "Reinitialize the weights of the entire RNN. Retrain the entire model on the prediction task by using the new set of objects."}, "option_flag": false}, {"option_text": {"zhcn": "重新初始化卷积神经网络末层全连接层的权重参数，并采用新版对象集对网络进行分类任务的再训练。最高票当选方案。", "enus": "Reinitialize the weights of the last fully connected layer of the CNN. Retrain the CNN on the classification task by using the new set of objects. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "重新初始化循环神经网络最后一层的权重参数，并基于新增对象集对模型进行预测任务的完整重训练。采纳最高票选方案。", "enus": "Reinitialize the weights of the last layer of the RNN. Retrain the entire model on the prediction task by using the new set of objects. Most Voted"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "DE"}, {"id": "355", "question": {"enus": "A company distributes an online multiple-choice survey to several thousand people. Respondents to the survey can select multiple options for each question. A machine learning (ML) engineer needs to comprehensively represent every response from all respondents in a dataset. The ML engineer will use the dataset to train a logistic regression model. Which solution will meet these requirements? ", "zhcn": "某公司向数千人分发了一份在线选择题问卷。受访者可为每个问题选择多个选项。一位机器学习工程师需要将全体受访者的每项回答完整呈现在数据集中。该工程师将使用该数据集训练逻辑回归模型。下列哪种方案能满足这些要求？"}, "option": [{"option_text": {"zhcn": "对问卷中每道题目的所有选项进行独热编码处理。最高票当选。", "enus": "Perform one-hot encoding on every possible option for each question of the survey. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "对每位受访者在每道题目中所作的选择进行归类整理。", "enus": "Perform binning on all the answers each respondent selected for each question."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊土耳其机器人（Amazon Mechanical Turk）为每组可能的回答生成分类标签。", "enus": "Use Amazon Mechanical Turk to create categorical labels for each set of possible responses."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon Textract为每组可能的回答生成数字特征。", "enus": "Use Amazon Textract to create numeric features for each set of possible responses."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "356", "question": {"enus": "A manufacturing company stores production volume data in a PostgreSQL database. The company needs an end-to-end solution that will give business analysts the ability to prepare data for processing and to predict future production volume based the previous year's production volume. The solution must not require the company to have coding knowledge. Which solution will meet these requirements with the LEAST effort? ", "zhcn": "一家制造企业将其产量数据存储于PostgreSQL数据库中。该公司需要一套端到端的解决方案，使业务分析师能够为数据处理做好准备，并依据往年产量预测未来生产规模。该方案必须确保企业无需具备编程知识。哪种方案能以最小投入满足这些需求？"}, "option": [{"option_text": {"zhcn": "运用AWS数据库迁移服务（AWS DMS）将PostgreSQL数据库中的数据迁移至Amazon S3存储桶。随后创建Amazon EMR集群读取S3存储桶中的数据并进行预处理，最终通过Amazon SageMaker Studio平台完成预测模型的构建工作。", "enus": "Use AWS Database Migration Service (AWS DMS) to transfer the data from the PostgreSQL database to an Amazon S3 bucket. Create an Amazon EMR duster to read the S3 bucket and perform the data preparation. Use Amazon SageMaker Studio for the prediction modeling."}, "option_flag": false}, {"option_text": {"zhcn": "使用AWS Glue DataBrew从PostgreSQL数据库中读取数据并进行数据预处理，通过Amazon SageMaker Canvas平台实现预测建模。此为最高票选方案。", "enus": "Use AWS Glue DataBrew to read the data that is in the PostgreSQL database and to perform the data preparation. Use Amazon SageMaker Canvas for the prediction modeling. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "使用AWS数据库迁移服务（AWS DMS）将PostgreSQL数据库中的数据迁移至Amazon S3存储桶。通过AWS Glue读取S3存储桶内的数据并进行预处理，最终借助Amazon SageMaker Canvas平台完成预测模型的构建。", "enus": "Use AWS Database Migration Service (AWS DMS) to transfer the data from the PostgreSQL database to an Amazon S3 bucket. Use AWS Glue to read the data in the S3 bucket and to perform the data preparation. Use Amazon SageMaker Canvas for the prediction modeling."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue DataBrew读取PostgreSQL数据库中的数据并进行数据预处理，随后通过Amazon SageMaker Studio平台开展预测建模工作。", "enus": "Use AWS Glue DataBrew to read the data that is in the PostgreSQL database and to perform the data preparation. Use Amazon SageMaker Studio for the prediction modeling."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "357", "question": {"enus": "A data scientist needs to create a model for predictive maintenance. The model will be based on historical data to identify rare anomalies in the data. The historical data is stored in an Amazon S3 bucket. The data scientist needs to use Amazon SageMaker Data Wrangler to ingest the data. The data scientist also needs to perform exploratory data analysis (EDA) to understand the statistical properties of the data. Which solution will meet these requirements with the LEAST amount of compute resources? ", "zhcn": "数据科学家需要构建一个预测性维护模型。该模型将基于历史数据识别其中的罕见异常。历史数据存储于Amazon S3存储桶中，数据科学家需使用Amazon SageMaker Data Wrangler进行数据摄取，同时还需开展探索性数据分析（EDA）以理解数据的统计特性。哪种方案能够以最少的计算资源满足这些需求？"}, "option": [{"option_text": {"zhcn": "使用“无”选项导入数据。", "enus": "Import the data by using the None option."}, "option_flag": false}, {"option_text": {"zhcn": "采用分层抽样方式导入数据。", "enus": "Import the data by using the Stratified option."}, "option_flag": false}, {"option_text": {"zhcn": "使用“前K项”选项导入数据，并依据领域知识推断K的取值。", "enus": "Import the data by using the First K option. Infer the value of K from domain knowledge."}, "option_flag": true}, {"option_text": {"zhcn": "通过随机化选项导入数据，并依据领域知识推断随机样本规模。", "enus": "Import the data by using the Randomized option. Infer the random size from domain knowledge."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "358", "question": {"enus": "An ecommerce company has observed that customers who use the company's website rarely view items that the website recommends to customers. The company wants to recommend items to customers that customers are more likely to want to purchase. Which solution will meet this requirement in the SHORTEST amount of time? ", "zhcn": "一家电商公司发现，其网站向顾客推荐的商品很少被浏览。为提升推荐商品的购买转化率，该公司希望在最短时间内找到最有效的解决方案。下列哪种方式能最快实现这一目标？"}, "option": [{"option_text": {"zhcn": "将公司网站部署于亚马逊EC2加速计算实例，可显著提升网站响应速度。", "enus": "Host the company's website on Amazon EC2 Accelerated Computing instances to increase the website response speed."}, "option_flag": false}, {"option_text": {"zhcn": "将公司网站部署于亚马逊EC2 GPU实例之上，以提升网站搜索工具的响应速度。", "enus": "Host the company's website on Amazon EC2 GPU-based instances to increase the speed of the website's search tool."}, "option_flag": false}, {"option_text": {"zhcn": "将Amazon Personalize整合至公司官网，为顾客提供个性化推荐服务。", "enus": "Integrate Amazon Personalize into the company's website to provide customers with personalized recommendations."}, "option_flag": true}, {"option_text": {"zhcn": "利用亚马逊 SageMaker 训练神经协同过滤（NCF）模型，实现个性化商品推荐。", "enus": "Use Amazon SageMaker to train a Neural Collaborative Filtering (NCF) model to make product recommendations."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "359", "question": {"enus": "A machine learning (ML) engineer is preparing a dataset for a classification model. The ML engineer notices that some continuous numeric features have a significantly greater value than most other features. A business expert explains that the features are independently informative and that the dataset is representative of the target distribution. After training, the model's inferences accuracy is lower than expected. Which preprocessing technique will result in the GREATEST increase of the model's inference accuracy? ", "zhcn": "一位机器学习工程师正在为分类模型准备数据集。他注意到某些连续数值型特征的量级远高于其他特征。业务专家解释称这些特征各自具有独立信息价值，且数据集能代表目标分布。然而模型训练后的推理准确率却低于预期。下列哪种预处理技术能最大程度提升模型的推理准确率？"}, "option": [{"option_text": {"zhcn": "化解棘手特征，使其归于和谐。", "enus": "Normalize the problematic features."}, "option_flag": true}, {"option_text": {"zhcn": "**启动问题功能。**", "enus": "Bootstrap the problematic features."}, "option_flag": false}, {"option_text": {"zhcn": "去除有问题的功能。", "enus": "Remove the problematic features."}, "option_flag": false}, {"option_text": {"zhcn": "推演合成特征。", "enus": "Extrapolate synthetic features."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "360", "question": {"enus": "A manufacturing company produces 100 types of steel rods. The rod types have varying material grades and dimensions. The company has sales data for the steel rods for the past 50 years. A data scientist needs to build a machine learning (ML) model to predict future sales of the steel rods. Which solution will meet this requirement in the MOST operationally efficient way? ", "zhcn": "一家钢铁制品公司生产百种规格的螺纹钢，其材质等级与尺寸参数各不相同。该公司拥有过去五十年间的螺纹钢销售数据，一位数据科学家需构建机器学习模型以预测未来销量。下列哪种解决方案能以最高运营效率满足此需求？"}, "option": [{"option_text": {"zhcn": "利用Amazon SageMaker的DeepAR预测算法，为所有产品构建统一预测模型。", "enus": "Use the Amazon SageMaker DeepAR forecasting algorithm to build a single model for all the products."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon SageMaker平台的DeepAR预测算法，为每款产品分别建立专属预测模型。", "enus": "Use the Amazon SageMaker DeepAR forecasting algorithm to build separate models for each product."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker Autopilot，为所有产品构建统一模型。", "enus": "Use Amazon SageMaker Autopilot to build a single model for all the products."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker Autopilot为每款产品分别构建专属模型。完成度：百分之百。", "enus": "Use Amazon SageMaker Autopilot to build separate models for each product.  A (100%)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "361", "question": {"enus": "A machine learning (ML) specialist is building a credit score model for a financial institution. The ML specialist has collected data for the previous 3 years of transactions and third-party metadata that is related to the transactions. After the ML specialist builds the initial model, the ML specialist discovers that the model has low accuracy for both the training data and the test data. The ML specialist needs to improve the accuracy of the model. Which solutions will meet this requirement? (Choose two.) ", "zhcn": "一位机器学习专家正为某金融机构构建信用评分模型。该专家已收集了过去三年的交易数据及与之相关的第三方元数据。在完成初始模型构建后，专家发现该模型对训练数据和测试数据的准确度均不理想。现需提升模型精准度，下列哪两项措施可达成此目标？（请选择两项）"}, "option": [{"option_text": {"zhcn": "增加对现有训练数据的处理轮次。进一步优化超参数配置。", "enus": "Increase the number of passes on the existing training data. Perform more hyperparameter tuning."}, "option_flag": true}, {"option_text": {"zhcn": "增强正则化强度，减少特征组合的使用。", "enus": "Increase the amount of regularization. Use fewer feature combinations."}, "option_flag": false}, {"option_text": {"zhcn": "增添特定领域的新功能，采用更复杂的模型架构。", "enus": "Add new domain-specific features. Use more complex models."}, "option_flag": true}, {"option_text": {"zhcn": "减少特征组合数量。缩减数值属性分箱区间。", "enus": "Use fewer feature combinations. Decrease the number of numeric attribute bins."}, "option_flag": false}, {"option_text": {"zhcn": "减少训练数据样本的数量。降低对现有训练数据的遍历次数。AC（100%）", "enus": "Decrease the amount of training data examples. Reduce the number of passes on the existing training data.  AC (100%)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "AC"}, {"id": "362", "question": {"enus": "A data scientist uses Amazon SageMaker to perform hyperparameter tuning for a prototype machine leaming (ML) model. The data scientist's domain knowledge suggests that the hyperparameter is highly sensitive to changes. The optimal value, x, is in the 0.5 < x < 1.0 range. The data scientist's domain knowledge suggests that the optimal value is close to 1.0. The data scientist needs to find the optimal hyperparameter value with a minimum number of runs and with a high degree of consistent tuning conditions. Which hyperparameter scaling type should the data scientist use to meet these requirements? ", "zhcn": "一位数据科学家正借助Amazon SageMaker平台，为机器学习原型模型进行超参数调优。根据其专业领域的经验判断，该超参数对数值变化极为敏感，其最优解x应落在0.5至1.0的区间内，且极有可能趋近于1.0。在确保调优条件高度一致的前提下，该数据科学家需以最少的实验次数精准定位最优超参数值。请问，为达成此目标，应采用何种超参数缩放方式？"}, "option": [{"option_text": {"zhcn": "自动扩缩容", "enus": "Auto scaling"}, "option_flag": false}, {"option_text": {"zhcn": "线性扩展", "enus": "Linear scaling"}, "option_flag": false}, {"option_text": {"zhcn": "对数尺度", "enus": "Logarithmic scaling"}, "option_flag": false}, {"option_text": {"zhcn": "逆对数缩放", "enus": "Reverse logarithmic scaling"}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "363", "question": {"enus": "A data scientist uses Amazon SageMaker Data Wrangler to analyze and visualize data. The data scientist wants to refine a training dataset by selecting predictor variables that are strongly predictive of the target variable. The target variable correlates with other predictor variables. The data scientist wants to understand the variance in the data along various directions in the feature space. Which solution will meet these requirements? ", "zhcn": "一位数据科学家运用亚马逊SageMaker数据整理工具进行数据分析和可视化。为优化训练数据集，该科学家需筛选出对目标变量具有强预测力的特征变量。由于目标变量与其他特征变量存在相关性，科学家需要理解数据在特征空间不同方向上的变异程度。何种方案可满足上述需求？"}, "option": [{"option_text": {"zhcn": "运用SageMaker Data Wrangler的多重共线性检测功能，通过方差膨胀系数（VIF）指标来量化变量间的关联程度。VIF分值越高，表明自变量之间的线性相关性越强。", "enus": "Use the SageMaker Data Wrangler multicollinearity measurement features with a variance inflation factor (VIF) score. Use the VIF score as a measurement of how closely the variables are related to each other."}, "option_flag": false}, {"option_text": {"zhcn": "利用SageMaker Data Wrangler的数据质量与洞察报告快速模型可视化功能，可预估基于当前数据训练的模型预期质量。", "enus": "Use the SageMaker Data Wrangler Data Quality and Insights Report quick model visualization to estimate the expected quality of a model that is trained on the data."}, "option_flag": false}, {"option_text": {"zhcn": "运用SageMaker Data Wrangler的多重共线性检测功能，结合主成分分析（PCA）算法，可构建包含全部预测变量的特征空间。", "enus": "Use the SageMaker Data Wrangler multicollinearity measurement features with the principal component analysis (PCA) algorithm to provide a feature space that includes all of the predictor variables."}, "option_flag": true}, {"option_text": {"zhcn": "使用SageMaker Data Wrangler的数据质量与洞察报告功能，可依据特征变量的预测能力对其进行评估分析。", "enus": "Use the SageMaker Data Wrangler Data Quality and Insights Report feature to review features by their predictive power."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "364", "question": {"enus": "A business to business (B2B) ecommerce company wants to develop a fair and equitable risk mitigation strategy to reject potentially fraudulent transactions. The company wants to reject fraudulent transactions despite the possibility of losing some profitable transactions or customers. Which solution will meet these requirements with the LEAST operational effort? ", "zhcn": "一家企业间电子商务公司希望制定一套公平合理的风险管控策略，用以拦截潜在欺诈交易。即便可能损失部分盈利性交易或客户，该公司仍坚持拒绝欺诈交易。在满足上述要求的前提下，何种方案能以最小的运营成本实现这一目标？"}, "option": [{"option_text": {"zhcn": "利用Amazon SageMaker，仅对公司过往销售过的产品交易予以批准。", "enus": "Use Amazon SageMaker to approve transactions only for products the company has sold in the past."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker，基于客户数据训练定制化的欺诈检测模型。", "enus": "Use Amazon SageMaker to train a custom fraud detection model based on customer data."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊欺诈检测预测接口，可对系统识别出的可疑活动进行自动化审核，及时拦截欺诈行为。", "enus": "Use the Amazon Fraud Detector prediction API to approve or deny any activities that Fraud Detector identifies as fraudulent."}, "option_flag": true}, {"option_text": {"zhcn": "利用Amazon Fraud Detector预测API识别潜在欺诈行为，以便企业能够及时核查并拦截欺诈交易。", "enus": "Use the Amazon Fraud Detector prediction API to identify potentially fraudulent activities so the company can review the activities and reject fraudulent transactions."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "365", "question": {"enus": "A data scientist needs to develop a model to detect fraud. The data scientist has less data for fraudulent transactions than for legitimate transactions. The data scientist needs to check for bias in the model before finalizing the model. The data scientist needs to develop the model quickly. Which solution will meet these requirements with the LEAST operational overhead? ", "zhcn": "数据科学家需要开发一个欺诈检测模型。目前掌握的欺诈交易数据量远少于正常交易数据。在模型定型前，数据科学家必须进行偏差检验，同时还需快速完成模型开发。哪种解决方案能以最小的运维成本满足这些要求？"}, "option": [{"option_text": {"zhcn": "在亚马逊EMR中运用合成少数类过采样技术（SMOTE）处理并消减数据偏差，通过亚马逊SageMaker Studio Classic进行模型开发，并借助亚马逊增强型人工智能服务（Amazon A2I）在模型定稿前完成偏差检测。", "enus": "Process and reduce bias by using the synthetic minority oversampling technique (SMOTE) in Amazon EMR. Use Amazon SageMaker Studio Classic to develop the model. Use Amazon Augmented Al (Amazon A2I) to check the model for bias before finalizing the model."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon EMR中运用合成少数类过采样技术（SMOTE）处理并消减数据偏差，继而通过Amazon SageMaker Clarify进行模型开发。在模型定稿前，可借助Amazon Augmented AI（Amazon A2I）对模型进行偏差校验，以确保其公正性。", "enus": "Process and reduce bias by using the synthetic minority oversampling technique (SMOTE) in Amazon EMR. Use Amazon SageMaker Clarify to develop the model. Use Amazon Augmented AI (Amazon A2I) to check the model for bias before finalizing the model."}, "option_flag": false}, {"option_text": {"zhcn": "在Amazon SageMaker Studio中运用合成少数类过采样技术（SMOTE）处理并消减数据偏差。通过Amazon SageMaker JumpStart构建模型框架，并借助Amazon SageMaker Clarify在模型定型前进行偏差检测，确保模型输出的公正性。", "enus": "Process and reduce bias by using the synthetic minority oversampling technique (SMOTE) in Amazon SageMaker Studio. Use Amazon SageMaker JumpStart to develop the model. Use Amazon SageMaker Clarify to check the model for bias before finalizing the model."}, "option_flag": true}, {"option_text": {"zhcn": "通过亚马逊SageMaker Studio笔记本实现偏见处理与消减，借助亚马逊SageMaker JumpStart进行模型开发，并在模型定稿前使用亚马逊SageMaker Model Monitor进行偏见检测。", "enus": "Process and reduce bias by using an Amazon SageMaker Studio notebook. Use Amazon SageMaker JumpStart to develop the model. Use Amazon SageMaker Model Monitor to check the model for bias before finalizing the model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "366", "question": {"enus": "A company has 2,000 retail stores. The company needs to develop a new model to predict demand based on holidays and weather conditions. The model must predict demand in each geographic area where the retail stores are located. Before deploying the newly developed model, the company wants to test the model for 2 to 3 days. The model needs to be robust enough to adapt to supply chain and retail store requirements. Which combination of steps should the company take to meet these requirements with the LEAST operational overhead? (Choose two.) ", "zhcn": "一家企业拥有2000家零售门店，现需开发新型预测模型，将节假日与天气状况纳入需求预测考量。该模型须针对每家门店所在区域进行精准需求预测。在正式部署前，企业计划对模型进行2至3天的测试，且模型需具备足够灵活性以适应供应链与门店运营需求。请问以下哪两项措施组合能以最低运营成本满足上述需求？（请选择两项）"}, "option": [{"option_text": {"zhcn": "采用亚马逊 Forecast Prophet 模型进行建模。", "enus": "Develop the model by using the Amazon Forecast Prophet model."}, "option_flag": false}, {"option_text": {"zhcn": "运用亚马逊预测的节假日特征化处理与天气指数来构建该模型。", "enus": "Develop the model by using the Amazon Forecast holidays featurization and weather index."}, "option_flag": true}, {"option_text": {"zhcn": "采用金丝雀部署策略，通过亚马逊SageMaker与AWS Step Functions服务实现模型部署。", "enus": "Deploy the model by using a canary strategy that uses Amazon SageMaker and AWS Step Functions."}, "option_flag": true}, {"option_text": {"zhcn": "采用亚马逊SageMaker流水线进行A/B测试，实现模型部署。", "enus": "Deploy the model by using an A/B testing strategy that uses Amazon SageMaker Pipelines."}, "option_flag": false}, {"option_text": {"zhcn": "采用亚马逊SageMaker与AWS Step Functions服务，通过A/B测试策略部署模型。流量分配比例为BC版本67%，BE版本33%。", "enus": "Deploy the model by using an A/B testing strategy that uses Amazon SageMaker and AWS Step Functions.  BC (67%)  BE (33%)"}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "BC"}, {"id": "367", "question": {"enus": "A finance company has collected stock return data for 5,000 publicly traded companies. A financial analyst has a dataset that contains 2,000 attributes for each company. The financial analyst wants to use Amazon SageMaker to identify the top 15 attributes that are most valuable to predict future stock returns. Which solution will meet these requirements with the LEAST operational overhead? ", "zhcn": "一家金融公司已收集了5000家上市企业的股票回报数据。某金融分析师掌握的数据集包含每家企业的2000项特征属性。该分析师希望借助Amazon SageMaker甄选出对未来股票回报预测最具价值的15项核心属性。在满足需求的前提下，哪种解决方案能最大限度降低运维复杂度？"}, "option": [{"option_text": {"zhcn": "在 SageMaker 中运用线性学习器算法训练线性回归模型，以预测股票收益率。通过按系数绝对值大小进行排序，识别出最具预测力的特征。", "enus": "Use the linear leaner algorithm in SageMaker to train a linear regression model to predict the stock returns. Identify the most predictive features by ranking absolute coefficient values."}, "option_flag": false}, {"option_text": {"zhcn": "在SageMaker中运用随机森林回归算法训练模型，用以预测股票收益率。根据基尼重要性评分，筛选出最具预测力的特征变量。", "enus": "Use random forest regression in SageMaker to train a model to predict the stock returns. Identify the most predictive features based on Gini importance scores."}, "option_flag": false}, {"option_text": {"zhcn": "利用亚马逊SageMaker数据整理器的快速模型可视化功能预测股票收益，并根据快速模式的特征重要性评分识别最具预测力的特征。", "enus": "Use an Amazon SageMaker Data Wrangler quick model visualization to predict the stock returns. Identify the most predictive features based on the quick mode's feature importance scores."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker Autopilot构建回归模型以预测股票收益，并通过Amazon SageMaker Clarify报告识别最具预测性的特征。", "enus": "Use Amazon SageMaker Autopilot to build a regression model to predict the stock returns. Identify the most predictive features based on an Amazon SageMaker Clarify report."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "368", "question": {"enus": "An ecommerce company is hosting a web application on Amazon EC2 instances to handle continuously changing customer demand. The EC2 instances are part of an Auto Scaling group. The company wants to implement a solution to distribute traffic from customers to the EC2 instances. The company must encrypt all traffic at all stages between the customers and the application servers. No decryption at intermediate points is allowed. Which solution will meet these requirements? ", "zhcn": "一家电商公司将其网络应用程序部署于亚马逊EC2实例之上，以应对持续波动的客户需求。这些EC2实例隶属于自动扩展组。该公司需要实施一套解决方案，将客户流量分发至各个EC2实例，且必须确保客户与应用服务器之间所有传输阶段的数据全程加密，禁止在中间节点进行解密。下列哪种方案符合这些要求？"}, "option": [{"option_text": {"zhcn": "创建应用型负载均衡器（ALB），并为该负载均衡器配置HTTPS监听器。", "enus": "Create an Application Load Balancer (ALB). Add an HTTPS listener to the AL"}, "option_flag": false}, {"option_text": {"zhcn": "将自动扩缩组配置为向ALB目标组注册实例。  \nB. 创建Amazon CloudFront分发服务。使用自定义SSL/TLS证书配置该分发，并将自动扩缩组设置为分发的源站。", "enus": "Configure the Auto Scaling group to register instances with the ALB's target group.  B. Create an Amazon CloudFront distribution. Configure the distribution with a custom SSL/TLS certificate. Set the Auto Scaling group as the distribution's origin."}, "option_flag": false}, {"option_text": {"zhcn": "创建网络负载均衡器（NLB）。为该负载均衡器添加TCP监听器。将自动扩展组配置为向NLB目标组注册实例。高票采纳方案。", "enus": "Create a Network Load Balancer (NLB). Add a TCP listener to the NLB. Configure the Auto Scaling group to register instances with the NLB's target group. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "创建网关负载均衡器（GLB）。配置自动扩展组，将实例注册至GLB的目标组。", "enus": "Create a Gateway Load Balancer (GLB). Configure the Auto Scaling group to register instances with the GLB's target group."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "C"}, {"id": "369", "question": {"enus": "A company has two on-premises data center locations. There is a company-managed router at each data center. Each data center has a dedicated AWS Direct Connect connection to a Direct Connect gateway through a private virtual interface. The router for the first location is advertising 110 routes to the Direct Connect gateway by using BGP, and the router for the second location is advertising 60 routes to the Direct Connect gateway by using BGP. The Direct Connect gateway is attached to a company VPC through a virtual private gateway. A network engineer receives reports that resources in the VPC are not reachable from various locations in either data center. The network engineer checks the VPC route table and sees that the routes from the first data center location are not being populated into the route table. The network engineer must resolve this issue in the most operationally efficient manner. What should the network engineer do to meet these requirements? ", "zhcn": "某公司拥有两处本地数据中心站点，每个站点均部署了由公司自主管理的路由器。各数据中心通过专用虚拟接口，经由独立的AWS Direct Connect链路连接至Direct Connect网关。第一处站点的路由器通过BGP协议向Direct Connect网关通告了110条路由，第二处站点则通告了60条路由。该Direct Connect网关通过虚拟私有网关与公司VPC相连。网络工程师接报称，两处数据中心内多个位置均无法访问VPC中的资源。经检查VPC路由表，工程师发现第一处数据中心的路由条目未正常注入路由表。当前需以最高操作效率解决此问题，网络工程师应采取何种措施？"}, "option": [{"option_text": {"zhcn": "移除直连网关，并在每台企业路由器与VPC的虚拟私有网关之间创建新的私有虚拟接口。", "enus": "Remove the Direct Connect gateway, and create a new private virtual interface from each company router to the virtual private gateway of the VPC."}, "option_flag": false}, {"option_text": {"zhcn": "调整路由器配置以汇总通告路由。最高票选方案。", "enus": "Change the router configurations to summarize the advertised routes. Most Voted"}, "option_flag": true}, {"option_text": {"zhcn": "请提交支持工单以提升通告至VPC路由表的路由配额上限。", "enus": "Open a support ticket to increase the quota on advertised routes to the VPC route table."}, "option_flag": false}, {"option_text": {"zhcn": "创建AWS Transit Gateway，将其连接至VPC，并将Direct Connect网关接入该中转网关。", "enus": "Create an AWS Transit Gateway. Attach the transit gateway to the VPC, and connect the Direct Connect gateway to the transit gateway."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}]