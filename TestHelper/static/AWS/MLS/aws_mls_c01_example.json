[{"id": "1", "question": {"enus": "A large mobile network operating company is building a machine learning model to predict customers who are likely to unsubscribe from the service. The company plans to offer an incentive for these customers as the cost of churn is far greater than the cost of the incentive. The model produces the following confusion matrix after evaluating on a test dataset of 100 customers: Based on the model evaluation results, why is this a viable model for production? ", "zhcn": "一家大型移动网络运营商正构建机器学习模型，以预测可能取消服务订阅的客户。鉴于客户流失的成本远高于激励措施的成本，该公司计划为这些客户提供激励。该模型在对100名客户的测试数据集进行评估后，生成了如下混淆矩阵：基于模型评估结果，为何该模型是适用于生产环境的可行方案？"}, "option": [{"option_text": {"zhcn": "模型准确率达86%，且公司因假阴性所承担的成本低于假阳性。", "enus": "The model is 86% accurate and the cost incurred by the company as a result of false negatives is less than the false positives."}, "option_flag": true}, {"option_text": {"zhcn": "该模型的precision为86%，低于其accuracy。", "enus": "The precision of the model is 86%, which is less than the accuracy of the model."}, "option_flag": false}, {"option_text": {"zhcn": "模型准确率达86%，且公司因假阳性产生的成本低于因假阴性产生的成本。", "enus": "The model is 86% accurate and the cost incurred by the company as a result of false positives is less than the false negatives."}, "option_flag": false}, {"option_text": {"zhcn": "该模型的precision为86%，高于其accuracy。", "enus": "The precision of the model is 86%, which is greater than the accuracy of the model."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "2", "question": {"enus": "A Machine Learning Specialist is designing a system for improving sales for a company. The objective is to use the large amount of information the company has on users' behavior and product preferences to predict which products users would like based on the users' similarity to other users. What should the Specialist do to meet this objective? ", "zhcn": "一位机器学习专家正为某家公司设计一套旨在提升销售业绩的系统。该目标在于，借助公司所掌握的海量用户行为数据与产品偏好信息，通过分析用户与其他用户的相似性，预测用户可能青睐的产品。那么，专家应如何实现这一目标呢？"}, "option": [{"option_text": {"zhcn": "使用Apache Spark ML在Amazon EMR上构建基于内容的过滤推荐引擎", "enus": "Build a content-based filtering recommendation engine with Apache Spark ML on Amazon EMR"}, "option_flag": false}, {"option_text": {"zhcn": "使用Apache Spark ML在Amazon EMR上构建协同过滤推荐引擎。", "enus": "Build a collaborative filtering recommendation engine with Apache Spark ML on Amazon EMR."}, "option_flag": true}, {"option_text": {"zhcn": "使用Apache Spark ML在Amazon EMR上构建基于模型的过滤推荐引擎", "enus": "Build a model-based filtering recommendation engine with Apache Spark ML on Amazon EMR"}, "option_flag": false}, {"option_text": {"zhcn": "\n基于Apache Spark ML在Amazon EMR上构建组合过滤推荐引擎", "enus": "Build a combinative filtering recommendation engine with Apache Spark ML on Amazon EMR"}, "option_flag": false}], "analysis": {"enus": "Many developers want to implement the famous Amazon model that was used to power the People who bought this also bought these items feature on Amazon.com. This model is based on a method called Collaborative Filtering. It takes items such as movies, books, and products that were rated highly by a set of users and recommending them to other users who also gave them high ratings. This method works well in domains where explicit ratings or implicit user actions can be gathered and analyzed. Reference: https://aws.amazon.com/blogs/big-data/building-a-recommendation-engine-with-spark-ml-on-amazon-emr-using-zeppelin/", "zhcn": ""}, "answer": "B"}, {"id": "3", "question": {"enus": "A Mobile Network Operator is building an analytics platform to analyze and optimize a company's operations using Amazon Athena and Amazon S3. The source systems send data in .CSV format in real time. The Data Engineering team wants to transform the data to the Apache Parquet format before storing it on Amazon S3. Which solution takes the LEAST effort to implement? ", "zhcn": "\n一家移动网络运营商正利用Amazon Athena和Amazon S3构建分析平台，以分析和优化公司运营。源系统实时以.CSV格式发送数据，数据工程团队希望在将数据存储到Amazon S3之前，将其转换为Apache Parquet格式。那么，哪种方案实现起来最省力？"}, "option": [{"option_text": {"zhcn": "在Amazon EC2实例上使用Apache Kafka Streams导入CSV数据，并借助Kafka Connect S3将数据序列化为Parquet格式。", "enus": "Ingest .CSV data using Apache Kafka Streams on Amazon EC2 instances and use Kafka Connect S3 to serialize data as Parquet"}, "option_flag": false}, {"option_text": {"zhcn": "\n从Amazon Kinesis Data Streams摄入CSV数据，并使用Amazon Glue将其转换为Parquet格式。", "enus": "Ingest .CSV data from Amazon Kinesis Data Streams and use Amazon Glue to convert data into Parquet."}, "option_flag": true}, {"option_text": {"zhcn": "在Amazon EMR集群中使用Apache Spark结构化流导入CSV数据，并借助Apache Spark将数据转换为Parquet格式。", "enus": "Ingest .CSV data using Apache Spark Structured Streaming in an Amazon EMR cluster and use Apache Spark to convert data into  Parquet."}, "option_flag": false}, {"option_text": {"zhcn": "\n从Amazon Kinesis Data Streams接入CSV数据，并借助Amazon Kinesis Data Firehose将其转换为Parquet格式。", "enus": "Ingest .CSV data from Amazon Kinesis Data Streams and use Amazon Kinesis Data Firehose to convert data into Parquet."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "4", "question": {"enus": "A city wants to monitor its air quality to address the consequences of air pollution. A Machine Learning Specialist needs to forecast the air quality in parts per million of contaminates for the next 2 days in the city. As this is a prototype, only daily data from the last year is available. Which model is MOST likely to provide the best results in Amazon SageMaker? ", "zhcn": "某市希望监测空气质量，以应对空气污染带来的后果。机器学习专家需要预测该市未来两天的空气质量，具体为污染物的百万分比浓度。由于这是一个原型项目，目前仅有过去一年的每日数据可用。在Amazon SageMaker中，哪种模型最有可能提供最佳结果？"}, "option": [{"option_text": {"zhcn": "在由全年数据构成的单个时间序列上，使用Amazon SageMaker的k-近邻（kNN）算法，并将预测器类型设置为回归器。", "enus": "Use the Amazon SageMaker k-Nearest-Neighbors (kNN) algorithm on the single time series consisting of the full year of data with a  predictor_type of regressor."}, "option_flag": false}, {"option_text": {"zhcn": "将Amazon SageMaker随机切割森林（RCF）应用于包含全年数据的单个时间序列。", "enus": "Use Amazon SageMaker Random Cut Forest (RCF) on the single time series consisting of the full year of data."}, "option_flag": false}, {"option_text": {"zhcn": "将Amazon SageMaker Linear Learner算法应用于由全年数据构成的单一时间序列，预测器类型为回归器。", "enus": "Use the Amazon SageMaker Linear Learner algorithm on the single time series consisting of the full year of data with a predictor_type  of regressor."}, "option_flag": true}, {"option_text": {"zhcn": "使用Amazon SageMaker Linear Learner算法，针对由全年数据构成的单一时间序列，并将预测器类型指定为分类器。", "enus": "Use the Amazon SageMaker Linear Learner algorithm on the single time series consisting of the full year of data with a predictor_type  of classifier."}, "option_flag": false}], "analysis": {"enus": "Reference: https://aws.amazon.com/blogs/machine-learning/build-a-model-to-predict-the-impact-of-weather-on-urban-air-quality-using-amazon- sagemaker/? ref=Welcome.AI", "zhcn": ""}, "answer": "C"}, {"id": "5", "question": {"enus": "A Data Engineer needs to build a model using a dataset containing customer credit card information How can the Data Engineer ensure the data remains encrypted and the credit card information is secure? ", "zhcn": "数据工程师需要使用包含客户信用卡信息的数据集构建模型，如何确保数据保持加密状态，且信用卡信息得到安全保障？"}, "option": [{"option_text": {"zhcn": "通过自定义加密算法对数据进行加密，并将数据存储在VPC中的Amazon SageMaker实例上。利用SageMaker DeepAR算法对信用卡号码进行随机化处理。", "enus": "Use a custom encryption algorithm to encrypt the data and store the data on an Amazon SageMaker instance in a VPC. Use the  SageMaker DeepAR algorithm to randomize the credit card numbers."}, "option_flag": false}, {"option_text": {"zhcn": "使用IAM策略对Amazon S3存储桶和Amazon Kinesis中的数据进行加密，自动丢弃信用卡号并插入虚假信用卡号。", "enus": "Use an IAM policy to encrypt the data on the Amazon S3 bucket and Amazon Kinesis to automatically discard credit card numbers and  insert fake credit card numbers."}, "option_flag": false}, {"option_text": {"zhcn": "利用Amazon SageMaker启动配置，在数据被复制到VPC中的SageMaker实例后对其进行加密；采用SageMaker主成分分析（PCA）算法，精简信用卡号码的长度。", "enus": "Use an Amazon SageMaker launch configuration to encrypt the data once it is copied to the SageMaker instance in a VPC. Use the  SageMaker principal component analysis (PCA) algorithm to reduce the length of the credit card numbers."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS KMS对Amazon S3和Amazon SageMaker上的数据进行加密，并借助AWS Glue对客户数据中的信用卡号进行脱敏处理。", "enus": "Use AWS KMS to encrypt the data on Amazon S3 and Amazon SageMaker, and redact the credit card numbers from the customer data  with AWS Glue."}, "option_flag": true}], "analysis": {"enus": "", "zhcn": ""}, "answer": "D"}, {"id": "6", "question": {"enus": "A Machine Learning Specialist is using an Amazon SageMaker notebook instance in a private subnet of a corporate VPC. The ML Specialist has important data stored on the Amazon SageMaker notebook instance's Amazon EBS volume, and needs to take a snapshot of that EBS volume. However, the ML Specialist cannot find the Amazon SageMaker notebook instance's EBS volume or Amazon EC2 instance within the VPC. Why is the ML Specialist not seeing the instance visible in the VPC? ", "zhcn": "\n一位机器学习专家正在企业VPC的私有子网中使用一个Amazon SageMaker笔记本实例。该机器学习专家的重要数据存储在Amazon SageMaker笔记本实例的Amazon EBS卷上，故需要为该EBS卷创建快照。然而，该机器学习专家在VPC内既找不到Amazon SageMaker笔记本实例的EBS卷，也找不到其对应的Amazon EC2实例。为何该机器学习专家在VPC中看不到该实例？"}, "option": [{"option_text": {"zhcn": "\nAmazon SageMaker notebook instances基于客户账户内的EC2实例，但它们运行在VPC之外。", "enus": "Amazon SageMaker notebook instances are based on the EC2 instances within the customer account, but they run outside of VPCs."}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker notebook 实例构建于客户账户内的 Amazon ECS 服务之上。", "enus": "Amazon SageMaker notebook instances are based on the Amazon ECS service within customer accounts."}, "option_flag": false}, {"option_text": {"zhcn": "Amazon SageMaker 笔记本实例基于运行在 AWS 服务账户内的 EC2 实例构建而成。", "enus": "Amazon SageMaker notebook instances are based on EC2 instances running within AWS service accounts."}, "option_flag": true}, {"option_text": {"zhcn": "Amazon SageMaker notebook 实例基于运行在AWS服务账户内的ECS实例构建而成。", "enus": "Amazon SageMaker notebook instances are based on AWS ECS instances running within AWS service accounts."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html", "zhcn": ""}, "answer": "C"}, {"id": "7", "question": {"enus": "A Machine Learning Specialist is building a model that will perform time series forecasting using Amazon SageMaker. The Specialist has finished training the model and is now planning to perform load testing on the endpoint so they can configure Auto Scaling for the model variant. Which approach will allow the Specialist to review the latency, memory utilization, and CPU utilization during the load test? ", "zhcn": "一位机器学习专家正在构建一个利用Amazon SageMaker进行时间序列预测的模型。模型训练完成后，该专家计划对终端节点进行负载测试，以便为模型变体配置自动扩缩容功能。若要在此次负载测试中同步监测延迟、内存利用率及CPU利用率指标，应采用以下哪种方案？"}, "option": [{"option_text": {"zhcn": "借助Amazon Athena与Amazon QuickSight，可实时分析写入Amazon S3的SageMaker日志，并在日志生成过程中实现可视化呈现。", "enus": "Review SageMaker logs that have been written to Amazon S3 by leveraging Amazon Athena and Amazon QuickSight to visualize logs as  they are being produced."}, "option_flag": false}, {"option_text": {"zhcn": "为集中展示亚马逊SageMaker输出的延迟、内存利用率和CPU利用率指标，请生成亚马逊CloudWatch监控看板。", "enus": "Generate an Amazon CloudWatch dashboard to create a single view for the latency, memory utilization, and CPU utilization metrics that  are outputted by Amazon SageMaker."}, "option_flag": true}, {"option_text": {"zhcn": "构建自定义的Amazon CloudWatch日志组，随后运用Amazon ES与Kibana平台，在Amazon SageMaker生成日志数据的同时即可进行实时查询与可视化呈现。", "enus": "Build custom Amazon CloudWatch Logs and then leverage Amazon ES and Kibana to query and visualize the log data as it is generated  by Amazon SageMaker."}, "option_flag": false}, {"option_text": {"zhcn": "将亚马逊SageMaker生成的亚马逊云监控日志发送至亚马逊ES服务，并借助Kibana对日志数据进行查询与可视化分析。", "enus": "Send Amazon CloudWatch Logs that were generated by Amazon SageMaker to Amazon ES and use Kibana to query and visualize the  log data."}, "option_flag": false}], "analysis": {"enus": "Reference: https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html", "zhcn": ""}, "answer": "B"}, {"id": "8", "question": {"enus": "A manufacturing company has structured and unstructured data stored in an Amazon S3 bucket. A Machine Learning Specialist wants to use SQL to run queries on this data. Which solution requires the LEAST effort to be able to query this data? ", "zhcn": "一家制造公司将其结构化与非结构化数据存储于亚马逊S3存储桶中。机器学习专家需使用SQL语言对此数据进行查询。若要实现数据查询，何种解决方案所需投入精力最少？"}, "option": [{"option_text": {"zhcn": "借助AWS Data Pipeline对数据进行转换处理，并运用Amazon RDS执行查询操作。", "enus": "Use AWS Data Pipeline to transform the data and Amazon RDS to run queries."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue进行数据编目，再通过Amazon Athena执行查询。", "enus": "Use AWS Glue to catalogue the data and Amazon Athena to run queries."}, "option_flag": true}, {"option_text": {"zhcn": "利用AWS Batch对数据进行ETL处理，并通过Amazon Aurora执行查询操作。", "enus": "Use AWS Batch to run ETL on the data and Amazon Aurora to run the queries."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Lambda进行数据转换，并通过Amazon Kinesis Data Analytics执行查询分析。", "enus": "Use AWS Lambda to transform the data and Amazon Kinesis Data Analytics to run queries."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}, {"id": "9", "question": {"enus": "A Machine Learning Specialist is developing a custom video recommendation model for an application. The dataset used to train this model is very large with millions of data points and is hosted in an Amazon S3 bucket. The Specialist wants to avoid loading all of this data onto an Amazon SageMaker notebook instance because it would take hours to move and will exceed the attached 5 GB Amazon EBS volume on the notebook instance. Which approach allows the Specialist to use all the data to train the model? ", "zhcn": "一位机器学习专家正在为某应用程序开发定制化视频推荐模型。训练模型所用的数据集包含数百万个数据点，规模极为庞大，目前存储于亚马逊S3存储桶中。由于将所有数据加载到亚马逊SageMaker笔记本实例需耗时数小时，且会超出该实例附加的5GB亚马逊EBS存储容量，专家希望避免此操作。请问采用何种方法可确保专家能够使用全部数据完成模型训练？"}, "option": [{"option_text": {"zhcn": "将数据集的较小子集载入SageMaker笔记本并在本地进行训练。验证训练代码能否正常执行，并确认模型参数设置合理。随后使用S3存储桶中的完整数据集，通过Pipe输入模式启动SageMaker训练任务。", "enus": "Load a smaller subset of the data into the SageMaker notebook and train locally. Confirm that the training code is executing and the  model parameters seem reasonable. Initiate a SageMaker training job using the full dataset from the S3 bucket using Pipe input mode."}, "option_flag": true}, {"option_text": {"zhcn": "在AWS深度学习AMI上启动一台Amazon EC2实例，并将S3存储桶挂载至该实例。先使用少量数据进行训练，以验证训练代码与超参数配置是否恰当。随后返回Amazon SageMaker平台，利用完整数据集完成模型训练。", "enus": "Launch an Amazon EC2 instance with an AWS Deep Learning AMI and attach the S3 bucket to the instance. Train on a small amount of  the data to verify the training code and hyperparameters. Go back to Amazon SageMaker and train using the full dataset"}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS Glue对数据的小规模样本进行模型训练，以验证数据与Amazon SageMaker的兼容性。随后通过Pipe输入模式，调用S3存储桶中的完整数据集启动SageMaker训练任务。", "enus": "Use AWS Glue to train a model using a small subset of the data to confirm that the data will be compatible with Amazon SageMaker.  Initiate a SageMaker training job using the full dataset from the S3 bucket using Pipe input mode."}, "option_flag": false}, {"option_text": {"zhcn": "将数据子集载入SageMaker笔记本进行本地训练，确保代码正常运行且模型参数设置合理。随后启动搭载AWS深度学习镜像的Amazon EC2实例，并挂载S3存储桶以完成全量数据集训练。", "enus": "Load a smaller subset of the data into the SageMaker notebook and train locally. Confirm that the training code is executing and the  model parameters seem reasonable. Launch an Amazon EC2 instance with an AWS Deep Learning AMI and attach the S3 bucket to train  the full dataset."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "A"}, {"id": "10", "question": {"enus": "A Machine Learning Specialist has completed a proof of concept for a company using a small data sample, and now the Specialist is ready to implement an end- to-end solution in AWS using Amazon SageMaker. The historical training data is stored in Amazon RDS. Which approach should the Specialist use for training a model using that data? ", "zhcn": "一位机器学习专家已利用小样本数据为公司完成了概念验证，现准备基于亚马逊SageMaker在AWS平台上部署端到端解决方案。历史训练数据存储于Amazon RDS数据库中，此时专家应采用何种方案利用该数据训练模型？"}, "option": [{"option_text": {"zhcn": "在笔记本中直接连接SQL数据库并导入数据。", "enus": "Write a direct connection to the SQL database within the notebook and pull data in"}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS数据管道将微软SQL Server中的数据推送至Amazon S3，并在笔记本中提供S3存储路径。", "enus": "Push the data from Microsoft SQL Server to Amazon S3 using an AWS Data Pipeline and provide the S3 location within the notebook."}, "option_flag": true}, {"option_text": {"zhcn": "将数据迁移至Amazon DynamoDB，并在笔记本中建立与DynamoDB的连接以获取数据。", "enus": "Move the data to Amazon DynamoDB and set up a connection to DynamoDB within the notebook to pull data in."}, "option_flag": false}, {"option_text": {"zhcn": "利用AWS DMS服务将数据迁移至Amazon ElastiCache，并在笔记本环境中配置连接以快速获取数据。", "enus": "Move the data to Amazon ElastiCache using AWS DMS and set up a connection within the notebook to pull data in for fast access."}, "option_flag": false}], "analysis": {"enus": "", "zhcn": ""}, "answer": "B"}]